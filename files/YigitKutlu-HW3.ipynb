{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IE 582 Statistical Learning for Data Mining - Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "library(readr)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "library(stringr)\n",
    "library(tidyr)\n",
    "library(reshape2)\n",
    "library(glmnet)\n",
    "\n",
    "#read the data\n",
    "\n",
    "data <- read.csv(file = 'RealTimeConsumption.csv', stringsAsFactors= FALSE)\n",
    "# 1st Nov 2020 to 1st Dec 2020 - 31 days = 744hrs so last 744 rows will be test data\n",
    "# data is messy has \",\" as 1000 seperator which messes up everything used gsub to remove \",\" from consumption and convert it to numeric\n",
    "data$Consumption..MWh. =  gsub(\",\", \"\",data$Consumption..MWh., fixed = TRUE)\n",
    "data$Consumption..MWh. = as.numeric(data$Consumption..MWh.)\n",
    "\n",
    "#problems due to daylight savings time shift etc., it is done on sundays, so we will remove the week accordingly. \n",
    "\n",
    "A <- which(data$Consumption..MWh. == 0, arr.ind=TRUE)  # find the day timechange accours\n",
    "data$Date <- as.Date(data$Date,\"%d.%m.%Y\")          #change Date column to \"Date\"\n",
    "high = data$Date[A]                             \n",
    "low = data$Date[A-(24*6)]\n",
    "data = filter(data,data$Date > high | data$Date < low)   #remove the week from the data....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MAPE for lag 48 is 8.06\"\n",
      "[1] \"MAPE for lag 168 is 3.449\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n",
       " 0.00955  1.64348  5.72972  8.06031 10.10699 43.77075 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n",
       " 0.008521  1.335853  2.514032  3.449188  4.548818 19.565225 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len = nrow(data)\n",
    "data_test = data[(len-743):len, ]\n",
    "len_test = nrow(data_test)\n",
    "\n",
    "#get lag data for each day and hour for test period\n",
    "for (i in 1:len_test){\n",
    "    data_test$lag48[i] <- data[(len-(len_test-i+48)),3]\n",
    "                    }\n",
    "\n",
    "for (i in 1:len_test){\n",
    "    data_test$lag168[i] <- data[(len-(len_test-i+168)),3]\n",
    "                    }\n",
    "\n",
    "#calculate the prediction error\n",
    "for (i in 1:len_test){\n",
    "    data_test$error48[i] <- abs((data_test$Consumption..MWh.[i] - data_test$lag48[i])/data_test$Consumption..MWh.[i])*100\n",
    "\n",
    "                    } \n",
    "\n",
    "for (i in 1:len_test){\n",
    "    data_test$error168[i] <- abs((data_test$Consumption..MWh.[i] - data_test$lag168[i])/data_test$Consumption..MWh.[i])*100\n",
    "\n",
    "                    } \n",
    "\n",
    "#calculate the MAPE for each lag selections\n",
    "MAPE48 <- mean(data_test$error48)\n",
    "MAPE168 <- mean(data_test$error168)\n",
    "MAPE48 = signif(MAPE48, digits = 4)\n",
    "MAPE168=signif(MAPE168, digits = 4)\n",
    "\n",
    "A <-paste(\"MAPE for lag 48 is\", MAPE48)\n",
    "B <-paste(\"MAPE for lag 168 is\",MAPE168)\n",
    "print(A)\n",
    "print(B)\n",
    "\n",
    "\n",
    "# for the box plot part we may need MAPE's on hourly selections\n",
    "MAPE48hourly = c()\n",
    "MAPE168hourly =c()\n",
    "for (i in 0:23){\n",
    "    time = paste0(i,\":00\")\n",
    "    filtered = data_test %>% filter(Hour == time)\n",
    "    MAPE48hourly[(i+1)] = mean(filtered$error48)\n",
    "    MAPE168hourly[(i+1)] = mean(filtered$error168)\n",
    "}\n",
    "\n",
    "#the overall error data summary, maybe used in boxplot\n",
    "summary(data_test$error48)\n",
    "summary(data_test$error168)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Comments on Task 1\n",
    "We have better MAPE values for lag 168 than lag 48. Since the weekday / weekend  behaviour will change the consuption values, I expected to get better values for lag168. Consumptions will change between Thursday and Saturday. Same day last week is safer prediction than 2 days ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>1570</dd>\n",
       "\t<dt>lag48</dt>\n",
       "\t\t<dd>0.3086</dd>\n",
       "\t<dt>lag168</dt>\n",
       "\t\t<dd>0.6434</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 1570\n",
       "\\item[lag48] 0.3086\n",
       "\\item[lag168] 0.6434\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   1570lag48\n",
       ":   0.3086lag168\n",
       ":   0.6434\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)       lag48      lag168 \n",
       "  1570.0000      0.3086      0.6434 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MAPE for Linear Regression model using lag 48 and lag 168 is 4.23\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n",
       " 0.004324  1.826045  3.308445  4.229593  5.704970 16.611280 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = data[(169:(len-744)), ]   #train data should not include first 168 hours of data becouse they dont have lag 168 values\n",
    "len_train = nrow(data_train)\n",
    "\n",
    "#get lag data for each day and hour for train period\n",
    "for (i in 1:len_train){\n",
    "    data_train$lag48[i] <- data[((i+168)-48),3]\n",
    "                    }\n",
    "\n",
    "for (i in 1:len_train){\n",
    "    data_train$lag168[i] <- data[i,3]\n",
    "                    }\n",
    "\n",
    "#linear model\n",
    "model <- lm(Consumption..MWh.~lag48+lag168,data_train)\n",
    "\n",
    "data_test$predict = predict.lm(model,data_test)\n",
    "\n",
    "#calculate the prediction error\n",
    "for (i in 1:len_test){\n",
    "    data_test$predicterror[i] <- abs((data_test$Consumption..MWh.[i] - data_test$predict[i])/data_test$Consumption..MWh.[i])*100\n",
    "                    }\n",
    "\n",
    "model$coefficients = signif(model$coefficients, digits = 4)\n",
    "model$coefficients  #print the coefficients and intercept\n",
    "\n",
    "#calculate the MAPE for linear\n",
    "MAPE_LM <- mean(data_test$predicterror)\n",
    "MAPE_LM = signif(MAPE_LM, digits = 4)\n",
    "A <-paste(\"MAPE for Linear Regression model using lag 48 and lag 168 is\",MAPE_LM)\n",
    "print(A)\n",
    "\n",
    "# for the box plot part we may need MAPE's on hourly selections\n",
    "MAPE_LMhourly =c()\n",
    "for (i in 0:23){\n",
    "    time = paste0(i,\":00\")\n",
    "    filtered = data_test %>% filter(Hour == time)\n",
    "    MAPE_LMhourly[(i+1)] = mean(filtered$predicterror)\n",
    "}\n",
    "\n",
    "#the overall error data summary, maybe used in boxplot\n",
    "summary(data_test$predicterror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### Comments on Task2\n",
    "We obtained \"1570\" as intercept value and coefficients for lag48 and lag 168 obtained as \"0.3086\" and \"0.6434\" repectively. The weight of lag168 data is almost the double of the lag48 as expected. We have obtained better results for lag168 prediction in previous section, so I was expecting to get higher coefficient for lag168. But the fact that using only lag168 values for prediction than the linear model using both lag48 and lag168 gives better MAPE value suprises me. On the other hand, we are forcing the model to include a higher error data so it seems normal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Intercept of the Linear Model for hour 0 is 2208\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 0 is 0.4871\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 0 is 0.4421\"\n",
      "[1] \"Intercept of the Linear Model for hour 1 is 2137\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 1 is 0.4922\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 1 is 0.4356\"\n",
      "[1] \"Intercept of the Linear Model for hour 2 is 2212\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 2 is 0.4972\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 2 is 0.4252\"\n",
      "[1] \"Intercept of the Linear Model for hour 3 is 2243\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 3 is 0.4928\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 3 is 0.4265\"\n",
      "[1] \"Intercept of the Linear Model for hour 4 is 2214\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 4 is 0.4747\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 4 is 0.4446\"\n",
      "[1] \"Intercept of the Linear Model for hour 5 is 2235\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 5 is 0.4397\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 5 is 0.4782\"\n",
      "[1] \"Intercept of the Linear Model for hour 6 is 2139\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 6 is 0.3758\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 6 is 0.546\"\n",
      "[1] \"Intercept of the Linear Model for hour 7 is 2319\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 7 is 0.2668\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 7 is 0.6521\"\n",
      "[1] \"Intercept of the Linear Model for hour 8 is 3241\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 8 is 0.1741\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 8 is 0.7249\"\n",
      "[1] \"Intercept of the Linear Model for hour 9 is 3603\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 9 is 0.1747\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 9 is 0.7201\"\n",
      "[1] \"Intercept of the Linear Model for hour 10 is 3747\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 10 is 0.2066\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 10 is 0.6864\"\n",
      "[1] \"Intercept of the Linear Model for hour 11 is 3966\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 11 is 0.2252\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 11 is 0.6632\"\n",
      "[1] \"Intercept of the Linear Model for hour 12 is 3671\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 12 is 0.2802\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 12 is 0.6129\"\n",
      "[1] \"Intercept of the Linear Model for hour 13 is 3815\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 13 is 0.3037\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 13 is 0.5864\"\n",
      "[1] \"Intercept of the Linear Model for hour 14 is 4078\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 14 is 0.2598\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 14 is 0.6252\"\n",
      "[1] \"Intercept of the Linear Model for hour 15 is 3963\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 15 is 0.2565\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 15 is 0.6315\"\n",
      "[1] \"Intercept of the Linear Model for hour 16 is 3830\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 16 is 0.2473\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 16 is 0.6451\"\n",
      "[1] \"Intercept of the Linear Model for hour 17 is 3408\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 17 is 0.2625\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 17 is 0.6422\"\n",
      "[1] \"Intercept of the Linear Model for hour 18 is 3036\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 18 is 0.3351\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 18 is 0.5801\"\n",
      "[1] \"Intercept of the Linear Model for hour 19 is 3177\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 19 is 0.3872\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 19 is 0.5244\"\n",
      "[1] \"Intercept of the Linear Model for hour 20 is 2797\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 20 is 0.4076\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 20 is 0.5144\"\n",
      "[1] \"Intercept of the Linear Model for hour 21 is 2674\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 21 is 0.4285\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 21 is 0.4955\"\n",
      "[1] \"Intercept of the Linear Model for hour 22 is 2839\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 22 is 0.442\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 22 is 0.4757\"\n",
      "[1] \"Intercept of the Linear Model for hour 23 is 2556\"\n",
      "[1] \"Coefficient of lag48 for the Linear Model of hour 23 is 0.4505\"\n",
      "[1] \"Coefficient of lag168 for the Linear Model of hour 23 is 0.4722\"\n",
      "[1] \"MAPE of hour 0 for using Linear Model is  3.264\"\n",
      "[1] \"MAPE of hour 1 for using Linear Model is  3.285\"\n",
      "[1] \"MAPE of hour 2 for using Linear Model is  3.42\"\n",
      "[1] \"MAPE of hour 3 for using Linear Model is  3.202\"\n",
      "[1] \"MAPE of hour 4 for using Linear Model is  3.184\"\n",
      "[1] \"MAPE of hour 5 for using Linear Model is  3.19\"\n",
      "[1] \"MAPE of hour 6 for using Linear Model is  3.146\"\n",
      "[1] \"MAPE of hour 7 for using Linear Model is  3.776\"\n",
      "[1] \"MAPE of hour 8 for using Linear Model is  4.678\"\n",
      "[1] \"MAPE of hour 9 for using Linear Model is  5.489\"\n",
      "[1] \"MAPE of hour 10 for using Linear Model is  6.089\"\n",
      "[1] \"MAPE of hour 11 for using Linear Model is  6.276\"\n",
      "[1] \"MAPE of hour 12 for using Linear Model is  6.545\"\n",
      "[1] \"MAPE of hour 13 for using Linear Model is  6.686\"\n",
      "[1] \"MAPE of hour 14 for using Linear Model is  6.483\"\n",
      "[1] \"MAPE of hour 15 for using Linear Model is  6.085\"\n",
      "[1] \"MAPE of hour 16 for using Linear Model is  5.148\"\n",
      "[1] \"MAPE of hour 17 for using Linear Model is  4.613\"\n",
      "[1] \"MAPE of hour 18 for using Linear Model is  3.744\"\n",
      "[1] \"MAPE of hour 19 for using Linear Model is  3.435\"\n",
      "[1] \"MAPE of hour 20 for using Linear Model is  3.164\"\n",
      "[1] \"MAPE of hour 21 for using Linear Model is  3.169\"\n",
      "[1] \"MAPE of hour 22 for using Linear Model is  3.166\"\n",
      "[1] \"MAPE of hour 23 for using Linear Model is  3.385\"\n",
      "[1] \"Overall mean MAPE value for using Linear Model is  4.359\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       " 0.0625  2.1872  3.7350  4.3593  5.9177 16.5750 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for hourly based analysis \"for\" loop is used. Needed matrixes defined beforehand.\n",
    "daily_pred = matrix(0,31,24)\n",
    "lm_error = matrix(0,31,24)\n",
    "MAPE_hr_lm = c()\n",
    "coefs = c()\n",
    "for (i in 1:24){\n",
    "    k = (i-1)\n",
    "    time = paste0(k,\":00\")\n",
    "    filtered = data_train %>% filter(Hour == time)\n",
    "    filtered_test = data_test %>% filter(Hour == time)\n",
    "    model <- lm(Consumption..MWh.~lag48+lag168,filtered)\n",
    "    # I wanted to report the coefficients & intercept value for the each model but it is long!\n",
    "    model$coefficients <- signif(model$coefficients, digits = 4)\n",
    "    int <-paste(\"Intercept of the Linear Model for hour\", (i-1), \"is\", model$coefficients[1])\n",
    "    coef1 <-paste(\"Coefficient of lag48 for the Linear Model of hour\", (i-1), \"is\", model$coefficients[2])\n",
    "    coef2 <-paste(\"Coefficient of lag168 for the Linear Model of hour\", (i-1), \"is\", model$coefficients[3])\n",
    "    print(int)\n",
    "    print(coef1)\n",
    "    print(coef2)\n",
    "    lm_predict = predict.lm(model,filtered_test)\n",
    "    lm_predict = data.frame(lm_predict)\n",
    "    n = nrow(lm_predict)\n",
    "    # we need the predicted values, I keep them in a new matrix, easy to calculate error\n",
    "    for (j in 1:n){\n",
    "        daily_pred[j,i] = lm_predict[j,1]\n",
    "        lm_error[j,i] = abs((filtered_test$Consumption..MWh.[j]-daily_pred[j,i])/filtered_test$Consumption..MWh.[j])*100\n",
    "    }\n",
    "    # I could calculate MAPE for each hourly model...\n",
    "    MAPE_hr_lm[i] = mean(lm_error[,i])\n",
    "    \n",
    "}\n",
    "\n",
    "MAPE_hr_lm = signif(MAPE_hr_lm, digits = 4)\n",
    "\n",
    "for (i in 1:24){\n",
    "    B <-paste(\"For Linear Model of hour\", (i-1), \"intercept \",MAPE_hr_lm[i])\n",
    "    A <-paste(\"MAPE of hour\", (i-1), \"for using Linear Model is \",MAPE_hr_lm[i])\n",
    "    print(A)\n",
    "    }\n",
    "\n",
    "MAPE_hr_lm_mean <- mean(MAPE_hr_lm)\n",
    "MAPE_hr_lm_mean = signif(MAPE_hr_lm_mean, digits = 4)\n",
    "\n",
    "A <-paste(\"Overall mean MAPE value for using Linear Model is \",MAPE_hr_lm_mean)\n",
    "print(A)\n",
    "\n",
    "#obtaining the overall error data for each hour & day to give summary and use in boxplot? \n",
    "lm_error_ovr <- melt(lm_error)\n",
    "colnames(lm_error_ovr) <- c(\"Hour\",\"Day\",\"Error\")\n",
    "summary(lm_error_ovr$Error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comments on Task3\n",
    "First of all I wanted to include the coeeficients for each model but it is a bit long so I am sorry for that. What I observed is that, during the daylight hours weight of the lag48 and lag168 differs wheras, during night time they are close to each other. So, that may mean that night time consumptions does not have weakly seasonalities (importance of data from 2 days ago and 7 days ago is almost equal) but for the daylight time consumption last weeks data have more importance. On the other hand, I observed a higher MAPE values (worse predictions) for the daylight hours than the nightime hours. I would sugggest using the 7 days ago same hour and 14 days ago same hour data for daylight hours especially. Also using last weeks same day last month's same day data and last year's same day data can be beneficial. (Last month may not work due to months having different day counts!?)  Our mean MAPE value for using hourly linear models is worse than the overall linear model which I did not expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MAPE of hour 0 for using Lasso Model is  1.436\"\n",
      "[1] \"MAPE of hour 1 for using Lasso Model is  1.552\"\n",
      "[1] \"MAPE of hour 2 for using Lasso Model is  4.11\"\n",
      "[1] \"MAPE of hour 3 for using Lasso Model is  4.366\"\n",
      "[1] \"MAPE of hour 4 for using Lasso Model is  4.666\"\n",
      "[1] \"MAPE of hour 5 for using Lasso Model is  4.533\"\n",
      "[1] \"MAPE of hour 6 for using Lasso Model is  4.336\"\n",
      "[1] \"MAPE of hour 7 for using Lasso Model is  3.828\"\n",
      "[1] \"MAPE of hour 8 for using Lasso Model is  2.935\"\n",
      "[1] \"MAPE of hour 9 for using Lasso Model is  2.038\"\n",
      "[1] \"MAPE of hour 10 for using Lasso Model is  1.681\"\n",
      "[1] \"MAPE of hour 11 for using Lasso Model is  1.587\"\n",
      "[1] \"MAPE of hour 12 for using Lasso Model is  1.497\"\n",
      "[1] \"MAPE of hour 13 for using Lasso Model is  1.621\"\n",
      "[1] \"MAPE of hour 14 for using Lasso Model is  1.713\"\n",
      "[1] \"MAPE of hour 15 for using Lasso Model is  1.562\"\n",
      "[1] \"MAPE of hour 16 for using Lasso Model is  1.83\"\n",
      "[1] \"MAPE of hour 17 for using Lasso Model is  1.412\"\n",
      "[1] \"MAPE of hour 18 for using Lasso Model is  1.506\"\n",
      "[1] \"MAPE of hour 19 for using Lasso Model is  1.43\"\n",
      "[1] \"MAPE of hour 20 for using Lasso Model is  1.747\"\n",
      "[1] \"MAPE of hour 21 for using Lasso Model is  1.839\"\n",
      "[1] \"MAPE of hour 22 for using Lasso Model is  2.583\"\n",
      "[1] \"MAPE of hour 23 for using Lasso Model is  3.626\"\n",
      "[1] \"Overall mean MAPE value for using Lasso Model is  2.476\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n",
       " 0.004159  0.787189  1.699064  2.476421  3.258726 12.977982 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train2 = data_train # I did not want to change the data that much but it seems unneccesery now - maybe not?\n",
    "\n",
    "# Converting the long data to wide data...\n",
    "# I will use a \"for\" loop again for that instead of creating 24 different matrixes for consumption I added them to wide data\n",
    "Lag_48hourly = dcast(data_train2, Date ~ Hour, sum, value.var = \"lag48\" )\n",
    "colnames(Lag_48hourly) <- c(\"Date\",paste0(\"Lag48_hour_\", 0:23))\n",
    "Lag_168hourly = dcast(data_train2, Date ~ Hour, sum, value.var = \"lag168\" )\n",
    "colnames(Lag_168hourly) <- c(\"Date\",paste0(\"Lag168_hour_\", 0:23))\n",
    "Consump_hourly = dcast(data_train2, Date ~ Hour, sum, value.var = \"Consumption..MWh.\" )\n",
    "colnames(Consump_hourly) <- c(\"Date\",paste0(\"Consump_hour_\", 0:23))\n",
    "\n",
    "new_train <- cbind(Lag_48hourly, Lag_168hourly[,2:25], Consump_hourly[,2:25])\n",
    "\n",
    "#same process for the test period\n",
    "data_test2 = data_test\n",
    "Lag_48hourly_test = dcast(data_test2, Date ~ Hour, sum, value.var = \"lag48\" )\n",
    "colnames(Lag_48hourly_test) <- c(\"Date\",paste0(\"Lag48_hour_\", 0:23))\n",
    "Lag_168hourly_test = dcast(data_test2, Date ~ Hour, sum, value.var = \"lag168\" )\n",
    "colnames(Lag_168hourly_test) <- c(\"Date\",paste0(\"Lag168_hour_\", 0:23))\n",
    "Consump_hourly_test = dcast(data_test2, Date ~ Hour, sum, value.var = \"Consumption..MWh.\" )\n",
    "colnames(Consump_hourly_test) <- c(\"Date\",paste0(\"Consump_hour_\", 0:23))\n",
    "\n",
    "new_test <- cbind(Lag_48hourly_test, Lag_168hourly_test[,2:25], Consump_hourly_test[,2:25])\n",
    "\n",
    "#lasso prediction in \"for\" loop for each hour, defined the matrixes needed first used \"best(min) lambda\" for prediction\n",
    "x =  as.matrix(new_train[,2:49])\n",
    "x_test =  as.matrix(new_test[,2:49])\n",
    "lasso = c()\n",
    "lasso_pred = matrix(0,31,24)\n",
    "error_lasso = matrix(0,31,24)\n",
    "mape_lasso = c()\n",
    "for (i in 1:24){\n",
    "    set.seed(636) # it is used to get same lambda values for each time we run the code.\n",
    "    y = new_train[,49+i]\n",
    "    y_test = new_test[,49+i]\n",
    "    y = as.matrix(y)\n",
    "    lasso_model = cv.glmnet(x, y, type.measure=\"mse\", family=\"gaussian\", nfolds = 10)\n",
    "    lambda_best = lasso_model$lambda.min\n",
    "    lasso_best = glmnet(x, y, alpha =1, lambda = lambda_best)\n",
    "    lasso = predict(lasso_best,  s=lambda_best, newx = x_test)\n",
    "    len_test =nrow(x_test)\n",
    "    #again need the predictions so I keep them in a new matrix \n",
    "    for (j in 1:len_test){\n",
    "        lasso_pred[j,i] = lasso[j,1]\n",
    "        error_lasso[j,i] = abs((y_test[j]-lasso_pred[j,i])/y_test[j])*100\n",
    "    }\n",
    "    mape_lasso[i] = mean(error_lasso[,i])\n",
    "    \n",
    "}\n",
    "\n",
    "mape_lasso = signif(mape_lasso, digits = 4)\n",
    "for (i in 1:24){\n",
    "    A <-paste(\"MAPE of hour\", (i-1), \"for using Lasso Model is \",mape_lasso[i])\n",
    "    print(A)\n",
    "    }\n",
    "\n",
    "mape_lasso_mean <- mean(mape_lasso)\n",
    "mape_lasso_mean = signif(mape_lasso_mean, digits = 4)\n",
    "A <-paste(\"Overall mean MAPE value for using Lasso Model is \",mape_lasso_mean)\n",
    "print(A)\n",
    "\n",
    "#obtaining the overall error data for each hour & day to give summary and use in boxplot? \n",
    "lasso_error_ovr <- melt(error_lasso)\n",
    "colnames(lasso_error_ovr) <- c(\"Hour\",\"Day\",\"Error\")\n",
    "summary(lasso_error_ovr$Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comments on Task 4\n",
    "\n",
    "When we use Lasso Model with minimum lambda, we obtained better MAPE values for many hours. For the time period 3 to 7 our linear model gives slightly better results. But overall, using Lasso Model decreases prediction errors. In the Lasso prediction we used 48 variables, instead of 2 (used in linear model), so it may have effect on results. I dont know if it is possible to use same 48 variables for linear model, but for comperasion it would be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the boxplot part I plotted the MAPEs converted the lag48 lag168 and linear model to hourly MAPEs\n",
    "#In order to plot them together with hourly based model. \n",
    "#I think we should plot the errors as box plot which will give us means etc. So I ploted 2 boxplots, hourly MAPEs and errors\n",
    "\n",
    "MAPES_hourly <- cbind (MAPE48hourly, MAPE168hourly, MAPE_LMhourly, MAPE_hr_lm, mape_lasso)\n",
    "colnames(MAPES_hourly) <- c(\"Lag48\",\"Lag168\",\"Linear\" , \"Hourly Linear\" , \"Lasso\")\n",
    "OVR_Error <- cbind(data_test$error48, data_test$error168, data_test$predicterror, lm_error_ovr$Error, lasso_error_ovr$Error)\n",
    "colnames(OVR_Error) <- c(\"Lag48\",\"Lag168\",\"Linear\" , \"Hourly Linear\" , \"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\n/gHTWvLczZxGNwAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Hourly MAPEs\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nAEECBBAkQABBAgQQJEAAQQIE/AP9mDgDONDcpgAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Individual Errors for Each Model\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(MAPES_hourly, main= \"Hourly MAPEs\", ylab = \"MAPE\")\n",
    "boxplot(OVR_Error, main= \"Individual Errors for Each Model\", ylab = \"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comments on Task6\n",
    "I did not quite understand if I should plot the errors or MAPE values. In order to plot the MAPE value I converted all models to hourly MAPEs to obtain uniformity. Observing each prediction's error is also nice so I plotted the second figure too. We observe lots of outliers in each model but all in all each model has MAPE value smaller than 10. Overall, Lasso prediction gives the lowest MAPE value which is a more complicated model than the others and it is expected to obtain better results in the Lasso Model. Our worse model is Lag48 data which only predicts the two days ago same hour consumption data as prediction and it is not a good vay (especially due to weekend/weekday difference). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

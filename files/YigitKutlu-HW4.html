<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Untitled</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; }
td.linenos pre { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
span.linenos { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
td.linenos pre.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
/*!

Copyright 2015-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-top:0;
  margin-bottom:10px; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  line-height:40px;
  font-size:36px; }

h2.bp3-heading, .bp3-running-text h2{
  line-height:32px;
  font-size:28px; }

h3.bp3-heading, .bp3-running-text h3{
  line-height:25px;
  font-size:22px; }

h4.bp3-heading, .bp3-running-text h4{
  line-height:21px;
  font-size:18px; }

h5.bp3-heading, .bp3-running-text h5{
  line-height:19px;
  font-size:16px; }

h6.bp3-heading, .bp3-running-text h6{
  line-height:16px;
  font-size:14px; }
.bp3-ui-text{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400; }

.bp3-monospace-text{
  text-transform:none;
  font-family:monospace; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  line-height:1.5;
  font-size:14px; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    margin:20px 0;
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15); }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  text-decoration:none;
  color:#106ba3; }
  a:hover{
    cursor:pointer;
    text-decoration:underline;
    color:#106ba3; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  text-transform:none;
  font-family:monospace;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  background:rgba(255, 255, 255, 0.7);
  padding:2px 5px;
  color:#5c7080;
  font-size:smaller; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  text-transform:none;
  font-family:monospace;
  display:block;
  margin:10px 0;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  background:rgba(255, 255, 255, 0.7);
  padding:13px 15px 12px;
  line-height:1.4;
  color:#182026;
  font-size:13px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    padding:0;
    color:inherit;
    font-size:inherit; }

.bp3-running-text kbd, .bp3-key{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  min-width:24px;
  height:24px;
  padding:3px 6px;
  vertical-align:middle;
  line-height:24px;
  color:#5c7080;
  font-family:inherit;
  font-size:12px; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    background:#394b59;
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  margin:0 0 10px;
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  margin:0;
  padding:0;
  list-style:none; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    margin-top:0;
    margin-right:20px;
    font-size:40px; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  margin:0;
  cursor:default;
  height:30px;
  padding:0;
  list-style:none; }
  .bp3-breadcrumbs > li{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }
    .bp3-breadcrumbs > li::after{
      display:block;
      margin:0 5px;
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 0 0-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 0 0 1.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      width:16px;
      height:16px;
      content:""; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    vertical-align:baseline;
    font-size:inherit;
    font-weight:inherit; }

.bp3-breadcrumbs-collapsed{
  margin-right:2px;
  border:none;
  border-radius:3px;
  background:#ced9e0;
  cursor:pointer;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    display:block;
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    width:16px;
    height:16px;
    content:""; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    text-decoration:none;
    color:#182026; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  min-width:30px;
  min-height:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#106ba3; }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0e5a8a;
      background-image:none; }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#0d8050; }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0a6640;
      background-image:none; }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#bf7326; }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a66321;
      background-image:none; }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#c23030; }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a82a2a;
      background-image:none; }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-width:40px;
    min-height:40px;
    padding:5px 15px;
    font-size:16px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      position:absolute;
      margin:0; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-image:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button.bp3-minimal:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:-1px;
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-button-group.bp3-minimal .bp3-button{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      width:unset;
      height:100%; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  line-height:1.5;
  font-size:14px;
  position:relative;
  border-radius:3px;
  background-color:rgba(138, 155, 168, 0.15);
  width:100%;
  padding:10px 12px 9px; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout .bp3-heading{
    margin-top:0;
    margin-bottom:5px;
    line-height:20px; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  background-color:#ffffff;
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
    background-color:#30404d; }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  opacity:0.9;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  margin:5px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }

.bp3-dialog{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ebf1f5;
  width:500px;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#293742;
    color:#f5f8fa; }

.bp3-dialog-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  background:#ffffff;
  min-height:40px;
  padding-right:5px;
  padding-left:20px; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
    background:#30404d; }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  margin:20px;
  line-height:18px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-drawer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    top:0;
    right:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-bottom{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-left{
    top:0;
    bottom:0;
    left:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-right{
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#30404d;
    color:#f5f8fa; }

.bp3-drawer-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  min-height:40px;
  padding:5px;
  padding-left:20px; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  overflow:auto;
  line-height:18px; }

.bp3-drawer-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  padding:10px 20px; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  display:inline-block;
  position:relative;
  cursor:text;
  max-width:100%;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    position:absolute;
    top:-3px;
    right:-3px;
    bottom:-3px;
    left:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  display:inherit;
  position:relative;
  min-width:inherit;
  max-width:inherit;
  vertical-align:top;
  text-transform:inherit;
  letter-spacing:inherit;
  color:inherit;
  font:inherit;
  resize:none; }

.bp3-editable-text-input{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  width:100%;
  padding:0;
  white-space:pre-wrap; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    position:absolute;
    left:0;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    z-index:2;
    border-radius:inherit; }
    .bp3-control-group .bp3-input:focus{
      z-index:14;
      border-radius:3px; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    z-index:4;
    border-radius:inherit; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:-1px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    margin-right:0;
    border-radius:0 3px 3px 0; }
  .bp3-control-group > :only-child{
    margin-right:0;
    border-radius:3px; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      margin-top:0;
      border-radius:3px 3px 0 0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  display:block;
  position:relative;
  margin-bottom:10px;
  cursor:pointer;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    position:absolute;
    top:0;
    left:0;
    opacity:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    display:inline-block;
    position:relative;
    margin-top:-3px;
    margin-right:10px;
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    cursor:pointer;
    width:1em;
    height:1em;
    vertical-align:middle;
    font-size:16px;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none; }
    .bp3-control .bp3-control-indicator::before{
      display:block;
      width:1em;
      height:1em;
      content:""; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#d8e1e8; }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-top:1px;
    margin-left:10px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 0 0-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0 0 12 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    width:auto;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      position:absolute;
      left:0;
      margin:2px;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      background:#ffffff;
      width:calc(1em - 4px);
      height:calc(1em - 4px);
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background:#394b59; }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    text-align:center;
    font-size:0.7em; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    visibility:hidden;
    margin-right:1.2em;
    margin-left:0.5em;
    line-height:0; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    visibility:visible;
    margin-right:0.5em;
    margin-left:1.2em;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    visibility:visible;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    visibility:hidden;
    line-height:0; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0)); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background:#202b33; }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  display:inline-block;
  position:relative;
  cursor:pointer;
  height:30px; }
  .bp3-file-input input{
    opacity:0;
    margin:0;
    min-width:200px; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(206, 217, 224, 0.5);
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6);
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        outline:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        cursor:not-allowed;
        color:rgba(92, 112, 128, 0.6); }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:rgba(57, 75, 89, 0.5);
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          -webkit-box-shadow:none;
                  box-shadow:none;
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  position:absolute;
  top:0;
  right:0;
  left:0;
  padding-right:80px;
  color:rgba(92, 112, 128, 0.6);
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-file-upload-input::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026;
    min-width:24px;
    min-height:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    position:absolute;
    top:0;
    right:0;
    margin:3px;
    border-radius:3px;
    width:70px;
    text-align:center;
    line-height:24px;
    content:"Browse"; }
    .bp3-file-upload-input::after:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-file-upload-input:active::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-large .bp3-file-upload-input{
    height:40px;
    line-height:40px;
    font-size:16px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-width:30px;
      min-height:30px;
      margin:5px;
      width:85px;
      line-height:30px; }
  .bp3-dark .bp3-file-upload-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
        background-color:#30404d; }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
        background-color:#202b33;
        background-image:none; }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-file-upload-input:active::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }

.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    margin-top:5px;
    color:#5c7080;
    font-size:12px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      margin:0 10px 0 0;
      line-height:40px; }
    .bp3-form-group.bp3-inline label.bp3-label{
      margin:0 10px 0 0;
      line-height:30px; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-width:24px;
    min-height:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-icon{
    z-index:1;
    color:#5c7080; }
    .bp3-input-group > .bp3-icon:empty{
      line-height:1;
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-width:30px;
    min-height:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none; }
  .bp3-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-input.bp3-large{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-top:0;
  margin-bottom:15px; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    width:100%;
    vertical-align:top;
    font-weight:400; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  width:30px;
  min-height:0;
  padding:0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  border-radius:3px;
  width:100%;
  height:30px;
  padding:0 25px 0 10px;
  -moz-appearance:none;
  -webkit-appearance:none; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(167, 182, 194, 0.3);
    text-decoration:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(115, 134, 148, 0.3);
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  height:40px;
  padding-right:35px;
  font-size:16px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#202b33;
    background-image:none; }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:rgba(206, 217, 224, 0.5);
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  position:absolute;
  top:7px;
  right:7px;
  color:#5c7080;
  pointer-events:none; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  position:relative;
  vertical-align:middle;
  letter-spacing:normal; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    top:12px;
    right:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    vertical-align:top;
    text-align:left; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-top:6px;
  padding-bottom:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(92, 112, 128, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
    -webkit-box-shadow:none;
            box-shadow:none; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(92, 112, 128, 0.3);
  cursor:pointer; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  top:40px;
  padding-bottom:0; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-right:0;
  margin-left:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  line-height:1;
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  line-height:1;
  font-family:"Icons20";
  font-size:inherit;
  font-weight:400;
  font-style:normal; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  margin:0;
  border-radius:3px;
  background:#ffffff;
  min-width:180px;
  padding:5px;
  list-style:none;
  text-align:left;
  color:#182026; }

.bp3-menu-divider{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  padding:5px 7px;
  text-decoration:none;
  line-height:20px;
  color:inherit;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    margin-top:2px;
    color:#5c7080; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    outline:none !important;
    background-color:inherit !important;
    cursor:not-allowed !important;
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    padding:9px 7px;
    line-height:22px;
    font-size:16px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-top:1px;
      margin-right:10px; }

button.bp3-menu-item{
  border:none;
  background:none;
  width:100%;
  text-align:left; }
.bp3-menu-header{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    margin:0;
    padding:10px 7px 0 1px;
    line-height:17px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    padding-top:15px;
    padding-bottom:5px;
    font-size:18px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item.bp3-intent-primary{
  color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
    color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
    background-color:#137cbd; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
    background-color:#106ba3; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-success{
  color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
    color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
    background-color:#0f9960; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:active{
    background-color:#0d8050; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-warning{
  color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
    color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
    background-color:#d9822b; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
    background-color:#bf7326; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-danger{
  color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
    color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
    background-color:#db3737; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
    background-color:#c23030; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item::before,
.bp3-dark .bp3-menu-item > .bp3-icon{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item .bp3-menu-item-label{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
  background-color:rgba(138, 155, 168, 0.3); }

.bp3-dark .bp3-menu-item.bp3-disabled{
  color:rgba(167, 182, 194, 0.6) !important; }
  .bp3-dark .bp3-menu-item.bp3-disabled::before,
  .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
  .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
    color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  position:relative;
  z-index:10;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:100%;
  height:50px;
  padding:0 15px; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    position:fixed;
    top:0;
    right:0;
    left:0; }

.bp3-navbar-heading{
  margin-right:15px;
  font-size:16px; }

.bp3-navbar-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  margin:0 10px;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  height:100%;
  text-align:center; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  position:static;
  top:0;
  right:0;
  bottom:0;
  left:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    position:fixed;
    overflow:hidden; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    position:fixed;
    overflow:auto; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  position:fixed;
  top:0;
  right:0;
  bottom:0;
  left:0;
  opacity:1;
  z-index:20;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  position:relative;
  overflow:hidden; }

.bp3-panel-stack-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  z-index:1;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  height:30px; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  position:absolute;
  top:0;
  right:0;
  bottom:0;
  left:0;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  background-color:#ffffff;
  overflow-y:auto; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  display:inline-block;
  z-index:20;
  border-radius:3px; }
  .bp3-popover .bp3-popover-arrow{
    position:absolute;
    width:30px;
    height:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      margin:5px;
      width:20px;
      height:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-top:-17px;
    margin-bottom:17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-right:17px;
    margin-left:-17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover .bp3-popover-content{
    position:relative;
    border-radius:3px; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg);
  border-radius:2px;
  content:""; }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  position:absolute;
  top:0;
  right:0;
  left:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  display:block;
  position:relative;
  border-radius:40px;
  background:rgba(92, 112, 128, 0.2);
  width:100%;
  height:8px;
  overflow:hidden; }
  .bp3-progress-bar .bp3-progress-meter{
    position:absolute;
    border-radius:40px;
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    width:100%;
    height:100%;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  cursor:default;
  color:transparent !important;
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  width:100%;
  min-width:150px;
  height:40px;
  position:relative;
  outline:none;
  cursor:default;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    opacity:0.5;
    cursor:not-allowed; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  top:5px;
  right:0;
  left:0;
  height:6px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  position:absolute;
  top:0;
  left:0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  width:16px;
  height:16px; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5;
    z-index:2;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab; }
  .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#bfccd6;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#5c7080; }
  .bp3-slider-handle .bp3-slider-label{
    margin-left:8px;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    background:#394b59;
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      background:#e1e8ed;
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    margin-left:8px;
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  position:absolute;
  padding:2px 5px;
  vertical-align:top;
  line-height:1;
  font-size:12px; }

.bp3-slider.bp3-vertical{
  width:40px;
  min-width:40px;
  height:150px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:0;
    bottom:0;
    left:5px;
    width:6px;
    height:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-top:-8px;
      margin-left:0; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      margin-left:0;
      width:16px;
      height:8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-top-left-radius:0;
      border-bottom-right-radius:3px; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      margin-bottom:8px;
      border-top-left-radius:3px;
      border-bottom-left-radius:0;
      border-bottom-right-radius:0; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round; }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      width:100%;
      padding:0 10px; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(19, 124, 189, 0.2); }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      top:0;
      right:0;
      bottom:0;
      left:0;
      border-radius:3px;
      background-color:rgba(19, 124, 189, 0.2);
      height:auto; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  position:relative;
  margin:0;
  border:none;
  padding:0;
  list-style:none; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  cursor:pointer;
  max-width:100%;
  vertical-align:top;
  line-height:30px;
  color:#182026;
  font-size:14px; }
  .bp3-tab a{
    display:block;
    text-decoration:none;
    color:inherit; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    background-color:transparent !important; }
  .bp3-tab[aria-disabled="true"]{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    line-height:40px;
    font-size:16px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  position:absolute;
  top:0;
  left:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
  pointer-events:none; }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    position:absolute;
    right:0;
    bottom:0;
    left:0;
    background-color:#106ba3;
    height:3px; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:#5c7080;
  min-width:20px;
  max-width:100%;
  min-height:20px;
  padding:2px 6px;
  line-height:16px;
  color:#f5f8fa;
  font-size:12px; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-right:8px;
    padding-left:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    min-width:30px;
    min-height:30px;
    padding:0 10px;
    line-height:20px;
    font-size:14px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-right:12px;
      padding-left:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  opacity:0.5;
  margin-top:-2px;
  margin-right:-6px !important;
  margin-bottom:-2px;
  border:none;
  background:none;
  cursor:pointer;
  padding:2px;
  padding-left:0;
  color:inherit; }
  .bp3-tag-remove:hover{
    opacity:0.8;
    background:none;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:5px;
    padding-left:0; }
    .bp3-large .bp3-tag-remove:empty::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  min-height:30px;
  padding-right:0;
  padding-left:5px;
  line-height:inherit; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    margin-top:7px;
    margin-right:7px;
    margin-left:2px;
    color:#5c7080; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    margin-top:5px;
    margin-right:7px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:80px;
    line-height:20px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-top:10px;
      margin-left:5px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-width:30px;
      min-height:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  position:relative !important;
  margin:20px 0 0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  min-width:300px;
  max-width:500px;
  pointer-events:all; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:50ms;
            transition-delay:50ms; }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    margin:12px;
    margin-right:0;
    color:#5c7080; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
    background-color:#394b59; }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:fixed;
  right:0;
  left:0;
  z-index:40;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0;
    bottom:auto; }
  .bp3-toast-container.bp3-toast-container-bottom{
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto;
    bottom:0; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    position:absolute;
    width:22px;
    height:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      margin:4px;
      width:14px;
      height:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-top:-11px;
    margin-bottom:11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-right:11px;
    margin-left:-11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  margin:0;
  padding-left:0;
  list-style:none; }

.bp3-tree-root{
  position:relative;
  background-color:transparent;
  cursor:default;
  padding-left:0; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  width:100%;
  height:30px;
  padding-right:5px; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  cursor:pointer;
  padding:7px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  position:relative;
  margin-right:7px; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
/*!

Copyright 2017-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  top:20vh;
  left:calc(50% - 250px);
  z-index:21;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:500px; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar .bp3-input{
    border-radius:0;
    background-color:transparent; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    background-color:transparent;
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzkiIGhlaWdodD0iNTEiIHZpZXdCb3g9IjAgMCAzOSA1MSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSgtMTYzOCAtMjI4MSkiPgogICAgPGcgY2xhc3M9ImpwLWljb24td2FybjAiIGZpbGw9IiNGMzc3MjYiPgogICAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxNjM5Ljc0IDIzMTEuOTgpIiBkPSJNIDE4LjI2NDYgNy4xMzQxMUMgMTAuNDE0NSA3LjEzNDExIDMuNTU4NzIgNC4yNTc2IDAgMEMgMS4zMjUzOSAzLjgyMDQgMy43OTU1NiA3LjEzMDgxIDcuMDY4NiA5LjQ3MzAzQyAxMC4zNDE3IDExLjgxNTIgMTQuMjU1NyAxMy4wNzM0IDE4LjI2OSAxMy4wNzM0QyAyMi4yODIzIDEzLjA3MzQgMjYuMTk2MyAxMS44MTUyIDI5LjQ2OTQgOS40NzMwM0MgMzIuNzQyNCA3LjEzMDgxIDM1LjIxMjYgMy44MjA0IDM2LjUzOCAwQyAzMi45NzA1IDQuMjU3NiAyNi4xMTQ4IDcuMTM0MTEgMTguMjY0NiA3LjEzNDExWiIvPgogICAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxNjM5LjczIDIyODUuNDgpIiBkPSJNIDE4LjI3MzMgNS45MzkzMUMgMjYuMTIzNSA1LjkzOTMxIDMyLjk3OTMgOC44MTU4MyAzNi41MzggMTMuMDczNEMgMzUuMjEyNiA5LjI1MzAzIDMyLjc0MjQgNS45NDI2MiAyOS40Njk0IDMuNjAwNEMgMjYuMTk2MyAxLjI1ODE4IDIyLjI4MjMgMCAxOC4yNjkgMEMgMTQuMjU1NyAwIDEwLjM0MTcgMS4yNTgxOCA3LjA2ODYgMy42MDA0QyAzLjc5NTU2IDUuOTQyNjIgMS4zMjUzOSA5LjI1MzAzIDAgMTMuMDczNEMgMy41Njc0NSA4LjgyNDYzIDEwLjQyMzIgNS45MzkzMSAxOC4yNzMzIDUuOTM5MzFaIi8+CiAgICA8L2c+CiAgICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxNjY5LjMgMjI4MS4zMSkiIGQ9Ik0gNS44OTM1MyAyLjg0NEMgNS45MTg4OSAzLjQzMTY1IDUuNzcwODUgNC4wMTM2NyA1LjQ2ODE1IDQuNTE2NDVDIDUuMTY1NDUgNS4wMTkyMiA0LjcyMTY4IDUuNDIwMTUgNC4xOTI5OSA1LjY2ODUxQyAzLjY2NDMgNS45MTY4OCAzLjA3NDQ0IDYuMDAxNTEgMi40OTgwNSA1LjkxMTcxQyAxLjkyMTY2IDUuODIxOSAxLjM4NDYzIDUuNTYxNyAwLjk1NDg5OCA1LjE2NDAxQyAwLjUyNTE3IDQuNzY2MzMgMC4yMjIwNTYgNC4yNDkwMyAwLjA4MzkwMzcgMy42Nzc1N0MgLTAuMDU0MjQ4MyAzLjEwNjExIC0wLjAyMTIzIDIuNTA2MTcgMC4xNzg3ODEgMS45NTM2NEMgMC4zNzg3OTMgMS40MDExIDAuNzM2ODA5IDAuOTIwODE3IDEuMjA3NTQgMC41NzM1MzhDIDEuNjc4MjYgMC4yMjYyNTkgMi4yNDA1NSAwLjAyNzU5MTkgMi44MjMyNiAwLjAwMjY3MjI5QyAzLjYwMzg5IC0wLjAzMDcxMTUgNC4zNjU3MyAwLjI0OTc4OSA0Ljk0MTQyIDAuNzgyNTUxQyA1LjUxNzExIDEuMzE1MzEgNS44NTk1NiAyLjA1Njc2IDUuODkzNTMgMi44NDRaIi8+CiAgICAgIDxwYXRoIHRyYW5zZm9ybT0idHJhbnNsYXRlKDE2MzkuOCAyMzIzLjgxKSIgZD0iTSA3LjQyNzg5IDMuNTgzMzhDIDcuNDYwMDggNC4zMjQzIDcuMjczNTUgNS4wNTgxOSA2Ljg5MTkzIDUuNjkyMTNDIDYuNTEwMzEgNi4zMjYwNyA1Ljk1MDc1IDYuODMxNTYgNS4yODQxMSA3LjE0NDZDIDQuNjE3NDcgNy40NTc2MyAzLjg3MzcxIDcuNTY0MTQgMy4xNDcwMiA3LjQ1MDYzQyAyLjQyMDMyIDcuMzM3MTIgMS43NDMzNiA3LjAwODcgMS4yMDE4NCA2LjUwNjk1QyAwLjY2MDMyOCA2LjAwNTIgMC4yNzg2MSA1LjM1MjY4IDAuMTA1MDE3IDQuNjMyMDJDIC0wLjA2ODU3NTcgMy45MTEzNSAtMC4wMjYyMzYxIDMuMTU0OTQgMC4yMjY2NzUgMi40NTg1NkMgMC40Nzk1ODcgMS43NjIxNyAwLjkzMTY5NyAxLjE1NzEzIDEuNTI1NzYgMC43MjAwMzNDIDIuMTE5ODMgMC4yODI5MzUgMi44MjkxNCAwLjAzMzQzOTUgMy41NjM4OSAwLjAwMzEzMzQ0QyA0LjU0NjY3IC0wLjAzNzQwMzMgNS41MDUyOSAwLjMxNjcwNiA2LjIyOTYxIDAuOTg3ODM1QyA2Ljk1MzkzIDEuNjU4OTYgNy4zODQ4NCAyLjU5MjM1IDcuNDI3ODkgMy41ODMzOEwgNy40Mjc4OSAzLjU4MzM4WiIvPgogICAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxNjM4LjM2IDIyODYuMDYpIiBkPSJNIDIuMjc0NzEgNC4zOTYyOUMgMS44NDM2MyA0LjQxNTA4IDEuNDE2NzEgNC4zMDQ0NSAxLjA0Nzk5IDQuMDc4NDNDIDAuNjc5MjY4IDMuODUyNCAwLjM4NTMyOCAzLjUyMTE0IDAuMjAzMzcxIDMuMTI2NTZDIDAuMDIxNDEzNiAyLjczMTk4IC0wLjA0MDM3OTggMi4yOTE4MyAwLjAyNTgxMTYgMS44NjE4MUMgMC4wOTIwMDMxIDEuNDMxOCAwLjI4MzIwNCAxLjAzMTI2IDAuNTc1MjEzIDAuNzEwODgzQyAwLjg2NzIyMiAwLjM5MDUxIDEuMjQ2OTEgMC4xNjQ3MDggMS42NjYyMiAwLjA2MjA1OTJDIDIuMDg1NTMgLTAuMDQwNTg5NyAyLjUyNTYxIC0wLjAxNTQ3MTQgMi45MzA3NiAwLjEzNDIzNUMgMy4zMzU5MSAwLjI4Mzk0MSAzLjY4NzkyIDAuNTUxNTA1IDMuOTQyMjIgMC45MDMwNkMgNC4xOTY1MiAxLjI1NDYyIDQuMzQxNjkgMS42NzQzNiA0LjM1OTM1IDIuMTA5MTZDIDQuMzgyOTkgMi42OTEwNyA0LjE3Njc4IDMuMjU4NjkgMy43ODU5NyAzLjY4NzQ2QyAzLjM5NTE2IDQuMTE2MjQgMi44NTE2NiA0LjM3MTE2IDIuMjc0NzEgNC4zOTYyOUwgMi4yNzQ3MSA0LjM5NjI5WiIvPgogICAgPC9nPgogIDwvZz4+Cjwvc3ZnPgo=);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

:root {
  --jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
}

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.lm-CommandPalette-wrapper::after {
  content: ' ';
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  height: 30px;
  width: 10px;
  padding: 0px 10px;
  background-image: var(--jp-icon-search-white);
  background-size: 20px;
  background-repeat: no-repeat;
  background-position: center;
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color3);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item.lm-mod-active {
  background: var(--jp-layout-color3);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  background: var(--jp-layout-color4);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.4;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

.jp-Dialog-header {
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 30px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -30px; margin-right: -30px;
  padding-bottom: 30px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 30px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -30px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*
  Name:       material
  Author:     Mattia Astorino (http://github.com/equinusocio)
  Website:    https://material-theme.site/
*/

.cm-s-material.CodeMirror {
  background-color: #263238;
  color: #EEFFFF;
}

.cm-s-material .CodeMirror-gutters {
  background: #263238;
  color: #546E7A;
  border: none;
}

.cm-s-material .CodeMirror-guttermarker,
.cm-s-material .CodeMirror-guttermarker-subtle,
.cm-s-material .CodeMirror-linenumber {
  color: #546E7A;
}

.cm-s-material .CodeMirror-cursor {
  border-left: 1px solid #FFCC00;
}

.cm-s-material div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material.CodeMirror-focused div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::selection,
.cm-s-material .CodeMirror-line>span::selection,
.cm-s-material .CodeMirror-line>span>span::selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::-moz-selection,
.cm-s-material .CodeMirror-line>span::-moz-selection,
.cm-s-material .CodeMirror-line>span>span::-moz-selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.5);
}

.cm-s-material .cm-keyword {
  color: #C792EA;
}

.cm-s-material .cm-operator {
  color: #89DDFF;
}

.cm-s-material .cm-variable-2 {
  color: #EEFFFF;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #f07178;
}

.cm-s-material .cm-builtin {
  color: #FFCB6B;
}

.cm-s-material .cm-atom {
  color: #F78C6C;
}

.cm-s-material .cm-number {
  color: #FF5370;
}

.cm-s-material .cm-def {
  color: #82AAFF;
}

.cm-s-material .cm-string {
  color: #C3E88D;
}

.cm-s-material .cm-string-2 {
  color: #f07178;
}

.cm-s-material .cm-comment {
  color: #546E7A;
}

.cm-s-material .cm-variable {
  color: #f07178;
}

.cm-s-material .cm-tag {
  color: #FF5370;
}

.cm-s-material .cm-meta {
  color: #FFCB6B;
}

.cm-s-material .cm-attribute {
  color: #C792EA;
}

.cm-s-material .cm-property {
  color: #C792EA;
}

.cm-s-material .cm-qualifier {
  color: #DECB6B;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #DECB6B;
}


.cm-s-material .cm-error {
  color: rgba(255, 255, 255, 1.0);
  background-color: #FF5370;
}

.cm-s-material .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: white !important;
}
/**
 * "
 *  Using Zenburn color palette from the Emacs Zenburn Theme
 *  https://github.com/bbatsov/zenburn-emacs/blob/master/zenburn-theme.el
 *
 *  Also using parts of https://github.com/xavi/coderay-lighttable-theme
 * "
 * From: https://github.com/wisenomad/zenburn-lighttable-theme/blob/master/zenburn.css
 */

.cm-s-zenburn .CodeMirror-gutters { background: #3f3f3f !important; }
.cm-s-zenburn .CodeMirror-foldgutter-open, .CodeMirror-foldgutter-folded { color: #999; }
.cm-s-zenburn .CodeMirror-cursor { border-left: 1px solid white; }
.cm-s-zenburn { background-color: #3f3f3f; color: #dcdccc; }
.cm-s-zenburn span.cm-builtin { color: #dcdccc; font-weight: bold; }
.cm-s-zenburn span.cm-comment { color: #7f9f7f; }
.cm-s-zenburn span.cm-keyword { color: #f0dfaf; font-weight: bold; }
.cm-s-zenburn span.cm-atom { color: #bfebbf; }
.cm-s-zenburn span.cm-def { color: #dcdccc; }
.cm-s-zenburn span.cm-variable { color: #dfaf8f; }
.cm-s-zenburn span.cm-variable-2 { color: #dcdccc; }
.cm-s-zenburn span.cm-string { color: #cc9393; }
.cm-s-zenburn span.cm-string-2 { color: #cc9393; }
.cm-s-zenburn span.cm-number { color: #dcdccc; }
.cm-s-zenburn span.cm-tag { color: #93e0e3; }
.cm-s-zenburn span.cm-property { color: #dfaf8f; }
.cm-s-zenburn span.cm-attribute { color: #dfaf8f; }
.cm-s-zenburn span.cm-qualifier { color: #7cb8bb; }
.cm-s-zenburn span.cm-meta { color: #f0dfaf; }
.cm-s-zenburn span.cm-header { color: #f0efd0; }
.cm-s-zenburn span.cm-operator { color: #f0efd0; }
.cm-s-zenburn span.CodeMirror-matchingbracket { box-sizing: border-box; background: transparent; border-bottom: 1px solid; }
.cm-s-zenburn span.CodeMirror-nonmatchingbracket { border-bottom: 1px solid; background: none; }
.cm-s-zenburn .CodeMirror-activeline { background: #000000; }
.cm-s-zenburn .CodeMirror-activeline-background { background: #000000; }
.cm-s-zenburn div.CodeMirror-selected { background: #545454; }
.cm-s-zenburn .CodeMirror-focused div.CodeMirror-selected { background: #4f4f4f; }

.cm-s-abcdef.CodeMirror { background: #0f0f0f; color: #defdef; }
.cm-s-abcdef div.CodeMirror-selected { background: #515151; }
.cm-s-abcdef .CodeMirror-line::selection, .cm-s-abcdef .CodeMirror-line > span::selection, .cm-s-abcdef .CodeMirror-line > span > span::selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-line::-moz-selection, .cm-s-abcdef .CodeMirror-line > span::-moz-selection, .cm-s-abcdef .CodeMirror-line > span > span::-moz-selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-gutters { background: #555; border-right: 2px solid #314151; }
.cm-s-abcdef .CodeMirror-guttermarker { color: #222; }
.cm-s-abcdef .CodeMirror-guttermarker-subtle { color: azure; }
.cm-s-abcdef .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-abcdef .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-abcdef span.cm-keyword { color: darkgoldenrod; font-weight: bold; }
.cm-s-abcdef span.cm-atom { color: #77F; }
.cm-s-abcdef span.cm-number { color: violet; }
.cm-s-abcdef span.cm-def { color: #fffabc; }
.cm-s-abcdef span.cm-variable { color: #abcdef; }
.cm-s-abcdef span.cm-variable-2 { color: #cacbcc; }
.cm-s-abcdef span.cm-variable-3, .cm-s-abcdef span.cm-type { color: #def; }
.cm-s-abcdef span.cm-property { color: #fedcba; }
.cm-s-abcdef span.cm-operator { color: #ff0; }
.cm-s-abcdef span.cm-comment { color: #7a7b7c; font-style: italic;}
.cm-s-abcdef span.cm-string { color: #2b4; }
.cm-s-abcdef span.cm-meta { color: #C9F; }
.cm-s-abcdef span.cm-qualifier { color: #FFF700; }
.cm-s-abcdef span.cm-builtin { color: #30aabc; }
.cm-s-abcdef span.cm-bracket { color: #8a8a8a; }
.cm-s-abcdef span.cm-tag { color: #FFDD44; }
.cm-s-abcdef span.cm-attribute { color: #DDFF00; }
.cm-s-abcdef span.cm-error { color: #FF0000; }
.cm-s-abcdef span.cm-header { color: aquamarine; font-weight: bold; }
.cm-s-abcdef span.cm-link { color: blueviolet; }

.cm-s-abcdef .CodeMirror-activeline-background { background: #314151; }

/*

    Name:       Base16 Default Light
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-light.CodeMirror { background: #f5f5f5; color: #202020; }
.cm-s-base16-light div.CodeMirror-selected { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::selection, .cm-s-base16-light .CodeMirror-line > span::selection, .cm-s-base16-light .CodeMirror-line > span > span::selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::-moz-selection, .cm-s-base16-light .CodeMirror-line > span::-moz-selection, .cm-s-base16-light .CodeMirror-line > span > span::-moz-selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-gutters { background: #f5f5f5; border-right: 0px; }
.cm-s-base16-light .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-light .CodeMirror-guttermarker-subtle { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-linenumber { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-cursor { border-left: 1px solid #505050; }

.cm-s-base16-light span.cm-comment { color: #8f5536; }
.cm-s-base16-light span.cm-atom { color: #aa759f; }
.cm-s-base16-light span.cm-number { color: #aa759f; }

.cm-s-base16-light span.cm-property, .cm-s-base16-light span.cm-attribute { color: #90a959; }
.cm-s-base16-light span.cm-keyword { color: #ac4142; }
.cm-s-base16-light span.cm-string { color: #f4bf75; }

.cm-s-base16-light span.cm-variable { color: #90a959; }
.cm-s-base16-light span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-light span.cm-def { color: #d28445; }
.cm-s-base16-light span.cm-bracket { color: #202020; }
.cm-s-base16-light span.cm-tag { color: #ac4142; }
.cm-s-base16-light span.cm-link { color: #aa759f; }
.cm-s-base16-light span.cm-error { background: #ac4142; color: #505050; }

.cm-s-base16-light .CodeMirror-activeline-background { background: #DDDCDC; }
.cm-s-base16-light .CodeMirror-matchingbracket { color: #f5f5f5 !important; background-color: #6A9FB5 !important}

/*

    Name:       Base16 Default Dark
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-dark.CodeMirror { background: #151515; color: #e0e0e0; }
.cm-s-base16-dark div.CodeMirror-selected { background: #303030; }
.cm-s-base16-dark .CodeMirror-line::selection, .cm-s-base16-dark .CodeMirror-line > span::selection, .cm-s-base16-dark .CodeMirror-line > span > span::selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-line::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-gutters { background: #151515; border-right: 0px; }
.cm-s-base16-dark .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-dark .CodeMirror-guttermarker-subtle { color: #505050; }
.cm-s-base16-dark .CodeMirror-linenumber { color: #505050; }
.cm-s-base16-dark .CodeMirror-cursor { border-left: 1px solid #b0b0b0; }

.cm-s-base16-dark span.cm-comment { color: #8f5536; }
.cm-s-base16-dark span.cm-atom { color: #aa759f; }
.cm-s-base16-dark span.cm-number { color: #aa759f; }

.cm-s-base16-dark span.cm-property, .cm-s-base16-dark span.cm-attribute { color: #90a959; }
.cm-s-base16-dark span.cm-keyword { color: #ac4142; }
.cm-s-base16-dark span.cm-string { color: #f4bf75; }

.cm-s-base16-dark span.cm-variable { color: #90a959; }
.cm-s-base16-dark span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-dark span.cm-def { color: #d28445; }
.cm-s-base16-dark span.cm-bracket { color: #e0e0e0; }
.cm-s-base16-dark span.cm-tag { color: #ac4142; }
.cm-s-base16-dark span.cm-link { color: #aa759f; }
.cm-s-base16-dark span.cm-error { background: #ac4142; color: #b0b0b0; }

.cm-s-base16-dark .CodeMirror-activeline-background { background: #202020; }
.cm-s-base16-dark .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       dracula
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original dracula color scheme by Zeno Rocha (https://github.com/zenorocha/dracula-theme)

*/


.cm-s-dracula.CodeMirror, .cm-s-dracula .CodeMirror-gutters {
  background-color: #282a36 !important;
  color: #f8f8f2 !important;
  border: none;
}
.cm-s-dracula .CodeMirror-gutters { color: #282a36; }
.cm-s-dracula .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-dracula .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-dracula .CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::selection, .cm-s-dracula .CodeMirror-line > span::selection, .cm-s-dracula .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::-moz-selection, .cm-s-dracula .CodeMirror-line > span::-moz-selection, .cm-s-dracula .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula span.cm-comment { color: #6272a4; }
.cm-s-dracula span.cm-string, .cm-s-dracula span.cm-string-2 { color: #f1fa8c; }
.cm-s-dracula span.cm-number { color: #bd93f9; }
.cm-s-dracula span.cm-variable { color: #50fa7b; }
.cm-s-dracula span.cm-variable-2 { color: white; }
.cm-s-dracula span.cm-def { color: #50fa7b; }
.cm-s-dracula span.cm-operator { color: #ff79c6; }
.cm-s-dracula span.cm-keyword { color: #ff79c6; }
.cm-s-dracula span.cm-atom { color: #bd93f9; }
.cm-s-dracula span.cm-meta { color: #f8f8f2; }
.cm-s-dracula span.cm-tag { color: #ff79c6; }
.cm-s-dracula span.cm-attribute { color: #50fa7b; }
.cm-s-dracula span.cm-qualifier { color: #50fa7b; }
.cm-s-dracula span.cm-property { color: #66d9ef; }
.cm-s-dracula span.cm-builtin { color: #50fa7b; }
.cm-s-dracula span.cm-variable-3, .cm-s-dracula span.cm-type { color: #ffb86c; }

.cm-s-dracula .CodeMirror-activeline-background { background: rgba(255,255,255,0.1); }
.cm-s-dracula .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       Hopscotch
    Author:     Jan T. Sott

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-hopscotch.CodeMirror {background: #322931; color: #d5d3d5;}
.cm-s-hopscotch div.CodeMirror-selected {background: #433b42 !important;}
.cm-s-hopscotch .CodeMirror-gutters {background: #322931; border-right: 0px;}
.cm-s-hopscotch .CodeMirror-linenumber {color: #797379;}
.cm-s-hopscotch .CodeMirror-cursor {border-left: 1px solid #989498 !important;}

.cm-s-hopscotch span.cm-comment {color: #b33508;}
.cm-s-hopscotch span.cm-atom {color: #c85e7c;}
.cm-s-hopscotch span.cm-number {color: #c85e7c;}

.cm-s-hopscotch span.cm-property, .cm-s-hopscotch span.cm-attribute {color: #8fc13e;}
.cm-s-hopscotch span.cm-keyword {color: #dd464c;}
.cm-s-hopscotch span.cm-string {color: #fdcc59;}

.cm-s-hopscotch span.cm-variable {color: #8fc13e;}
.cm-s-hopscotch span.cm-variable-2 {color: #1290bf;}
.cm-s-hopscotch span.cm-def {color: #fd8b19;}
.cm-s-hopscotch span.cm-error {background: #dd464c; color: #989498;}
.cm-s-hopscotch span.cm-bracket {color: #d5d3d5;}
.cm-s-hopscotch span.cm-tag {color: #dd464c;}
.cm-s-hopscotch span.cm-link {color: #c85e7c;}

.cm-s-hopscotch .CodeMirror-matchingbracket { text-decoration: underline; color: white !important;}
.cm-s-hopscotch .CodeMirror-activeline-background { background: #302020; }

/****************************************************************/
/*   Based on mbonaci's Brackets mbo theme                      */
/*   https://github.com/mbonaci/global/blob/master/Mbo.tmTheme  */
/*   Create your own: http://tmtheme-editor.herokuapp.com       */
/****************************************************************/

.cm-s-mbo.CodeMirror { background: #2c2c2c; color: #ffffec; }
.cm-s-mbo div.CodeMirror-selected { background: #716C62; }
.cm-s-mbo .CodeMirror-line::selection, .cm-s-mbo .CodeMirror-line > span::selection, .cm-s-mbo .CodeMirror-line > span > span::selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-line::-moz-selection, .cm-s-mbo .CodeMirror-line > span::-moz-selection, .cm-s-mbo .CodeMirror-line > span > span::-moz-selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-gutters { background: #4e4e4e; border-right: 0px; }
.cm-s-mbo .CodeMirror-guttermarker { color: white; }
.cm-s-mbo .CodeMirror-guttermarker-subtle { color: grey; }
.cm-s-mbo .CodeMirror-linenumber { color: #dadada; }
.cm-s-mbo .CodeMirror-cursor { border-left: 1px solid #ffffec; }

.cm-s-mbo span.cm-comment { color: #95958a; }
.cm-s-mbo span.cm-atom { color: #00a8c6; }
.cm-s-mbo span.cm-number { color: #00a8c6; }

.cm-s-mbo span.cm-property, .cm-s-mbo span.cm-attribute { color: #9ddfe9; }
.cm-s-mbo span.cm-keyword { color: #ffb928; }
.cm-s-mbo span.cm-string { color: #ffcf6c; }
.cm-s-mbo span.cm-string.cm-property { color: #ffffec; }

.cm-s-mbo span.cm-variable { color: #ffffec; }
.cm-s-mbo span.cm-variable-2 { color: #00a8c6; }
.cm-s-mbo span.cm-def { color: #ffffec; }
.cm-s-mbo span.cm-bracket { color: #fffffc; font-weight: bold; }
.cm-s-mbo span.cm-tag { color: #9ddfe9; }
.cm-s-mbo span.cm-link { color: #f54b07; }
.cm-s-mbo span.cm-error { border-bottom: #636363; color: #ffffec; }
.cm-s-mbo span.cm-qualifier { color: #ffffec; }

.cm-s-mbo .CodeMirror-activeline-background { background: #494b41; }
.cm-s-mbo .CodeMirror-matchingbracket { color: #ffb928 !important; }
.cm-s-mbo .CodeMirror-matchingtag { background: rgba(255, 255, 255, .37); }

/*
  MDN-LIKE Theme - Mozilla
  Ported to CodeMirror by Peter Kroon <plakroon@gmail.com>
  Report bugs/issues here: https://github.com/codemirror/CodeMirror/issues
  GitHub: @peterkroon

  The mdn-like theme is inspired on the displayed code examples at: https://developer.mozilla.org/en-US/docs/Web/CSS/animation

*/
.cm-s-mdn-like.CodeMirror { color: #999; background-color: #fff; }
.cm-s-mdn-like div.CodeMirror-selected { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::selection, .cm-s-mdn-like .CodeMirror-line > span::selection, .cm-s-mdn-like .CodeMirror-line > span > span::selection { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span > span::-moz-selection { background: #cfc; }

.cm-s-mdn-like .CodeMirror-gutters { background: #f8f8f8; border-left: 6px solid rgba(0,83,159,0.65); color: #333; }
.cm-s-mdn-like .CodeMirror-linenumber { color: #aaa; padding-left: 8px; }
.cm-s-mdn-like .CodeMirror-cursor { border-left: 2px solid #222; }

.cm-s-mdn-like .cm-keyword { color: #6262FF; }
.cm-s-mdn-like .cm-atom { color: #F90; }
.cm-s-mdn-like .cm-number { color:  #ca7841; }
.cm-s-mdn-like .cm-def { color: #8DA6CE; }
.cm-s-mdn-like span.cm-variable-2, .cm-s-mdn-like span.cm-tag { color: #690; }
.cm-s-mdn-like span.cm-variable-3, .cm-s-mdn-like span.cm-def, .cm-s-mdn-like span.cm-type { color: #07a; }

.cm-s-mdn-like .cm-variable { color: #07a; }
.cm-s-mdn-like .cm-property { color: #905; }
.cm-s-mdn-like .cm-qualifier { color: #690; }

.cm-s-mdn-like .cm-operator { color: #cda869; }
.cm-s-mdn-like .cm-comment { color:#777; font-weight:normal; }
.cm-s-mdn-like .cm-string { color:#07a; font-style:italic; }
.cm-s-mdn-like .cm-string-2 { color:#bd6b18; } /*?*/
.cm-s-mdn-like .cm-meta { color: #000; } /*?*/
.cm-s-mdn-like .cm-builtin { color: #9B7536; } /*?*/
.cm-s-mdn-like .cm-tag { color: #997643; }
.cm-s-mdn-like .cm-attribute { color: #d6bb6d; } /*?*/
.cm-s-mdn-like .cm-header { color: #FF6400; }
.cm-s-mdn-like .cm-hr { color: #AEAEAE; }
.cm-s-mdn-like .cm-link { color:#ad9361; font-style:italic; text-decoration:none; }
.cm-s-mdn-like .cm-error { border-bottom: 1px solid red; }

div.cm-s-mdn-like .CodeMirror-activeline-background { background: #efefff; }
div.cm-s-mdn-like span.CodeMirror-matchingbracket { outline:1px solid grey; color: inherit; }

.cm-s-mdn-like.CodeMirror { background-image: url(data:image/png;base64,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); }

/*

    Name:       seti
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original seti color scheme by Jesse Weed (https://github.com/jesseweed/seti-syntax)

*/


.cm-s-seti.CodeMirror {
  background-color: #151718 !important;
  color: #CFD2D1 !important;
  border: none;
}
.cm-s-seti .CodeMirror-gutters {
  color: #404b53;
  background-color: #0E1112;
  border: none;
}
.cm-s-seti .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-seti .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-seti.CodeMirror-focused div.CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::selection, .cm-s-seti .CodeMirror-line > span::selection, .cm-s-seti .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::-moz-selection, .cm-s-seti .CodeMirror-line > span::-moz-selection, .cm-s-seti .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti span.cm-comment { color: #41535b; }
.cm-s-seti span.cm-string, .cm-s-seti span.cm-string-2 { color: #55b5db; }
.cm-s-seti span.cm-number { color: #cd3f45; }
.cm-s-seti span.cm-variable { color: #55b5db; }
.cm-s-seti span.cm-variable-2 { color: #a074c4; }
.cm-s-seti span.cm-def { color: #55b5db; }
.cm-s-seti span.cm-keyword { color: #ff79c6; }
.cm-s-seti span.cm-operator { color: #9fca56; }
.cm-s-seti span.cm-keyword { color: #e6cd69; }
.cm-s-seti span.cm-atom { color: #cd3f45; }
.cm-s-seti span.cm-meta { color: #55b5db; }
.cm-s-seti span.cm-tag { color: #55b5db; }
.cm-s-seti span.cm-attribute { color: #9fca56; }
.cm-s-seti span.cm-qualifier { color: #9fca56; }
.cm-s-seti span.cm-property { color: #a074c4; }
.cm-s-seti span.cm-variable-3, .cm-s-seti span.cm-type { color: #9fca56; }
.cm-s-seti span.cm-builtin { color: #9fca56; }
.cm-s-seti .CodeMirror-activeline-background { background: #101213; }
.cm-s-seti .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*
Solarized theme for code-mirror
http://ethanschoonover.com/solarized
*/

/*
Solarized color palette
http://ethanschoonover.com/solarized/img/solarized-palette.png
*/

.solarized.base03 { color: #002b36; }
.solarized.base02 { color: #073642; }
.solarized.base01 { color: #586e75; }
.solarized.base00 { color: #657b83; }
.solarized.base0 { color: #839496; }
.solarized.base1 { color: #93a1a1; }
.solarized.base2 { color: #eee8d5; }
.solarized.base3  { color: #fdf6e3; }
.solarized.solar-yellow  { color: #b58900; }
.solarized.solar-orange  { color: #cb4b16; }
.solarized.solar-red { color: #dc322f; }
.solarized.solar-magenta { color: #d33682; }
.solarized.solar-violet  { color: #6c71c4; }
.solarized.solar-blue { color: #268bd2; }
.solarized.solar-cyan { color: #2aa198; }
.solarized.solar-green { color: #859900; }

/* Color scheme for code-mirror */

.cm-s-solarized {
  line-height: 1.45em;
  color-profile: sRGB;
  rendering-intent: auto;
}
.cm-s-solarized.cm-s-dark {
  color: #839496;
  background-color: #002b36;
  text-shadow: #002b36 0 1px;
}
.cm-s-solarized.cm-s-light {
  background-color: #fdf6e3;
  color: #657b83;
  text-shadow: #eee8d5 0 1px;
}

.cm-s-solarized .CodeMirror-widget {
  text-shadow: none;
}

.cm-s-solarized .cm-header { color: #586e75; }
.cm-s-solarized .cm-quote { color: #93a1a1; }

.cm-s-solarized .cm-keyword { color: #cb4b16; }
.cm-s-solarized .cm-atom { color: #d33682; }
.cm-s-solarized .cm-number { color: #d33682; }
.cm-s-solarized .cm-def { color: #2aa198; }

.cm-s-solarized .cm-variable { color: #839496; }
.cm-s-solarized .cm-variable-2 { color: #b58900; }
.cm-s-solarized .cm-variable-3, .cm-s-solarized .cm-type { color: #6c71c4; }

.cm-s-solarized .cm-property { color: #2aa198; }
.cm-s-solarized .cm-operator { color: #6c71c4; }

.cm-s-solarized .cm-comment { color: #586e75; font-style:italic; }

.cm-s-solarized .cm-string { color: #859900; }
.cm-s-solarized .cm-string-2 { color: #b58900; }

.cm-s-solarized .cm-meta { color: #859900; }
.cm-s-solarized .cm-qualifier { color: #b58900; }
.cm-s-solarized .cm-builtin { color: #d33682; }
.cm-s-solarized .cm-bracket { color: #cb4b16; }
.cm-s-solarized .CodeMirror-matchingbracket { color: #859900; }
.cm-s-solarized .CodeMirror-nonmatchingbracket { color: #dc322f; }
.cm-s-solarized .cm-tag { color: #93a1a1; }
.cm-s-solarized .cm-attribute { color: #2aa198; }
.cm-s-solarized .cm-hr {
  color: transparent;
  border-top: 1px solid #586e75;
  display: block;
}
.cm-s-solarized .cm-link { color: #93a1a1; cursor: pointer; }
.cm-s-solarized .cm-special { color: #6c71c4; }
.cm-s-solarized .cm-em {
  color: #999;
  text-decoration: underline;
  text-decoration-style: dotted;
}
.cm-s-solarized .cm-error,
.cm-s-solarized .cm-invalidchar {
  color: #586e75;
  border-bottom: 1px dotted #dc322f;
}

.cm-s-solarized.cm-s-dark div.CodeMirror-selected { background: #073642; }
.cm-s-solarized.cm-s-dark.CodeMirror ::selection { background: rgba(7, 54, 66, 0.99); }
.cm-s-solarized.cm-s-dark .CodeMirror-line::-moz-selection, .cm-s-dark .CodeMirror-line > span::-moz-selection, .cm-s-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(7, 54, 66, 0.99); }

.cm-s-solarized.cm-s-light div.CodeMirror-selected { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::selection, .cm-s-light .CodeMirror-line > span::selection, .cm-s-light .CodeMirror-line > span > span::selection { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::-moz-selection, .cm-s-ligh .CodeMirror-line > span::-moz-selection, .cm-s-ligh .CodeMirror-line > span > span::-moz-selection { background: #eee8d5; }

/* Editor styling */



/* Little shadow on the view-port of the buffer view */
.cm-s-solarized.CodeMirror {
  -moz-box-shadow: inset 7px 0 12px -6px #000;
  -webkit-box-shadow: inset 7px 0 12px -6px #000;
  box-shadow: inset 7px 0 12px -6px #000;
}

/* Remove gutter border */
.cm-s-solarized .CodeMirror-gutters {
  border-right: 0;
}

/* Gutter colors and line number styling based of color scheme (dark / light) */

/* Dark */
.cm-s-solarized.cm-s-dark .CodeMirror-gutters {
  background-color: #073642;
}

.cm-s-solarized.cm-s-dark .CodeMirror-linenumber {
  color: #586e75;
  text-shadow: #021014 0 -1px;
}

/* Light */
.cm-s-solarized.cm-s-light .CodeMirror-gutters {
  background-color: #eee8d5;
}

.cm-s-solarized.cm-s-light .CodeMirror-linenumber {
  color: #839496;
}

/* Common */
.cm-s-solarized .CodeMirror-linenumber {
  padding: 0 5px;
}
.cm-s-solarized .CodeMirror-guttermarker-subtle { color: #586e75; }
.cm-s-solarized.cm-s-dark .CodeMirror-guttermarker { color: #ddd; }
.cm-s-solarized.cm-s-light .CodeMirror-guttermarker { color: #cb4b16; }

.cm-s-solarized .CodeMirror-gutter .CodeMirror-gutter-text {
  color: #586e75;
}

/* Cursor */
.cm-s-solarized .CodeMirror-cursor { border-left: 1px solid #819090; }

/* Fat cursor */
.cm-s-solarized.cm-s-light.cm-fat-cursor .CodeMirror-cursor { background: #77ee77; }
.cm-s-solarized.cm-s-light .cm-animate-fat-cursor { background-color: #77ee77; }
.cm-s-solarized.cm-s-dark.cm-fat-cursor .CodeMirror-cursor { background: #586e75; }
.cm-s-solarized.cm-s-dark .cm-animate-fat-cursor { background-color: #586e75; }

/* Active line */
.cm-s-solarized.cm-s-dark .CodeMirror-activeline-background {
  background: rgba(255, 255, 255, 0.06);
}
.cm-s-solarized.cm-s-light .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.06);
}

.cm-s-the-matrix.CodeMirror { background: #000000; color: #00FF00; }
.cm-s-the-matrix div.CodeMirror-selected { background: #2D2D2D; }
.cm-s-the-matrix .CodeMirror-line::selection, .cm-s-the-matrix .CodeMirror-line > span::selection, .cm-s-the-matrix .CodeMirror-line > span > span::selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-line::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span > span::-moz-selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-gutters { background: #060; border-right: 2px solid #00FF00; }
.cm-s-the-matrix .CodeMirror-guttermarker { color: #0f0; }
.cm-s-the-matrix .CodeMirror-guttermarker-subtle { color: white; }
.cm-s-the-matrix .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-the-matrix .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-the-matrix span.cm-keyword { color: #008803; font-weight: bold; }
.cm-s-the-matrix span.cm-atom { color: #3FF; }
.cm-s-the-matrix span.cm-number { color: #FFB94F; }
.cm-s-the-matrix span.cm-def { color: #99C; }
.cm-s-the-matrix span.cm-variable { color: #F6C; }
.cm-s-the-matrix span.cm-variable-2 { color: #C6F; }
.cm-s-the-matrix span.cm-variable-3, .cm-s-the-matrix span.cm-type { color: #96F; }
.cm-s-the-matrix span.cm-property { color: #62FFA0; }
.cm-s-the-matrix span.cm-operator { color: #999; }
.cm-s-the-matrix span.cm-comment { color: #CCCCCC; }
.cm-s-the-matrix span.cm-string { color: #39C; }
.cm-s-the-matrix span.cm-meta { color: #C9F; }
.cm-s-the-matrix span.cm-qualifier { color: #FFF700; }
.cm-s-the-matrix span.cm-builtin { color: #30a; }
.cm-s-the-matrix span.cm-bracket { color: #cc7; }
.cm-s-the-matrix span.cm-tag { color: #FFBD40; }
.cm-s-the-matrix span.cm-attribute { color: #FFF700; }
.cm-s-the-matrix span.cm-error { color: #FF0000; }

.cm-s-the-matrix .CodeMirror-activeline-background { background: #040; }

/*
Copyright (C) 2011 by MarkLogic Corporation
Author: Mike Brevoort <mike@brevoort.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/
.cm-s-xq-light span.cm-keyword { line-height: 1em; font-weight: bold; color: #5A5CAD; }
.cm-s-xq-light span.cm-atom { color: #6C8CD5; }
.cm-s-xq-light span.cm-number { color: #164; }
.cm-s-xq-light span.cm-def { text-decoration:underline; }
.cm-s-xq-light span.cm-variable { color: black; }
.cm-s-xq-light span.cm-variable-2 { color:black; }
.cm-s-xq-light span.cm-variable-3, .cm-s-xq-light span.cm-type { color: black; }
.cm-s-xq-light span.cm-property {}
.cm-s-xq-light span.cm-operator {}
.cm-s-xq-light span.cm-comment { color: #0080FF; font-style: italic; }
.cm-s-xq-light span.cm-string { color: red; }
.cm-s-xq-light span.cm-meta { color: yellow; }
.cm-s-xq-light span.cm-qualifier { color: grey; }
.cm-s-xq-light span.cm-builtin { color: #7EA656; }
.cm-s-xq-light span.cm-bracket { color: #cc7; }
.cm-s-xq-light span.cm-tag { color: #3F7F7F; }
.cm-s-xq-light span.cm-attribute { color: #7F007F; }
.cm-s-xq-light span.cm-error { color: #f00; }

.cm-s-xq-light .CodeMirror-activeline-background { background: #e8f2ff; }
.cm-s-xq-light .CodeMirror-matchingbracket { outline:1px solid grey;color:black !important;background:yellow; }

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor-static {
  margin: var(--jp-code-padding);
}

.jp-CodeMirrorEditor,
.jp-CodeMirrorEditor-static {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
  line-height: normal;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 4px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: space-evenly;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 1;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 100%;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item.jp-mod-selected {
  color: white;
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: limegreen;
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

.jp-FileDialog.jp-mod-conflict input {
  color: red;
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

.jp-OutputArea-executeResult.jp-RenderedText {
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: flex;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: 'Source Code Pro', monospace;
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 180px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
a.anchor-link {
   display: none;
}
.highlight  {
    margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
    overflow: hidden;
}

.jp-InputArea-editor {
    overflow: hidden;
}

@media print {
  body {
    margin: 0;
  }
}
</style>



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#used libraries</span>
<span class="nf">library</span><span class="p">(</span><span class="n">data.table</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">Matrix</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">rpart</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">Metrics</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">randomForest</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">gbm</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Dataset-1---Cardiotocography-Data-Set">Dataset 1 - Cardiotocography Data Set<a class="anchor-link" href="#Dataset-1---Cardiotocography-Data-Set">&#182;</a></h1>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p><a href="https://archive.ics.uci.edu/ml/datasets/cardiotocography">https://archive.ics.uci.edu/ml/datasets/cardiotocography</a></p>
<h5 id="Dataset-has-21-features-and-2-different-classifications">Dataset has 21 features and 2 different classifications<a class="anchor-link" href="#Dataset-has-21-features-and-2-different-classifications">&#182;</a></h5><h6 id="Data-Set-Information:">Data Set Information:<a class="anchor-link" href="#Data-Set-Information:">&#182;</a></h6><p>2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.</p>
<h6 id="3-class-experiment-setup-is-used.-Classified-attribute-is-&quot;NSP&quot;---fetal-state-class-code">3-class experiment setup is used. Classified attribute is "NSP" - fetal state class code<a class="anchor-link" href="#3-class-experiment-setup-is-used.-Classified-attribute-is-&quot;NSP&quot;---fetal-state-class-code">&#182;</a></h6><h6 id="Attribute-Information:">Attribute Information:<a class="anchor-link" href="#Attribute-Information:">&#182;</a></h6><p>LB - FHR baseline (beats per minute)</p>
<p>AC - # of accelerations per second</p>
<p>FM - # of fetal movements per second</p>
<p>UC - # of uterine contractions per second</p>
<p>DL - # of light decelerations per second</p>
<p>DS - # of severe decelerations per second</p>
<p>DP - # of prolongued decelerations per second</p>
<p>ASTV - percentage of time with abnormal short term variability</p>
<p>MSTV - mean value of short term variability</p>
<p>ALTV - percentage of time with abnormal long term variability</p>
<p>MLTV - mean value of long term variability</p>
<p>Width - width of FHR histogram</p>
<p>Min - minimum of FHR histogram</p>
<p>Max - Maximum of FHR histogram</p>
<p>Nmax - # of histogram peaks</p>
<p>Nzeros - # of histogram zeros</p>
<p>Mode - histogram mode</p>
<p>Mean - histogram mean</p>
<p>Median - histogram median</p>
<p>Variance - histogram variance</p>
<p>Tendency - histogram tendency</p>
<p>CLASS - FHR pattern class code (1 to 10)</p>
<p>NSP - fetal state class code (N=normal; S=suspect; P=pathologic)</p>
<p>Relevant Papers:</p>
<p>Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># reading the data</span>
<span class="n">CTG_data</span> <span class="o">&lt;-</span> <span class="nf">read.csv</span><span class="p">(</span><span class="s">&quot;CTGData.csv&quot;</span><span class="p">)</span>
<span class="c1"># Data have 2 types of classes, &quot;class and NSP&quot; , I run to predict &quot;NSP&quot;, have 21 features located at columns 11-31 others are removed</span>
<span class="n">n</span> <span class="o">&lt;-</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">CTG_data</span><span class="p">)</span>
<span class="n">n</span> <span class="o">&lt;-</span> <span class="p">(</span><span class="n">n</span><span class="m">-2</span><span class="p">)</span>  <span class="c1">#last 2 rows are N/A </span>
<span class="n">CTG_data2</span> <span class="o">&lt;-</span>  <span class="n">CTG_data</span><span class="p">[,</span><span class="m">11</span><span class="o">:</span><span class="m">31</span><span class="p">]</span>
<span class="n">CTG_data2</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">CTG_data2</span><span class="p">,</span><span class="n">CTG_data</span><span class="o">$</span><span class="n">NSP</span><span class="p">)</span>
<span class="nf">names</span><span class="p">(</span><span class="n">CTG_data2</span><span class="p">)[</span><span class="nf">names</span><span class="p">(</span><span class="n">CTG_data2</span><span class="p">)</span> <span class="o">==</span> <span class="s">&quot;CTG_data$NSP&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="s">&quot;NSP&quot;</span>

<span class="n">m</span><span class="o">=</span> <span class="n">n</span><span class="o">*</span><span class="m">0.7</span>  <span class="c1"># %70 selected as train data, rest selected as test data</span>
<span class="n">train_CTG</span> <span class="o">=</span> <span class="n">CTG_data2</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">m</span><span class="p">,]</span>
<span class="n">test_CTG</span> <span class="o">=</span> <span class="n">CTG_data2</span><span class="p">[(</span><span class="n">m</span><span class="m">+1</span><span class="p">)</span><span class="o">:</span><span class="n">n</span><span class="p">,]</span>
<span class="n">train_CTG</span><span class="o">=</span><span class="nf">data.frame</span><span class="p">(</span><span class="n">train_CTG</span><span class="p">)</span>
<span class="n">test_CTG</span><span class="o">=</span><span class="nf">data.frame</span><span class="p">(</span><span class="n">test_CTG</span><span class="p">)</span>
<span class="n">train_CTG</span><span class="o">$</span><span class="n">NSP</span> <span class="o">&lt;-</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">train_CTG</span><span class="o">$</span><span class="n">NSP</span><span class="p">)</span>
<span class="n">test_CTG</span><span class="o">$</span><span class="n">NSP</span> <span class="o">&lt;-</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">test_CTG</span><span class="o">$</span><span class="n">NSP</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 1 - Lasso Regression</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">636</span><span class="p">)</span>
<span class="n">lambda_seq</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0.0001</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="m">6</span><span class="p">))</span> <span class="c1">#tried several times but we are asked to use 6 different lamda (I rerun the code)</span>
<span class="n">n_repeats</span><span class="o">=</span><span class="m">5</span>
<span class="n">n_folds</span><span class="o">=</span><span class="m">10</span>
<span class="n">lasso_grid</span> <span class="o">=</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">lambda</span><span class="o">=</span><span class="n">lambda_seq</span><span class="p">)</span>
<span class="n">lasso_control</span><span class="o">=</span><span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span>                        
<span class="n">CTG_lasso_fit</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">NSP</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">train_CTG</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s">&quot;glmnet&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">lasso_grid</span><span class="p">,</span><span class="n">trControl</span> <span class="o">=</span> <span class="n">lasso_control</span><span class="p">)</span> 
<span class="n">CTG_lasso_fit</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>glmnet 

1488 samples
  21 predictor
   3 classes: &#39;1&#39;, &#39;2&#39;, &#39;3&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 1340, 1339, 1339, 1340, 1338, 1340, ... 
Resampling results across tuning parameters:

  lambda   Accuracy   Kappa    
  0.00010  0.9026776  0.7533099
  0.02008  0.8990633  0.7277907
  0.04006  0.8682881  0.6200405
  0.06004  0.8539092  0.5584588
  0.08002  0.8314591  0.4634936
  0.10000  0.8110235  0.3753781

Tuning parameter &#39;alpha&#39; was held constant at a value of 1
Accuracy was used to select the optimal model using the largest value.
The final values used for the model were alpha = 1 and lambda = 1e-04.</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 2 - Decision Trees</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">636</span><span class="p">)</span>

<span class="n">DT_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span> 
<span class="n">DT_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">cp</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.01</span><span class="p">,</span><span class="m">0.02</span><span class="p">,</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.005</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="m">0.07</span><span class="p">))</span> <span class="c1"># cp by default 0.01, I change by both increasing and decreasing</span>

<span class="c1"># minbucket is originaly &quot;20/3 = 7&quot; so I tried original &quot;7&quot;, increase to &quot;20&quot;, decrease to &quot;2&quot;...</span>
<span class="n">CTG_DT_fit1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">NSP</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_CTG</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">7</span><span class="p">))</span>

<span class="n">CTG_DT_fit2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">NSP</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_CTG</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">20</span><span class="p">))</span>

<span class="n">CTG_DT_fit3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">NSP</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_CTG</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">2</span><span class="p">))</span>

<span class="n">CTG_DT_fit1</span>
<span class="n">CTG_DT_fit2</span>
<span class="n">CTG_DT_fit3</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

1488 samples
  21 predictor
   3 classes: &#39;1&#39;, &#39;2&#39;, &#39;3&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 1340, 1339, 1339, 1340, 1338, 1340, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa    
  0.005  0.9443488  0.8535169
  0.010  0.9434065  0.8498413
  0.020  0.9369625  0.8264977
  0.050  0.9231087  0.7874870
  0.070  0.9083225  0.7453928
  0.100  0.9083225  0.7453928

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.005.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

1488 samples
  21 predictor
   3 classes: &#39;1&#39;, &#39;2&#39;, &#39;3&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 1340, 1339, 1339, 1339, 1338, 1339, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa    
  0.005  0.9329048  0.8266155
  0.010  0.9314237  0.8220140
  0.020  0.9224330  0.7827004
  0.050  0.9200177  0.7776848
  0.070  0.9085927  0.7451896
  0.100  0.9085927  0.7451896

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.005.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

1488 samples
  21 predictor
   3 classes: &#39;1&#39;, &#39;2&#39;, &#39;3&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 1338, 1339, 1340, 1340, 1339, 1339, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa    
  0.005  0.9420776  0.8486936
  0.010  0.9423370  0.8478277
  0.020  0.9369786  0.8268224
  0.050  0.9231293  0.7873493
  0.070  0.9083422  0.7454791
  0.100  0.9083422  0.7454791

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.01.</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Best Accuracy obtained with minbucket 7 so, CTG_DT_fit1 is used.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">plot</span><span class="p">(</span><span class="n">CTG_DT_fit1</span><span class="o">$</span><span class="n">finalModel</span><span class="p">)</span>
<span class="nf">text</span><span class="p">(</span><span class="n">CTG_DT_fit1</span><span class="o">$</span><span class="n">finalModel</span><span class="p">,</span> <span class="n">all</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">cex</span><span class="o">=</span><span class="n">.</span><span class="m">8</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAABlBMVEUAAAD///+l2Z/dAAAA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"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 3 - Random Forest</span>

<span class="n">RF_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">mtry</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">7</span><span class="p">,</span><span class="m">9</span><span class="p">,</span><span class="m">11</span><span class="p">))</span> <span class="c1"># default value is 5 I change by both increasing and decreasing</span>
<span class="n">RF_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span> 
<span class="n">CTG_RF_fit</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">NSP</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_CTG</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rf&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">RF_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">RF_control</span><span class="p">)</span>
<span class="n">CTG_RF_fit</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">CTG_RF_fit</span><span class="p">)</span>
<span class="n">CTG_RF_fit</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Random Forest 

1488 samples
  21 predictor
   3 classes: &#39;1&#39;, &#39;2&#39;, &#39;3&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 1339, 1340, 1339, 1340, 1339, 1339, ... 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa    
   1    0.8923234  0.6942200
   3    0.9373505  0.8341871
   5    0.9436685  0.8512596
   7    0.9443414  0.8534772
   9    0.9455477  0.8569599
  11    0.9455495  0.8576967

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 11.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAgP9NTU1oaGh8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"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 4 - Stochastic Gradient Boosting</span>

<span class="c1"># interaction.depth default is 1 tried 2,3 and 5, n.trees default is 100 I change by both increasing and decreasing, </span>
<span class="c1"># shrinkage default is 0.1 I change by both increasing and decreasing</span>
<span class="n">SGB_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">interaction.depth</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">),</span> <span class="n">n.trees</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">200</span><span class="p">,</span><span class="m">50</span><span class="p">),</span><span class="n">shrinkage</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="m">0.2</span><span class="p">),</span><span class="n">n.minobsinnode</span> <span class="o">=</span><span class="m">10</span><span class="p">)</span>
<span class="n">SGB_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span> 
<span class="n">CTG_SGB_fit</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">NSP</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_CTG</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;gbm&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">SGB_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">SGB_control</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1805
     2        0.9943             nan     0.0500    0.1463
     3        0.9084             nan     0.0500    0.1255
     4        0.8339             nan     0.0500    0.1061
     5        0.7703             nan     0.0500    0.0904
     6        0.7168             nan     0.0500    0.0767
     7        0.6718             nan     0.0500    0.0664
     8        0.6296             nan     0.0500    0.0590
     9        0.5933             nan     0.0500    0.0511
    10        0.5610             nan     0.0500    0.0451
    20        0.3802             nan     0.0500    0.0136
    40        0.2606             nan     0.0500    0.0043
    60        0.2126             nan     0.0500    0.0007
    80        0.1864             nan     0.0500    0.0005
   100        0.1656             nan     0.0500    0.0003
   120        0.1533             nan     0.0500    0.0000
   140        0.1431             nan     0.0500   -0.0005
   160        0.1353             nan     0.0500   -0.0001
   180        0.1291             nan     0.0500   -0.0004
   200        0.1237             nan     0.0500   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1940
     2        0.9872             nan     0.0500    0.1577
     3        0.8932             nan     0.0500    0.1328
     4        0.8137             nan     0.0500    0.1120
     5        0.7443             nan     0.0500    0.0972
     6        0.6854             nan     0.0500    0.0821
     7        0.6346             nan     0.0500    0.0713
     8        0.5904             nan     0.0500    0.0610
     9        0.5521             nan     0.0500    0.0536
    10        0.5185             nan     0.0500    0.0498
    20        0.3168             nan     0.0500    0.0157
    40        0.1913             nan     0.0500    0.0018
    60        0.1512             nan     0.0500    0.0002
    80        0.1294             nan     0.0500   -0.0001
   100        0.1131             nan     0.0500   -0.0011
   120        0.1023             nan     0.0500   -0.0007
   140        0.0923             nan     0.0500   -0.0006
   160        0.0851             nan     0.0500   -0.0009
   180        0.0788             nan     0.0500   -0.0004
   200        0.0736             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1995
     2        0.9815             nan     0.0500    0.1671
     3        0.8834             nan     0.0500    0.1373
     4        0.8009             nan     0.0500    0.1138
     5        0.7304             nan     0.0500    0.0978
     6        0.6703             nan     0.0500    0.0859
     7        0.6185             nan     0.0500    0.0744
     8        0.5710             nan     0.0500    0.0678
     9        0.5294             nan     0.0500    0.0579
    10        0.4929             nan     0.0500    0.0496
    20        0.2843             nan     0.0500    0.0172
    40        0.1601             nan     0.0500    0.0007
    60        0.1210             nan     0.0500    0.0015
    80        0.1001             nan     0.0500   -0.0003
   100        0.0858             nan     0.0500   -0.0003
   120        0.0745             nan     0.0500   -0.0009
   140        0.0665             nan     0.0500   -0.0005
   160        0.0589             nan     0.0500   -0.0007
   180        0.0532             nan     0.0500   -0.0002
   200        0.0474             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2105
     2        0.9757             nan     0.0500    0.1728
     3        0.8734             nan     0.0500    0.1457
     4        0.7874             nan     0.0500    0.1217
     5        0.7135             nan     0.0500    0.1016
     6        0.6514             nan     0.0500    0.0952
     7        0.5955             nan     0.0500    0.0800
     8        0.5468             nan     0.0500    0.0703
     9        0.5041             nan     0.0500    0.0590
    10        0.4669             nan     0.0500    0.0532
    20        0.2572             nan     0.0500    0.0189
    40        0.1309             nan     0.0500    0.0019
    60        0.0901             nan     0.0500    0.0004
    80        0.0688             nan     0.0500   -0.0003
   100        0.0558             nan     0.0500   -0.0011
   120        0.0461             nan     0.0500   -0.0004
   140        0.0395             nan     0.0500   -0.0009
   160        0.0342             nan     0.0500   -0.0005
   180        0.0298             nan     0.0500   -0.0005
   200        0.0262             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3286
     2        0.9005             nan     0.1000    0.2180
     3        0.7651             nan     0.1000    0.1652
     4        0.6627             nan     0.1000    0.1202
     5        0.5842             nan     0.1000    0.0917
     6        0.5268             nan     0.1000    0.0692
     7        0.4803             nan     0.1000    0.0534
     8        0.4430             nan     0.1000    0.0453
     9        0.4101             nan     0.1000    0.0392
    10        0.3848             nan     0.1000    0.0303
    20        0.2610             nan     0.1000    0.0048
    40        0.1875             nan     0.1000    0.0015
    60        0.1567             nan     0.1000   -0.0007
    80        0.1385             nan     0.1000    0.0000
   100        0.1257             nan     0.1000   -0.0017
   120        0.1170             nan     0.1000   -0.0011
   140        0.1082             nan     0.1000   -0.0016
   160        0.1022             nan     0.1000   -0.0026
   180        0.0977             nan     0.1000   -0.0011
   200        0.0919             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3550
     2        0.8801             nan     0.1000    0.2398
     3        0.7340             nan     0.1000    0.1712
     4        0.6270             nan     0.1000    0.1274
     5        0.5452             nan     0.1000    0.0962
     6        0.4815             nan     0.1000    0.0774
     7        0.4288             nan     0.1000    0.0608
     8        0.3866             nan     0.1000    0.0520
     9        0.3501             nan     0.1000    0.0394
    10        0.3218             nan     0.1000    0.0337
    20        0.1950             nan     0.1000    0.0065
    40        0.1315             nan     0.1000    0.0001
    60        0.1027             nan     0.1000   -0.0053
    80        0.0861             nan     0.1000   -0.0015
   100        0.0741             nan     0.1000   -0.0007
   120        0.0643             nan     0.1000   -0.0032
   140        0.0568             nan     0.1000   -0.0020
   160        0.0520             nan     0.1000   -0.0009
   180        0.0460             nan     0.1000   -0.0009
   200        0.0406             nan     0.1000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3700
     2        0.8717             nan     0.1000    0.2434
     3        0.7167             nan     0.1000    0.1752
     4        0.6047             nan     0.1000    0.1347
     5        0.5197             nan     0.1000    0.0977
     6        0.4534             nan     0.1000    0.0827
     7        0.3963             nan     0.1000    0.0563
     8        0.3559             nan     0.1000    0.0462
     9        0.3216             nan     0.1000    0.0470
    10        0.2901             nan     0.1000    0.0311
    20        0.1630             nan     0.1000    0.0046
    40        0.1031             nan     0.1000   -0.0026
    60        0.0781             nan     0.1000   -0.0030
    80        0.0629             nan     0.1000   -0.0012
   100        0.0496             nan     0.1000   -0.0007
   120        0.0415             nan     0.1000   -0.0011
   140        0.0366             nan     0.1000   -0.0028
   160        0.0313             nan     0.1000   -0.0011
   180        0.0272             nan     0.1000   -0.0004
   200        0.0240             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3828
     2        0.8610             nan     0.1000    0.2597
     3        0.7008             nan     0.1000    0.1907
     4        0.5829             nan     0.1000    0.1392
     5        0.4920             nan     0.1000    0.1039
     6        0.4220             nan     0.1000    0.0804
     7        0.3677             nan     0.1000    0.0594
     8        0.3243             nan     0.1000    0.0489
     9        0.2889             nan     0.1000    0.0374
    10        0.2612             nan     0.1000    0.0269
    20        0.1345             nan     0.1000   -0.0003
    40        0.0710             nan     0.1000   -0.0010
    60        0.0486             nan     0.1000   -0.0015
    80        0.0357             nan     0.1000   -0.0016
   100        0.0263             nan     0.1000   -0.0016
   120        0.0205             nan     0.1000   -0.0015
   140        0.0170             nan     0.1000   -0.0011
   160        0.0142             nan     0.1000   -0.0007
   180        0.0118             nan     0.1000   -0.0013
   200        0.0099             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5487
     2        0.7330             nan     0.2000    0.2396
     3        0.5643             nan     0.2000    0.1508
     4        0.4630             nan     0.2000    0.0916
     5        0.4018             nan     0.2000    0.0600
     6        0.3579             nan     0.2000    0.0351
     7        0.3218             nan     0.2000    0.0381
     8        0.2946             nan     0.2000    0.0273
     9        0.2758             nan     0.2000    0.0159
    10        0.2600             nan     0.2000    0.0100
    20        0.1873             nan     0.2000   -0.0001
    40        0.1416             nan     0.2000   -0.0018
    60        0.1192             nan     0.2000   -0.0028
    80        0.1060             nan     0.2000   -0.0018
   100        0.0955             nan     0.2000   -0.0031
   120        0.0873             nan     0.2000   -0.0025
   140        0.0807             nan     0.2000   -0.0019
   160        0.0749             nan     0.2000   -0.0054
   180        0.0694             nan     0.2000   -0.0022
   200        0.0660             nan     0.2000   -0.0056

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5820
     2        0.7075             nan     0.2000    0.2732
     3        0.5225             nan     0.2000    0.1511
     4        0.4112             nan     0.2000    0.1016
     5        0.3407             nan     0.2000    0.0700
     6        0.2876             nan     0.2000    0.0397
     7        0.2540             nan     0.2000    0.0327
     8        0.2273             nan     0.2000    0.0106
     9        0.2114             nan     0.2000    0.0181
    10        0.1949             nan     0.2000    0.0169
    20        0.1292             nan     0.2000   -0.0013
    40        0.0872             nan     0.2000   -0.0031
    60        0.0697             nan     0.2000   -0.0042
    80        0.0539             nan     0.2000   -0.0038
   100        0.0433             nan     0.2000   -0.0047
   120        0.0376             nan     0.2000   -0.0030
   140        0.0304             nan     0.2000   -0.0006
   160        0.0260             nan     0.2000   -0.0024
   180        0.0226             nan     0.2000   -0.0017
   200        0.0210             nan     0.2000   -0.0027

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6139
     2        0.6883             nan     0.2000    0.2607
     3        0.5024             nan     0.2000    0.1746
     4        0.3832             nan     0.2000    0.0934
     5        0.3079             nan     0.2000    0.0596
     6        0.2604             nan     0.2000    0.0588
     7        0.2202             nan     0.2000    0.0285
     8        0.1959             nan     0.2000    0.0183
     9        0.1767             nan     0.2000    0.0074
    10        0.1656             nan     0.2000   -0.0074
    20        0.1024             nan     0.2000   -0.0023
    40        0.0593             nan     0.2000   -0.0015
    60        0.0432             nan     0.2000   -0.0030
    80        0.0338             nan     0.2000   -0.0025
   100        0.0248             nan     0.2000   -0.0030
   120        0.0192             nan     0.2000   -0.0020
   140        0.0157             nan     0.2000   -0.0009
   160        0.0132             nan     0.2000   -0.0016
   180        0.0108             nan     0.2000   -0.0020
   200        0.0090             nan     0.2000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6637
     2        0.6713             nan     0.2000    0.2783
     3        0.4730             nan     0.2000    0.1670
     4        0.3561             nan     0.2000    0.0994
     5        0.2842             nan     0.2000    0.0653
     6        0.2324             nan     0.2000    0.0358
     7        0.1924             nan     0.2000    0.0139
     8        0.1712             nan     0.2000    0.0093
     9        0.1541             nan     0.2000    0.0089
    10        0.1390             nan     0.2000    0.0029
    20        0.0746             nan     0.2000   -0.0065
    40        0.0393             nan     0.2000   -0.0043
    60        0.0228             nan     0.2000   -0.0032
    80        0.0151             nan     0.2000   -0.0013
   100        0.0113             nan     0.2000   -0.0023
   120        0.0079             nan     0.2000   -0.0020
   140        0.0064             nan     0.2000   -0.0018
   160        0.0048             nan     0.2000   -0.0026
   180        0.0037             nan     0.2000   -0.0028
   200        0.0034             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1817
     2        0.9941             nan     0.0500    0.1506
     3        0.9071             nan     0.0500    0.1268
     4        0.8340             nan     0.0500    0.1066
     5        0.7688             nan     0.0500    0.0912
     6        0.7141             nan     0.0500    0.0782
     7        0.6667             nan     0.0500    0.0677
     8        0.6251             nan     0.0500    0.0586
     9        0.5882             nan     0.0500    0.0507
    10        0.5559             nan     0.0500    0.0445
    20        0.3743             nan     0.0500    0.0133
    40        0.2563             nan     0.0500    0.0066
    60        0.2110             nan     0.0500    0.0020
    80        0.1851             nan     0.0500    0.0009
   100        0.1664             nan     0.0500    0.0020
   120        0.1509             nan     0.0500   -0.0010
   140        0.1410             nan     0.0500   -0.0010
   160        0.1333             nan     0.0500   -0.0016
   180        0.1266             nan     0.0500   -0.0004
   200        0.1219             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1957
     2        0.9857             nan     0.0500    0.1610
     3        0.8931             nan     0.0500    0.1347
     4        0.8143             nan     0.0500    0.1126
     5        0.7443             nan     0.0500    0.0956
     6        0.6852             nan     0.0500    0.0826
     7        0.6345             nan     0.0500    0.0733
     8        0.5892             nan     0.0500    0.0641
     9        0.5495             nan     0.0500    0.0562
    10        0.5148             nan     0.0500    0.0487
    20        0.3118             nan     0.0500    0.0154
    40        0.1891             nan     0.0500    0.0023
    60        0.1493             nan     0.0500    0.0001
    80        0.1251             nan     0.0500   -0.0010
   100        0.1091             nan     0.0500   -0.0003
   120        0.0988             nan     0.0500    0.0002
   140        0.0906             nan     0.0500   -0.0014
   160        0.0842             nan     0.0500   -0.0011
   180        0.0784             nan     0.0500   -0.0007
   200        0.0734             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2021
     2        0.9806             nan     0.0500    0.1619
     3        0.8852             nan     0.0500    0.1385
     4        0.8023             nan     0.0500    0.1180
     5        0.7310             nan     0.0500    0.1041
     6        0.6684             nan     0.0500    0.0879
     7        0.6151             nan     0.0500    0.0769
     8        0.5677             nan     0.0500    0.0671
     9        0.5269             nan     0.0500    0.0584
    10        0.4897             nan     0.0500    0.0519
    20        0.2790             nan     0.0500    0.0167
    40        0.1550             nan     0.0500    0.0006
    60        0.1183             nan     0.0500    0.0004
    80        0.0983             nan     0.0500   -0.0007
   100        0.0845             nan     0.0500   -0.0012
   120        0.0738             nan     0.0500   -0.0006
   140        0.0657             nan     0.0500   -0.0006
   160        0.0594             nan     0.0500   -0.0005
   180        0.0539             nan     0.0500   -0.0010
   200        0.0495             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2126
     2        0.9768             nan     0.0500    0.1692
     3        0.8754             nan     0.0500    0.1466
     4        0.7898             nan     0.0500    0.1231
     5        0.7157             nan     0.0500    0.1052
     6        0.6514             nan     0.0500    0.0906
     7        0.5966             nan     0.0500    0.0804
     8        0.5480             nan     0.0500    0.0674
     9        0.5061             nan     0.0500    0.0593
    10        0.4674             nan     0.0500    0.0507
    20        0.2534             nan     0.0500    0.0169
    40        0.1263             nan     0.0500    0.0014
    60        0.0907             nan     0.0500   -0.0008
    80        0.0719             nan     0.0500   -0.0008
   100        0.0588             nan     0.0500   -0.0015
   120        0.0490             nan     0.0500   -0.0006
   140        0.0422             nan     0.0500   -0.0006
   160        0.0361             nan     0.0500   -0.0008
   180        0.0315             nan     0.0500   -0.0006
   200        0.0281             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3357
     2        0.8987             nan     0.1000    0.2235
     3        0.7527             nan     0.1000    0.1583
     4        0.6564             nan     0.1000    0.1129
     5        0.5833             nan     0.1000    0.0946
     6        0.5220             nan     0.1000    0.0709
     7        0.4757             nan     0.1000    0.0592
     8        0.4366             nan     0.1000    0.0450
     9        0.4067             nan     0.1000    0.0289
    10        0.3845             nan     0.1000    0.0300
    20        0.2570             nan     0.1000    0.0067
    40        0.1836             nan     0.1000    0.0042
    60        0.1534             nan     0.1000    0.0001
    80        0.1359             nan     0.1000   -0.0029
   100        0.1239             nan     0.1000   -0.0018
   120        0.1156             nan     0.1000   -0.0023
   140        0.1080             nan     0.1000   -0.0009
   160        0.1014             nan     0.1000   -0.0002
   180        0.0977             nan     0.1000   -0.0007
   200        0.0936             nan     0.1000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3551
     2        0.8822             nan     0.1000    0.2423
     3        0.7295             nan     0.1000    0.1757
     4        0.6215             nan     0.1000    0.1285
     5        0.5366             nan     0.1000    0.0955
     6        0.4743             nan     0.1000    0.0780
     7        0.4225             nan     0.1000    0.0647
     8        0.3783             nan     0.1000    0.0457
     9        0.3454             nan     0.1000    0.0428
    10        0.3163             nan     0.1000    0.0309
    20        0.1883             nan     0.1000    0.0039
    40        0.1276             nan     0.1000   -0.0019
    60        0.1024             nan     0.1000   -0.0011
    80        0.0862             nan     0.1000   -0.0037
   100        0.0750             nan     0.1000   -0.0007
   120        0.0660             nan     0.1000   -0.0016
   140        0.0587             nan     0.1000   -0.0014
   160        0.0527             nan     0.1000   -0.0020
   180        0.0478             nan     0.1000   -0.0014
   200        0.0432             nan     0.1000   -0.0023

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3697
     2        0.8712             nan     0.1000    0.2477
     3        0.7166             nan     0.1000    0.1820
     4        0.6015             nan     0.1000    0.1368
     5        0.5155             nan     0.1000    0.1029
     6        0.4500             nan     0.1000    0.0791
     7        0.3972             nan     0.1000    0.0601
     8        0.3551             nan     0.1000    0.0465
     9        0.3208             nan     0.1000    0.0393
    10        0.2924             nan     0.1000    0.0351
    20        0.1594             nan     0.1000    0.0067
    40        0.0974             nan     0.1000   -0.0010
    60        0.0724             nan     0.1000   -0.0022
    80        0.0564             nan     0.1000   -0.0023
   100        0.0476             nan     0.1000   -0.0011
   120        0.0391             nan     0.1000   -0.0025
   140        0.0328             nan     0.1000   -0.0013
   160        0.0293             nan     0.1000   -0.0003
   180        0.0258             nan     0.1000   -0.0006
   200        0.0234             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3800
     2        0.8651             nan     0.1000    0.2610
     3        0.7027             nan     0.1000    0.1889
     4        0.5852             nan     0.1000    0.1329
     5        0.4951             nan     0.1000    0.1022
     6        0.4273             nan     0.1000    0.0862
     7        0.3705             nan     0.1000    0.0585
     8        0.3279             nan     0.1000    0.0439
     9        0.2947             nan     0.1000    0.0441
    10        0.2633             nan     0.1000    0.0296
    20        0.1330             nan     0.1000    0.0059
    40        0.0705             nan     0.1000   -0.0039
    60        0.0497             nan     0.1000   -0.0015
    80        0.0364             nan     0.1000   -0.0026
   100        0.0275             nan     0.1000   -0.0012
   120        0.0214             nan     0.1000   -0.0010
   140        0.0177             nan     0.1000   -0.0011
   160        0.0149             nan     0.1000   -0.0008
   180        0.0130             nan     0.1000   -0.0006
   200        0.0114             nan     0.1000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5531
     2        0.7311             nan     0.2000    0.2584
     3        0.5604             nan     0.2000    0.1413
     4        0.4580             nan     0.2000    0.0752
     5        0.3975             nan     0.2000    0.0588
     6        0.3516             nan     0.2000    0.0472
     7        0.3137             nan     0.2000    0.0332
     8        0.2875             nan     0.2000    0.0206
     9        0.2674             nan     0.2000    0.0154
    10        0.2518             nan     0.2000    0.0080
    20        0.1799             nan     0.2000   -0.0053
    40        0.1322             nan     0.2000   -0.0065
    60        0.1160             nan     0.2000   -0.0035
    80        0.1041             nan     0.2000   -0.0076
   100        0.0941             nan     0.2000   -0.0040
   120        0.0878             nan     0.2000   -0.0008
   140        0.0795             nan     0.2000   -0.0029
   160        0.0746             nan     0.2000   -0.0030
   180        0.0706             nan     0.2000   -0.0023
   200        0.0666             nan     0.2000   -0.0055

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5805
     2        0.7017             nan     0.2000    0.2788
     3        0.5139             nan     0.2000    0.1459
     4        0.4057             nan     0.2000    0.0856
     5        0.3362             nan     0.2000    0.0476
     6        0.2891             nan     0.2000    0.0463
     7        0.2523             nan     0.2000    0.0324
     8        0.2269             nan     0.2000    0.0229
     9        0.2051             nan     0.2000    0.0103
    10        0.1912             nan     0.2000    0.0125
    20        0.1240             nan     0.2000   -0.0030
    40        0.0870             nan     0.2000   -0.0075
    60        0.0691             nan     0.2000   -0.0023
    80        0.0522             nan     0.2000   -0.0028
   100        0.0425             nan     0.2000   -0.0018
   120        0.0353             nan     0.2000   -0.0023
   140        0.0302             nan     0.2000   -0.0031
   160        0.0270             nan     0.2000   -0.0013
   180        0.0242             nan     0.2000   -0.0000
   200        0.0212             nan     0.2000   -0.0035

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6041
     2        0.6827             nan     0.2000    0.2572
     3        0.4929             nan     0.2000    0.1460
     4        0.3790             nan     0.2000    0.1020
     5        0.3033             nan     0.2000    0.0622
     6        0.2559             nan     0.2000    0.0377
     7        0.2257             nan     0.2000    0.0274
     8        0.1955             nan     0.2000    0.0032
     9        0.1792             nan     0.2000    0.0156
    10        0.1648             nan     0.2000    0.0049
    20        0.1056             nan     0.2000   -0.0006
    40        0.0620             nan     0.2000   -0.0039
    60        0.0434             nan     0.2000   -0.0025
    80        0.0316             nan     0.2000   -0.0006
   100        0.0237             nan     0.2000   -0.0012
   120        0.0189             nan     0.2000   -0.0019
   140        0.0161             nan     0.2000   -0.0028
   160        0.0134             nan     0.2000   -0.0003
   180        0.0116             nan     0.2000   -0.0023
   200        0.0108             nan     0.2000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6061
     2        0.6719             nan     0.2000    0.2883
     3        0.4641             nan     0.2000    0.1599
     4        0.3469             nan     0.2000    0.0942
     5        0.2743             nan     0.2000    0.0468
     6        0.2257             nan     0.2000    0.0292
     7        0.1938             nan     0.2000    0.0190
     8        0.1691             nan     0.2000    0.0166
     9        0.1476             nan     0.2000    0.0043
    10        0.1361             nan     0.2000    0.0027
    20        0.0763             nan     0.2000   -0.0050
    40        0.0401             nan     0.2000   -0.0043
    60        0.0252             nan     0.2000   -0.0041
    80        0.0161             nan     0.2000   -0.0004
   100        0.0119             nan     0.2000   -0.0010
   120        0.0093             nan     0.2000   -0.0018
   140        0.0074             nan     0.2000   -0.0028
   160        0.0067             nan     0.2000   -0.0002
   180        0.0053             nan     0.2000   -0.0017
   200        0.0045             nan     0.2000   -0.0025

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1814
     2        0.9943             nan     0.0500    0.1461
     3        0.9077             nan     0.0500    0.1257
     4        0.8324             nan     0.0500    0.1080
     5        0.7694             nan     0.0500    0.0905
     6        0.7136             nan     0.0500    0.0784
     7        0.6656             nan     0.0500    0.0676
     8        0.6253             nan     0.0500    0.0591
     9        0.5890             nan     0.0500    0.0527
    10        0.5567             nan     0.0500    0.0457
    20        0.3756             nan     0.0500    0.0164
    40        0.2557             nan     0.0500    0.0044
    60        0.2108             nan     0.0500    0.0015
    80        0.1838             nan     0.0500    0.0015
   100        0.1664             nan     0.0500    0.0001
   120        0.1536             nan     0.0500   -0.0007
   140        0.1439             nan     0.0500   -0.0002
   160        0.1360             nan     0.0500   -0.0004
   180        0.1292             nan     0.0500   -0.0006
   200        0.1233             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1943
     2        0.9853             nan     0.0500    0.1604
     3        0.8910             nan     0.0500    0.1334
     4        0.8123             nan     0.0500    0.1131
     5        0.7435             nan     0.0500    0.0966
     6        0.6843             nan     0.0500    0.0844
     7        0.6319             nan     0.0500    0.0714
     8        0.5877             nan     0.0500    0.0620
     9        0.5486             nan     0.0500    0.0575
    10        0.5137             nan     0.0500    0.0479
    20        0.3129             nan     0.0500    0.0177
    40        0.1886             nan     0.0500    0.0036
    60        0.1523             nan     0.0500    0.0004
    80        0.1282             nan     0.0500   -0.0009
   100        0.1126             nan     0.0500    0.0000
   120        0.1011             nan     0.0500    0.0000
   140        0.0919             nan     0.0500   -0.0009
   160        0.0849             nan     0.0500   -0.0013
   180        0.0778             nan     0.0500   -0.0006
   200        0.0724             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2004
     2        0.9807             nan     0.0500    0.1617
     3        0.8837             nan     0.0500    0.1389
     4        0.8009             nan     0.0500    0.1185
     5        0.7296             nan     0.0500    0.0969
     6        0.6685             nan     0.0500    0.0866
     7        0.6152             nan     0.0500    0.0749
     8        0.5685             nan     0.0500    0.0653
     9        0.5271             nan     0.0500    0.0584
    10        0.4909             nan     0.0500    0.0510
    20        0.2842             nan     0.0500    0.0185
    40        0.1594             nan     0.0500   -0.0004
    60        0.1210             nan     0.0500   -0.0000
    80        0.0999             nan     0.0500   -0.0004
   100        0.0855             nan     0.0500   -0.0002
   120        0.0753             nan     0.0500   -0.0003
   140        0.0665             nan     0.0500   -0.0008
   160        0.0598             nan     0.0500   -0.0012
   180        0.0544             nan     0.0500   -0.0004
   200        0.0491             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2044
     2        0.9782             nan     0.0500    0.1752
     3        0.8755             nan     0.0500    0.1393
     4        0.7919             nan     0.0500    0.1222
     5        0.7177             nan     0.0500    0.1046
     6        0.6531             nan     0.0500    0.0936
     7        0.5974             nan     0.0500    0.0814
     8        0.5485             nan     0.0500    0.0662
     9        0.5062             nan     0.0500    0.0592
    10        0.4676             nan     0.0500    0.0514
    20        0.2515             nan     0.0500    0.0147
    40        0.1318             nan     0.0500    0.0024
    60        0.0923             nan     0.0500   -0.0008
    80        0.0727             nan     0.0500   -0.0012
   100        0.0589             nan     0.0500   -0.0009
   120        0.0490             nan     0.0500   -0.0007
   140        0.0416             nan     0.0500   -0.0006
   160        0.0353             nan     0.0500   -0.0006
   180        0.0313             nan     0.0500   -0.0002
   200        0.0273             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3314
     2        0.8949             nan     0.1000    0.2243
     3        0.7558             nan     0.1000    0.1643
     4        0.6553             nan     0.1000    0.1236
     5        0.5799             nan     0.1000    0.0913
     6        0.5207             nan     0.1000    0.0725
     7        0.4731             nan     0.1000    0.0517
     8        0.4362             nan     0.1000    0.0430
     9        0.4055             nan     0.1000    0.0382
    10        0.3802             nan     0.1000    0.0287
    20        0.2567             nan     0.1000    0.0063
    40        0.1855             nan     0.1000    0.0020
    60        0.1550             nan     0.1000   -0.0001
    80        0.1375             nan     0.1000   -0.0035
   100        0.1242             nan     0.1000   -0.0018
   120        0.1140             nan     0.1000   -0.0026
   140        0.1055             nan     0.1000   -0.0003
   160        0.0999             nan     0.1000   -0.0014
   180        0.0942             nan     0.1000   -0.0011
   200        0.0898             nan     0.1000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3590
     2        0.8826             nan     0.1000    0.2449
     3        0.7316             nan     0.1000    0.1751
     4        0.6205             nan     0.1000    0.1323
     5        0.5389             nan     0.1000    0.0974
     6        0.4790             nan     0.1000    0.0809
     7        0.4246             nan     0.1000    0.0639
     8        0.3832             nan     0.1000    0.0483
     9        0.3497             nan     0.1000    0.0455
    10        0.3192             nan     0.1000    0.0286
    20        0.1910             nan     0.1000    0.0072
    40        0.1285             nan     0.1000   -0.0009
    60        0.1014             nan     0.1000   -0.0013
    80        0.0855             nan     0.1000   -0.0010
   100        0.0724             nan     0.1000   -0.0015
   120        0.0634             nan     0.1000   -0.0021
   140        0.0564             nan     0.1000   -0.0029
   160        0.0500             nan     0.1000   -0.0009
   180        0.0457             nan     0.1000   -0.0018
   200        0.0417             nan     0.1000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3692
     2        0.8699             nan     0.1000    0.2516
     3        0.7148             nan     0.1000    0.1797
     4        0.6000             nan     0.1000    0.1316
     5        0.5153             nan     0.1000    0.1005
     6        0.4484             nan     0.1000    0.0807
     7        0.3949             nan     0.1000    0.0700
     8        0.3490             nan     0.1000    0.0534
     9        0.3136             nan     0.1000    0.0359
    10        0.2857             nan     0.1000    0.0329
    20        0.1640             nan     0.1000    0.0046
    40        0.1014             nan     0.1000   -0.0048
    60        0.0787             nan     0.1000   -0.0032
    80        0.0610             nan     0.1000   -0.0013
   100        0.0504             nan     0.1000   -0.0010
   120        0.0426             nan     0.1000   -0.0019
   140        0.0358             nan     0.1000   -0.0014
   160        0.0322             nan     0.1000   -0.0008
   180        0.0284             nan     0.1000   -0.0008
   200        0.0258             nan     0.1000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3777
     2        0.8623             nan     0.1000    0.2478
     3        0.7055             nan     0.1000    0.1855
     4        0.5871             nan     0.1000    0.1398
     5        0.4980             nan     0.1000    0.1070
     6        0.4287             nan     0.1000    0.0835
     7        0.3726             nan     0.1000    0.0692
     8        0.3269             nan     0.1000    0.0489
     9        0.2905             nan     0.1000    0.0379
    10        0.2623             nan     0.1000    0.0295
    20        0.1332             nan     0.1000    0.0042
    40        0.0721             nan     0.1000   -0.0011
    60        0.0489             nan     0.1000   -0.0011
    80        0.0360             nan     0.1000   -0.0023
   100        0.0278             nan     0.1000   -0.0011
   120        0.0224             nan     0.1000   -0.0007
   140        0.0185             nan     0.1000   -0.0011
   160        0.0157             nan     0.1000   -0.0007
   180        0.0138             nan     0.1000   -0.0010
   200        0.0121             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5579
     2        0.7339             nan     0.2000    0.2567
     3        0.5575             nan     0.2000    0.1421
     4        0.4550             nan     0.2000    0.0918
     5        0.3895             nan     0.2000    0.0581
     6        0.3454             nan     0.2000    0.0349
     7        0.3178             nan     0.2000    0.0234
     8        0.2969             nan     0.2000    0.0200
     9        0.2816             nan     0.2000    0.0273
    10        0.2603             nan     0.2000    0.0109
    20        0.1814             nan     0.2000    0.0054
    40        0.1364             nan     0.2000   -0.0045
    60        0.1139             nan     0.2000   -0.0003
    80        0.1003             nan     0.2000   -0.0001
   100        0.0894             nan     0.2000   -0.0027
   120        0.0817             nan     0.2000   -0.0027
   140        0.0749             nan     0.2000   -0.0041
   160        0.0687             nan     0.2000   -0.0031
   180        0.0648             nan     0.2000   -0.0016
   200        0.0609             nan     0.2000   -0.0028

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6031
     2        0.7054             nan     0.2000    0.2810
     3        0.5136             nan     0.2000    0.1606
     4        0.4054             nan     0.2000    0.0930
     5        0.3346             nan     0.2000    0.0534
     6        0.2907             nan     0.2000    0.0480
     7        0.2506             nan     0.2000    0.0298
     8        0.2258             nan     0.2000    0.0151
     9        0.2072             nan     0.2000    0.0109
    10        0.1924             nan     0.2000    0.0137
    20        0.1311             nan     0.2000   -0.0019
    40        0.0855             nan     0.2000   -0.0032
    60        0.0663             nan     0.2000   -0.0035
    80        0.0534             nan     0.2000   -0.0011
   100        0.0446             nan     0.2000   -0.0003
   120        0.0372             nan     0.2000   -0.0021
   140        0.0330             nan     0.2000   -0.0021
   160        0.0278             nan     0.2000   -0.0037
   180        0.0243             nan     0.2000   -0.0010
   200        0.0203             nan     0.2000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6245
     2        0.6887             nan     0.2000    0.2769
     3        0.4896             nan     0.2000    0.1551
     4        0.3790             nan     0.2000    0.1041
     5        0.3041             nan     0.2000    0.0636
     6        0.2583             nan     0.2000    0.0235
     7        0.2289             nan     0.2000    0.0211
     8        0.1959             nan     0.2000   -0.0130
     9        0.1778             nan     0.2000    0.0102
    10        0.1658             nan     0.2000    0.0077
    20        0.1039             nan     0.2000   -0.0009
    40        0.0658             nan     0.2000   -0.0052
    60        0.0451             nan     0.2000   -0.0032
    80        0.0346             nan     0.2000   -0.0012
   100        0.0280             nan     0.2000   -0.0037
   120        0.0235             nan     0.2000   -0.0017
   140        0.0185             nan     0.2000   -0.0019
   160        0.0158             nan     0.2000   -0.0008
   180        0.0137             nan     0.2000   -0.0013
   200        0.0125             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6287
     2        0.6696             nan     0.2000    0.2939
     3        0.4664             nan     0.2000    0.1666
     4        0.3463             nan     0.2000    0.0969
     5        0.2741             nan     0.2000    0.0671
     6        0.2242             nan     0.2000    0.0216
     7        0.1948             nan     0.2000    0.0255
     8        0.1699             nan     0.2000    0.0085
     9        0.1530             nan     0.2000    0.0046
    10        0.1403             nan     0.2000    0.0003
    20        0.0796             nan     0.2000   -0.0020
    40        0.0401             nan     0.2000   -0.0046
    60        0.0268             nan     0.2000   -0.0064
    80        0.0197             nan     0.2000   -0.0035
   100        0.0140             nan     0.2000   -0.0038
   120        0.0110             nan     0.2000   -0.0027
   140        0.0088             nan     0.2000   -0.0030
   160        0.0070             nan     0.2000   -0.0005
   180        0.0059             nan     0.2000   -0.0022
   200        0.0051             nan     0.2000   -0.0000

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1783
     2        0.9944             nan     0.0500    0.1491
     3        0.9083             nan     0.0500    0.1230
     4        0.8363             nan     0.0500    0.1063
     5        0.7745             nan     0.0500    0.0910
     6        0.7207             nan     0.0500    0.0778
     7        0.6732             nan     0.0500    0.0652
     8        0.6327             nan     0.0500    0.0579
     9        0.5964             nan     0.0500    0.0494
    10        0.5647             nan     0.0500    0.0455
    20        0.3832             nan     0.0500    0.0161
    40        0.2663             nan     0.0500    0.0063
    60        0.2185             nan     0.0500    0.0037
    80        0.1878             nan     0.0500    0.0000
   100        0.1702             nan     0.0500   -0.0004
   120        0.1566             nan     0.0500    0.0002
   140        0.1456             nan     0.0500   -0.0004
   160        0.1381             nan     0.0500   -0.0010
   180        0.1320             nan     0.0500   -0.0002
   200        0.1254             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1919
     2        0.9845             nan     0.0500    0.1576
     3        0.8917             nan     0.0500    0.1305
     4        0.8125             nan     0.0500    0.1117
     5        0.7453             nan     0.0500    0.0947
     6        0.6868             nan     0.0500    0.0829
     7        0.6367             nan     0.0500    0.0719
     8        0.5936             nan     0.0500    0.0629
     9        0.5548             nan     0.0500    0.0537
    10        0.5204             nan     0.0500    0.0482
    20        0.3191             nan     0.0500    0.0160
    40        0.1933             nan     0.0500    0.0024
    60        0.1521             nan     0.0500   -0.0003
    80        0.1287             nan     0.0500   -0.0008
   100        0.1136             nan     0.0500    0.0002
   120        0.1025             nan     0.0500   -0.0012
   140        0.0925             nan     0.0500   -0.0003
   160        0.0853             nan     0.0500   -0.0003
   180        0.0796             nan     0.0500   -0.0005
   200        0.0745             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1976
     2        0.9812             nan     0.0500    0.1635
     3        0.8849             nan     0.0500    0.1394
     4        0.8031             nan     0.0500    0.1175
     5        0.7336             nan     0.0500    0.0999
     6        0.6738             nan     0.0500    0.0857
     7        0.6204             nan     0.0500    0.0759
     8        0.5736             nan     0.0500    0.0665
     9        0.5314             nan     0.0500    0.0584
    10        0.4956             nan     0.0500    0.0513
    20        0.2889             nan     0.0500    0.0235
    40        0.1599             nan     0.0500    0.0005
    60        0.1225             nan     0.0500   -0.0004
    80        0.1006             nan     0.0500   -0.0014
   100        0.0848             nan     0.0500   -0.0002
   120        0.0738             nan     0.0500   -0.0000
   140        0.0658             nan     0.0500   -0.0010
   160        0.0595             nan     0.0500   -0.0007
   180        0.0538             nan     0.0500   -0.0005
   200        0.0492             nan     0.0500   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2033
     2        0.9776             nan     0.0500    0.1710
     3        0.8773             nan     0.0500    0.1436
     4        0.7913             nan     0.0500    0.1211
     5        0.7184             nan     0.0500    0.1030
     6        0.6560             nan     0.0500    0.0916
     7        0.6005             nan     0.0500    0.0785
     8        0.5511             nan     0.0500    0.0673
     9        0.5095             nan     0.0500    0.0568
    10        0.4729             nan     0.0500    0.0535
    20        0.2575             nan     0.0500    0.0151
    40        0.1308             nan     0.0500    0.0041
    60        0.0899             nan     0.0500   -0.0013
    80        0.0702             nan     0.0500   -0.0000
   100        0.0575             nan     0.0500   -0.0008
   120        0.0491             nan     0.0500    0.0000
   140        0.0421             nan     0.0500   -0.0011
   160        0.0365             nan     0.0500   -0.0004
   180        0.0317             nan     0.0500   -0.0007
   200        0.0279             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3266
     2        0.8966             nan     0.1000    0.2209
     3        0.7600             nan     0.1000    0.1607
     4        0.6601             nan     0.1000    0.1197
     5        0.5849             nan     0.1000    0.0890
     6        0.5254             nan     0.1000    0.0683
     7        0.4800             nan     0.1000    0.0563
     8        0.4422             nan     0.1000    0.0445
     9        0.4132             nan     0.1000    0.0371
    10        0.3848             nan     0.1000    0.0335
    20        0.2647             nan     0.1000    0.0052
    40        0.1911             nan     0.1000    0.0001
    60        0.1588             nan     0.1000   -0.0027
    80        0.1413             nan     0.1000   -0.0017
   100        0.1276             nan     0.1000   -0.0022
   120        0.1180             nan     0.1000   -0.0017
   140        0.1105             nan     0.1000   -0.0005
   160        0.1045             nan     0.1000   -0.0018
   180        0.0988             nan     0.1000   -0.0031
   200        0.0945             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3586
     2        0.8860             nan     0.1000    0.2411
     3        0.7357             nan     0.1000    0.1715
     4        0.6293             nan     0.1000    0.1292
     5        0.5457             nan     0.1000    0.0974
     6        0.4814             nan     0.1000    0.0756
     7        0.4302             nan     0.1000    0.0621
     8        0.3897             nan     0.1000    0.0455
     9        0.3548             nan     0.1000    0.0373
    10        0.3282             nan     0.1000    0.0371
    20        0.1931             nan     0.1000    0.0026
    40        0.1312             nan     0.1000   -0.0013
    60        0.1023             nan     0.1000   -0.0012
    80        0.0841             nan     0.1000   -0.0013
   100        0.0719             nan     0.1000   -0.0010
   120        0.0634             nan     0.1000   -0.0015
   140        0.0566             nan     0.1000   -0.0023
   160        0.0510             nan     0.1000   -0.0013
   180        0.0465             nan     0.1000   -0.0010
   200        0.0424             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3683
     2        0.8728             nan     0.1000    0.2455
     3        0.7179             nan     0.1000    0.1766
     4        0.6050             nan     0.1000    0.1353
     5        0.5175             nan     0.1000    0.1017
     6        0.4522             nan     0.1000    0.0768
     7        0.3998             nan     0.1000    0.0641
     8        0.3578             nan     0.1000    0.0564
     9        0.3205             nan     0.1000    0.0355
    10        0.2933             nan     0.1000    0.0288
    20        0.1586             nan     0.1000    0.0064
    40        0.0971             nan     0.1000   -0.0031
    60        0.0755             nan     0.1000   -0.0017
    80        0.0600             nan     0.1000   -0.0013
   100        0.0484             nan     0.1000   -0.0019
   120        0.0407             nan     0.1000   -0.0014
   140        0.0356             nan     0.1000   -0.0013
   160        0.0308             nan     0.1000    0.0000
   180        0.0268             nan     0.1000   -0.0008
   200        0.0242             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3756
     2        0.8663             nan     0.1000    0.2575
     3        0.7032             nan     0.1000    0.1862
     4        0.5871             nan     0.1000    0.1390
     5        0.4978             nan     0.1000    0.1059
     6        0.4283             nan     0.1000    0.0830
     7        0.3736             nan     0.1000    0.0678
     8        0.3275             nan     0.1000    0.0440
     9        0.2936             nan     0.1000    0.0426
    10        0.2639             nan     0.1000    0.0293
    20        0.1324             nan     0.1000    0.0011
    40        0.0740             nan     0.1000   -0.0021
    60        0.0511             nan     0.1000   -0.0022
    80        0.0371             nan     0.1000   -0.0008
   100        0.0281             nan     0.1000   -0.0017
   120        0.0231             nan     0.1000   -0.0008
   140        0.0189             nan     0.1000   -0.0015
   160        0.0161             nan     0.1000   -0.0013
   180        0.0138             nan     0.1000   -0.0009
   200        0.0117             nan     0.1000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5404
     2        0.7313             nan     0.2000    0.2328
     3        0.5648             nan     0.2000    0.1435
     4        0.4648             nan     0.2000    0.0919
     5        0.4015             nan     0.2000    0.0570
     6        0.3563             nan     0.2000    0.0417
     7        0.3262             nan     0.2000    0.0262
     8        0.3063             nan     0.2000    0.0254
     9        0.2865             nan     0.2000    0.0213
    10        0.2712             nan     0.2000    0.0130
    20        0.1844             nan     0.2000    0.0048
    40        0.1366             nan     0.2000   -0.0024
    60        0.1175             nan     0.2000   -0.0045
    80        0.1053             nan     0.2000   -0.0003
   100        0.0964             nan     0.2000    0.0007
   120        0.0864             nan     0.2000   -0.0022
   140        0.0806             nan     0.2000   -0.0017
   160        0.0731             nan     0.2000   -0.0028
   180        0.0700             nan     0.2000   -0.0050
   200        0.0661             nan     0.2000   -0.0043

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5811
     2        0.7020             nan     0.2000    0.2554
     3        0.5138             nan     0.2000    0.1494
     4        0.4110             nan     0.2000    0.0802
     5        0.3430             nan     0.2000    0.0731
     6        0.2917             nan     0.2000    0.0370
     7        0.2595             nan     0.2000    0.0220
     8        0.2357             nan     0.2000    0.0244
     9        0.2174             nan     0.2000    0.0134
    10        0.1970             nan     0.2000    0.0085
    20        0.1315             nan     0.2000   -0.0026
    40        0.0884             nan     0.2000   -0.0062
    60        0.0665             nan     0.2000   -0.0022
    80        0.0543             nan     0.2000   -0.0023
   100        0.0427             nan     0.2000   -0.0027
   120        0.0360             nan     0.2000   -0.0024
   140        0.0318             nan     0.2000   -0.0015
   160        0.0282             nan     0.2000   -0.0015
   180        0.0241             nan     0.2000   -0.0022
   200        0.0211             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6181
     2        0.6885             nan     0.2000    0.2700
     3        0.4955             nan     0.2000    0.1583
     4        0.3818             nan     0.2000    0.1132
     5        0.3056             nan     0.2000    0.0473
     6        0.2608             nan     0.2000    0.0401
     7        0.2277             nan     0.2000    0.0328
     8        0.2004             nan     0.2000    0.0160
     9        0.1794             nan     0.2000    0.0090
    10        0.1676             nan     0.2000    0.0083
    20        0.1087             nan     0.2000   -0.0112
    40        0.0649             nan     0.2000   -0.0060
    60        0.0437             nan     0.2000   -0.0047
    80        0.0357             nan     0.2000   -0.0029
   100        0.0280             nan     0.2000   -0.0033
   120        0.0219             nan     0.2000   -0.0039
   140        0.0189             nan     0.2000   -0.0033
   160        0.0159             nan     0.2000   -0.0016
   180        0.0136             nan     0.2000   -0.0036
   200        0.0111             nan     0.2000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6293
     2        0.6646             nan     0.2000    0.2786
     3        0.4696             nan     0.2000    0.1546
     4        0.3561             nan     0.2000    0.0867
     5        0.2851             nan     0.2000    0.0679
     6        0.2322             nan     0.2000    0.0324
     7        0.1998             nan     0.2000    0.0187
     8        0.1784             nan     0.2000    0.0265
     9        0.1532             nan     0.2000    0.0103
    10        0.1388             nan     0.2000   -0.0006
    20        0.0771             nan     0.2000   -0.0040
    40        0.0431             nan     0.2000   -0.0045
    60        0.0254             nan     0.2000   -0.0030
    80        0.0169             nan     0.2000   -0.0016
   100        0.0133             nan     0.2000   -0.0024
   120        0.0099             nan     0.2000   -0.0028
   140        0.0081             nan     0.2000   -0.0014
   160        0.0067             nan     0.2000   -0.0017
   180        0.0058             nan     0.2000   -0.0021
   200        0.0056             nan     0.2000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1801
     2        0.9938             nan     0.0500    0.1466
     3        0.9089             nan     0.0500    0.1246
     4        0.8327             nan     0.0500    0.1056
     5        0.7694             nan     0.0500    0.0902
     6        0.7161             nan     0.0500    0.0775
     7        0.6694             nan     0.0500    0.0683
     8        0.6282             nan     0.0500    0.0578
     9        0.5911             nan     0.0500    0.0515
    10        0.5595             nan     0.0500    0.0431
    20        0.3792             nan     0.0500    0.0157
    40        0.2602             nan     0.0500    0.0038
    60        0.2120             nan     0.0500    0.0020
    80        0.1855             nan     0.0500    0.0003
   100        0.1671             nan     0.0500    0.0002
   120        0.1539             nan     0.0500    0.0001
   140        0.1441             nan     0.0500   -0.0001
   160        0.1354             nan     0.0500   -0.0009
   180        0.1284             nan     0.0500   -0.0000
   200        0.1233             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1927
     2        0.9864             nan     0.0500    0.1594
     3        0.8919             nan     0.0500    0.1295
     4        0.8156             nan     0.0500    0.1159
     5        0.7472             nan     0.0500    0.0989
     6        0.6886             nan     0.0500    0.0846
     7        0.6374             nan     0.0500    0.0728
     8        0.5919             nan     0.0500    0.0631
     9        0.5515             nan     0.0500    0.0550
    10        0.5161             nan     0.0500    0.0485
    20        0.3137             nan     0.0500    0.0194
    40        0.1870             nan     0.0500    0.0037
    60        0.1473             nan     0.0500    0.0007
    80        0.1242             nan     0.0500   -0.0001
   100        0.1081             nan     0.0500   -0.0017
   120        0.0975             nan     0.0500   -0.0010
   140        0.0896             nan     0.0500   -0.0014
   160        0.0820             nan     0.0500   -0.0003
   180        0.0762             nan     0.0500   -0.0011
   200        0.0720             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2011
     2        0.9805             nan     0.0500    0.1675
     3        0.8841             nan     0.0500    0.1388
     4        0.8016             nan     0.0500    0.1177
     5        0.7308             nan     0.0500    0.1029
     6        0.6690             nan     0.0500    0.0873
     7        0.6157             nan     0.0500    0.0748
     8        0.5690             nan     0.0500    0.0645
     9        0.5288             nan     0.0500    0.0598
    10        0.4916             nan     0.0500    0.0497
    20        0.2823             nan     0.0500    0.0134
    40        0.1545             nan     0.0500    0.0011
    60        0.1171             nan     0.0500   -0.0019
    80        0.0971             nan     0.0500   -0.0016
   100        0.0837             nan     0.0500   -0.0009
   120        0.0728             nan     0.0500   -0.0007
   140        0.0650             nan     0.0500   -0.0005
   160        0.0586             nan     0.0500   -0.0011
   180        0.0525             nan     0.0500   -0.0004
   200        0.0481             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2157
     2        0.9757             nan     0.0500    0.1676
     3        0.8750             nan     0.0500    0.1376
     4        0.7915             nan     0.0500    0.1205
     5        0.7189             nan     0.0500    0.1100
     6        0.6535             nan     0.0500    0.0892
     7        0.5989             nan     0.0500    0.0786
     8        0.5505             nan     0.0500    0.0694
     9        0.5077             nan     0.0500    0.0598
    10        0.4704             nan     0.0500    0.0519
    20        0.2580             nan     0.0500    0.0189
    40        0.1290             nan     0.0500    0.0013
    60        0.0910             nan     0.0500    0.0003
    80        0.0710             nan     0.0500   -0.0016
   100        0.0579             nan     0.0500   -0.0014
   120        0.0485             nan     0.0500   -0.0008
   140        0.0404             nan     0.0500   -0.0008
   160        0.0348             nan     0.0500   -0.0008
   180        0.0301             nan     0.0500   -0.0008
   200        0.0267             nan     0.0500   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3294
     2        0.8967             nan     0.1000    0.2265
     3        0.7611             nan     0.1000    0.1642
     4        0.6590             nan     0.1000    0.1204
     5        0.5836             nan     0.1000    0.0928
     6        0.5243             nan     0.1000    0.0708
     7        0.4791             nan     0.1000    0.0569
     8        0.4422             nan     0.1000    0.0444
     9        0.4117             nan     0.1000    0.0380
    10        0.3867             nan     0.1000    0.0280
    20        0.2596             nan     0.1000    0.0069
    40        0.1859             nan     0.1000    0.0018
    60        0.1536             nan     0.1000   -0.0001
    80        0.1366             nan     0.1000   -0.0024
   100        0.1252             nan     0.1000   -0.0003
   120        0.1137             nan     0.1000   -0.0024
   140        0.1069             nan     0.1000   -0.0026
   160        0.1011             nan     0.1000   -0.0015
   180        0.0940             nan     0.1000   -0.0007
   200        0.0903             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3592
     2        0.8842             nan     0.1000    0.2376
     3        0.7308             nan     0.1000    0.1772
     4        0.6220             nan     0.1000    0.1267
     5        0.5396             nan     0.1000    0.0983
     6        0.4770             nan     0.1000    0.0719
     7        0.4277             nan     0.1000    0.0586
     8        0.3875             nan     0.1000    0.0541
     9        0.3508             nan     0.1000    0.0410
    10        0.3223             nan     0.1000    0.0343
    20        0.1867             nan     0.1000    0.0029
    40        0.1272             nan     0.1000   -0.0017
    60        0.1004             nan     0.1000   -0.0019
    80        0.0829             nan     0.1000   -0.0008
   100        0.0734             nan     0.1000   -0.0017
   120        0.0646             nan     0.1000   -0.0013
   140        0.0572             nan     0.1000   -0.0001
   160        0.0512             nan     0.1000   -0.0009
   180        0.0462             nan     0.1000   -0.0009
   200        0.0423             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3725
     2        0.8723             nan     0.1000    0.2508
     3        0.7161             nan     0.1000    0.1827
     4        0.6019             nan     0.1000    0.1361
     5        0.5167             nan     0.1000    0.0999
     6        0.4517             nan     0.1000    0.0771
     7        0.3999             nan     0.1000    0.0642
     8        0.3563             nan     0.1000    0.0545
     9        0.3195             nan     0.1000    0.0456
    10        0.2875             nan     0.1000    0.0263
    20        0.1585             nan     0.1000    0.0048
    40        0.1015             nan     0.1000   -0.0027
    60        0.0793             nan     0.1000   -0.0007
    80        0.0620             nan     0.1000   -0.0013
   100        0.0505             nan     0.1000   -0.0004
   120        0.0422             nan     0.1000   -0.0011
   140        0.0361             nan     0.1000   -0.0010
   160        0.0321             nan     0.1000   -0.0004
   180        0.0278             nan     0.1000   -0.0011
   200        0.0242             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3815
     2        0.8628             nan     0.1000    0.2641
     3        0.6998             nan     0.1000    0.1850
     4        0.5842             nan     0.1000    0.1408
     5        0.4958             nan     0.1000    0.1058
     6        0.4254             nan     0.1000    0.0816
     7        0.3700             nan     0.1000    0.0642
     8        0.3264             nan     0.1000    0.0469
     9        0.2920             nan     0.1000    0.0404
    10        0.2629             nan     0.1000    0.0342
    20        0.1266             nan     0.1000    0.0037
    40        0.0722             nan     0.1000   -0.0023
    60        0.0487             nan     0.1000   -0.0025
    80        0.0357             nan     0.1000   -0.0022
   100        0.0272             nan     0.1000   -0.0023
   120        0.0217             nan     0.1000   -0.0013
   140        0.0179             nan     0.1000   -0.0005
   160        0.0147             nan     0.1000   -0.0010
   180        0.0126             nan     0.1000   -0.0010
   200        0.0109             nan     0.1000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5383
     2        0.7337             nan     0.2000    0.2551
     3        0.5582             nan     0.2000    0.1368
     4        0.4584             nan     0.2000    0.0787
     5        0.3978             nan     0.2000    0.0464
     6        0.3542             nan     0.2000    0.0414
     7        0.3242             nan     0.2000    0.0390
     8        0.2962             nan     0.2000    0.0194
     9        0.2769             nan     0.2000    0.0172
    10        0.2618             nan     0.2000    0.0139
    20        0.1896             nan     0.2000    0.0111
    40        0.1378             nan     0.2000   -0.0061
    60        0.1164             nan     0.2000   -0.0005
    80        0.0992             nan     0.2000   -0.0018
   100        0.0901             nan     0.2000   -0.0030
   120        0.0832             nan     0.2000   -0.0045
   140        0.0783             nan     0.2000   -0.0015
   160        0.0731             nan     0.2000   -0.0051
   180        0.0696             nan     0.2000   -0.0019
   200        0.0663             nan     0.2000   -0.0045

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5787
     2        0.6979             nan     0.2000    0.2754
     3        0.5188             nan     0.2000    0.1559
     4        0.4102             nan     0.2000    0.0858
     5        0.3370             nan     0.2000    0.0575
     6        0.2891             nan     0.2000    0.0366
     7        0.2566             nan     0.2000    0.0367
     8        0.2304             nan     0.2000    0.0247
     9        0.2110             nan     0.2000    0.0115
    10        0.1967             nan     0.2000    0.0139
    20        0.1277             nan     0.2000   -0.0093
    40        0.0838             nan     0.2000   -0.0061
    60        0.0632             nan     0.2000   -0.0044
    80        0.0515             nan     0.2000   -0.0032
   100        0.0418             nan     0.2000   -0.0019
   120        0.0348             nan     0.2000   -0.0042
   140        0.0301             nan     0.2000   -0.0024
   160        0.0278             nan     0.2000   -0.0012
   180        0.0249             nan     0.2000   -0.0019
   200        0.0225             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6181
     2        0.6896             nan     0.2000    0.2806
     3        0.4953             nan     0.2000    0.1449
     4        0.3842             nan     0.2000    0.1034
     5        0.3105             nan     0.2000    0.0801
     6        0.2500             nan     0.2000    0.0377
     7        0.2184             nan     0.2000    0.0254
     8        0.1934             nan     0.2000    0.0135
     9        0.1769             nan     0.2000    0.0051
    10        0.1614             nan     0.2000   -0.0081
    20        0.0934             nan     0.2000   -0.0161
    40        0.0609             nan     0.2000   -0.0096
    60        0.0433             nan     0.2000   -0.0037
    80        0.0325             nan     0.2000   -0.0010
   100        0.0248             nan     0.2000   -0.0025
   120        0.0192             nan     0.2000   -0.0010
   140        0.0161             nan     0.2000   -0.0036
   160        0.0136             nan     0.2000   -0.0026
   180        0.0114             nan     0.2000   -0.0010
   200        0.0099             nan     0.2000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6332
     2        0.6723             nan     0.2000    0.2988
     3        0.4689             nan     0.2000    0.1582
     4        0.3548             nan     0.2000    0.0990
     5        0.2793             nan     0.2000    0.0595
     6        0.2325             nan     0.2000    0.0248
     7        0.2024             nan     0.2000    0.0282
     8        0.1732             nan     0.2000    0.0049
     9        0.1575             nan     0.2000    0.0075
    10        0.1421             nan     0.2000    0.0078
    20        0.0774             nan     0.2000   -0.0020
    40        0.0383             nan     0.2000   -0.0011
    60        0.0226             nan     0.2000   -0.0015
    80        0.0157             nan     0.2000   -0.0022
   100        0.0114             nan     0.2000   -0.0011
   120        0.0088             nan     0.2000   -0.0009
   140        0.0077             nan     0.2000   -0.0038
   160        0.0065             nan     0.2000   -0.0005
   180        0.0062             nan     0.2000   -0.0033
   200        0.0048             nan     0.2000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1798
     2        0.9937             nan     0.0500    0.1471
     3        0.9067             nan     0.0500    0.1253
     4        0.8335             nan     0.0500    0.1063
     5        0.7715             nan     0.0500    0.0908
     6        0.7179             nan     0.0500    0.0784
     7        0.6714             nan     0.0500    0.0658
     8        0.6304             nan     0.0500    0.0566
     9        0.5949             nan     0.0500    0.0523
    10        0.5637             nan     0.0500    0.0450
    20        0.3818             nan     0.0500    0.0167
    40        0.2636             nan     0.0500    0.0060
    60        0.2153             nan     0.0500    0.0025
    80        0.1880             nan     0.0500    0.0025
   100        0.1696             nan     0.0500   -0.0002
   120        0.1582             nan     0.0500   -0.0012
   140        0.1484             nan     0.0500    0.0001
   160        0.1410             nan     0.0500   -0.0013
   180        0.1343             nan     0.0500   -0.0003
   200        0.1284             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1927
     2        0.9863             nan     0.0500    0.1586
     3        0.8907             nan     0.0500    0.1311
     4        0.8116             nan     0.0500    0.1113
     5        0.7452             nan     0.0500    0.0950
     6        0.6867             nan     0.0500    0.0811
     7        0.6367             nan     0.0500    0.0717
     8        0.5912             nan     0.0500    0.0620
     9        0.5523             nan     0.0500    0.0536
    10        0.5175             nan     0.0500    0.0479
    20        0.3165             nan     0.0500    0.0149
    40        0.1920             nan     0.0500    0.0026
    60        0.1524             nan     0.0500    0.0005
    80        0.1315             nan     0.0500    0.0006
   100        0.1159             nan     0.0500   -0.0006
   120        0.1045             nan     0.0500   -0.0006
   140        0.0942             nan     0.0500    0.0003
   160        0.0859             nan     0.0500   -0.0006
   180        0.0800             nan     0.0500   -0.0005
   200        0.0754             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1958
     2        0.9832             nan     0.0500    0.1638
     3        0.8883             nan     0.0500    0.1344
     4        0.8058             nan     0.0500    0.1181
     5        0.7344             nan     0.0500    0.1009
     6        0.6729             nan     0.0500    0.0865
     7        0.6199             nan     0.0500    0.0761
     8        0.5730             nan     0.0500    0.0684
     9        0.5312             nan     0.0500    0.0575
    10        0.4956             nan     0.0500    0.0494
    20        0.2859             nan     0.0500    0.0113
    40        0.1624             nan     0.0500    0.0017
    60        0.1249             nan     0.0500    0.0006
    80        0.1041             nan     0.0500   -0.0004
   100        0.0900             nan     0.0500   -0.0015
   120        0.0797             nan     0.0500   -0.0011
   140        0.0712             nan     0.0500   -0.0009
   160        0.0645             nan     0.0500   -0.0008
   180        0.0585             nan     0.0500   -0.0004
   200        0.0546             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2117
     2        0.9759             nan     0.0500    0.1728
     3        0.8764             nan     0.0500    0.1444
     4        0.7917             nan     0.0500    0.1108
     5        0.7213             nan     0.0500    0.1042
     6        0.6583             nan     0.0500    0.0940
     7        0.6014             nan     0.0500    0.0771
     8        0.5535             nan     0.0500    0.0686
     9        0.5106             nan     0.0500    0.0580
    10        0.4737             nan     0.0500    0.0506
    20        0.2614             nan     0.0500    0.0154
    40        0.1346             nan     0.0500   -0.0004
    60        0.0955             nan     0.0500   -0.0003
    80        0.0751             nan     0.0500   -0.0008
   100        0.0618             nan     0.0500   -0.0002
   120        0.0521             nan     0.0500   -0.0013
   140        0.0449             nan     0.0500   -0.0007
   160        0.0389             nan     0.0500   -0.0008
   180        0.0343             nan     0.0500   -0.0008
   200        0.0300             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3266
     2        0.8936             nan     0.1000    0.2170
     3        0.7581             nan     0.1000    0.1585
     4        0.6560             nan     0.1000    0.1185
     5        0.5805             nan     0.1000    0.0905
     6        0.5249             nan     0.1000    0.0677
     7        0.4782             nan     0.1000    0.0535
     8        0.4423             nan     0.1000    0.0449
     9        0.4129             nan     0.1000    0.0386
    10        0.3868             nan     0.1000    0.0323
    20        0.2597             nan     0.1000    0.0049
    40        0.1872             nan     0.1000   -0.0005
    60        0.1588             nan     0.1000   -0.0014
    80        0.1400             nan     0.1000    0.0001
   100        0.1253             nan     0.1000   -0.0021
   120        0.1184             nan     0.1000   -0.0012
   140        0.1115             nan     0.1000   -0.0006
   160        0.1054             nan     0.1000   -0.0012
   180        0.0992             nan     0.1000   -0.0008
   200        0.0952             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3519
     2        0.8837             nan     0.1000    0.2434
     3        0.7372             nan     0.1000    0.1780
     4        0.6278             nan     0.1000    0.1283
     5        0.5439             nan     0.1000    0.0962
     6        0.4801             nan     0.1000    0.0746
     7        0.4284             nan     0.1000    0.0635
     8        0.3866             nan     0.1000    0.0448
     9        0.3544             nan     0.1000    0.0365
    10        0.3274             nan     0.1000    0.0277
    20        0.1967             nan     0.1000    0.0031
    40        0.1344             nan     0.1000   -0.0003
    60        0.1074             nan     0.1000   -0.0007
    80        0.0900             nan     0.1000   -0.0025
   100        0.0780             nan     0.1000   -0.0007
   120        0.0686             nan     0.1000   -0.0025
   140        0.0598             nan     0.1000   -0.0008
   160        0.0536             nan     0.1000   -0.0009
   180        0.0477             nan     0.1000   -0.0003
   200        0.0439             nan     0.1000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3720
     2        0.8729             nan     0.1000    0.2505
     3        0.7182             nan     0.1000    0.1794
     4        0.6041             nan     0.1000    0.1344
     5        0.5185             nan     0.1000    0.1082
     6        0.4499             nan     0.1000    0.0779
     7        0.3984             nan     0.1000    0.0590
     8        0.3582             nan     0.1000    0.0429
     9        0.3268             nan     0.1000    0.0397
    10        0.2991             nan     0.1000    0.0268
    20        0.1634             nan     0.1000    0.0063
    40        0.1021             nan     0.1000   -0.0017
    60        0.0775             nan     0.1000   -0.0011
    80        0.0629             nan     0.1000   -0.0013
   100        0.0521             nan     0.1000   -0.0034
   120        0.0448             nan     0.1000   -0.0018
   140        0.0383             nan     0.1000   -0.0011
   160        0.0333             nan     0.1000   -0.0027
   180        0.0295             nan     0.1000   -0.0015
   200        0.0265             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3866
     2        0.8666             nan     0.1000    0.2477
     3        0.7086             nan     0.1000    0.1921
     4        0.5877             nan     0.1000    0.1394
     5        0.4984             nan     0.1000    0.1049
     6        0.4294             nan     0.1000    0.0859
     7        0.3739             nan     0.1000    0.0640
     8        0.3301             nan     0.1000    0.0504
     9        0.2961             nan     0.1000    0.0452
    10        0.2662             nan     0.1000    0.0301
    20        0.1359             nan     0.1000    0.0023
    40        0.0760             nan     0.1000   -0.0011
    60        0.0537             nan     0.1000   -0.0012
    80        0.0392             nan     0.1000   -0.0016
   100        0.0290             nan     0.1000   -0.0010
   120        0.0237             nan     0.1000   -0.0013
   140        0.0196             nan     0.1000   -0.0010
   160        0.0163             nan     0.1000   -0.0006
   180        0.0136             nan     0.1000   -0.0009
   200        0.0122             nan     0.1000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5416
     2        0.7292             nan     0.2000    0.2462
     3        0.5555             nan     0.2000    0.1416
     4        0.4615             nan     0.2000    0.0886
     5        0.4002             nan     0.2000    0.0599
     6        0.3565             nan     0.2000    0.0376
     7        0.3242             nan     0.2000    0.0293
     8        0.2988             nan     0.2000    0.0152
     9        0.2824             nan     0.2000    0.0072
    10        0.2728             nan     0.2000    0.0199
    20        0.1904             nan     0.2000   -0.0012
    40        0.1407             nan     0.2000   -0.0040
    60        0.1209             nan     0.2000   -0.0083
    80        0.1084             nan     0.2000   -0.0039
   100        0.0992             nan     0.2000   -0.0047
   120        0.0890             nan     0.2000   -0.0051
   140        0.0830             nan     0.2000   -0.0025
   160        0.0777             nan     0.2000   -0.0027
   180        0.0725             nan     0.2000   -0.0015
   200        0.0686             nan     0.2000   -0.0029

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5617
     2        0.7075             nan     0.2000    0.2670
     3        0.5206             nan     0.2000    0.1500
     4        0.4147             nan     0.2000    0.1057
     5        0.3405             nan     0.2000    0.0657
     6        0.2890             nan     0.2000    0.0323
     7        0.2595             nan     0.2000    0.0270
     8        0.2327             nan     0.2000    0.0175
     9        0.2144             nan     0.2000    0.0070
    10        0.2009             nan     0.2000    0.0034
    20        0.1325             nan     0.2000   -0.0101
    40        0.0870             nan     0.2000   -0.0053
    60        0.0669             nan     0.2000   -0.0074
    80        0.0528             nan     0.2000   -0.0017
   100        0.0431             nan     0.2000   -0.0011
   120        0.0358             nan     0.2000   -0.0032
   140        0.0306             nan     0.2000   -0.0011
   160        0.0260             nan     0.2000   -0.0025
   180        0.0239             nan     0.2000   -0.0006
   200        0.0209             nan     0.2000   -0.0037

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6158
     2        0.6915             nan     0.2000    0.2930
     3        0.4930             nan     0.2000    0.1634
     4        0.3779             nan     0.2000    0.0861
     5        0.3111             nan     0.2000    0.0635
     6        0.2640             nan     0.2000    0.0439
     7        0.2291             nan     0.2000    0.0334
     8        0.2004             nan     0.2000    0.0105
     9        0.1840             nan     0.2000    0.0101
    10        0.1710             nan     0.2000    0.0072
    20        0.1085             nan     0.2000   -0.0030
    40        0.0663             nan     0.2000   -0.0087
    60        0.0451             nan     0.2000   -0.0091
    80        0.0351             nan     0.2000   -0.0022
   100        0.0264             nan     0.2000   -0.0041
   120        0.0214             nan     0.2000   -0.0006
   140        0.0179             nan     0.2000   -0.0032
   160        0.0157             nan     0.2000   -0.0020
   180        0.0141             nan     0.2000   -0.0028
   200        0.0121             nan     0.2000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5957
     2        0.6763             nan     0.2000    0.2960
     3        0.4742             nan     0.2000    0.1622
     4        0.3576             nan     0.2000    0.0985
     5        0.2846             nan     0.2000    0.0429
     6        0.2399             nan     0.2000    0.0489
     7        0.1996             nan     0.2000    0.0211
     8        0.1732             nan     0.2000    0.0182
     9        0.1542             nan     0.2000   -0.0009
    10        0.1415             nan     0.2000    0.0005
    20        0.0841             nan     0.2000   -0.0036
    40        0.0444             nan     0.2000   -0.0018
    60        0.0279             nan     0.2000   -0.0028
    80        0.0190             nan     0.2000   -0.0037
   100        0.0144             nan     0.2000   -0.0019
   120        0.0105             nan     0.2000   -0.0024
   140        0.0083             nan     0.2000   -0.0018
   160        0.0068             nan     0.2000   -0.0004
   180        0.0053             nan     0.2000   -0.0034
   200        0.0046             nan     0.2000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1800
     2        0.9942             nan     0.0500    0.1489
     3        0.9060             nan     0.0500    0.1236
     4        0.8327             nan     0.0500    0.1039
     5        0.7737             nan     0.0500    0.0911
     6        0.7191             nan     0.0500    0.0773
     7        0.6722             nan     0.0500    0.0678
     8        0.6316             nan     0.0500    0.0600
     9        0.5949             nan     0.0500    0.0514
    10        0.5639             nan     0.0500    0.0418
    20        0.3833             nan     0.0500    0.0160
    40        0.2653             nan     0.0500    0.0034
    60        0.2177             nan     0.0500    0.0011
    80        0.1892             nan     0.0500    0.0012
   100        0.1691             nan     0.0500   -0.0007
   120        0.1564             nan     0.0500   -0.0005
   140        0.1465             nan     0.0500    0.0000
   160        0.1393             nan     0.0500    0.0002
   180        0.1324             nan     0.0500   -0.0009
   200        0.1272             nan     0.0500   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1942
     2        0.9855             nan     0.0500    0.1572
     3        0.8935             nan     0.0500    0.1357
     4        0.8140             nan     0.0500    0.1130
     5        0.7462             nan     0.0500    0.0967
     6        0.6859             nan     0.0500    0.0833
     7        0.6341             nan     0.0500    0.0732
     8        0.5894             nan     0.0500    0.0632
     9        0.5504             nan     0.0500    0.0563
    10        0.5160             nan     0.0500    0.0492
    20        0.3158             nan     0.0500    0.0160
    40        0.1902             nan     0.0500    0.0016
    60        0.1506             nan     0.0500   -0.0009
    80        0.1288             nan     0.0500   -0.0012
   100        0.1143             nan     0.0500    0.0000
   120        0.1021             nan     0.0500   -0.0008
   140        0.0928             nan     0.0500   -0.0005
   160        0.0858             nan     0.0500   -0.0005
   180        0.0788             nan     0.0500   -0.0006
   200        0.0736             nan     0.0500    0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2016
     2        0.9802             nan     0.0500    0.1630
     3        0.8835             nan     0.0500    0.1377
     4        0.8024             nan     0.0500    0.1172
     5        0.7303             nan     0.0500    0.1011
     6        0.6694             nan     0.0500    0.0858
     7        0.6164             nan     0.0500    0.0755
     8        0.5701             nan     0.0500    0.0640
     9        0.5294             nan     0.0500    0.0600
    10        0.4913             nan     0.0500    0.0494
    20        0.2845             nan     0.0500    0.0160
    40        0.1613             nan     0.0500   -0.0005
    60        0.1229             nan     0.0500   -0.0000
    80        0.1028             nan     0.0500   -0.0013
   100        0.0882             nan     0.0500   -0.0004
   120        0.0775             nan     0.0500   -0.0009
   140        0.0690             nan     0.0500   -0.0008
   160        0.0624             nan     0.0500   -0.0014
   180        0.0567             nan     0.0500   -0.0007
   200        0.0516             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2108
     2        0.9765             nan     0.0500    0.1706
     3        0.8758             nan     0.0500    0.1407
     4        0.7908             nan     0.0500    0.1226
     5        0.7167             nan     0.0500    0.1044
     6        0.6537             nan     0.0500    0.0925
     7        0.5980             nan     0.0500    0.0797
     8        0.5491             nan     0.0500    0.0659
     9        0.5075             nan     0.0500    0.0582
    10        0.4709             nan     0.0500    0.0505
    20        0.2600             nan     0.0500    0.0161
    40        0.1321             nan     0.0500    0.0012
    60        0.0935             nan     0.0500   -0.0002
    80        0.0727             nan     0.0500   -0.0009
   100        0.0605             nan     0.0500   -0.0004
   120        0.0497             nan     0.0500   -0.0011
   140        0.0416             nan     0.0500   -0.0011
   160        0.0358             nan     0.0500   -0.0004
   180        0.0313             nan     0.0500   -0.0006
   200        0.0278             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3312
     2        0.8971             nan     0.1000    0.2192
     3        0.7594             nan     0.1000    0.1609
     4        0.6579             nan     0.1000    0.1188
     5        0.5808             nan     0.1000    0.0892
     6        0.5227             nan     0.1000    0.0681
     7        0.4776             nan     0.1000    0.0551
     8        0.4421             nan     0.1000    0.0377
     9        0.4118             nan     0.1000    0.0370
    10        0.3850             nan     0.1000    0.0327
    20        0.2614             nan     0.1000    0.0043
    40        0.1897             nan     0.1000   -0.0020
    60        0.1562             nan     0.1000   -0.0004
    80        0.1387             nan     0.1000   -0.0007
   100        0.1275             nan     0.1000   -0.0012
   120        0.1164             nan     0.1000   -0.0019
   140        0.1099             nan     0.1000   -0.0009
   160        0.1043             nan     0.1000   -0.0022
   180        0.0986             nan     0.1000   -0.0016
   200        0.0949             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3536
     2        0.8801             nan     0.1000    0.2396
     3        0.7323             nan     0.1000    0.1742
     4        0.6225             nan     0.1000    0.1299
     5        0.5399             nan     0.1000    0.0967
     6        0.4787             nan     0.1000    0.0784
     7        0.4268             nan     0.1000    0.0618
     8        0.3863             nan     0.1000    0.0488
     9        0.3501             nan     0.1000    0.0381
    10        0.3216             nan     0.1000    0.0354
    20        0.1954             nan     0.1000    0.0098
    40        0.1321             nan     0.1000   -0.0009
    60        0.1026             nan     0.1000    0.0001
    80        0.0860             nan     0.1000   -0.0015
   100        0.0747             nan     0.1000   -0.0016
   120        0.0673             nan     0.1000   -0.0019
   140        0.0599             nan     0.1000   -0.0010
   160        0.0528             nan     0.1000   -0.0010
   180        0.0467             nan     0.1000   -0.0006
   200        0.0407             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3715
     2        0.8757             nan     0.1000    0.2541
     3        0.7200             nan     0.1000    0.1829
     4        0.6042             nan     0.1000    0.1348
     5        0.5174             nan     0.1000    0.1019
     6        0.4481             nan     0.1000    0.0790
     7        0.3937             nan     0.1000    0.0601
     8        0.3512             nan     0.1000    0.0486
     9        0.3167             nan     0.1000    0.0309
    10        0.2912             nan     0.1000    0.0320
    20        0.1611             nan     0.1000    0.0063
    40        0.0998             nan     0.1000   -0.0007
    60        0.0780             nan     0.1000   -0.0013
    80        0.0609             nan     0.1000   -0.0024
   100        0.0502             nan     0.1000   -0.0011
   120        0.0424             nan     0.1000   -0.0008
   140        0.0356             nan     0.1000   -0.0017
   160        0.0300             nan     0.1000   -0.0010
   180        0.0260             nan     0.1000   -0.0013
   200        0.0237             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3781
     2        0.8656             nan     0.1000    0.2589
     3        0.7027             nan     0.1000    0.1780
     4        0.5863             nan     0.1000    0.1407
     5        0.4975             nan     0.1000    0.1066
     6        0.4297             nan     0.1000    0.0818
     7        0.3770             nan     0.1000    0.0687
     8        0.3325             nan     0.1000    0.0535
     9        0.2963             nan     0.1000    0.0397
    10        0.2669             nan     0.1000    0.0270
    20        0.1347             nan     0.1000    0.0012
    40        0.0740             nan     0.1000   -0.0025
    60        0.0505             nan     0.1000   -0.0031
    80        0.0370             nan     0.1000   -0.0012
   100        0.0275             nan     0.1000   -0.0012
   120        0.0211             nan     0.1000   -0.0002
   140        0.0174             nan     0.1000   -0.0010
   160        0.0140             nan     0.1000   -0.0007
   180        0.0112             nan     0.1000   -0.0011
   200        0.0095             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5416
     2        0.7356             nan     0.2000    0.2591
     3        0.5626             nan     0.2000    0.1342
     4        0.4577             nan     0.2000    0.0846
     5        0.3987             nan     0.2000    0.0556
     6        0.3569             nan     0.2000    0.0405
     7        0.3250             nan     0.2000    0.0249
     8        0.3012             nan     0.2000    0.0254
     9        0.2805             nan     0.2000    0.0217
    10        0.2638             nan     0.2000    0.0058
    20        0.1915             nan     0.2000   -0.0111
    40        0.1406             nan     0.2000   -0.0012
    60        0.1199             nan     0.2000   -0.0013
    80        0.1063             nan     0.2000   -0.0053
   100        0.0968             nan     0.2000   -0.0008
   120        0.0893             nan     0.2000   -0.0030
   140        0.0815             nan     0.2000   -0.0039
   160        0.0747             nan     0.2000   -0.0029
   180        0.0704             nan     0.2000   -0.0029
   200        0.0674             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5617
     2        0.7037             nan     0.2000    0.2794
     3        0.5145             nan     0.2000    0.1473
     4        0.4080             nan     0.2000    0.0826
     5        0.3400             nan     0.2000    0.0718
     6        0.2874             nan     0.2000    0.0209
     7        0.2573             nan     0.2000    0.0323
     8        0.2299             nan     0.2000    0.0190
     9        0.2122             nan     0.2000    0.0141
    10        0.1971             nan     0.2000    0.0202
    20        0.1289             nan     0.2000   -0.0025
    40        0.0907             nan     0.2000   -0.0069
    60        0.0703             nan     0.2000   -0.0043
    80        0.0555             nan     0.2000   -0.0038
   100        0.0467             nan     0.2000   -0.0020
   120        0.0393             nan     0.2000   -0.0032
   140        0.0334             nan     0.2000   -0.0035
   160        0.0283             nan     0.2000   -0.0003
   180        0.0248             nan     0.2000   -0.0019
   200        0.0209             nan     0.2000   -0.0024

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5987
     2        0.6887             nan     0.2000    0.2767
     3        0.4953             nan     0.2000    0.1565
     4        0.3821             nan     0.2000    0.1009
     5        0.3082             nan     0.2000    0.0711
     6        0.2541             nan     0.2000    0.0295
     7        0.2232             nan     0.2000    0.0183
     8        0.2005             nan     0.2000    0.0220
     9        0.1789             nan     0.2000    0.0100
    10        0.1630             nan     0.2000    0.0014
    20        0.1062             nan     0.2000   -0.0020
    40        0.0650             nan     0.2000   -0.0032
    60        0.0465             nan     0.2000   -0.0040
    80        0.0336             nan     0.2000   -0.0023
   100        0.0263             nan     0.2000   -0.0018
   120        0.0198             nan     0.2000   -0.0022
   140        0.0162             nan     0.2000   -0.0024
   160        0.0136             nan     0.2000   -0.0007
   180        0.0107             nan     0.2000   -0.0023
   200        0.0092             nan     0.2000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6153
     2        0.6754             nan     0.2000    0.2753
     3        0.4713             nan     0.2000    0.1562
     4        0.3565             nan     0.2000    0.1043
     5        0.2823             nan     0.2000    0.0599
     6        0.2312             nan     0.2000    0.0326
     7        0.2011             nan     0.2000    0.0259
     8        0.1735             nan     0.2000    0.0089
     9        0.1570             nan     0.2000   -0.0011
    10        0.1460             nan     0.2000   -0.0098
    20        0.0814             nan     0.2000   -0.0032
    40        0.0396             nan     0.2000   -0.0030
    60        0.0227             nan     0.2000   -0.0016
    80        0.0149             nan     0.2000   -0.0021
   100        0.0102             nan     0.2000   -0.0015
   120        0.0076             nan     0.2000   -0.0004
   140        0.0057             nan     0.2000   -0.0004
   160        0.0044             nan     0.2000   -0.0015
   180        0.0034             nan     0.2000   -0.0019
   200        0.0029             nan     0.2000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1806
     2        0.9930             nan     0.0500    0.1499
     3        0.9058             nan     0.0500    0.1246
     4        0.8319             nan     0.0500    0.1083
     5        0.7690             nan     0.0500    0.0915
     6        0.7145             nan     0.0500    0.0789
     7        0.6674             nan     0.0500    0.0651
     8        0.6280             nan     0.0500    0.0588
     9        0.5924             nan     0.0500    0.0521
    10        0.5597             nan     0.0500    0.0460
    20        0.3781             nan     0.0500    0.0157
    40        0.2593             nan     0.0500    0.0065
    60        0.2136             nan     0.0500    0.0009
    80        0.1863             nan     0.0500    0.0005
   100        0.1683             nan     0.0500   -0.0002
   120        0.1541             nan     0.0500   -0.0004
   140        0.1448             nan     0.0500   -0.0004
   160        0.1358             nan     0.0500    0.0010
   180        0.1286             nan     0.0500   -0.0012
   200        0.1222             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1950
     2        0.9859             nan     0.0500    0.1613
     3        0.8910             nan     0.0500    0.1353
     4        0.8111             nan     0.0500    0.1143
     5        0.7433             nan     0.0500    0.0969
     6        0.6848             nan     0.0500    0.0829
     7        0.6346             nan     0.0500    0.0743
     8        0.5891             nan     0.0500    0.0642
     9        0.5501             nan     0.0500    0.0530
    10        0.5167             nan     0.0500    0.0449
    20        0.3165             nan     0.0500    0.0184
    40        0.1895             nan     0.0500    0.0020
    60        0.1492             nan     0.0500    0.0001
    80        0.1268             nan     0.0500   -0.0000
   100        0.1105             nan     0.0500   -0.0007
   120        0.0993             nan     0.0500   -0.0008
   140        0.0896             nan     0.0500   -0.0011
   160        0.0829             nan     0.0500   -0.0006
   180        0.0773             nan     0.0500   -0.0003
   200        0.0728             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2002
     2        0.9834             nan     0.0500    0.1656
     3        0.8838             nan     0.0500    0.1371
     4        0.8006             nan     0.0500    0.1179
     5        0.7303             nan     0.0500    0.1013
     6        0.6695             nan     0.0500    0.0874
     7        0.6167             nan     0.0500    0.0730
     8        0.5709             nan     0.0500    0.0669
     9        0.5298             nan     0.0500    0.0558
    10        0.4951             nan     0.0500    0.0468
    20        0.2883             nan     0.0500    0.0176
    40        0.1577             nan     0.0500    0.0013
    60        0.1199             nan     0.0500   -0.0008
    80        0.0985             nan     0.0500    0.0000
   100        0.0852             nan     0.0500   -0.0012
   120        0.0753             nan     0.0500   -0.0005
   140        0.0670             nan     0.0500   -0.0007
   160        0.0605             nan     0.0500   -0.0006
   180        0.0543             nan     0.0500   -0.0003
   200        0.0498             nan     0.0500   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2059
     2        0.9771             nan     0.0500    0.1723
     3        0.8766             nan     0.0500    0.1448
     4        0.7919             nan     0.0500    0.1213
     5        0.7171             nan     0.0500    0.1059
     6        0.6536             nan     0.0500    0.0933
     7        0.5973             nan     0.0500    0.0755
     8        0.5493             nan     0.0500    0.0674
     9        0.5070             nan     0.0500    0.0600
    10        0.4685             nan     0.0500    0.0499
    20        0.2577             nan     0.0500    0.0141
    40        0.1298             nan     0.0500    0.0015
    60        0.0918             nan     0.0500    0.0001
    80        0.0715             nan     0.0500   -0.0013
   100        0.0583             nan     0.0500   -0.0005
   120        0.0489             nan     0.0500   -0.0014
   140        0.0414             nan     0.0500   -0.0008
   160        0.0349             nan     0.0500   -0.0010
   180        0.0299             nan     0.0500   -0.0001
   200        0.0266             nan     0.0500   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3342
     2        0.8918             nan     0.1000    0.2231
     3        0.7536             nan     0.1000    0.1609
     4        0.6538             nan     0.1000    0.1186
     5        0.5767             nan     0.1000    0.0863
     6        0.5185             nan     0.1000    0.0685
     7        0.4724             nan     0.1000    0.0556
     8        0.4343             nan     0.1000    0.0383
     9        0.4060             nan     0.1000    0.0366
    10        0.3818             nan     0.1000    0.0297
    20        0.2589             nan     0.1000    0.0048
    40        0.1865             nan     0.1000    0.0044
    60        0.1583             nan     0.1000    0.0009
    80        0.1396             nan     0.1000   -0.0002
   100        0.1275             nan     0.1000   -0.0013
   120        0.1186             nan     0.1000   -0.0009
   140        0.1107             nan     0.1000   -0.0011
   160        0.1060             nan     0.1000   -0.0017
   180        0.0994             nan     0.1000   -0.0019
   200        0.0932             nan     0.1000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3606
     2        0.8820             nan     0.1000    0.2408
     3        0.7306             nan     0.1000    0.1652
     4        0.6262             nan     0.1000    0.1339
     5        0.5402             nan     0.1000    0.0950
     6        0.4776             nan     0.1000    0.0753
     7        0.4269             nan     0.1000    0.0654
     8        0.3839             nan     0.1000    0.0494
     9        0.3494             nan     0.1000    0.0328
    10        0.3226             nan     0.1000    0.0361
    20        0.1942             nan     0.1000    0.0077
    40        0.1259             nan     0.1000   -0.0021
    60        0.0981             nan     0.1000   -0.0023
    80        0.0841             nan     0.1000   -0.0012
   100        0.0729             nan     0.1000   -0.0007
   120        0.0654             nan     0.1000   -0.0021
   140        0.0575             nan     0.1000   -0.0022
   160        0.0520             nan     0.1000   -0.0018
   180        0.0463             nan     0.1000   -0.0015
   200        0.0430             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3694
     2        0.8712             nan     0.1000    0.2458
     3        0.7186             nan     0.1000    0.1752
     4        0.6069             nan     0.1000    0.1375
     5        0.5189             nan     0.1000    0.1066
     6        0.4506             nan     0.1000    0.0813
     7        0.3975             nan     0.1000    0.0618
     8        0.3564             nan     0.1000    0.0518
     9        0.3216             nan     0.1000    0.0389
    10        0.2939             nan     0.1000    0.0370
    20        0.1621             nan     0.1000    0.0039
    40        0.1022             nan     0.1000   -0.0007
    60        0.0781             nan     0.1000   -0.0010
    80        0.0633             nan     0.1000   -0.0007
   100        0.0505             nan     0.1000   -0.0013
   120        0.0427             nan     0.1000   -0.0006
   140        0.0354             nan     0.1000   -0.0013
   160        0.0303             nan     0.1000   -0.0014
   180        0.0270             nan     0.1000   -0.0003
   200        0.0238             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3721
     2        0.8717             nan     0.1000    0.2681
     3        0.7057             nan     0.1000    0.1845
     4        0.5884             nan     0.1000    0.1336
     5        0.5012             nan     0.1000    0.1003
     6        0.4329             nan     0.1000    0.0771
     7        0.3811             nan     0.1000    0.0647
     8        0.3366             nan     0.1000    0.0496
     9        0.3008             nan     0.1000    0.0455
    10        0.2714             nan     0.1000    0.0310
    20        0.1360             nan     0.1000    0.0046
    40        0.0769             nan     0.1000   -0.0021
    60        0.0497             nan     0.1000   -0.0005
    80        0.0367             nan     0.1000   -0.0016
   100        0.0288             nan     0.1000   -0.0021
   120        0.0221             nan     0.1000   -0.0008
   140        0.0173             nan     0.1000   -0.0009
   160        0.0143             nan     0.1000   -0.0003
   180        0.0120             nan     0.1000   -0.0006
   200        0.0098             nan     0.1000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5473
     2        0.7292             nan     0.2000    0.2503
     3        0.5578             nan     0.2000    0.1355
     4        0.4599             nan     0.2000    0.0759
     5        0.3992             nan     0.2000    0.0544
     6        0.3573             nan     0.2000    0.0420
     7        0.3258             nan     0.2000    0.0257
     8        0.3023             nan     0.2000    0.0313
     9        0.2830             nan     0.2000    0.0237
    10        0.2656             nan     0.2000    0.0150
    20        0.1817             nan     0.2000    0.0001
    40        0.1346             nan     0.2000   -0.0026
    60        0.1144             nan     0.2000   -0.0057
    80        0.1031             nan     0.2000   -0.0039
   100        0.0913             nan     0.2000   -0.0051
   120        0.0864             nan     0.2000   -0.0041
   140        0.0775             nan     0.2000   -0.0095
   160        0.0730             nan     0.2000   -0.0014
   180        0.0683             nan     0.2000   -0.0007
   200        0.0640             nan     0.2000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6006
     2        0.7089             nan     0.2000    0.2811
     3        0.5174             nan     0.2000    0.1435
     4        0.4095             nan     0.2000    0.0954
     5        0.3380             nan     0.2000    0.0724
     6        0.2877             nan     0.2000    0.0440
     7        0.2479             nan     0.2000    0.0282
     8        0.2249             nan     0.2000    0.0132
     9        0.2088             nan     0.2000    0.0115
    10        0.1931             nan     0.2000    0.0033
    20        0.1323             nan     0.2000   -0.0030
    40        0.0883             nan     0.2000   -0.0008
    60        0.0664             nan     0.2000   -0.0044
    80        0.0506             nan     0.2000   -0.0083
   100        0.0414             nan     0.2000   -0.0029
   120        0.0345             nan     0.2000   -0.0039
   140        0.0285             nan     0.2000   -0.0022
   160        0.0239             nan     0.2000   -0.0018
   180        0.0203             nan     0.2000   -0.0006
   200        0.0180             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6175
     2        0.6871             nan     0.2000    0.2650
     3        0.4967             nan     0.2000    0.1568
     4        0.3841             nan     0.2000    0.0896
     5        0.3119             nan     0.2000    0.0552
     6        0.2650             nan     0.2000    0.0514
     7        0.2271             nan     0.2000    0.0209
     8        0.2043             nan     0.2000    0.0099
     9        0.1857             nan     0.2000    0.0040
    10        0.1723             nan     0.2000   -0.0079
    20        0.1037             nan     0.2000   -0.0015
    40        0.0665             nan     0.2000   -0.0022
    60        0.0464             nan     0.2000   -0.0057
    80        0.0335             nan     0.2000   -0.0016
   100        0.0268             nan     0.2000   -0.0009
   120        0.0192             nan     0.2000   -0.0007
   140        0.0150             nan     0.2000   -0.0022
   160        0.0122             nan     0.2000   -0.0008
   180        0.0102             nan     0.2000   -0.0009
   200        0.0084             nan     0.2000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6237
     2        0.6750             nan     0.2000    0.2954
     3        0.4726             nan     0.2000    0.1508
     4        0.3621             nan     0.2000    0.1041
     5        0.2839             nan     0.2000    0.0626
     6        0.2351             nan     0.2000    0.0457
     7        0.1925             nan     0.2000    0.0288
     8        0.1674             nan     0.2000    0.0133
     9        0.1496             nan     0.2000    0.0055
    10        0.1376             nan     0.2000    0.0037
    20        0.0804             nan     0.2000   -0.0045
    40        0.0402             nan     0.2000   -0.0026
    60        0.0243             nan     0.2000   -0.0036
    80        0.0160             nan     0.2000   -0.0036
   100        0.0110             nan     0.2000   -0.0023
   120        0.0085             nan     0.2000   -0.0029
   140        0.0065             nan     0.2000   -0.0005
   160        0.0053             nan     0.2000   -0.0014
   180        0.0039             nan     0.2000   -0.0016
   200        0.0031             nan     0.2000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1783
     2        0.9956             nan     0.0500    0.1514
     3        0.9082             nan     0.0500    0.1253
     4        0.8324             nan     0.0500    0.1084
     5        0.7697             nan     0.0500    0.0923
     6        0.7152             nan     0.0500    0.0762
     7        0.6681             nan     0.0500    0.0682
     8        0.6269             nan     0.0500    0.0601
     9        0.5909             nan     0.0500    0.0524
    10        0.5574             nan     0.0500    0.0450
    20        0.3731             nan     0.0500    0.0136
    40        0.2509             nan     0.0500    0.0028
    60        0.2036             nan     0.0500    0.0002
    80        0.1782             nan     0.0500    0.0000
   100        0.1609             nan     0.0500    0.0018
   120        0.1485             nan     0.0500   -0.0001
   140        0.1380             nan     0.0500   -0.0007
   160        0.1307             nan     0.0500   -0.0018
   180        0.1241             nan     0.0500   -0.0006
   200        0.1193             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1944
     2        0.9857             nan     0.0500    0.1606
     3        0.8907             nan     0.0500    0.1335
     4        0.8113             nan     0.0500    0.1131
     5        0.7442             nan     0.0500    0.0962
     6        0.6838             nan     0.0500    0.0810
     7        0.6348             nan     0.0500    0.0741
     8        0.5891             nan     0.0500    0.0604
     9        0.5495             nan     0.0500    0.0563
    10        0.5145             nan     0.0500    0.0495
    20        0.3082             nan     0.0500    0.0195
    40        0.1828             nan     0.0500    0.0018
    60        0.1422             nan     0.0500    0.0008
    80        0.1191             nan     0.0500   -0.0001
   100        0.1045             nan     0.0500   -0.0009
   120        0.0934             nan     0.0500   -0.0002
   140        0.0842             nan     0.0500   -0.0010
   160        0.0772             nan     0.0500   -0.0010
   180        0.0709             nan     0.0500   -0.0011
   200        0.0646             nan     0.0500   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1997
     2        0.9804             nan     0.0500    0.1672
     3        0.8809             nan     0.0500    0.1373
     4        0.7973             nan     0.0500    0.1197
     5        0.7250             nan     0.0500    0.1002
     6        0.6640             nan     0.0500    0.0874
     7        0.6116             nan     0.0500    0.0742
     8        0.5649             nan     0.0500    0.0643
     9        0.5242             nan     0.0500    0.0572
    10        0.4878             nan     0.0500    0.0509
    20        0.2783             nan     0.0500    0.0169
    40        0.1555             nan     0.0500    0.0014
    60        0.1144             nan     0.0500    0.0002
    80        0.0935             nan     0.0500    0.0000
   100        0.0783             nan     0.0500   -0.0002
   120        0.0671             nan     0.0500   -0.0004
   140        0.0586             nan     0.0500   -0.0007
   160        0.0517             nan     0.0500   -0.0004
   180        0.0469             nan     0.0500   -0.0002
   200        0.0417             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2042
     2        0.9762             nan     0.0500    0.1666
     3        0.8773             nan     0.0500    0.1460
     4        0.7897             nan     0.0500    0.1269
     5        0.7122             nan     0.0500    0.1061
     6        0.6486             nan     0.0500    0.0938
     7        0.5925             nan     0.0500    0.0791
     8        0.5439             nan     0.0500    0.0691
     9        0.5002             nan     0.0500    0.0619
    10        0.4619             nan     0.0500    0.0513
    20        0.2479             nan     0.0500    0.0142
    40        0.1248             nan     0.0500    0.0006
    60        0.0853             nan     0.0500   -0.0000
    80        0.0646             nan     0.0500   -0.0000
   100        0.0506             nan     0.0500   -0.0011
   120        0.0419             nan     0.0500   -0.0004
   140        0.0352             nan     0.0500   -0.0008
   160        0.0299             nan     0.0500   -0.0006
   180        0.0253             nan     0.0500   -0.0005
   200        0.0219             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3355
     2        0.9014             nan     0.1000    0.2308
     3        0.7596             nan     0.1000    0.1649
     4        0.6576             nan     0.1000    0.1164
     5        0.5840             nan     0.1000    0.0900
     6        0.5258             nan     0.1000    0.0693
     7        0.4778             nan     0.1000    0.0597
     8        0.4380             nan     0.1000    0.0425
     9        0.4073             nan     0.1000    0.0417
    10        0.3802             nan     0.1000    0.0331
    20        0.2515             nan     0.1000    0.0074
    40        0.1776             nan     0.1000    0.0020
    60        0.1462             nan     0.1000   -0.0002
    80        0.1310             nan     0.1000   -0.0011
   100        0.1198             nan     0.1000   -0.0010
   120        0.1075             nan     0.1000   -0.0019
   140        0.1020             nan     0.1000   -0.0006
   160        0.0937             nan     0.1000   -0.0009
   180        0.0873             nan     0.1000   -0.0010
   200        0.0825             nan     0.1000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3525
     2        0.8820             nan     0.1000    0.2401
     3        0.7331             nan     0.1000    0.1725
     4        0.6231             nan     0.1000    0.1258
     5        0.5404             nan     0.1000    0.0990
     6        0.4748             nan     0.1000    0.0726
     7        0.4238             nan     0.1000    0.0640
     8        0.3807             nan     0.1000    0.0510
     9        0.3461             nan     0.1000    0.0364
    10        0.3187             nan     0.1000    0.0361
    20        0.1847             nan     0.1000    0.0062
    40        0.1183             nan     0.1000   -0.0009
    60        0.0943             nan     0.1000    0.0007
    80        0.0759             nan     0.1000   -0.0042
   100        0.0641             nan     0.1000   -0.0027
   120        0.0562             nan     0.1000   -0.0010
   140        0.0491             nan     0.1000   -0.0011
   160        0.0423             nan     0.1000   -0.0007
   180        0.0381             nan     0.1000   -0.0012
   200        0.0344             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3593
     2        0.8759             nan     0.1000    0.2502
     3        0.7216             nan     0.1000    0.1737
     4        0.6055             nan     0.1000    0.1284
     5        0.5156             nan     0.1000    0.1013
     6        0.4475             nan     0.1000    0.0867
     7        0.3928             nan     0.1000    0.0643
     8        0.3471             nan     0.1000    0.0459
     9        0.3140             nan     0.1000    0.0413
    10        0.2852             nan     0.1000    0.0314
    20        0.1594             nan     0.1000    0.0001
    40        0.0979             nan     0.1000    0.0012
    60        0.0731             nan     0.1000   -0.0015
    80        0.0569             nan     0.1000   -0.0002
   100        0.0453             nan     0.1000   -0.0020
   120        0.0374             nan     0.1000   -0.0006
   140        0.0310             nan     0.1000   -0.0014
   160        0.0262             nan     0.1000   -0.0006
   180        0.0228             nan     0.1000   -0.0011
   200        0.0200             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3863
     2        0.8633             nan     0.1000    0.2628
     3        0.6996             nan     0.1000    0.1848
     4        0.5801             nan     0.1000    0.1301
     5        0.4931             nan     0.1000    0.1024
     6        0.4248             nan     0.1000    0.0877
     7        0.3671             nan     0.1000    0.0647
     8        0.3239             nan     0.1000    0.0518
     9        0.2880             nan     0.1000    0.0377
    10        0.2596             nan     0.1000    0.0331
    20        0.1264             nan     0.1000    0.0033
    40        0.0671             nan     0.1000    0.0002
    60        0.0443             nan     0.1000   -0.0016
    80        0.0310             nan     0.1000   -0.0005
   100        0.0229             nan     0.1000   -0.0014
   120        0.0180             nan     0.1000   -0.0015
   140        0.0146             nan     0.1000   -0.0006
   160        0.0119             nan     0.1000   -0.0009
   180        0.0098             nan     0.1000   -0.0003
   200        0.0084             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5462
     2        0.7282             nan     0.2000    0.2516
     3        0.5577             nan     0.2000    0.1348
     4        0.4532             nan     0.2000    0.0891
     5        0.3926             nan     0.2000    0.0544
     6        0.3479             nan     0.2000    0.0364
     7        0.3210             nan     0.2000    0.0347
     8        0.2918             nan     0.2000    0.0282
     9        0.2675             nan     0.2000    0.0151
    10        0.2534             nan     0.2000    0.0134
    20        0.1781             nan     0.2000    0.0009
    40        0.1317             nan     0.2000   -0.0049
    60        0.1104             nan     0.2000   -0.0051
    80        0.0998             nan     0.2000   -0.0013
   100        0.0912             nan     0.2000   -0.0020
   120        0.0804             nan     0.2000   -0.0015
   140        0.0740             nan     0.2000   -0.0065
   160        0.0694             nan     0.2000   -0.0030
   180        0.0636             nan     0.2000   -0.0023
   200        0.0594             nan     0.2000   -0.0029

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5663
     2        0.6977             nan     0.2000    0.2615
     3        0.5168             nan     0.2000    0.1612
     4        0.4026             nan     0.2000    0.0971
     5        0.3319             nan     0.2000    0.0620
     6        0.2844             nan     0.2000    0.0247
     7        0.2544             nan     0.2000    0.0358
     8        0.2247             nan     0.2000    0.0215
     9        0.2049             nan     0.2000    0.0202
    10        0.1868             nan     0.2000   -0.0078
    20        0.1277             nan     0.2000    0.0013
    40        0.0763             nan     0.2000   -0.0004
    60        0.0579             nan     0.2000    0.0003
    80        0.0443             nan     0.2000   -0.0023
   100        0.0355             nan     0.2000   -0.0017
   120        0.0277             nan     0.2000   -0.0010
   140        0.0231             nan     0.2000   -0.0009
   160        0.0203             nan     0.2000   -0.0021
   180        0.0177             nan     0.2000   -0.0021
   200        0.0159             nan     0.2000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5846
     2        0.6969             nan     0.2000    0.2882
     3        0.4932             nan     0.2000    0.1481
     4        0.3809             nan     0.2000    0.1119
     5        0.3046             nan     0.2000    0.0600
     6        0.2543             nan     0.2000    0.0615
     7        0.2098             nan     0.2000    0.0245
     8        0.1844             nan     0.2000    0.0199
     9        0.1663             nan     0.2000   -0.0020
    10        0.1542             nan     0.2000   -0.0130
    20        0.0957             nan     0.2000   -0.0047
    40        0.0552             nan     0.2000   -0.0044
    60        0.0363             nan     0.2000   -0.0029
    80        0.0263             nan     0.2000   -0.0011
   100        0.0207             nan     0.2000   -0.0016
   120        0.0156             nan     0.2000   -0.0018
   140        0.0132             nan     0.2000   -0.0025
   160        0.0113             nan     0.2000   -0.0010
   180        0.0096             nan     0.2000   -0.0016
   200        0.0084             nan     0.2000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6397
     2        0.6721             nan     0.2000    0.2985
     3        0.4665             nan     0.2000    0.1688
     4        0.3422             nan     0.2000    0.0904
     5        0.2722             nan     0.2000    0.0599
     6        0.2258             nan     0.2000    0.0240
     7        0.1991             nan     0.2000    0.0261
     8        0.1729             nan     0.2000    0.0181
     9        0.1514             nan     0.2000    0.0070
    10        0.1363             nan     0.2000    0.0021
    20        0.0705             nan     0.2000   -0.0063
    40        0.0334             nan     0.2000   -0.0010
    60        0.0195             nan     0.2000   -0.0020
    80        0.0126             nan     0.2000   -0.0027
   100        0.0095             nan     0.2000   -0.0034
   120        0.0075             nan     0.2000   -0.0010
   140        0.0057             nan     0.2000   -0.0018
   160        0.0050             nan     0.2000   -0.0002
   180        0.0042             nan     0.2000   -0.0023
   200        0.0037             nan     0.2000   -0.0039

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1799
     2        0.9948             nan     0.0500    0.1476
     3        0.9074             nan     0.0500    0.1237
     4        0.8325             nan     0.0500    0.1023
     5        0.7697             nan     0.0500    0.0890
     6        0.7174             nan     0.0500    0.0782
     7        0.6703             nan     0.0500    0.0666
     8        0.6297             nan     0.0500    0.0579
     9        0.5942             nan     0.0500    0.0504
    10        0.5634             nan     0.0500    0.0415
    20        0.3822             nan     0.0500    0.0129
    40        0.2677             nan     0.0500    0.0049
    60        0.2184             nan     0.0500    0.0020
    80        0.1919             nan     0.0500    0.0007
   100        0.1720             nan     0.0500   -0.0004
   120        0.1597             nan     0.0500    0.0000
   140        0.1500             nan     0.0500   -0.0004
   160        0.1421             nan     0.0500   -0.0008
   180        0.1359             nan     0.0500   -0.0022
   200        0.1302             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1912
     2        0.9863             nan     0.0500    0.1565
     3        0.8943             nan     0.0500    0.1340
     4        0.8137             nan     0.0500    0.1127
     5        0.7448             nan     0.0500    0.0954
     6        0.6869             nan     0.0500    0.0830
     7        0.6352             nan     0.0500    0.0718
     8        0.5909             nan     0.0500    0.0609
     9        0.5525             nan     0.0500    0.0564
    10        0.5183             nan     0.0500    0.0464
    20        0.3188             nan     0.0500    0.0199
    40        0.1928             nan     0.0500    0.0019
    60        0.1553             nan     0.0500    0.0002
    80        0.1335             nan     0.0500   -0.0006
   100        0.1189             nan     0.0500   -0.0004
   120        0.1069             nan     0.0500   -0.0003
   140        0.0977             nan     0.0500   -0.0006
   160        0.0909             nan     0.0500   -0.0010
   180        0.0850             nan     0.0500   -0.0010
   200        0.0785             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1999
     2        0.9830             nan     0.0500    0.1628
     3        0.8857             nan     0.0500    0.1362
     4        0.8018             nan     0.0500    0.1173
     5        0.7318             nan     0.0500    0.0983
     6        0.6726             nan     0.0500    0.0869
     7        0.6179             nan     0.0500    0.0762
     8        0.5707             nan     0.0500    0.0625
     9        0.5312             nan     0.0500    0.0578
    10        0.4952             nan     0.0500    0.0514
    20        0.2888             nan     0.0500    0.0139
    40        0.1646             nan     0.0500    0.0017
    60        0.1260             nan     0.0500    0.0002
    80        0.1044             nan     0.0500   -0.0015
   100        0.0909             nan     0.0500   -0.0005
   120        0.0790             nan     0.0500   -0.0011
   140        0.0701             nan     0.0500   -0.0007
   160        0.0638             nan     0.0500   -0.0006
   180        0.0579             nan     0.0500   -0.0005
   200        0.0531             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2053
     2        0.9777             nan     0.0500    0.1738
     3        0.8758             nan     0.0500    0.1435
     4        0.7909             nan     0.0500    0.1218
     5        0.7180             nan     0.0500    0.1021
     6        0.6562             nan     0.0500    0.0916
     7        0.6013             nan     0.0500    0.0797
     8        0.5521             nan     0.0500    0.0693
     9        0.5095             nan     0.0500    0.0613
    10        0.4710             nan     0.0500    0.0530
    20        0.2584             nan     0.0500    0.0156
    40        0.1365             nan     0.0500    0.0010
    60        0.0959             nan     0.0500   -0.0009
    80        0.0755             nan     0.0500   -0.0009
   100        0.0616             nan     0.0500   -0.0012
   120        0.0517             nan     0.0500   -0.0007
   140        0.0446             nan     0.0500   -0.0006
   160        0.0386             nan     0.0500   -0.0011
   180        0.0332             nan     0.0500   -0.0005
   200        0.0289             nan     0.0500   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3290
     2        0.9003             nan     0.1000    0.2241
     3        0.7635             nan     0.1000    0.1601
     4        0.6650             nan     0.1000    0.1229
     5        0.5899             nan     0.1000    0.0882
     6        0.5299             nan     0.1000    0.0671
     7        0.4844             nan     0.1000    0.0574
     8        0.4464             nan     0.1000    0.0441
     9        0.4173             nan     0.1000    0.0360
    10        0.3913             nan     0.1000    0.0317
    20        0.2640             nan     0.1000    0.0073
    40        0.1951             nan     0.1000    0.0009
    60        0.1640             nan     0.1000   -0.0012
    80        0.1485             nan     0.1000    0.0015
   100        0.1333             nan     0.1000   -0.0039
   120        0.1230             nan     0.1000   -0.0041
   140        0.1146             nan     0.1000   -0.0021
   160        0.1085             nan     0.1000   -0.0016
   180        0.1025             nan     0.1000   -0.0022
   200        0.0986             nan     0.1000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3446
     2        0.8822             nan     0.1000    0.2353
     3        0.7323             nan     0.1000    0.1724
     4        0.6255             nan     0.1000    0.1248
     5        0.5449             nan     0.1000    0.0974
     6        0.4810             nan     0.1000    0.0813
     7        0.4304             nan     0.1000    0.0580
     8        0.3896             nan     0.1000    0.0457
     9        0.3567             nan     0.1000    0.0425
    10        0.3278             nan     0.1000    0.0321
    20        0.1952             nan     0.1000    0.0064
    40        0.1340             nan     0.1000    0.0012
    60        0.1084             nan     0.1000   -0.0026
    80        0.0921             nan     0.1000   -0.0015
   100        0.0801             nan     0.1000   -0.0022
   120        0.0708             nan     0.1000   -0.0018
   140        0.0605             nan     0.1000   -0.0018
   160        0.0550             nan     0.1000   -0.0016
   180        0.0494             nan     0.1000   -0.0013
   200        0.0444             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3685
     2        0.8734             nan     0.1000    0.2465
     3        0.7190             nan     0.1000    0.1785
     4        0.6045             nan     0.1000    0.1281
     5        0.5192             nan     0.1000    0.1055
     6        0.4520             nan     0.1000    0.0779
     7        0.3990             nan     0.1000    0.0683
     8        0.3534             nan     0.1000    0.0430
     9        0.3210             nan     0.1000    0.0427
    10        0.2913             nan     0.1000    0.0304
    20        0.1659             nan     0.1000    0.0043
    40        0.1067             nan     0.1000   -0.0015
    60        0.0814             nan     0.1000   -0.0018
    80        0.0677             nan     0.1000   -0.0015
   100        0.0559             nan     0.1000   -0.0001
   120        0.0476             nan     0.1000   -0.0016
   140        0.0392             nan     0.1000   -0.0002
   160        0.0331             nan     0.1000   -0.0005
   180        0.0298             nan     0.1000   -0.0012
   200        0.0258             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3767
     2        0.8679             nan     0.1000    0.2609
     3        0.7061             nan     0.1000    0.1864
     4        0.5864             nan     0.1000    0.1357
     5        0.4976             nan     0.1000    0.1019
     6        0.4285             nan     0.1000    0.0828
     7        0.3736             nan     0.1000    0.0642
     8        0.3313             nan     0.1000    0.0494
     9        0.2955             nan     0.1000    0.0395
    10        0.2680             nan     0.1000    0.0366
    20        0.1381             nan     0.1000    0.0050
    40        0.0746             nan     0.1000   -0.0018
    60        0.0522             nan     0.1000   -0.0011
    80        0.0389             nan     0.1000   -0.0011
   100        0.0290             nan     0.1000   -0.0012
   120        0.0229             nan     0.1000   -0.0006
   140        0.0183             nan     0.1000   -0.0007
   160        0.0151             nan     0.1000   -0.0004
   180        0.0121             nan     0.1000   -0.0004
   200        0.0100             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5438
     2        0.7334             nan     0.2000    0.2498
     3        0.5679             nan     0.2000    0.1383
     4        0.4661             nan     0.2000    0.0857
     5        0.4049             nan     0.2000    0.0443
     6        0.3633             nan     0.2000    0.0457
     7        0.3309             nan     0.2000    0.0362
     8        0.2977             nan     0.2000    0.0227
     9        0.2789             nan     0.2000    0.0200
    10        0.2599             nan     0.2000    0.0069
    20        0.1915             nan     0.2000   -0.0015
    40        0.1400             nan     0.2000   -0.0027
    60        0.1195             nan     0.2000   -0.0056
    80        0.1084             nan     0.2000   -0.0037
   100        0.1001             nan     0.2000   -0.0019
   120        0.0911             nan     0.2000   -0.0034
   140        0.0850             nan     0.2000   -0.0011
   160        0.0785             nan     0.2000   -0.0035
   180        0.0731             nan     0.2000   -0.0021
   200        0.0684             nan     0.2000   -0.0029

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5680
     2        0.7096             nan     0.2000    0.2649
     3        0.5232             nan     0.2000    0.1566
     4        0.4153             nan     0.2000    0.1039
     5        0.3444             nan     0.2000    0.0680
     6        0.2909             nan     0.2000    0.0332
     7        0.2586             nan     0.2000    0.0209
     8        0.2364             nan     0.2000    0.0195
     9        0.2179             nan     0.2000    0.0113
    10        0.1999             nan     0.2000    0.0048
    20        0.1355             nan     0.2000    0.0006
    40        0.0934             nan     0.2000   -0.0013
    60        0.0706             nan     0.2000   -0.0019
    80        0.0544             nan     0.2000   -0.0046
   100        0.0439             nan     0.2000   -0.0064
   120        0.0364             nan     0.2000   -0.0027
   140        0.0300             nan     0.2000   -0.0033
   160        0.0270             nan     0.2000   -0.0029
   180        0.0242             nan     0.2000   -0.0008
   200        0.0203             nan     0.2000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6104
     2        0.6881             nan     0.2000    0.2572
     3        0.5022             nan     0.2000    0.1538
     4        0.3905             nan     0.2000    0.1052
     5        0.3156             nan     0.2000    0.0650
     6        0.2613             nan     0.2000    0.0482
     7        0.2220             nan     0.2000    0.0171
     8        0.1993             nan     0.2000    0.0096
     9        0.1771             nan     0.2000    0.0106
    10        0.1644             nan     0.2000   -0.0031
    20        0.1096             nan     0.2000   -0.0095
    40        0.0682             nan     0.2000   -0.0005
    60        0.0447             nan     0.2000   -0.0015
    80        0.0339             nan     0.2000   -0.0040
   100        0.0251             nan     0.2000   -0.0037
   120        0.0211             nan     0.2000   -0.0015
   140        0.0169             nan     0.2000   -0.0019
   160        0.0139             nan     0.2000   -0.0027
   180        0.0123             nan     0.2000   -0.0015
   200        0.0101             nan     0.2000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6214
     2        0.6699             nan     0.2000    0.2723
     3        0.4740             nan     0.2000    0.1696
     4        0.3558             nan     0.2000    0.0953
     5        0.2800             nan     0.2000    0.0467
     6        0.2337             nan     0.2000    0.0342
     7        0.2010             nan     0.2000    0.0224
     8        0.1779             nan     0.2000    0.0145
     9        0.1581             nan     0.2000    0.0143
    10        0.1397             nan     0.2000   -0.0034
    20        0.0783             nan     0.2000   -0.0025
    40        0.0386             nan     0.2000   -0.0039
    60        0.0245             nan     0.2000   -0.0033
    80        0.0164             nan     0.2000   -0.0020
   100        0.0121             nan     0.2000   -0.0020
   120        0.0085             nan     0.2000   -0.0008
   140        0.0062             nan     0.2000   -0.0006
   160        0.0051             nan     0.2000   -0.0018
   180        0.0040             nan     0.2000   -0.0015
   200        0.0033             nan     0.2000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1765
     2        0.9976             nan     0.0500    0.1494
     3        0.9086             nan     0.0500    0.1245
     4        0.8350             nan     0.0500    0.1056
     5        0.7726             nan     0.0500    0.0886
     6        0.7192             nan     0.0500    0.0772
     7        0.6726             nan     0.0500    0.0672
     8        0.6314             nan     0.0500    0.0569
     9        0.5952             nan     0.0500    0.0490
    10        0.5635             nan     0.0500    0.0405
    20        0.3817             nan     0.0500    0.0129
    40        0.2643             nan     0.0500    0.0045
    60        0.2155             nan     0.0500    0.0024
    80        0.1886             nan     0.0500   -0.0004
   100        0.1716             nan     0.0500   -0.0014
   120        0.1576             nan     0.0500   -0.0010
   140        0.1481             nan     0.0500   -0.0006
   160        0.1404             nan     0.0500   -0.0005
   180        0.1340             nan     0.0500    0.0005
   200        0.1285             nan     0.0500   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1898
     2        0.9855             nan     0.0500    0.1580
     3        0.8931             nan     0.0500    0.1337
     4        0.8162             nan     0.0500    0.1130
     5        0.7485             nan     0.0500    0.0946
     6        0.6924             nan     0.0500    0.0863
     7        0.6414             nan     0.0500    0.0724
     8        0.5968             nan     0.0500    0.0634
     9        0.5573             nan     0.0500    0.0555
    10        0.5227             nan     0.0500    0.0478
    20        0.3210             nan     0.0500    0.0182
    40        0.1940             nan     0.0500    0.0031
    60        0.1515             nan     0.0500    0.0002
    80        0.1302             nan     0.0500    0.0002
   100        0.1141             nan     0.0500   -0.0004
   120        0.1031             nan     0.0500   -0.0002
   140        0.0930             nan     0.0500   -0.0002
   160        0.0857             nan     0.0500   -0.0003
   180        0.0806             nan     0.0500   -0.0000
   200        0.0747             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1973
     2        0.9803             nan     0.0500    0.1617
     3        0.8857             nan     0.0500    0.1344
     4        0.8035             nan     0.0500    0.1148
     5        0.7347             nan     0.0500    0.0994
     6        0.6732             nan     0.0500    0.0846
     7        0.6205             nan     0.0500    0.0737
     8        0.5751             nan     0.0500    0.0683
     9        0.5334             nan     0.0500    0.0586
    10        0.4968             nan     0.0500    0.0503
    20        0.2889             nan     0.0500    0.0169
    40        0.1610             nan     0.0500    0.0027
    60        0.1238             nan     0.0500   -0.0007
    80        0.1018             nan     0.0500   -0.0006
   100        0.0888             nan     0.0500   -0.0015
   120        0.0782             nan     0.0500   -0.0009
   140        0.0693             nan     0.0500   -0.0009
   160        0.0621             nan     0.0500   -0.0004
   180        0.0557             nan     0.0500   -0.0005
   200        0.0512             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2094
     2        0.9761             nan     0.0500    0.1683
     3        0.8747             nan     0.0500    0.1412
     4        0.7902             nan     0.0500    0.1229
     5        0.7166             nan     0.0500    0.1059
     6        0.6540             nan     0.0500    0.0897
     7        0.5983             nan     0.0500    0.0792
     8        0.5501             nan     0.0500    0.0662
     9        0.5087             nan     0.0500    0.0601
    10        0.4703             nan     0.0500    0.0530
    20        0.2572             nan     0.0500    0.0165
    40        0.1375             nan     0.0500    0.0015
    60        0.0961             nan     0.0500   -0.0003
    80        0.0741             nan     0.0500   -0.0009
   100        0.0595             nan     0.0500   -0.0022
   120        0.0504             nan     0.0500   -0.0012
   140        0.0427             nan     0.0500   -0.0014
   160        0.0369             nan     0.0500   -0.0009
   180        0.0319             nan     0.0500   -0.0010
   200        0.0278             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3285
     2        0.8975             nan     0.1000    0.2210
     3        0.7596             nan     0.1000    0.1624
     4        0.6604             nan     0.1000    0.1191
     5        0.5862             nan     0.1000    0.0866
     6        0.5289             nan     0.1000    0.0710
     7        0.4835             nan     0.1000    0.0564
     8        0.4462             nan     0.1000    0.0435
     9        0.4160             nan     0.1000    0.0405
    10        0.3909             nan     0.1000    0.0307
    20        0.2617             nan     0.1000    0.0064
    40        0.1887             nan     0.1000    0.0040
    60        0.1591             nan     0.1000    0.0001
    80        0.1428             nan     0.1000   -0.0015
   100        0.1288             nan     0.1000    0.0004
   120        0.1187             nan     0.1000   -0.0011
   140        0.1111             nan     0.1000   -0.0009
   160        0.1058             nan     0.1000   -0.0006
   180        0.0993             nan     0.1000   -0.0011
   200        0.0953             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3562
     2        0.8869             nan     0.1000    0.2438
     3        0.7370             nan     0.1000    0.1736
     4        0.6304             nan     0.1000    0.1269
     5        0.5479             nan     0.1000    0.1010
     6        0.4827             nan     0.1000    0.0829
     7        0.4286             nan     0.1000    0.0607
     8        0.3866             nan     0.1000    0.0450
     9        0.3535             nan     0.1000    0.0412
    10        0.3253             nan     0.1000    0.0326
    20        0.1961             nan     0.1000    0.0035
    40        0.1304             nan     0.1000   -0.0015
    60        0.1040             nan     0.1000   -0.0042
    80        0.0887             nan     0.1000   -0.0009
   100        0.0764             nan     0.1000   -0.0018
   120        0.0678             nan     0.1000   -0.0026
   140        0.0595             nan     0.1000   -0.0011
   160        0.0527             nan     0.1000   -0.0016
   180        0.0474             nan     0.1000   -0.0020
   200        0.0431             nan     0.1000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3543
     2        0.8795             nan     0.1000    0.2451
     3        0.7278             nan     0.1000    0.1841
     4        0.6128             nan     0.1000    0.1365
     5        0.5242             nan     0.1000    0.1036
     6        0.4594             nan     0.1000    0.0771
     7        0.4062             nan     0.1000    0.0582
     8        0.3656             nan     0.1000    0.0513
     9        0.3286             nan     0.1000    0.0349
    10        0.3005             nan     0.1000    0.0304
    20        0.1659             nan     0.1000    0.0049
    40        0.1047             nan     0.1000   -0.0006
    60        0.0792             nan     0.1000   -0.0013
    80        0.0619             nan     0.1000   -0.0019
   100        0.0526             nan     0.1000   -0.0021
   120        0.0439             nan     0.1000   -0.0015
   140        0.0366             nan     0.1000   -0.0012
   160        0.0314             nan     0.1000   -0.0019
   180        0.0278             nan     0.1000   -0.0009
   200        0.0243             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3797
     2        0.8665             nan     0.1000    0.2622
     3        0.7076             nan     0.1000    0.1889
     4        0.5895             nan     0.1000    0.1372
     5        0.4992             nan     0.1000    0.1027
     6        0.4309             nan     0.1000    0.0867
     7        0.3743             nan     0.1000    0.0635
     8        0.3312             nan     0.1000    0.0526
     9        0.2940             nan     0.1000    0.0444
    10        0.2628             nan     0.1000    0.0295
    20        0.1387             nan     0.1000    0.0031
    40        0.0773             nan     0.1000    0.0001
    60        0.0523             nan     0.1000   -0.0010
    80        0.0358             nan     0.1000   -0.0014
   100        0.0276             nan     0.1000   -0.0019
   120        0.0215             nan     0.1000   -0.0007
   140        0.0170             nan     0.1000   -0.0009
   160        0.0138             nan     0.1000   -0.0003
   180        0.0113             nan     0.1000   -0.0010
   200        0.0096             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5504
     2        0.7404             nan     0.2000    0.2553
     3        0.5670             nan     0.2000    0.1400
     4        0.4673             nan     0.2000    0.0884
     5        0.4041             nan     0.2000    0.0614
     6        0.3585             nan     0.2000    0.0260
     7        0.3223             nan     0.2000    0.0316
     8        0.2958             nan     0.2000    0.0127
     9        0.2772             nan     0.2000    0.0207
    10        0.2623             nan     0.2000    0.0066
    20        0.1886             nan     0.2000    0.0019
    40        0.1403             nan     0.2000   -0.0036
    60        0.1203             nan     0.2000   -0.0032
    80        0.1070             nan     0.2000   -0.0016
   100        0.0998             nan     0.2000   -0.0062
   120        0.0911             nan     0.2000   -0.0012
   140        0.0843             nan     0.2000   -0.0027
   160        0.0763             nan     0.2000   -0.0011
   180        0.0720             nan     0.2000   -0.0021
   200        0.0674             nan     0.2000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5778
     2        0.7077             nan     0.2000    0.2725
     3        0.5233             nan     0.2000    0.1514
     4        0.4170             nan     0.2000    0.0955
     5        0.3460             nan     0.2000    0.0590
     6        0.2982             nan     0.2000    0.0572
     7        0.2578             nan     0.2000    0.0199
     8        0.2362             nan     0.2000    0.0261
     9        0.2137             nan     0.2000    0.0109
    10        0.2009             nan     0.2000    0.0111
    20        0.1378             nan     0.2000    0.0004
    40        0.0910             nan     0.2000   -0.0076
    60        0.0699             nan     0.2000   -0.0026
    80        0.0569             nan     0.2000   -0.0041
   100        0.0461             nan     0.2000   -0.0038
   120        0.0394             nan     0.2000   -0.0008
   140        0.0330             nan     0.2000   -0.0005
   160        0.0287             nan     0.2000   -0.0009
   180        0.0254             nan     0.2000   -0.0012
   200        0.0227             nan     0.2000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5930
     2        0.7000             nan     0.2000    0.2690
     3        0.5052             nan     0.2000    0.1648
     4        0.3886             nan     0.2000    0.1130
     5        0.3092             nan     0.2000    0.0506
     6        0.2629             nan     0.2000    0.0449
     7        0.2260             nan     0.2000    0.0315
     8        0.1970             nan     0.2000    0.0169
     9        0.1782             nan     0.2000    0.0066
    10        0.1656             nan     0.2000    0.0064
    20        0.1065             nan     0.2000   -0.0053
    40        0.0628             nan     0.2000   -0.0039
    60        0.0443             nan     0.2000    0.0002
    80        0.0322             nan     0.2000   -0.0023
   100        0.0235             nan     0.2000   -0.0023
   120        0.0195             nan     0.2000   -0.0020
   140        0.0153             nan     0.2000   -0.0008
   160        0.0127             nan     0.2000   -0.0037
   180        0.0106             nan     0.2000   -0.0026
   200        0.0095             nan     0.2000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6171
     2        0.6812             nan     0.2000    0.3072
     3        0.4735             nan     0.2000    0.1650
     4        0.3543             nan     0.2000    0.0953
     5        0.2816             nan     0.2000    0.0576
     6        0.2347             nan     0.2000    0.0313
     7        0.2022             nan     0.2000    0.0230
     8        0.1776             nan     0.2000    0.0198
     9        0.1566             nan     0.2000    0.0086
    10        0.1415             nan     0.2000   -0.0060
    20        0.0750             nan     0.2000   -0.0019
    40        0.0387             nan     0.2000   -0.0027
    60        0.0232             nan     0.2000   -0.0017
    80        0.0149             nan     0.2000   -0.0042
   100        0.0106             nan     0.2000   -0.0006
   120        0.0077             nan     0.2000   -0.0019
   140        0.0056             nan     0.2000   -0.0003
   160        0.0043             nan     0.2000   -0.0003
   180        0.0047             nan     0.2000    0.0000
   200        0.0028             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1793
     2        0.9907             nan     0.0500    0.1470
     3        0.9046             nan     0.0500    0.1259
     4        0.8308             nan     0.0500    0.1042
     5        0.7681             nan     0.0500    0.0887
     6        0.7160             nan     0.0500    0.0776
     7        0.6692             nan     0.0500    0.0674
     8        0.6276             nan     0.0500    0.0577
     9        0.5907             nan     0.0500    0.0487
    10        0.5595             nan     0.0500    0.0437
    20        0.3785             nan     0.0500    0.0135
    40        0.2592             nan     0.0500    0.0037
    60        0.2128             nan     0.0500    0.0027
    80        0.1860             nan     0.0500   -0.0006
   100        0.1680             nan     0.0500    0.0000
   120        0.1553             nan     0.0500    0.0004
   140        0.1457             nan     0.0500   -0.0005
   160        0.1384             nan     0.0500   -0.0006
   180        0.1322             nan     0.0500   -0.0006
   200        0.1255             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1945
     2        0.9861             nan     0.0500    0.1601
     3        0.8918             nan     0.0500    0.1337
     4        0.8113             nan     0.0500    0.1133
     5        0.7429             nan     0.0500    0.0965
     6        0.6843             nan     0.0500    0.0835
     7        0.6319             nan     0.0500    0.0689
     8        0.5886             nan     0.0500    0.0575
     9        0.5514             nan     0.0500    0.0553
    10        0.5173             nan     0.0500    0.0497
    20        0.3146             nan     0.0500    0.0156
    40        0.1874             nan     0.0500    0.0017
    60        0.1504             nan     0.0500    0.0004
    80        0.1276             nan     0.0500   -0.0011
   100        0.1121             nan     0.0500   -0.0010
   120        0.1022             nan     0.0500    0.0002
   140        0.0924             nan     0.0500   -0.0002
   160        0.0844             nan     0.0500   -0.0006
   180        0.0788             nan     0.0500   -0.0004
   200        0.0734             nan     0.0500    0.0000

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1970
     2        0.9801             nan     0.0500    0.1654
     3        0.8833             nan     0.0500    0.1385
     4        0.8013             nan     0.0500    0.1180
     5        0.7311             nan     0.0500    0.0997
     6        0.6688             nan     0.0500    0.0874
     7        0.6165             nan     0.0500    0.0744
     8        0.5707             nan     0.0500    0.0670
     9        0.5298             nan     0.0500    0.0566
    10        0.4947             nan     0.0500    0.0533
    20        0.2814             nan     0.0500    0.0168
    40        0.1593             nan     0.0500    0.0031
    60        0.1207             nan     0.0500   -0.0001
    80        0.0996             nan     0.0500   -0.0003
   100        0.0846             nan     0.0500   -0.0008
   120        0.0740             nan     0.0500   -0.0002
   140        0.0657             nan     0.0500   -0.0009
   160        0.0588             nan     0.0500   -0.0004
   180        0.0534             nan     0.0500   -0.0004
   200        0.0486             nan     0.0500   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2067
     2        0.9769             nan     0.0500    0.1681
     3        0.8767             nan     0.0500    0.1463
     4        0.7896             nan     0.0500    0.1221
     5        0.7157             nan     0.0500    0.1019
     6        0.6518             nan     0.0500    0.0922
     7        0.5961             nan     0.0500    0.0779
     8        0.5479             nan     0.0500    0.0690
     9        0.5051             nan     0.0500    0.0625
    10        0.4659             nan     0.0500    0.0524
    20        0.2522             nan     0.0500    0.0151
    40        0.1301             nan     0.0500    0.0017
    60        0.0920             nan     0.0500   -0.0008
    80        0.0718             nan     0.0500   -0.0013
   100        0.0588             nan     0.0500   -0.0010
   120        0.0498             nan     0.0500   -0.0002
   140        0.0428             nan     0.0500   -0.0012
   160        0.0370             nan     0.0500   -0.0003
   180        0.0318             nan     0.0500   -0.0004
   200        0.0284             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3274
     2        0.8952             nan     0.1000    0.2264
     3        0.7576             nan     0.1000    0.1624
     4        0.6607             nan     0.1000    0.1222
     5        0.5844             nan     0.1000    0.0910
     6        0.5282             nan     0.1000    0.0739
     7        0.4822             nan     0.1000    0.0549
     8        0.4432             nan     0.1000    0.0447
     9        0.4139             nan     0.1000    0.0361
    10        0.3867             nan     0.1000    0.0297
    20        0.2633             nan     0.1000    0.0144
    40        0.1850             nan     0.1000    0.0019
    60        0.1530             nan     0.1000   -0.0002
    80        0.1369             nan     0.1000   -0.0004
   100        0.1258             nan     0.1000   -0.0000
   120        0.1156             nan     0.1000   -0.0018
   140        0.1085             nan     0.1000   -0.0001
   160        0.1027             nan     0.1000   -0.0012
   180        0.0972             nan     0.1000   -0.0042
   200        0.0925             nan     0.1000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3509
     2        0.8841             nan     0.1000    0.2433
     3        0.7344             nan     0.1000    0.1790
     4        0.6242             nan     0.1000    0.1262
     5        0.5411             nan     0.1000    0.0985
     6        0.4781             nan     0.1000    0.0800
     7        0.4273             nan     0.1000    0.0579
     8        0.3856             nan     0.1000    0.0478
     9        0.3524             nan     0.1000    0.0384
    10        0.3250             nan     0.1000    0.0316
    20        0.1958             nan     0.1000    0.0031
    40        0.1310             nan     0.1000    0.0012
    60        0.1060             nan     0.1000   -0.0010
    80        0.0880             nan     0.1000   -0.0015
   100        0.0770             nan     0.1000   -0.0014
   120        0.0653             nan     0.1000   -0.0003
   140        0.0575             nan     0.1000   -0.0016
   160        0.0527             nan     0.1000   -0.0005
   180        0.0482             nan     0.1000   -0.0013
   200        0.0442             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3694
     2        0.8741             nan     0.1000    0.2468
     3        0.7195             nan     0.1000    0.1797
     4        0.6077             nan     0.1000    0.1365
     5        0.5202             nan     0.1000    0.1010
     6        0.4548             nan     0.1000    0.0814
     7        0.4027             nan     0.1000    0.0630
     8        0.3602             nan     0.1000    0.0484
     9        0.3259             nan     0.1000    0.0377
    10        0.2943             nan     0.1000    0.0241
    20        0.1625             nan     0.1000    0.0059
    40        0.1021             nan     0.1000   -0.0001
    60        0.0797             nan     0.1000    0.0000
    80        0.0626             nan     0.1000   -0.0016
   100        0.0521             nan     0.1000   -0.0027
   120        0.0434             nan     0.1000   -0.0012
   140        0.0375             nan     0.1000   -0.0018
   160        0.0333             nan     0.1000   -0.0008
   180        0.0284             nan     0.1000   -0.0008
   200        0.0251             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3833
     2        0.8654             nan     0.1000    0.2643
     3        0.6987             nan     0.1000    0.1798
     4        0.5815             nan     0.1000    0.1395
     5        0.4906             nan     0.1000    0.1010
     6        0.4206             nan     0.1000    0.0810
     7        0.3666             nan     0.1000    0.0617
     8        0.3233             nan     0.1000    0.0476
     9        0.2887             nan     0.1000    0.0413
    10        0.2584             nan     0.1000    0.0321
    20        0.1306             nan     0.1000    0.0020
    40        0.0709             nan     0.1000   -0.0018
    60        0.0473             nan     0.1000   -0.0011
    80        0.0347             nan     0.1000   -0.0016
   100        0.0270             nan     0.1000   -0.0010
   120        0.0217             nan     0.1000   -0.0007
   140        0.0182             nan     0.1000   -0.0006
   160        0.0154             nan     0.1000   -0.0013
   180        0.0130             nan     0.1000   -0.0013
   200        0.0115             nan     0.1000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5390
     2        0.7265             nan     0.2000    0.2447
     3        0.5592             nan     0.2000    0.1366
     4        0.4567             nan     0.2000    0.0856
     5        0.3956             nan     0.2000    0.0534
     6        0.3508             nan     0.2000    0.0324
     7        0.3240             nan     0.2000    0.0303
     8        0.2990             nan     0.2000    0.0237
     9        0.2800             nan     0.2000    0.0280
    10        0.2610             nan     0.2000    0.0072
    20        0.1829             nan     0.2000   -0.0014
    40        0.1381             nan     0.2000   -0.0063
    60        0.1152             nan     0.2000   -0.0011
    80        0.0998             nan     0.2000   -0.0081
   100        0.0919             nan     0.2000   -0.0014
   120        0.0841             nan     0.2000   -0.0036
   140        0.0782             nan     0.2000   -0.0013
   160        0.0734             nan     0.2000   -0.0032
   180        0.0691             nan     0.2000   -0.0032
   200        0.0638             nan     0.2000   -0.0028

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5765
     2        0.7009             nan     0.2000    0.2718
     3        0.5118             nan     0.2000    0.1454
     4        0.4054             nan     0.2000    0.1092
     5        0.3311             nan     0.2000    0.0401
     6        0.2912             nan     0.2000    0.0396
     7        0.2583             nan     0.2000    0.0249
     8        0.2342             nan     0.2000    0.0152
     9        0.2162             nan     0.2000    0.0100
    10        0.1948             nan     0.2000    0.0015
    20        0.1333             nan     0.2000   -0.0038
    40        0.0878             nan     0.2000    0.0004
    60        0.0658             nan     0.2000   -0.0019
    80        0.0552             nan     0.2000   -0.0048
   100        0.0450             nan     0.2000   -0.0020
   120        0.0383             nan     0.2000   -0.0011
   140        0.0322             nan     0.2000   -0.0026
   160        0.0272             nan     0.2000   -0.0017
   180        0.0236             nan     0.2000   -0.0004
   200        0.0212             nan     0.2000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6060
     2        0.6936             nan     0.2000    0.2979
     3        0.4955             nan     0.2000    0.1633
     4        0.3821             nan     0.2000    0.0977
     5        0.3107             nan     0.2000    0.0712
     6        0.2600             nan     0.2000    0.0407
     7        0.2253             nan     0.2000    0.0217
     8        0.2005             nan     0.2000    0.0203
     9        0.1803             nan     0.2000    0.0092
    10        0.1623             nan     0.2000    0.0038
    20        0.1022             nan     0.2000   -0.0084
    40        0.0660             nan     0.2000   -0.0059
    60        0.0493             nan     0.2000   -0.0019
    80        0.0388             nan     0.2000   -0.0019
   100        0.0278             nan     0.2000   -0.0033
   120        0.0226             nan     0.2000   -0.0049
   140        0.0181             nan     0.2000   -0.0013
   160        0.0156             nan     0.2000   -0.0005
   180        0.0140             nan     0.2000   -0.0011
   200        0.0129             nan     0.2000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6216
     2        0.6794             nan     0.2000    0.2755
     3        0.4740             nan     0.2000    0.1545
     4        0.3599             nan     0.2000    0.0948
     5        0.2878             nan     0.2000    0.0569
     6        0.2308             nan     0.2000    0.0388
     7        0.1934             nan     0.2000    0.0356
     8        0.1611             nan     0.2000    0.0007
     9        0.1482             nan     0.2000   -0.0087
    10        0.1357             nan     0.2000    0.0031
    20        0.0738             nan     0.2000   -0.0144
    40        0.0368             nan     0.2000   -0.0026
    60        0.0239             nan     0.2000   -0.0047
    80        0.0171             nan     0.2000   -0.0042
   100        0.0129             nan     0.2000   -0.0005
   120        0.0095             nan     0.2000   -0.0042
   140        0.0082             nan     0.2000   -0.0018
   160        0.0064             nan     0.2000   -0.0020
   180        0.0055             nan     0.2000   -0.0026
   200        0.0048             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1782
     2        0.9931             nan     0.0500    0.1483
     3        0.9058             nan     0.0500    0.1267
     4        0.8313             nan     0.0500    0.1067
     5        0.7697             nan     0.0500    0.0925
     6        0.7150             nan     0.0500    0.0798
     7        0.6675             nan     0.0500    0.0679
     8        0.6256             nan     0.0500    0.0588
     9        0.5899             nan     0.0500    0.0510
    10        0.5571             nan     0.0500    0.0438
    20        0.3744             nan     0.0500    0.0158
    40        0.2564             nan     0.0500    0.0045
    60        0.2109             nan     0.0500    0.0004
    80        0.1861             nan     0.0500    0.0003
   100        0.1672             nan     0.0500   -0.0004
   120        0.1531             nan     0.0500   -0.0000
   140        0.1428             nan     0.0500    0.0002
   160        0.1350             nan     0.0500    0.0005
   180        0.1282             nan     0.0500   -0.0007
   200        0.1219             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1918
     2        0.9888             nan     0.0500    0.1585
     3        0.8955             nan     0.0500    0.1318
     4        0.8157             nan     0.0500    0.1150
     5        0.7456             nan     0.0500    0.0976
     6        0.6856             nan     0.0500    0.0844
     7        0.6347             nan     0.0500    0.0741
     8        0.5901             nan     0.0500    0.0654
     9        0.5503             nan     0.0500    0.0533
    10        0.5153             nan     0.0500    0.0486
    20        0.3120             nan     0.0500    0.0184
    40        0.1916             nan     0.0500    0.0047
    60        0.1492             nan     0.0500    0.0008
    80        0.1268             nan     0.0500   -0.0009
   100        0.1106             nan     0.0500   -0.0003
   120        0.0996             nan     0.0500   -0.0007
   140        0.0897             nan     0.0500   -0.0009
   160        0.0825             nan     0.0500   -0.0003
   180        0.0764             nan     0.0500   -0.0007
   200        0.0714             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2010
     2        0.9817             nan     0.0500    0.1672
     3        0.8828             nan     0.0500    0.1384
     4        0.8011             nan     0.0500    0.1145
     5        0.7324             nan     0.0500    0.1017
     6        0.6708             nan     0.0500    0.0875
     7        0.6168             nan     0.0500    0.0769
     8        0.5703             nan     0.0500    0.0677
     9        0.5285             nan     0.0500    0.0586
    10        0.4922             nan     0.0500    0.0519
    20        0.2826             nan     0.0500    0.0171
    40        0.1595             nan     0.0500    0.0012
    60        0.1181             nan     0.0500    0.0000
    80        0.0988             nan     0.0500   -0.0005
   100        0.0854             nan     0.0500   -0.0003
   120        0.0747             nan     0.0500   -0.0025
   140        0.0670             nan     0.0500   -0.0010
   160        0.0593             nan     0.0500   -0.0009
   180        0.0528             nan     0.0500   -0.0003
   200        0.0478             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2086
     2        0.9775             nan     0.0500    0.1703
     3        0.8750             nan     0.0500    0.1414
     4        0.7907             nan     0.0500    0.1238
     5        0.7175             nan     0.0500    0.1056
     6        0.6536             nan     0.0500    0.0894
     7        0.5989             nan     0.0500    0.0788
     8        0.5501             nan     0.0500    0.0695
     9        0.5070             nan     0.0500    0.0609
    10        0.4689             nan     0.0500    0.0529
    20        0.2570             nan     0.0500    0.0165
    40        0.1304             nan     0.0500    0.0031
    60        0.0932             nan     0.0500   -0.0010
    80        0.0719             nan     0.0500   -0.0010
   100        0.0589             nan     0.0500   -0.0003
   120        0.0478             nan     0.0500   -0.0010
   140        0.0404             nan     0.0500   -0.0008
   160        0.0349             nan     0.0500   -0.0007
   180        0.0304             nan     0.0500   -0.0004
   200        0.0263             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3285
     2        0.8956             nan     0.1000    0.2293
     3        0.7570             nan     0.1000    0.1633
     4        0.6577             nan     0.1000    0.1192
     5        0.5834             nan     0.1000    0.0946
     6        0.5218             nan     0.1000    0.0748
     7        0.4738             nan     0.1000    0.0582
     8        0.4366             nan     0.1000    0.0405
     9        0.4065             nan     0.1000    0.0348
    10        0.3783             nan     0.1000    0.0312
    20        0.2603             nan     0.1000    0.0138
    40        0.1835             nan     0.1000    0.0000
    60        0.1568             nan     0.1000   -0.0006
    80        0.1381             nan     0.1000   -0.0020
   100        0.1270             nan     0.1000   -0.0017
   120        0.1170             nan     0.1000   -0.0007
   140        0.1078             nan     0.1000   -0.0006
   160        0.1032             nan     0.1000   -0.0011
   180        0.0976             nan     0.1000   -0.0017
   200        0.0922             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3516
     2        0.8803             nan     0.1000    0.2439
     3        0.7312             nan     0.1000    0.1729
     4        0.6205             nan     0.1000    0.1305
     5        0.5356             nan     0.1000    0.1015
     6        0.4704             nan     0.1000    0.0744
     7        0.4192             nan     0.1000    0.0618
     8        0.3776             nan     0.1000    0.0432
     9        0.3474             nan     0.1000    0.0383
    10        0.3189             nan     0.1000    0.0299
    20        0.1912             nan     0.1000    0.0053
    40        0.1278             nan     0.1000   -0.0005
    60        0.1001             nan     0.1000   -0.0033
    80        0.0862             nan     0.1000   -0.0002
   100        0.0725             nan     0.1000   -0.0011
   120        0.0635             nan     0.1000   -0.0009
   140        0.0573             nan     0.1000   -0.0010
   160        0.0504             nan     0.1000   -0.0009
   180        0.0454             nan     0.1000   -0.0017
   200        0.0417             nan     0.1000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3695
     2        0.8722             nan     0.1000    0.2455
     3        0.7170             nan     0.1000    0.1844
     4        0.6026             nan     0.1000    0.1336
     5        0.5152             nan     0.1000    0.0956
     6        0.4523             nan     0.1000    0.0827
     7        0.3990             nan     0.1000    0.0639
     8        0.3558             nan     0.1000    0.0503
     9        0.3206             nan     0.1000    0.0367
    10        0.2942             nan     0.1000    0.0382
    20        0.1614             nan     0.1000    0.0076
    40        0.1013             nan     0.1000   -0.0010
    60        0.0780             nan     0.1000   -0.0022
    80        0.0627             nan     0.1000   -0.0000
   100        0.0509             nan     0.1000   -0.0021
   120        0.0423             nan     0.1000   -0.0000
   140        0.0355             nan     0.1000   -0.0008
   160        0.0302             nan     0.1000   -0.0016
   180        0.0260             nan     0.1000   -0.0012
   200        0.0223             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3796
     2        0.8658             nan     0.1000    0.2510
     3        0.7047             nan     0.1000    0.1836
     4        0.5886             nan     0.1000    0.1379
     5        0.4991             nan     0.1000    0.1061
     6        0.4305             nan     0.1000    0.0810
     7        0.3761             nan     0.1000    0.0604
     8        0.3322             nan     0.1000    0.0561
     9        0.2941             nan     0.1000    0.0388
    10        0.2659             nan     0.1000    0.0270
    20        0.1374             nan     0.1000    0.0031
    40        0.0772             nan     0.1000   -0.0024
    60        0.0510             nan     0.1000   -0.0025
    80        0.0362             nan     0.1000   -0.0015
   100        0.0275             nan     0.1000   -0.0006
   120        0.0212             nan     0.1000   -0.0004
   140        0.0166             nan     0.1000   -0.0004
   160        0.0136             nan     0.1000   -0.0006
   180        0.0108             nan     0.1000   -0.0003
   200        0.0090             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5566
     2        0.7312             nan     0.2000    0.2491
     3        0.5574             nan     0.2000    0.1404
     4        0.4547             nan     0.2000    0.0827
     5        0.3934             nan     0.2000    0.0588
     6        0.3472             nan     0.2000    0.0280
     7        0.3170             nan     0.2000    0.0339
     8        0.2898             nan     0.2000    0.0109
     9        0.2740             nan     0.2000    0.0066
    10        0.2607             nan     0.2000    0.0137
    20        0.1865             nan     0.2000   -0.0018
    40        0.1387             nan     0.2000   -0.0002
    60        0.1157             nan     0.2000   -0.0038
    80        0.1000             nan     0.2000   -0.0041
   100        0.0896             nan     0.2000   -0.0016
   120        0.0830             nan     0.2000   -0.0025
   140        0.0776             nan     0.2000   -0.0038
   160        0.0718             nan     0.2000   -0.0053
   180        0.0672             nan     0.2000   -0.0029
   200        0.0631             nan     0.2000   -0.0022

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5885
     2        0.7002             nan     0.2000    0.2658
     3        0.5142             nan     0.2000    0.1340
     4        0.4102             nan     0.2000    0.1128
     5        0.3334             nan     0.2000    0.0545
     6        0.2836             nan     0.2000    0.0429
     7        0.2523             nan     0.2000    0.0207
     8        0.2292             nan     0.2000    0.0170
     9        0.2111             nan     0.2000    0.0104
    10        0.1953             nan     0.2000    0.0059
    20        0.1247             nan     0.2000   -0.0053
    40        0.0868             nan     0.2000   -0.0132
    60        0.0661             nan     0.2000   -0.0022
    80        0.0497             nan     0.2000   -0.0053
   100        0.0414             nan     0.2000   -0.0007
   120        0.0344             nan     0.2000   -0.0027
   140        0.0290             nan     0.2000   -0.0013
   160        0.0237             nan     0.2000   -0.0008
   180        0.0207             nan     0.2000   -0.0006
   200        0.0179             nan     0.2000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6046
     2        0.6893             nan     0.2000    0.2781
     3        0.4936             nan     0.2000    0.1463
     4        0.3795             nan     0.2000    0.0877
     5        0.3120             nan     0.2000    0.0606
     6        0.2654             nan     0.2000    0.0323
     7        0.2239             nan     0.2000    0.0250
     8        0.2002             nan     0.2000    0.0144
     9        0.1822             nan     0.2000    0.0127
    10        0.1659             nan     0.2000   -0.0009
    20        0.0982             nan     0.2000   -0.0078
    40        0.0642             nan     0.2000   -0.0058
    60        0.0419             nan     0.2000   -0.0047
    80        0.0296             nan     0.2000   -0.0014
   100        0.0216             nan     0.2000   -0.0024
   120        0.0171             nan     0.2000   -0.0010
   140        0.0133             nan     0.2000   -0.0014
   160        0.0112             nan     0.2000   -0.0011
   180        0.0097             nan     0.2000   -0.0015
   200        0.0078             nan     0.2000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6325
     2        0.6676             nan     0.2000    0.2766
     3        0.4739             nan     0.2000    0.1570
     4        0.3601             nan     0.2000    0.0946
     5        0.2842             nan     0.2000    0.0675
     6        0.2331             nan     0.2000    0.0189
     7        0.2013             nan     0.2000    0.0299
     8        0.1697             nan     0.2000    0.0093
     9        0.1515             nan     0.2000    0.0094
    10        0.1369             nan     0.2000   -0.0017
    20        0.0801             nan     0.2000   -0.0056
    40        0.0366             nan     0.2000   -0.0011
    60        0.0212             nan     0.2000   -0.0022
    80        0.0137             nan     0.2000   -0.0017
   100        0.0093             nan     0.2000   -0.0011
   120        0.0065             nan     0.2000   -0.0006
   140        0.0048             nan     0.2000   -0.0024
   160        0.0038             nan     0.2000   -0.0003
   180        0.0032             nan     0.2000   -0.0001
   200        0.0026             nan     0.2000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1826
     2        0.9927             nan     0.0500    0.1487
     3        0.9045             nan     0.0500    0.1237
     4        0.8290             nan     0.0500    0.1058
     5        0.7657             nan     0.0500    0.0888
     6        0.7115             nan     0.0500    0.0780
     7        0.6650             nan     0.0500    0.0685
     8        0.6230             nan     0.0500    0.0589
     9        0.5873             nan     0.0500    0.0516
    10        0.5552             nan     0.0500    0.0441
    20        0.3737             nan     0.0500    0.0135
    40        0.2525             nan     0.0500    0.0032
    60        0.2051             nan     0.0500    0.0020
    80        0.1791             nan     0.0500    0.0004
   100        0.1638             nan     0.0500    0.0011
   120        0.1489             nan     0.0500   -0.0005
   140        0.1391             nan     0.0500    0.0002
   160        0.1304             nan     0.0500   -0.0006
   180        0.1245             nan     0.0500   -0.0006
   200        0.1189             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1923
     2        0.9871             nan     0.0500    0.1600
     3        0.8935             nan     0.0500    0.1332
     4        0.8138             nan     0.0500    0.1138
     5        0.7441             nan     0.0500    0.0992
     6        0.6835             nan     0.0500    0.0843
     7        0.6312             nan     0.0500    0.0731
     8        0.5865             nan     0.0500    0.0614
     9        0.5474             nan     0.0500    0.0562
    10        0.5116             nan     0.0500    0.0513
    20        0.3067             nan     0.0500    0.0173
    40        0.1823             nan     0.0500    0.0004
    60        0.1424             nan     0.0500    0.0009
    80        0.1208             nan     0.0500   -0.0010
   100        0.1068             nan     0.0500   -0.0008
   120        0.0958             nan     0.0500   -0.0025
   140        0.0869             nan     0.0500   -0.0004
   160        0.0793             nan     0.0500   -0.0004
   180        0.0734             nan     0.0500   -0.0005
   200        0.0673             nan     0.0500   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2001
     2        0.9788             nan     0.0500    0.1653
     3        0.8772             nan     0.0500    0.1406
     4        0.7951             nan     0.0500    0.1172
     5        0.7241             nan     0.0500    0.1024
     6        0.6630             nan     0.0500    0.0879
     7        0.6092             nan     0.0500    0.0738
     8        0.5633             nan     0.0500    0.0650
     9        0.5230             nan     0.0500    0.0569
    10        0.4865             nan     0.0500    0.0497
    20        0.2759             nan     0.0500    0.0196
    40        0.1495             nan     0.0500   -0.0022
    60        0.1107             nan     0.0500    0.0005
    80        0.0929             nan     0.0500   -0.0005
   100        0.0793             nan     0.0500    0.0002
   120        0.0685             nan     0.0500   -0.0017
   140        0.0596             nan     0.0500   -0.0004
   160        0.0523             nan     0.0500   -0.0002
   180        0.0463             nan     0.0500   -0.0001
   200        0.0411             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2034
     2        0.9796             nan     0.0500    0.1739
     3        0.8778             nan     0.0500    0.1430
     4        0.7906             nan     0.0500    0.1242
     5        0.7149             nan     0.0500    0.1070
     6        0.6511             nan     0.0500    0.0919
     7        0.5953             nan     0.0500    0.0827
     8        0.5461             nan     0.0500    0.0673
     9        0.5038             nan     0.0500    0.0604
    10        0.4649             nan     0.0500    0.0551
    20        0.2495             nan     0.0500    0.0146
    40        0.1238             nan     0.0500    0.0018
    60        0.0852             nan     0.0500    0.0002
    80        0.0656             nan     0.0500   -0.0003
   100        0.0521             nan     0.0500   -0.0004
   120        0.0423             nan     0.0500   -0.0009
   140        0.0351             nan     0.0500   -0.0004
   160        0.0297             nan     0.0500   -0.0006
   180        0.0248             nan     0.0500   -0.0007
   200        0.0218             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3279
     2        0.8915             nan     0.1000    0.2264
     3        0.7540             nan     0.1000    0.1587
     4        0.6498             nan     0.1000    0.1187
     5        0.5746             nan     0.1000    0.0880
     6        0.5170             nan     0.1000    0.0653
     7        0.4729             nan     0.1000    0.0577
     8        0.4349             nan     0.1000    0.0484
     9        0.4036             nan     0.1000    0.0368
    10        0.3785             nan     0.1000    0.0315
    20        0.2535             nan     0.1000    0.0109
    40        0.1806             nan     0.1000    0.0026
    60        0.1510             nan     0.1000    0.0022
    80        0.1312             nan     0.1000   -0.0011
   100        0.1184             nan     0.1000   -0.0021
   120        0.1108             nan     0.1000   -0.0011
   140        0.1033             nan     0.1000   -0.0013
   160        0.0983             nan     0.1000   -0.0015
   180        0.0928             nan     0.1000   -0.0003
   200        0.0885             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3564
     2        0.8790             nan     0.1000    0.2429
     3        0.7275             nan     0.1000    0.1743
     4        0.6200             nan     0.1000    0.1265
     5        0.5407             nan     0.1000    0.1021
     6        0.4744             nan     0.1000    0.0776
     7        0.4239             nan     0.1000    0.0567
     8        0.3840             nan     0.1000    0.0530
     9        0.3480             nan     0.1000    0.0421
    10        0.3198             nan     0.1000    0.0339
    20        0.1842             nan     0.1000    0.0059
    40        0.1211             nan     0.1000   -0.0009
    60        0.0957             nan     0.1000   -0.0008
    80        0.0792             nan     0.1000   -0.0018
   100        0.0673             nan     0.1000   -0.0010
   120        0.0591             nan     0.1000   -0.0030
   140        0.0524             nan     0.1000   -0.0005
   160        0.0467             nan     0.1000   -0.0007
   180        0.0414             nan     0.1000   -0.0021
   200        0.0378             nan     0.1000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3783
     2        0.8733             nan     0.1000    0.2567
     3        0.7192             nan     0.1000    0.1840
     4        0.6038             nan     0.1000    0.1360
     5        0.5154             nan     0.1000    0.1087
     6        0.4472             nan     0.1000    0.0805
     7        0.3938             nan     0.1000    0.0669
     8        0.3497             nan     0.1000    0.0505
     9        0.3141             nan     0.1000    0.0465
    10        0.2827             nan     0.1000    0.0318
    20        0.1505             nan     0.1000    0.0015
    40        0.0914             nan     0.1000   -0.0018
    60        0.0707             nan     0.1000   -0.0020
    80        0.0563             nan     0.1000   -0.0026
   100        0.0455             nan     0.1000   -0.0007
   120        0.0370             nan     0.1000   -0.0013
   140        0.0314             nan     0.1000   -0.0007
   160        0.0265             nan     0.1000   -0.0006
   180        0.0221             nan     0.1000   -0.0003
   200        0.0190             nan     0.1000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3864
     2        0.8626             nan     0.1000    0.2542
     3        0.7043             nan     0.1000    0.1902
     4        0.5855             nan     0.1000    0.1394
     5        0.4938             nan     0.1000    0.1069
     6        0.4213             nan     0.1000    0.0809
     7        0.3659             nan     0.1000    0.0619
     8        0.3242             nan     0.1000    0.0479
     9        0.2880             nan     0.1000    0.0369
    10        0.2602             nan     0.1000    0.0381
    20        0.1252             nan     0.1000    0.0023
    40        0.0666             nan     0.1000   -0.0015
    60        0.0447             nan     0.1000   -0.0003
    80        0.0333             nan     0.1000   -0.0008
   100        0.0255             nan     0.1000   -0.0015
   120        0.0202             nan     0.1000   -0.0012
   140        0.0159             nan     0.1000   -0.0008
   160        0.0126             nan     0.1000   -0.0006
   180        0.0106             nan     0.1000   -0.0007
   200        0.0089             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5485
     2        0.7276             nan     0.2000    0.2535
     3        0.5570             nan     0.2000    0.1488
     4        0.4567             nan     0.2000    0.0798
     5        0.3922             nan     0.2000    0.0603
     6        0.3473             nan     0.2000    0.0385
     7        0.3177             nan     0.2000    0.0311
     8        0.2894             nan     0.2000    0.0247
     9        0.2692             nan     0.2000    0.0105
    10        0.2591             nan     0.2000    0.0251
    20        0.1801             nan     0.2000   -0.0007
    40        0.1321             nan     0.2000   -0.0008
    60        0.1090             nan     0.2000   -0.0037
    80        0.0961             nan     0.2000   -0.0085
   100        0.0872             nan     0.2000   -0.0074
   120        0.0799             nan     0.2000   -0.0038
   140        0.0737             nan     0.2000   -0.0006
   160        0.0674             nan     0.2000   -0.0058
   180        0.0616             nan     0.2000   -0.0010
   200        0.0554             nan     0.2000   -0.0023

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5936
     2        0.7002             nan     0.2000    0.2628
     3        0.5073             nan     0.2000    0.1546
     4        0.4008             nan     0.2000    0.1017
     5        0.3304             nan     0.2000    0.0647
     6        0.2800             nan     0.2000    0.0305
     7        0.2504             nan     0.2000    0.0201
     8        0.2236             nan     0.2000    0.0209
     9        0.2030             nan     0.2000    0.0057
    10        0.1880             nan     0.2000    0.0074
    20        0.1235             nan     0.2000   -0.0071
    40        0.0832             nan     0.2000   -0.0010
    60        0.0636             nan     0.2000   -0.0039
    80        0.0490             nan     0.2000   -0.0038
   100        0.0401             nan     0.2000   -0.0005
   120        0.0323             nan     0.2000   -0.0014
   140        0.0254             nan     0.2000   -0.0016
   160        0.0216             nan     0.2000   -0.0015
   180        0.0191             nan     0.2000   -0.0027
   200        0.0163             nan     0.2000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6033
     2        0.6940             nan     0.2000    0.2988
     3        0.4950             nan     0.2000    0.1505
     4        0.3836             nan     0.2000    0.0927
     5        0.3077             nan     0.2000    0.0694
     6        0.2541             nan     0.2000    0.0443
     7        0.2189             nan     0.2000    0.0197
     8        0.1953             nan     0.2000    0.0225
     9        0.1757             nan     0.2000    0.0170
    10        0.1567             nan     0.2000    0.0041
    20        0.0910             nan     0.2000   -0.0068
    40        0.0530             nan     0.2000   -0.0025
    60        0.0365             nan     0.2000   -0.0016
    80        0.0283             nan     0.2000   -0.0038
   100        0.0208             nan     0.2000   -0.0016
   120        0.0165             nan     0.2000   -0.0017
   140        0.0127             nan     0.2000   -0.0023
   160        0.0101             nan     0.2000   -0.0003
   180        0.0088             nan     0.2000   -0.0014
   200        0.0074             nan     0.2000   -0.0019

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6367
     2        0.6734             nan     0.2000    0.3030
     3        0.4652             nan     0.2000    0.1579
     4        0.3509             nan     0.2000    0.1004
     5        0.2726             nan     0.2000    0.0564
     6        0.2216             nan     0.2000    0.0267
     7        0.1900             nan     0.2000    0.0222
     8        0.1665             nan     0.2000    0.0127
     9        0.1485             nan     0.2000    0.0065
    10        0.1346             nan     0.2000    0.0013
    20        0.0694             nan     0.2000   -0.0033
    40        0.0344             nan     0.2000   -0.0028
    60        0.0198             nan     0.2000   -0.0034
    80        0.0123             nan     0.2000   -0.0015
   100        0.0093             nan     0.2000   -0.0123
   120        0.0063             nan     0.2000   -0.0006
   140        0.0051             nan     0.2000   -0.0003
   160        0.0037             nan     0.2000   -0.0019
   180        0.0033             nan     0.2000   -0.0002
   200        0.0026             nan     0.2000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1805
     2        0.9947             nan     0.0500    0.1487
     3        0.9063             nan     0.0500    0.1250
     4        0.8306             nan     0.0500    0.1069
     5        0.7687             nan     0.0500    0.0906
     6        0.7150             nan     0.0500    0.0780
     7        0.6674             nan     0.0500    0.0664
     8        0.6259             nan     0.0500    0.0580
     9        0.5904             nan     0.0500    0.0508
    10        0.5596             nan     0.0500    0.0435
    20        0.3795             nan     0.0500    0.0162
    40        0.2593             nan     0.0500    0.0030
    60        0.2111             nan     0.0500    0.0012
    80        0.1836             nan     0.0500    0.0002
   100        0.1652             nan     0.0500    0.0002
   120        0.1523             nan     0.0500   -0.0004
   140        0.1423             nan     0.0500   -0.0007
   160        0.1338             nan     0.0500   -0.0007
   180        0.1269             nan     0.0500   -0.0009
   200        0.1207             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1923
     2        0.9856             nan     0.0500    0.1577
     3        0.8937             nan     0.0500    0.1347
     4        0.8126             nan     0.0500    0.1125
     5        0.7441             nan     0.0500    0.0958
     6        0.6857             nan     0.0500    0.0829
     7        0.6346             nan     0.0500    0.0734
     8        0.5903             nan     0.0500    0.0619
     9        0.5514             nan     0.0500    0.0553
    10        0.5168             nan     0.0500    0.0474
    20        0.3171             nan     0.0500    0.0159
    40        0.1900             nan     0.0500    0.0008
    60        0.1478             nan     0.0500   -0.0004
    80        0.1261             nan     0.0500   -0.0002
   100        0.1087             nan     0.0500    0.0009
   120        0.0965             nan     0.0500   -0.0005
   140        0.0861             nan     0.0500   -0.0001
   160        0.0784             nan     0.0500   -0.0007
   180        0.0726             nan     0.0500   -0.0010
   200        0.0678             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2021
     2        0.9818             nan     0.0500    0.1647
     3        0.8856             nan     0.0500    0.1391
     4        0.8025             nan     0.0500    0.1183
     5        0.7301             nan     0.0500    0.1006
     6        0.6682             nan     0.0500    0.0839
     7        0.6154             nan     0.0500    0.0727
     8        0.5696             nan     0.0500    0.0663
     9        0.5288             nan     0.0500    0.0589
    10        0.4929             nan     0.0500    0.0510
    20        0.2817             nan     0.0500    0.0148
    40        0.1568             nan     0.0500    0.0013
    60        0.1179             nan     0.0500    0.0007
    80        0.0958             nan     0.0500   -0.0002
   100        0.0829             nan     0.0500   -0.0005
   120        0.0719             nan     0.0500   -0.0003
   140        0.0632             nan     0.0500   -0.0005
   160        0.0567             nan     0.0500   -0.0010
   180        0.0514             nan     0.0500   -0.0011
   200        0.0470             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2044
     2        0.9782             nan     0.0500    0.1690
     3        0.8785             nan     0.0500    0.1485
     4        0.7913             nan     0.0500    0.1214
     5        0.7166             nan     0.0500    0.1065
     6        0.6524             nan     0.0500    0.0873
     7        0.5979             nan     0.0500    0.0788
     8        0.5489             nan     0.0500    0.0651
     9        0.5078             nan     0.0500    0.0608
    10        0.4703             nan     0.0500    0.0522
    20        0.2549             nan     0.0500    0.0183
    40        0.1270             nan     0.0500    0.0014
    60        0.0880             nan     0.0500    0.0003
    80        0.0675             nan     0.0500   -0.0006
   100        0.0551             nan     0.0500   -0.0011
   120        0.0459             nan     0.0500   -0.0005
   140        0.0386             nan     0.0500   -0.0007
   160        0.0332             nan     0.0500   -0.0006
   180        0.0290             nan     0.0500   -0.0010
   200        0.0256             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3295
     2        0.8969             nan     0.1000    0.2209
     3        0.7598             nan     0.1000    0.1659
     4        0.6580             nan     0.1000    0.1170
     5        0.5799             nan     0.1000    0.0895
     6        0.5220             nan     0.1000    0.0700
     7        0.4762             nan     0.1000    0.0522
     8        0.4403             nan     0.1000    0.0471
     9        0.4090             nan     0.1000    0.0294
    10        0.3860             nan     0.1000    0.0316
    20        0.2590             nan     0.1000    0.0121
    40        0.1830             nan     0.1000    0.0009
    60        0.1507             nan     0.1000   -0.0014
    80        0.1348             nan     0.1000   -0.0017
   100        0.1208             nan     0.1000   -0.0020
   120        0.1123             nan     0.1000    0.0007
   140        0.1054             nan     0.1000   -0.0020
   160        0.0989             nan     0.1000   -0.0013
   180        0.0938             nan     0.1000   -0.0014
   200        0.0891             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3541
     2        0.8841             nan     0.1000    0.2394
     3        0.7379             nan     0.1000    0.1773
     4        0.6285             nan     0.1000    0.1305
     5        0.5431             nan     0.1000    0.1026
     6        0.4777             nan     0.1000    0.0714
     7        0.4281             nan     0.1000    0.0598
     8        0.3871             nan     0.1000    0.0574
     9        0.3518             nan     0.1000    0.0389
    10        0.3242             nan     0.1000    0.0373
    20        0.1910             nan     0.1000   -0.0010
    40        0.1254             nan     0.1000   -0.0019
    60        0.0956             nan     0.1000   -0.0014
    80        0.0811             nan     0.1000   -0.0017
   100        0.0678             nan     0.1000    0.0000
   120        0.0586             nan     0.1000   -0.0003
   140        0.0529             nan     0.1000   -0.0001
   160        0.0477             nan     0.1000   -0.0008
   180        0.0432             nan     0.1000   -0.0009
   200        0.0385             nan     0.1000    0.0000

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3636
     2        0.8768             nan     0.1000    0.2487
     3        0.7222             nan     0.1000    0.1825
     4        0.6077             nan     0.1000    0.1358
     5        0.5192             nan     0.1000    0.0959
     6        0.4518             nan     0.1000    0.0752
     7        0.4000             nan     0.1000    0.0658
     8        0.3551             nan     0.1000    0.0461
     9        0.3209             nan     0.1000    0.0370
    10        0.2922             nan     0.1000    0.0320
    20        0.1594             nan     0.1000    0.0030
    40        0.1008             nan     0.1000   -0.0001
    60        0.0738             nan     0.1000   -0.0012
    80        0.0587             nan     0.1000   -0.0013
   100        0.0475             nan     0.1000   -0.0005
   120        0.0397             nan     0.1000   -0.0011
   140        0.0334             nan     0.1000   -0.0014
   160        0.0290             nan     0.1000   -0.0010
   180        0.0260             nan     0.1000   -0.0012
   200        0.0227             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3855
     2        0.8640             nan     0.1000    0.2478
     3        0.7066             nan     0.1000    0.1835
     4        0.5886             nan     0.1000    0.1390
     5        0.4981             nan     0.1000    0.1005
     6        0.4306             nan     0.1000    0.0820
     7        0.3731             nan     0.1000    0.0627
     8        0.3290             nan     0.1000    0.0479
     9        0.2945             nan     0.1000    0.0405
    10        0.2647             nan     0.1000    0.0339
    20        0.1317             nan     0.1000    0.0044
    40        0.0692             nan     0.1000   -0.0001
    60        0.0465             nan     0.1000   -0.0024
    80        0.0341             nan     0.1000   -0.0019
   100        0.0269             nan     0.1000   -0.0010
   120        0.0215             nan     0.1000   -0.0014
   140        0.0178             nan     0.1000   -0.0013
   160        0.0152             nan     0.1000   -0.0020
   180        0.0128             nan     0.1000   -0.0010
   200        0.0106             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5394
     2        0.7300             nan     0.2000    0.2484
     3        0.5555             nan     0.2000    0.1282
     4        0.4613             nan     0.2000    0.0851
     5        0.3992             nan     0.2000    0.0630
     6        0.3550             nan     0.2000    0.0369
     7        0.3253             nan     0.2000    0.0328
     8        0.3006             nan     0.2000    0.0322
     9        0.2713             nan     0.2000    0.0192
    10        0.2552             nan     0.2000    0.0134
    20        0.1829             nan     0.2000    0.0026
    40        0.1333             nan     0.2000    0.0002
    60        0.1109             nan     0.2000   -0.0021
    80        0.1002             nan     0.2000   -0.0020
   100        0.0898             nan     0.2000   -0.0020
   120        0.0812             nan     0.2000   -0.0035
   140        0.0747             nan     0.2000   -0.0030
   160        0.0692             nan     0.2000   -0.0041
   180        0.0657             nan     0.2000   -0.0030
   200        0.0617             nan     0.2000   -0.0019

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5954
     2        0.7082             nan     0.2000    0.2772
     3        0.5205             nan     0.2000    0.1548
     4        0.4080             nan     0.2000    0.0903
     5        0.3400             nan     0.2000    0.0678
     6        0.2891             nan     0.2000    0.0367
     7        0.2574             nan     0.2000    0.0285
     8        0.2317             nan     0.2000    0.0230
     9        0.2106             nan     0.2000    0.0171
    10        0.1950             nan     0.2000    0.0090
    20        0.1284             nan     0.2000   -0.0123
    40        0.0834             nan     0.2000   -0.0057
    60        0.0651             nan     0.2000   -0.0044
    80        0.0513             nan     0.2000   -0.0037
   100        0.0438             nan     0.2000   -0.0022
   120        0.0375             nan     0.2000   -0.0030
   140        0.0320             nan     0.2000   -0.0009
   160        0.0283             nan     0.2000   -0.0023
   180        0.0244             nan     0.2000   -0.0056
   200        0.0224             nan     0.2000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6078
     2        0.6915             nan     0.2000    0.2826
     3        0.4984             nan     0.2000    0.1762
     4        0.3770             nan     0.2000    0.0959
     5        0.3038             nan     0.2000    0.0581
     6        0.2575             nan     0.2000    0.0492
     7        0.2206             nan     0.2000    0.0279
     8        0.1948             nan     0.2000    0.0154
     9        0.1761             nan     0.2000    0.0016
    10        0.1612             nan     0.2000    0.0097
    20        0.0967             nan     0.2000   -0.0018
    40        0.0581             nan     0.2000   -0.0037
    60        0.0409             nan     0.2000   -0.0075
    80        0.0313             nan     0.2000   -0.0018
   100        0.0248             nan     0.2000   -0.0034
   120        0.0195             nan     0.2000   -0.0042
   140        0.0160             nan     0.2000   -0.0010
   160        0.0132             nan     0.2000   -0.0018
   180        0.0120             nan     0.2000   -0.0029
   200        0.0107             nan     0.2000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6141
     2        0.6707             nan     0.2000    0.2886
     3        0.4713             nan     0.2000    0.1609
     4        0.3536             nan     0.2000    0.0872
     5        0.2838             nan     0.2000    0.0632
     6        0.2336             nan     0.2000    0.0416
     7        0.1985             nan     0.2000    0.0065
     8        0.1766             nan     0.2000    0.0041
     9        0.1546             nan     0.2000    0.0083
    10        0.1399             nan     0.2000    0.0068
    20        0.0772             nan     0.2000   -0.0081
    40        0.0372             nan     0.2000   -0.0024
    60        0.0233             nan     0.2000   -0.0034
    80        0.0155             nan     0.2000   -0.0014
   100        0.0113             nan     0.2000   -0.0026
   120        0.0087             nan     0.2000   -0.0015
   140        0.0067             nan     0.2000   -0.0035
   160        0.0060             nan     0.2000   -0.0000
   180        0.0049             nan     0.2000   -0.0036
   200        0.0048             nan     0.2000   -0.0074

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1813
     2        0.9966             nan     0.0500    0.1487
     3        0.9097             nan     0.0500    0.1261
     4        0.8349             nan     0.0500    0.1061
     5        0.7734             nan     0.0500    0.0920
     6        0.7207             nan     0.0500    0.0761
     7        0.6740             nan     0.0500    0.0684
     8        0.6311             nan     0.0500    0.0582
     9        0.5950             nan     0.0500    0.0519
    10        0.5627             nan     0.0500    0.0452
    20        0.3787             nan     0.0500    0.0159
    40        0.2567             nan     0.0500    0.0033
    60        0.2136             nan     0.0500    0.0048
    80        0.1826             nan     0.0500    0.0007
   100        0.1663             nan     0.0500   -0.0003
   120        0.1545             nan     0.0500   -0.0002
   140        0.1438             nan     0.0500    0.0007
   160        0.1345             nan     0.0500   -0.0009
   180        0.1273             nan     0.0500   -0.0005
   200        0.1214             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1947
     2        0.9863             nan     0.0500    0.1598
     3        0.8912             nan     0.0500    0.1323
     4        0.8107             nan     0.0500    0.1141
     5        0.7420             nan     0.0500    0.0979
     6        0.6846             nan     0.0500    0.0827
     7        0.6341             nan     0.0500    0.0737
     8        0.5891             nan     0.0500    0.0625
     9        0.5503             nan     0.0500    0.0554
    10        0.5155             nan     0.0500    0.0485
    20        0.3135             nan     0.0500    0.0187
    40        0.1901             nan     0.0500    0.0021
    60        0.1507             nan     0.0500   -0.0011
    80        0.1277             nan     0.0500   -0.0000
   100        0.1129             nan     0.0500   -0.0010
   120        0.0999             nan     0.0500   -0.0005
   140        0.0911             nan     0.0500    0.0002
   160        0.0832             nan     0.0500   -0.0006
   180        0.0773             nan     0.0500   -0.0005
   200        0.0722             nan     0.0500   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1986
     2        0.9797             nan     0.0500    0.1656
     3        0.8824             nan     0.0500    0.1392
     4        0.7998             nan     0.0500    0.1188
     5        0.7297             nan     0.0500    0.1013
     6        0.6691             nan     0.0500    0.0873
     7        0.6167             nan     0.0500    0.0754
     8        0.5699             nan     0.0500    0.0643
     9        0.5294             nan     0.0500    0.0577
    10        0.4923             nan     0.0500    0.0493
    20        0.2839             nan     0.0500    0.0188
    40        0.1591             nan     0.0500    0.0014
    60        0.1215             nan     0.0500   -0.0015
    80        0.1007             nan     0.0500   -0.0010
   100        0.0857             nan     0.0500   -0.0011
   120        0.0750             nan     0.0500   -0.0008
   140        0.0668             nan     0.0500   -0.0003
   160        0.0609             nan     0.0500   -0.0011
   180        0.0553             nan     0.0500   -0.0006
   200        0.0500             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2066
     2        0.9775             nan     0.0500    0.1643
     3        0.8789             nan     0.0500    0.1459
     4        0.7922             nan     0.0500    0.1234
     5        0.7183             nan     0.0500    0.1048
     6        0.6554             nan     0.0500    0.0924
     7        0.5995             nan     0.0500    0.0790
     8        0.5508             nan     0.0500    0.0685
     9        0.5084             nan     0.0500    0.0599
    10        0.4703             nan     0.0500    0.0510
    20        0.2592             nan     0.0500    0.0164
    40        0.1332             nan     0.0500    0.0018
    60        0.0934             nan     0.0500   -0.0000
    80        0.0731             nan     0.0500   -0.0012
   100        0.0599             nan     0.0500   -0.0008
   120        0.0510             nan     0.0500   -0.0008
   140        0.0440             nan     0.0500   -0.0006
   160        0.0371             nan     0.0500   -0.0004
   180        0.0325             nan     0.0500   -0.0004
   200        0.0285             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3334
     2        0.9001             nan     0.1000    0.2223
     3        0.7538             nan     0.1000    0.1585
     4        0.6537             nan     0.1000    0.1176
     5        0.5780             nan     0.1000    0.0883
     6        0.5225             nan     0.1000    0.0712
     7        0.4767             nan     0.1000    0.0531
     8        0.4405             nan     0.1000    0.0427
     9        0.4118             nan     0.1000    0.0366
    10        0.3859             nan     0.1000    0.0320
    20        0.2583             nan     0.1000    0.0068
    40        0.1850             nan     0.1000    0.0014
    60        0.1534             nan     0.1000    0.0034
    80        0.1354             nan     0.1000   -0.0002
   100        0.1225             nan     0.1000    0.0004
   120        0.1116             nan     0.1000   -0.0006
   140        0.1055             nan     0.1000   -0.0017
   160        0.0995             nan     0.1000   -0.0012
   180        0.0948             nan     0.1000   -0.0005
   200        0.0906             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3489
     2        0.8826             nan     0.1000    0.2401
     3        0.7295             nan     0.1000    0.1703
     4        0.6219             nan     0.1000    0.1283
     5        0.5385             nan     0.1000    0.0981
     6        0.4752             nan     0.1000    0.0783
     7        0.4236             nan     0.1000    0.0579
     8        0.3841             nan     0.1000    0.0477
     9        0.3522             nan     0.1000    0.0386
    10        0.3234             nan     0.1000    0.0340
    20        0.1927             nan     0.1000    0.0073
    40        0.1293             nan     0.1000   -0.0010
    60        0.1030             nan     0.1000   -0.0012
    80        0.0867             nan     0.1000   -0.0009
   100        0.0738             nan     0.1000   -0.0013
   120        0.0656             nan     0.1000   -0.0016
   140        0.0587             nan     0.1000   -0.0023
   160        0.0521             nan     0.1000   -0.0035
   180        0.0477             nan     0.1000   -0.0010
   200        0.0435             nan     0.1000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3670
     2        0.8748             nan     0.1000    0.2516
     3        0.7216             nan     0.1000    0.1788
     4        0.6090             nan     0.1000    0.1369
     5        0.5204             nan     0.1000    0.1000
     6        0.4530             nan     0.1000    0.0797
     7        0.3988             nan     0.1000    0.0606
     8        0.3564             nan     0.1000    0.0562
     9        0.3197             nan     0.1000    0.0407
    10        0.2912             nan     0.1000    0.0281
    20        0.1589             nan     0.1000    0.0018
    40        0.1032             nan     0.1000    0.0007
    60        0.0759             nan     0.1000   -0.0007
    80        0.0620             nan     0.1000   -0.0014
   100        0.0510             nan     0.1000   -0.0010
   120        0.0423             nan     0.1000   -0.0012
   140        0.0356             nan     0.1000   -0.0014
   160        0.0306             nan     0.1000   -0.0005
   180        0.0274             nan     0.1000    0.0000
   200        0.0236             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3770
     2        0.8655             nan     0.1000    0.2574
     3        0.7064             nan     0.1000    0.1827
     4        0.5874             nan     0.1000    0.1386
     5        0.4978             nan     0.1000    0.1095
     6        0.4271             nan     0.1000    0.0761
     7        0.3739             nan     0.1000    0.0605
     8        0.3300             nan     0.1000    0.0480
     9        0.2936             nan     0.1000    0.0425
    10        0.2642             nan     0.1000    0.0300
    20        0.1364             nan     0.1000   -0.0007
    40        0.0730             nan     0.1000   -0.0015
    60        0.0523             nan     0.1000   -0.0036
    80        0.0384             nan     0.1000   -0.0013
   100        0.0289             nan     0.1000   -0.0008
   120        0.0230             nan     0.1000   -0.0017
   140        0.0184             nan     0.1000   -0.0012
   160        0.0156             nan     0.1000   -0.0010
   180        0.0129             nan     0.1000   -0.0015
   200        0.0109             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5479
     2        0.7318             nan     0.2000    0.2455
     3        0.5571             nan     0.2000    0.1394
     4        0.4600             nan     0.2000    0.0875
     5        0.3997             nan     0.2000    0.0543
     6        0.3566             nan     0.2000    0.0478
     7        0.3236             nan     0.2000    0.0268
     8        0.3015             nan     0.2000    0.0263
     9        0.2752             nan     0.2000    0.0201
    10        0.2608             nan     0.2000    0.0116
    20        0.1838             nan     0.2000   -0.0043
    40        0.1384             nan     0.2000   -0.0009
    60        0.1197             nan     0.2000   -0.0022
    80        0.1053             nan     0.2000   -0.0053
   100        0.0909             nan     0.2000   -0.0017
   120        0.0829             nan     0.2000   -0.0079
   140        0.0773             nan     0.2000   -0.0018
   160        0.0719             nan     0.2000   -0.0034
   180        0.0669             nan     0.2000   -0.0033
   200        0.0625             nan     0.2000   -0.0038

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6012
     2        0.7061             nan     0.2000    0.2552
     3        0.5225             nan     0.2000    0.1484
     4        0.4121             nan     0.2000    0.0849
     5        0.3433             nan     0.2000    0.0726
     6        0.2926             nan     0.2000    0.0399
     7        0.2598             nan     0.2000    0.0304
     8        0.2340             nan     0.2000    0.0249
     9        0.2134             nan     0.2000    0.0189
    10        0.1978             nan     0.2000    0.0166
    20        0.1354             nan     0.2000   -0.0108
    40        0.0912             nan     0.2000   -0.0010
    60        0.0724             nan     0.2000   -0.0020
    80        0.0573             nan     0.2000   -0.0021
   100        0.0480             nan     0.2000   -0.0020
   120        0.0388             nan     0.2000   -0.0017
   140        0.0321             nan     0.2000   -0.0016
   160        0.0276             nan     0.2000   -0.0015
   180        0.0245             nan     0.2000   -0.0034
   200        0.0219             nan     0.2000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5961
     2        0.6959             nan     0.2000    0.2887
     3        0.4914             nan     0.2000    0.1542
     4        0.3810             nan     0.2000    0.0944
     5        0.3101             nan     0.2000    0.0554
     6        0.2581             nan     0.2000    0.0526
     7        0.2175             nan     0.2000    0.0237
     8        0.1933             nan     0.2000    0.0192
     9        0.1752             nan     0.2000    0.0076
    10        0.1603             nan     0.2000    0.0035
    20        0.1025             nan     0.2000   -0.0106
    40        0.0616             nan     0.2000   -0.0026
    60        0.0433             nan     0.2000   -0.0035
    80        0.0332             nan     0.2000   -0.0025
   100        0.0242             nan     0.2000   -0.0017
   120        0.0185             nan     0.2000   -0.0029
   140        0.0156             nan     0.2000   -0.0006
   160        0.0127             nan     0.2000   -0.0006
   180        0.0101             nan     0.2000   -0.0003
   200        0.0087             nan     0.2000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6219
     2        0.6678             nan     0.2000    0.2771
     3        0.4721             nan     0.2000    0.1484
     4        0.3566             nan     0.2000    0.1008
     5        0.2793             nan     0.2000    0.0659
     6        0.2298             nan     0.2000    0.0357
     7        0.1968             nan     0.2000    0.0141
     8        0.1756             nan     0.2000    0.0182
     9        0.1548             nan     0.2000    0.0025
    10        0.1403             nan     0.2000   -0.0008
    20        0.0757             nan     0.2000   -0.0021
    40        0.0412             nan     0.2000   -0.0055
    60        0.0246             nan     0.2000   -0.0017
    80        0.0153             nan     0.2000   -0.0020
   100        0.0111             nan     0.2000   -0.0010
   120        0.0083             nan     0.2000   -0.0021
   140        0.0064             nan     0.2000   -0.0024
   160        0.0051             nan     0.2000   -0.0004
   180        0.0042             nan     0.2000   -0.0004
   200        0.0032             nan     0.2000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1825
     2        0.9927             nan     0.0500    0.1514
     3        0.9062             nan     0.0500    0.1271
     4        0.8317             nan     0.0500    0.1070
     5        0.7668             nan     0.0500    0.0909
     6        0.7113             nan     0.0500    0.0778
     7        0.6641             nan     0.0500    0.0659
     8        0.6250             nan     0.0500    0.0589
     9        0.5890             nan     0.0500    0.0517
    10        0.5568             nan     0.0500    0.0456
    20        0.3759             nan     0.0500    0.0162
    40        0.2595             nan     0.0500    0.0029
    60        0.2108             nan     0.0500    0.0015
    80        0.1829             nan     0.0500    0.0008
   100        0.1654             nan     0.0500    0.0012
   120        0.1529             nan     0.0500   -0.0004
   140        0.1425             nan     0.0500   -0.0015
   160        0.1345             nan     0.0500   -0.0008
   180        0.1267             nan     0.0500   -0.0003
   200        0.1211             nan     0.0500   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1913
     2        0.9854             nan     0.0500    0.1606
     3        0.8926             nan     0.0500    0.1352
     4        0.8129             nan     0.0500    0.1148
     5        0.7422             nan     0.0500    0.0979
     6        0.6842             nan     0.0500    0.0846
     7        0.6323             nan     0.0500    0.0742
     8        0.5875             nan     0.0500    0.0634
     9        0.5477             nan     0.0500    0.0563
    10        0.5129             nan     0.0500    0.0485
    20        0.3117             nan     0.0500    0.0151
    40        0.1881             nan     0.0500    0.0025
    60        0.1492             nan     0.0500   -0.0002
    80        0.1285             nan     0.0500   -0.0005
   100        0.1112             nan     0.0500   -0.0006
   120        0.0991             nan     0.0500   -0.0005
   140        0.0891             nan     0.0500   -0.0004
   160        0.0822             nan     0.0500   -0.0002
   180        0.0758             nan     0.0500   -0.0010
   200        0.0707             nan     0.0500   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2014
     2        0.9837             nan     0.0500    0.1674
     3        0.8832             nan     0.0500    0.1381
     4        0.7991             nan     0.0500    0.1184
     5        0.7289             nan     0.0500    0.1027
     6        0.6679             nan     0.0500    0.0872
     7        0.6129             nan     0.0500    0.0759
     8        0.5650             nan     0.0500    0.0641
     9        0.5250             nan     0.0500    0.0571
    10        0.4890             nan     0.0500    0.0505
    20        0.2798             nan     0.0500    0.0150
    40        0.1552             nan     0.0500    0.0026
    60        0.1175             nan     0.0500    0.0001
    80        0.0959             nan     0.0500   -0.0010
   100        0.0817             nan     0.0500   -0.0010
   120        0.0727             nan     0.0500   -0.0006
   140        0.0645             nan     0.0500   -0.0007
   160        0.0584             nan     0.0500   -0.0009
   180        0.0530             nan     0.0500   -0.0000
   200        0.0480             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2096
     2        0.9768             nan     0.0500    0.1705
     3        0.8746             nan     0.0500    0.1469
     4        0.7877             nan     0.0500    0.1243
     5        0.7142             nan     0.0500    0.1045
     6        0.6516             nan     0.0500    0.0931
     7        0.5953             nan     0.0500    0.0779
     8        0.5468             nan     0.0500    0.0713
     9        0.5034             nan     0.0500    0.0610
    10        0.4656             nan     0.0500    0.0557
    20        0.2516             nan     0.0500    0.0163
    40        0.1305             nan     0.0500    0.0014
    60        0.0918             nan     0.0500   -0.0020
    80        0.0700             nan     0.0500   -0.0010
   100        0.0573             nan     0.0500   -0.0009
   120        0.0480             nan     0.0500   -0.0014
   140        0.0408             nan     0.0500   -0.0011
   160        0.0350             nan     0.0500   -0.0012
   180        0.0302             nan     0.0500   -0.0004
   200        0.0266             nan     0.0500   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3351
     2        0.8954             nan     0.1000    0.2264
     3        0.7562             nan     0.1000    0.1638
     4        0.6519             nan     0.1000    0.1193
     5        0.5765             nan     0.1000    0.0886
     6        0.5174             nan     0.1000    0.0721
     7        0.4705             nan     0.1000    0.0530
     8        0.4346             nan     0.1000    0.0390
     9        0.4056             nan     0.1000    0.0325
    10        0.3804             nan     0.1000    0.0337
    20        0.2583             nan     0.1000    0.0049
    40        0.1851             nan     0.1000    0.0042
    60        0.1557             nan     0.1000   -0.0009
    80        0.1352             nan     0.1000    0.0003
   100        0.1227             nan     0.1000   -0.0023
   120        0.1141             nan     0.1000   -0.0019
   140        0.1058             nan     0.1000   -0.0008
   160        0.0994             nan     0.1000   -0.0017
   180        0.0956             nan     0.1000   -0.0018
   200        0.0912             nan     0.1000   -0.0036

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3586
     2        0.8804             nan     0.1000    0.2433
     3        0.7301             nan     0.1000    0.1754
     4        0.6185             nan     0.1000    0.1295
     5        0.5357             nan     0.1000    0.0935
     6        0.4724             nan     0.1000    0.0770
     7        0.4211             nan     0.1000    0.0597
     8        0.3798             nan     0.1000    0.0482
     9        0.3467             nan     0.1000    0.0357
    10        0.3210             nan     0.1000    0.0367
    20        0.1891             nan     0.1000    0.0055
    40        0.1249             nan     0.1000   -0.0023
    60        0.1006             nan     0.1000   -0.0024
    80        0.0866             nan     0.1000   -0.0019
   100        0.0744             nan     0.1000   -0.0005
   120        0.0644             nan     0.1000   -0.0017
   140        0.0568             nan     0.1000   -0.0005
   160        0.0512             nan     0.1000   -0.0009
   180        0.0465             nan     0.1000   -0.0022
   200        0.0432             nan     0.1000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3653
     2        0.8715             nan     0.1000    0.2471
     3        0.7148             nan     0.1000    0.1799
     4        0.5986             nan     0.1000    0.1359
     5        0.5130             nan     0.1000    0.0967
     6        0.4470             nan     0.1000    0.0777
     7        0.3937             nan     0.1000    0.0606
     8        0.3522             nan     0.1000    0.0449
     9        0.3187             nan     0.1000    0.0382
    10        0.2897             nan     0.1000    0.0303
    20        0.1576             nan     0.1000    0.0066
    40        0.0996             nan     0.1000   -0.0036
    60        0.0752             nan     0.1000   -0.0004
    80        0.0604             nan     0.1000   -0.0021
   100        0.0500             nan     0.1000   -0.0014
   120        0.0410             nan     0.1000   -0.0015
   140        0.0344             nan     0.1000   -0.0010
   160        0.0301             nan     0.1000   -0.0006
   180        0.0262             nan     0.1000   -0.0018
   200        0.0232             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3891
     2        0.8643             nan     0.1000    0.2660
     3        0.7026             nan     0.1000    0.1881
     4        0.5827             nan     0.1000    0.1451
     5        0.4913             nan     0.1000    0.1001
     6        0.4236             nan     0.1000    0.0815
     7        0.3685             nan     0.1000    0.0594
     8        0.3260             nan     0.1000    0.0451
     9        0.2928             nan     0.1000    0.0442
    10        0.2611             nan     0.1000    0.0298
    20        0.1328             nan     0.1000    0.0034
    40        0.0714             nan     0.1000   -0.0029
    60        0.0476             nan     0.1000   -0.0014
    80        0.0355             nan     0.1000   -0.0017
   100        0.0280             nan     0.1000   -0.0011
   120        0.0223             nan     0.1000   -0.0008
   140        0.0185             nan     0.1000   -0.0004
   160        0.0159             nan     0.1000   -0.0017
   180        0.0131             nan     0.1000   -0.0003
   200        0.0112             nan     0.1000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5506
     2        0.7256             nan     0.2000    0.2533
     3        0.5554             nan     0.2000    0.1326
     4        0.4576             nan     0.2000    0.0831
     5        0.3949             nan     0.2000    0.0675
     6        0.3449             nan     0.2000    0.0347
     7        0.3161             nan     0.2000    0.0265
     8        0.2930             nan     0.2000    0.0234
     9        0.2755             nan     0.2000    0.0154
    10        0.2598             nan     0.2000    0.0169
    20        0.1819             nan     0.2000   -0.0096
    40        0.1364             nan     0.2000   -0.0053
    60        0.1133             nan     0.2000   -0.0014
    80        0.1005             nan     0.2000   -0.0069
   100        0.0901             nan     0.2000   -0.0057
   120        0.0831             nan     0.2000   -0.0029
   140        0.0770             nan     0.2000   -0.0044
   160        0.0713             nan     0.2000   -0.0023
   180        0.0660             nan     0.2000   -0.0009
   200        0.0609             nan     0.2000   -0.0022

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5798
     2        0.7010             nan     0.2000    0.2701
     3        0.5113             nan     0.2000    0.1524
     4        0.4033             nan     0.2000    0.0896
     5        0.3348             nan     0.2000    0.0674
     6        0.2821             nan     0.2000    0.0413
     7        0.2515             nan     0.2000    0.0225
     8        0.2279             nan     0.2000    0.0123
     9        0.2102             nan     0.2000    0.0147
    10        0.1948             nan     0.2000    0.0074
    20        0.1253             nan     0.2000   -0.0072
    40        0.0845             nan     0.2000   -0.0042
    60        0.0663             nan     0.2000   -0.0027
    80        0.0533             nan     0.2000   -0.0015
   100        0.0443             nan     0.2000   -0.0022
   120        0.0371             nan     0.2000   -0.0025
   140        0.0299             nan     0.2000   -0.0027
   160        0.0264             nan     0.2000   -0.0036
   180        0.0225             nan     0.2000   -0.0018
   200        0.0198             nan     0.2000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6222
     2        0.6812             nan     0.2000    0.2852
     3        0.4910             nan     0.2000    0.1594
     4        0.3762             nan     0.2000    0.0955
     5        0.3042             nan     0.2000    0.0617
     6        0.2564             nan     0.2000    0.0385
     7        0.2193             nan     0.2000    0.0255
     8        0.1940             nan     0.2000    0.0130
     9        0.1764             nan     0.2000    0.0068
    10        0.1626             nan     0.2000    0.0055
    20        0.1026             nan     0.2000   -0.0032
    40        0.0621             nan     0.2000   -0.0043
    60        0.0424             nan     0.2000   -0.0009
    80        0.0318             nan     0.2000   -0.0021
   100        0.0249             nan     0.2000   -0.0043
   120        0.0207             nan     0.2000   -0.0034
   140        0.0176             nan     0.2000   -0.0013
   160        0.0152             nan     0.2000   -0.0024
   180        0.0127             nan     0.2000   -0.0011
   200        0.0114             nan     0.2000   -0.0028

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6321
     2        0.6718             nan     0.2000    0.3055
     3        0.4672             nan     0.2000    0.1642
     4        0.3502             nan     0.2000    0.0917
     5        0.2763             nan     0.2000    0.0613
     6        0.2279             nan     0.2000    0.0313
     7        0.1976             nan     0.2000    0.0154
     8        0.1713             nan     0.2000    0.0152
     9        0.1500             nan     0.2000    0.0026
    10        0.1392             nan     0.2000    0.0061
    20        0.0745             nan     0.2000   -0.0039
    40        0.0384             nan     0.2000   -0.0036
    60        0.0228             nan     0.2000   -0.0034
    80        0.0158             nan     0.2000   -0.0021
   100        0.0122             nan     0.2000   -0.0018
   120        0.0092             nan     0.2000   -0.0041
   140        0.0072             nan     0.2000   -0.0025
   160        0.0060             nan     0.2000   -0.0003
   180        0.0054             nan     0.2000   -0.0003
   200        0.0041             nan     0.2000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1808
     2        0.9941             nan     0.0500    0.1502
     3        0.9094             nan     0.0500    0.1266
     4        0.8346             nan     0.0500    0.1067
     5        0.7715             nan     0.0500    0.0915
     6        0.7173             nan     0.0500    0.0782
     7        0.6680             nan     0.0500    0.0671
     8        0.6267             nan     0.0500    0.0581
     9        0.5900             nan     0.0500    0.0507
    10        0.5576             nan     0.0500    0.0430
    20        0.3788             nan     0.0500    0.0149
    40        0.2579             nan     0.0500    0.0024
    60        0.2123             nan     0.0500    0.0016
    80        0.1836             nan     0.0500    0.0006
   100        0.1660             nan     0.0500   -0.0004
   120        0.1530             nan     0.0500    0.0005
   140        0.1447             nan     0.0500   -0.0008
   160        0.1363             nan     0.0500    0.0006
   180        0.1298             nan     0.0500   -0.0016
   200        0.1246             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1962
     2        0.9862             nan     0.0500    0.1612
     3        0.8917             nan     0.0500    0.1344
     4        0.8110             nan     0.0500    0.1139
     5        0.7432             nan     0.0500    0.0972
     6        0.6837             nan     0.0500    0.0812
     7        0.6341             nan     0.0500    0.0728
     8        0.5903             nan     0.0500    0.0643
     9        0.5514             nan     0.0500    0.0547
    10        0.5165             nan     0.0500    0.0479
    20        0.3153             nan     0.0500    0.0136
    40        0.1886             nan     0.0500    0.0030
    60        0.1437             nan     0.0500   -0.0001
    80        0.1221             nan     0.0500   -0.0000
   100        0.1088             nan     0.0500   -0.0001
   120        0.0974             nan     0.0500   -0.0003
   140        0.0891             nan     0.0500   -0.0011
   160        0.0823             nan     0.0500   -0.0010
   180        0.0766             nan     0.0500   -0.0006
   200        0.0719             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2035
     2        0.9814             nan     0.0500    0.1658
     3        0.8839             nan     0.0500    0.1361
     4        0.8023             nan     0.0500    0.1189
     5        0.7322             nan     0.0500    0.1028
     6        0.6698             nan     0.0500    0.0874
     7        0.6155             nan     0.0500    0.0717
     8        0.5682             nan     0.0500    0.0657
     9        0.5281             nan     0.0500    0.0591
    10        0.4920             nan     0.0500    0.0493
    20        0.2831             nan     0.0500    0.0177
    40        0.1556             nan     0.0500    0.0036
    60        0.1189             nan     0.0500    0.0003
    80        0.0986             nan     0.0500   -0.0009
   100        0.0849             nan     0.0500   -0.0002
   120        0.0745             nan     0.0500   -0.0006
   140        0.0658             nan     0.0500   -0.0004
   160        0.0595             nan     0.0500   -0.0010
   180        0.0542             nan     0.0500   -0.0014
   200        0.0490             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2090
     2        0.9765             nan     0.0500    0.1762
     3        0.8740             nan     0.0500    0.1396
     4        0.7881             nan     0.0500    0.1172
     5        0.7158             nan     0.0500    0.1077
     6        0.6504             nan     0.0500    0.0878
     7        0.5960             nan     0.0500    0.0802
     8        0.5469             nan     0.0500    0.0672
     9        0.5045             nan     0.0500    0.0586
    10        0.4673             nan     0.0500    0.0530
    20        0.2494             nan     0.0500    0.0143
    40        0.1263             nan     0.0500    0.0018
    60        0.0895             nan     0.0500   -0.0005
    80        0.0705             nan     0.0500   -0.0005
   100        0.0585             nan     0.0500   -0.0009
   120        0.0497             nan     0.0500   -0.0009
   140        0.0420             nan     0.0500   -0.0008
   160        0.0362             nan     0.0500   -0.0009
   180        0.0310             nan     0.0500   -0.0007
   200        0.0270             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3325
     2        0.8940             nan     0.1000    0.2190
     3        0.7549             nan     0.1000    0.1595
     4        0.6540             nan     0.1000    0.1181
     5        0.5770             nan     0.1000    0.0918
     6        0.5208             nan     0.1000    0.0657
     7        0.4747             nan     0.1000    0.0576
     8        0.4378             nan     0.1000    0.0441
     9        0.4083             nan     0.1000    0.0356
    10        0.3823             nan     0.1000    0.0243
    20        0.2592             nan     0.1000    0.0059
    40        0.1830             nan     0.1000   -0.0012
    60        0.1510             nan     0.1000   -0.0004
    80        0.1356             nan     0.1000   -0.0015
   100        0.1239             nan     0.1000   -0.0025
   120        0.1146             nan     0.1000   -0.0016
   140        0.1066             nan     0.1000    0.0003
   160        0.1009             nan     0.1000   -0.0003
   180        0.0952             nan     0.1000   -0.0007
   200        0.0907             nan     0.1000   -0.0024

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3553
     2        0.8816             nan     0.1000    0.2411
     3        0.7314             nan     0.1000    0.1743
     4        0.6192             nan     0.1000    0.1260
     5        0.5395             nan     0.1000    0.0993
     6        0.4760             nan     0.1000    0.0810
     7        0.4256             nan     0.1000    0.0598
     8        0.3850             nan     0.1000    0.0484
     9        0.3516             nan     0.1000    0.0452
    10        0.3216             nan     0.1000    0.0325
    20        0.1881             nan     0.1000    0.0028
    40        0.1260             nan     0.1000   -0.0005
    60        0.1021             nan     0.1000   -0.0024
    80        0.0857             nan     0.1000   -0.0027
   100        0.0753             nan     0.1000   -0.0001
   120        0.0665             nan     0.1000   -0.0020
   140        0.0579             nan     0.1000   -0.0017
   160        0.0524             nan     0.1000   -0.0020
   180        0.0478             nan     0.1000   -0.0007
   200        0.0435             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3705
     2        0.8715             nan     0.1000    0.2489
     3        0.7196             nan     0.1000    0.1809
     4        0.6085             nan     0.1000    0.1394
     5        0.5208             nan     0.1000    0.1046
     6        0.4531             nan     0.1000    0.0806
     7        0.3991             nan     0.1000    0.0671
     8        0.3541             nan     0.1000    0.0500
     9        0.3197             nan     0.1000    0.0418
    10        0.2909             nan     0.1000    0.0341
    20        0.1592             nan     0.1000    0.0045
    40        0.0985             nan     0.1000   -0.0052
    60        0.0778             nan     0.1000   -0.0022
    80        0.0612             nan     0.1000   -0.0019
   100        0.0509             nan     0.1000   -0.0011
   120        0.0424             nan     0.1000   -0.0010
   140        0.0358             nan     0.1000   -0.0008
   160        0.0309             nan     0.1000   -0.0016
   180        0.0270             nan     0.1000   -0.0007
   200        0.0243             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3881
     2        0.8603             nan     0.1000    0.2661
     3        0.6967             nan     0.1000    0.1879
     4        0.5805             nan     0.1000    0.1405
     5        0.4916             nan     0.1000    0.1101
     6        0.4208             nan     0.1000    0.0791
     7        0.3647             nan     0.1000    0.0639
     8        0.3202             nan     0.1000    0.0488
     9        0.2850             nan     0.1000    0.0404
    10        0.2552             nan     0.1000    0.0298
    20        0.1294             nan     0.1000    0.0013
    40        0.0697             nan     0.1000   -0.0027
    60        0.0488             nan     0.1000   -0.0004
    80        0.0351             nan     0.1000   -0.0006
   100        0.0266             nan     0.1000   -0.0019
   120        0.0210             nan     0.1000   -0.0007
   140        0.0172             nan     0.1000   -0.0011
   160        0.0142             nan     0.1000   -0.0005
   180        0.0119             nan     0.1000   -0.0008
   200        0.0103             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5515
     2        0.7300             nan     0.2000    0.2572
     3        0.5635             nan     0.2000    0.1344
     4        0.4657             nan     0.2000    0.0973
     5        0.3976             nan     0.2000    0.0605
     6        0.3541             nan     0.2000    0.0449
     7        0.3181             nan     0.2000    0.0334
     8        0.2906             nan     0.2000    0.0241
     9        0.2716             nan     0.2000    0.0096
    10        0.2598             nan     0.2000    0.0102
    20        0.1866             nan     0.2000    0.0009
    40        0.1376             nan     0.2000    0.0021
    60        0.1181             nan     0.2000   -0.0078
    80        0.1070             nan     0.2000   -0.0043
   100        0.1005             nan     0.2000   -0.0032
   120        0.0909             nan     0.2000   -0.0060
   140        0.0853             nan     0.2000   -0.0021
   160        0.0796             nan     0.2000   -0.0037
   180        0.0744             nan     0.2000   -0.0026
   200        0.0693             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5739
     2        0.7014             nan     0.2000    0.2750
     3        0.5136             nan     0.2000    0.1564
     4        0.4023             nan     0.2000    0.1011
     5        0.3318             nan     0.2000    0.0466
     6        0.2882             nan     0.2000    0.0420
     7        0.2560             nan     0.2000    0.0346
     8        0.2289             nan     0.2000    0.0148
     9        0.2110             nan     0.2000    0.0044
    10        0.1985             nan     0.2000    0.0131
    20        0.1273             nan     0.2000   -0.0047
    40        0.0874             nan     0.2000   -0.0052
    60        0.0662             nan     0.2000   -0.0043
    80        0.0524             nan     0.2000   -0.0017
   100        0.0422             nan     0.2000   -0.0019
   120        0.0354             nan     0.2000   -0.0031
   140        0.0290             nan     0.2000   -0.0032
   160        0.0254             nan     0.2000   -0.0029
   180        0.0216             nan     0.2000   -0.0015
   200        0.0193             nan     0.2000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6014
     2        0.6901             nan     0.2000    0.2874
     3        0.4986             nan     0.2000    0.1548
     4        0.3854             nan     0.2000    0.1047
     5        0.3130             nan     0.2000    0.0731
     6        0.2615             nan     0.2000    0.0509
     7        0.2240             nan     0.2000    0.0238
     8        0.2000             nan     0.2000    0.0187
     9        0.1782             nan     0.2000    0.0007
    10        0.1677             nan     0.2000   -0.0017
    20        0.0990             nan     0.2000   -0.0065
    40        0.0622             nan     0.2000   -0.0005
    60        0.0431             nan     0.2000   -0.0023
    80        0.0308             nan     0.2000   -0.0008
   100        0.0242             nan     0.2000   -0.0026
   120        0.0195             nan     0.2000   -0.0015
   140        0.0159             nan     0.2000   -0.0026
   160        0.0142             nan     0.2000   -0.0023
   180        0.0120             nan     0.2000   -0.0040
   200        0.0108             nan     0.2000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5984
     2        0.6840             nan     0.2000    0.3119
     3        0.4706             nan     0.2000    0.1564
     4        0.3564             nan     0.2000    0.1065
     5        0.2813             nan     0.2000    0.0600
     6        0.2308             nan     0.2000    0.0481
     7        0.1925             nan     0.2000    0.0286
     8        0.1667             nan     0.2000   -0.0007
     9        0.1512             nan     0.2000    0.0005
    10        0.1409             nan     0.2000   -0.0027
    20        0.0832             nan     0.2000   -0.0061
    40        0.0397             nan     0.2000   -0.0038
    60        0.0238             nan     0.2000   -0.0031
    80        0.0159             nan     0.2000   -0.0007
   100        0.0122             nan     0.2000   -0.0027
   120        0.0099             nan     0.2000   -0.0025
   140        0.0078             nan     0.2000   -0.0019
   160        0.0063             nan     0.2000   -0.0019
   180        0.0057             nan     0.2000   -0.0004
   200        0.0050             nan     0.2000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1809
     2        0.9971             nan     0.0500    0.1469
     3        0.9078             nan     0.0500    0.1248
     4        0.8337             nan     0.0500    0.1064
     5        0.7698             nan     0.0500    0.0907
     6        0.7161             nan     0.0500    0.0790
     7        0.6693             nan     0.0500    0.0662
     8        0.6283             nan     0.0500    0.0591
     9        0.5931             nan     0.0500    0.0518
    10        0.5607             nan     0.0500    0.0448
    20        0.3795             nan     0.0500    0.0156
    40        0.2627             nan     0.0500    0.0029
    60        0.2168             nan     0.0500   -0.0014
    80        0.1914             nan     0.0500    0.0011
   100        0.1727             nan     0.0500    0.0003
   120        0.1593             nan     0.0500   -0.0011
   140        0.1498             nan     0.0500   -0.0001
   160        0.1408             nan     0.0500   -0.0006
   180        0.1355             nan     0.0500   -0.0006
   200        0.1300             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1926
     2        0.9867             nan     0.0500    0.1593
     3        0.8931             nan     0.0500    0.1326
     4        0.8127             nan     0.0500    0.1145
     5        0.7450             nan     0.0500    0.0991
     6        0.6868             nan     0.0500    0.0828
     7        0.6363             nan     0.0500    0.0727
     8        0.5924             nan     0.0500    0.0644
     9        0.5533             nan     0.0500    0.0556
    10        0.5184             nan     0.0500    0.0510
    20        0.3170             nan     0.0500    0.0188
    40        0.1918             nan     0.0500    0.0031
    60        0.1529             nan     0.0500    0.0003
    80        0.1295             nan     0.0500   -0.0002
   100        0.1150             nan     0.0500   -0.0015
   120        0.1037             nan     0.0500   -0.0001
   140        0.0950             nan     0.0500   -0.0016
   160        0.0876             nan     0.0500   -0.0007
   180        0.0813             nan     0.0500   -0.0008
   200        0.0752             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2045
     2        0.9797             nan     0.0500    0.1658
     3        0.8805             nan     0.0500    0.1390
     4        0.7977             nan     0.0500    0.1165
     5        0.7283             nan     0.0500    0.1012
     6        0.6673             nan     0.0500    0.0877
     7        0.6126             nan     0.0500    0.0759
     8        0.5656             nan     0.0500    0.0672
     9        0.5241             nan     0.0500    0.0575
    10        0.4877             nan     0.0500    0.0512
    20        0.2805             nan     0.0500    0.0174
    40        0.1618             nan     0.0500    0.0020
    60        0.1242             nan     0.0500    0.0001
    80        0.1024             nan     0.0500   -0.0010
   100        0.0886             nan     0.0500   -0.0010
   120        0.0790             nan     0.0500   -0.0007
   140        0.0704             nan     0.0500   -0.0004
   160        0.0631             nan     0.0500   -0.0006
   180        0.0567             nan     0.0500   -0.0005
   200        0.0526             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2039
     2        0.9764             nan     0.0500    0.1730
     3        0.8726             nan     0.0500    0.1411
     4        0.7875             nan     0.0500    0.1225
     5        0.7135             nan     0.0500    0.1045
     6        0.6512             nan     0.0500    0.0912
     7        0.5956             nan     0.0500    0.0778
     8        0.5472             nan     0.0500    0.0678
     9        0.5066             nan     0.0500    0.0619
    10        0.4683             nan     0.0500    0.0502
    20        0.2576             nan     0.0500    0.0157
    40        0.1322             nan     0.0500   -0.0010
    60        0.0946             nan     0.0500    0.0005
    80        0.0737             nan     0.0500   -0.0013
   100        0.0605             nan     0.0500   -0.0014
   120        0.0509             nan     0.0500   -0.0011
   140        0.0436             nan     0.0500   -0.0007
   160        0.0373             nan     0.0500   -0.0005
   180        0.0327             nan     0.0500   -0.0007
   200        0.0287             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3338
     2        0.8981             nan     0.1000    0.2241
     3        0.7553             nan     0.1000    0.1626
     4        0.6552             nan     0.1000    0.1178
     5        0.5765             nan     0.1000    0.0844
     6        0.5194             nan     0.1000    0.0661
     7        0.4744             nan     0.1000    0.0528
     8        0.4388             nan     0.1000    0.0401
     9        0.4087             nan     0.1000    0.0371
    10        0.3825             nan     0.1000    0.0315
    20        0.2609             nan     0.1000    0.0067
    40        0.1882             nan     0.1000   -0.0015
    60        0.1564             nan     0.1000    0.0003
    80        0.1392             nan     0.1000   -0.0019
   100        0.1276             nan     0.1000   -0.0011
   120        0.1196             nan     0.1000   -0.0026
   140        0.1120             nan     0.1000   -0.0006
   160        0.1049             nan     0.1000   -0.0020
   180        0.0998             nan     0.1000   -0.0010
   200        0.0960             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3581
     2        0.8844             nan     0.1000    0.2389
     3        0.7336             nan     0.1000    0.1744
     4        0.6246             nan     0.1000    0.1219
     5        0.5445             nan     0.1000    0.0998
     6        0.4812             nan     0.1000    0.0770
     7        0.4310             nan     0.1000    0.0596
     8        0.3901             nan     0.1000    0.0438
     9        0.3576             nan     0.1000    0.0383
    10        0.3296             nan     0.1000    0.0286
    20        0.1992             nan     0.1000    0.0037
    40        0.1334             nan     0.1000    0.0016
    60        0.1045             nan     0.1000   -0.0027
    80        0.0867             nan     0.1000   -0.0019
   100        0.0761             nan     0.1000   -0.0016
   120        0.0673             nan     0.1000   -0.0026
   140        0.0593             nan     0.1000   -0.0008
   160        0.0539             nan     0.1000   -0.0012
   180        0.0488             nan     0.1000   -0.0014
   200        0.0446             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3733
     2        0.8733             nan     0.1000    0.2546
     3        0.7173             nan     0.1000    0.1827
     4        0.6027             nan     0.1000    0.1339
     5        0.5181             nan     0.1000    0.1061
     6        0.4521             nan     0.1000    0.0782
     7        0.3989             nan     0.1000    0.0595
     8        0.3565             nan     0.1000    0.0509
     9        0.3216             nan     0.1000    0.0426
    10        0.2911             nan     0.1000    0.0345
    20        0.1615             nan     0.1000    0.0042
    40        0.1008             nan     0.1000   -0.0023
    60        0.0770             nan     0.1000   -0.0014
    80        0.0626             nan     0.1000   -0.0035
   100        0.0521             nan     0.1000   -0.0024
   120        0.0447             nan     0.1000   -0.0023
   140        0.0393             nan     0.1000   -0.0004
   160        0.0340             nan     0.1000   -0.0009
   180        0.0293             nan     0.1000   -0.0002
   200        0.0261             nan     0.1000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3828
     2        0.8679             nan     0.1000    0.2596
     3        0.7046             nan     0.1000    0.1932
     4        0.5851             nan     0.1000    0.1440
     5        0.4934             nan     0.1000    0.1060
     6        0.4248             nan     0.1000    0.0818
     7        0.3706             nan     0.1000    0.0627
     8        0.3273             nan     0.1000    0.0477
     9        0.2928             nan     0.1000    0.0375
    10        0.2645             nan     0.1000    0.0332
    20        0.1340             nan     0.1000   -0.0009
    40        0.0759             nan     0.1000   -0.0050
    60        0.0547             nan     0.1000   -0.0005
    80        0.0401             nan     0.1000   -0.0016
   100        0.0308             nan     0.1000   -0.0012
   120        0.0254             nan     0.1000   -0.0016
   140        0.0208             nan     0.1000   -0.0016
   160        0.0173             nan     0.1000   -0.0008
   180        0.0152             nan     0.1000   -0.0013
   200        0.0127             nan     0.1000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5526
     2        0.7353             nan     0.2000    0.2533
     3        0.5627             nan     0.2000    0.1363
     4        0.4667             nan     0.2000    0.0934
     5        0.3985             nan     0.2000    0.0645
     6        0.3531             nan     0.2000    0.0296
     7        0.3227             nan     0.2000    0.0360
     8        0.2986             nan     0.2000    0.0222
     9        0.2752             nan     0.2000    0.0134
    10        0.2586             nan     0.2000    0.0085
    20        0.1905             nan     0.2000    0.0060
    40        0.1434             nan     0.2000   -0.0015
    60        0.1209             nan     0.2000   -0.0057
    80        0.1065             nan     0.2000   -0.0051
   100        0.0975             nan     0.2000   -0.0010
   120        0.0894             nan     0.2000   -0.0030
   140        0.0836             nan     0.2000   -0.0027
   160        0.0789             nan     0.2000   -0.0032
   180        0.0740             nan     0.2000   -0.0044
   200        0.0694             nan     0.2000   -0.0022

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5711
     2        0.7108             nan     0.2000    0.2693
     3        0.5108             nan     0.2000    0.1359
     4        0.4058             nan     0.2000    0.0804
     5        0.3395             nan     0.2000    0.0726
     6        0.2852             nan     0.2000    0.0415
     7        0.2533             nan     0.2000    0.0308
     8        0.2294             nan     0.2000    0.0177
     9        0.2138             nan     0.2000    0.0098
    10        0.2001             nan     0.2000    0.0153
    20        0.1350             nan     0.2000   -0.0053
    40        0.0895             nan     0.2000   -0.0049
    60        0.0706             nan     0.2000   -0.0053
    80        0.0566             nan     0.2000   -0.0021
   100        0.0488             nan     0.2000   -0.0022
   120        0.0407             nan     0.2000   -0.0033
   140        0.0338             nan     0.2000   -0.0024
   160        0.0291             nan     0.2000   -0.0007
   180        0.0246             nan     0.2000   -0.0010
   200        0.0216             nan     0.2000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6079
     2        0.6814             nan     0.2000    0.2674
     3        0.4867             nan     0.2000    0.1429
     4        0.3812             nan     0.2000    0.0973
     5        0.3096             nan     0.2000    0.0642
     6        0.2575             nan     0.2000    0.0251
     7        0.2235             nan     0.2000    0.0208
     8        0.1986             nan     0.2000    0.0122
     9        0.1827             nan     0.2000    0.0055
    10        0.1689             nan     0.2000    0.0081
    20        0.1111             nan     0.2000   -0.0008
    40        0.0713             nan     0.2000   -0.0053
    60        0.0496             nan     0.2000   -0.0050
    80        0.0360             nan     0.2000   -0.0036
   100        0.0289             nan     0.2000   -0.0017
   120        0.0239             nan     0.2000   -0.0037
   140        0.0193             nan     0.2000   -0.0040
   160        0.0172             nan     0.2000   -0.0020
   180        0.0152             nan     0.2000   -0.0009
   200        0.0130             nan     0.2000   -0.0028

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6252
     2        0.6750             nan     0.2000    0.2860
     3        0.4768             nan     0.2000    0.1629
     4        0.3618             nan     0.2000    0.0817
     5        0.2810             nan     0.2000    0.0551
     6        0.2362             nan     0.2000    0.0365
     7        0.2006             nan     0.2000    0.0230
     8        0.1769             nan     0.2000    0.0072
     9        0.1589             nan     0.2000    0.0118
    10        0.1423             nan     0.2000    0.0015
    20        0.0794             nan     0.2000   -0.0046
    40        0.0391             nan     0.2000   -0.0067
    60        0.0238             nan     0.2000   -0.0036
    80        0.0167             nan     0.2000   -0.0028
   100        0.0121             nan     0.2000   -0.0014
   120        0.0097             nan     0.2000   -0.0007
   140        0.0077             nan     0.2000   -0.0021
   160        0.0067             nan     0.2000   -0.0020
   180        0.0062             nan     0.2000   -0.0016
   200        0.0053             nan     0.2000   -0.0037

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1788
     2        0.9949             nan     0.0500    0.1466
     3        0.9063             nan     0.0500    0.1211
     4        0.8351             nan     0.0500    0.1034
     5        0.7730             nan     0.0500    0.0871
     6        0.7201             nan     0.0500    0.0751
     7        0.6744             nan     0.0500    0.0665
     8        0.6356             nan     0.0500    0.0578
     9        0.6001             nan     0.0500    0.0501
    10        0.5680             nan     0.0500    0.0445
    20        0.3894             nan     0.0500    0.0159
    40        0.2716             nan     0.0500    0.0036
    60        0.2235             nan     0.0500    0.0014
    80        0.1949             nan     0.0500    0.0001
   100        0.1781             nan     0.0500    0.0011
   120        0.1644             nan     0.0500   -0.0001
   140        0.1544             nan     0.0500   -0.0007
   160        0.1456             nan     0.0500   -0.0007
   180        0.1383             nan     0.0500   -0.0004
   200        0.1322             nan     0.0500   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1902
     2        0.9888             nan     0.0500    0.1595
     3        0.8957             nan     0.0500    0.1323
     4        0.8167             nan     0.0500    0.1005
     5        0.7524             nan     0.0500    0.0974
     6        0.6941             nan     0.0500    0.0816
     7        0.6430             nan     0.0500    0.0710
     8        0.5982             nan     0.0500    0.0643
     9        0.5581             nan     0.0500    0.0535
    10        0.5252             nan     0.0500    0.0483
    20        0.3240             nan     0.0500    0.0185
    40        0.1974             nan     0.0500    0.0009
    60        0.1573             nan     0.0500    0.0004
    80        0.1325             nan     0.0500   -0.0006
   100        0.1172             nan     0.0500   -0.0006
   120        0.1047             nan     0.0500   -0.0005
   140        0.0963             nan     0.0500   -0.0003
   160        0.0876             nan     0.0500   -0.0002
   180        0.0805             nan     0.0500   -0.0010
   200        0.0752             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1996
     2        0.9821             nan     0.0500    0.1614
     3        0.8860             nan     0.0500    0.1364
     4        0.8052             nan     0.0500    0.1164
     5        0.7357             nan     0.0500    0.0967
     6        0.6757             nan     0.0500    0.0828
     7        0.6223             nan     0.0500    0.0748
     8        0.5757             nan     0.0500    0.0644
     9        0.5347             nan     0.0500    0.0565
    10        0.4989             nan     0.0500    0.0527
    20        0.2910             nan     0.0500    0.0182
    40        0.1643             nan     0.0500    0.0027
    60        0.1258             nan     0.0500    0.0007
    80        0.1054             nan     0.0500   -0.0011
   100        0.0892             nan     0.0500   -0.0007
   120        0.0778             nan     0.0500   -0.0004
   140        0.0686             nan     0.0500   -0.0007
   160        0.0617             nan     0.0500   -0.0018
   180        0.0549             nan     0.0500   -0.0005
   200        0.0497             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1982
     2        0.9802             nan     0.0500    0.1715
     3        0.8765             nan     0.0500    0.1458
     4        0.7908             nan     0.0500    0.1198
     5        0.7181             nan     0.0500    0.1027
     6        0.6556             nan     0.0500    0.0906
     7        0.6005             nan     0.0500    0.0773
     8        0.5532             nan     0.0500    0.0685
     9        0.5114             nan     0.0500    0.0580
    10        0.4750             nan     0.0500    0.0533
    20        0.2625             nan     0.0500    0.0164
    40        0.1362             nan     0.0500    0.0022
    60        0.0971             nan     0.0500   -0.0009
    80        0.0753             nan     0.0500   -0.0001
   100        0.0613             nan     0.0500   -0.0015
   120        0.0518             nan     0.0500   -0.0007
   140        0.0441             nan     0.0500   -0.0005
   160        0.0382             nan     0.0500   -0.0011
   180        0.0336             nan     0.0500   -0.0006
   200        0.0292             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3286
     2        0.9030             nan     0.1000    0.2230
     3        0.7646             nan     0.1000    0.1624
     4        0.6658             nan     0.1000    0.1163
     5        0.5912             nan     0.1000    0.0915
     6        0.5324             nan     0.1000    0.0651
     7        0.4875             nan     0.1000    0.0572
     8        0.4493             nan     0.1000    0.0441
     9        0.4189             nan     0.1000    0.0362
    10        0.3931             nan     0.1000    0.0266
    20        0.2722             nan     0.1000    0.0073
    40        0.1960             nan     0.1000    0.0016
    60        0.1651             nan     0.1000    0.0015
    80        0.1439             nan     0.1000   -0.0027
   100        0.1315             nan     0.1000   -0.0012
   120        0.1227             nan     0.1000   -0.0011
   140        0.1158             nan     0.1000   -0.0006
   160        0.1098             nan     0.1000   -0.0006
   180        0.1046             nan     0.1000   -0.0003
   200        0.0989             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3551
     2        0.8870             nan     0.1000    0.2361
     3        0.7380             nan     0.1000    0.1677
     4        0.6309             nan     0.1000    0.1299
     5        0.5496             nan     0.1000    0.0954
     6        0.4846             nan     0.1000    0.0790
     7        0.4341             nan     0.1000    0.0616
     8        0.3939             nan     0.1000    0.0461
     9        0.3611             nan     0.1000    0.0400
    10        0.3321             nan     0.1000    0.0383
    20        0.2033             nan     0.1000    0.0038
    40        0.1353             nan     0.1000   -0.0013
    60        0.1071             nan     0.1000   -0.0017
    80        0.0889             nan     0.1000   -0.0002
   100        0.0772             nan     0.1000   -0.0019
   120        0.0675             nan     0.1000   -0.0013
   140        0.0593             nan     0.1000   -0.0008
   160        0.0527             nan     0.1000   -0.0016
   180        0.0480             nan     0.1000   -0.0013
   200        0.0436             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3622
     2        0.8774             nan     0.1000    0.2463
     3        0.7278             nan     0.1000    0.1788
     4        0.6129             nan     0.1000    0.1346
     5        0.5269             nan     0.1000    0.1000
     6        0.4623             nan     0.1000    0.0769
     7        0.4092             nan     0.1000    0.0565
     8        0.3676             nan     0.1000    0.0546
     9        0.3309             nan     0.1000    0.0354
    10        0.3044             nan     0.1000    0.0362
    20        0.1733             nan     0.1000    0.0055
    40        0.1068             nan     0.1000    0.0004
    60        0.0807             nan     0.1000   -0.0014
    80        0.0659             nan     0.1000   -0.0025
   100        0.0557             nan     0.1000   -0.0019
   120        0.0478             nan     0.1000   -0.0008
   140        0.0399             nan     0.1000   -0.0015
   160        0.0352             nan     0.1000   -0.0011
   180        0.0309             nan     0.1000   -0.0010
   200        0.0271             nan     0.1000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3879
     2        0.8647             nan     0.1000    0.2487
     3        0.7073             nan     0.1000    0.1821
     4        0.5913             nan     0.1000    0.1353
     5        0.5017             nan     0.1000    0.1045
     6        0.4323             nan     0.1000    0.0776
     7        0.3799             nan     0.1000    0.0579
     8        0.3387             nan     0.1000    0.0501
     9        0.3037             nan     0.1000    0.0462
    10        0.2711             nan     0.1000    0.0260
    20        0.1395             nan     0.1000    0.0049
    40        0.0743             nan     0.1000   -0.0015
    60        0.0522             nan     0.1000   -0.0026
    80        0.0394             nan     0.1000   -0.0024
   100        0.0302             nan     0.1000   -0.0016
   120        0.0238             nan     0.1000   -0.0007
   140        0.0189             nan     0.1000   -0.0017
   160        0.0164             nan     0.1000   -0.0012
   180        0.0134             nan     0.1000   -0.0014
   200        0.0116             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5370
     2        0.7342             nan     0.2000    0.2384
     3        0.5710             nan     0.2000    0.1510
     4        0.4720             nan     0.2000    0.0899
     5        0.4085             nan     0.2000    0.0594
     6        0.3656             nan     0.2000    0.0420
     7        0.3287             nan     0.2000    0.0308
     8        0.3033             nan     0.2000    0.0219
     9        0.2849             nan     0.2000    0.0036
    10        0.2714             nan     0.2000    0.0096
    20        0.1924             nan     0.2000   -0.0032
    40        0.1501             nan     0.2000   -0.0004
    60        0.1236             nan     0.2000   -0.0052
    80        0.1098             nan     0.2000   -0.0050
   100        0.1016             nan     0.2000   -0.0032
   120        0.0936             nan     0.2000   -0.0019
   140        0.0855             nan     0.2000   -0.0024
   160        0.0783             nan     0.2000   -0.0043
   180        0.0737             nan     0.2000   -0.0014
   200        0.0689             nan     0.2000   -0.0025

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5636
     2        0.7046             nan     0.2000    0.2597
     3        0.5232             nan     0.2000    0.1558
     4        0.4161             nan     0.2000    0.0916
     5        0.3470             nan     0.2000    0.0559
     6        0.3021             nan     0.2000    0.0406
     7        0.2622             nan     0.2000    0.0310
     8        0.2388             nan     0.2000    0.0144
     9        0.2212             nan     0.2000    0.0080
    10        0.2087             nan     0.2000    0.0102
    20        0.1366             nan     0.2000   -0.0038
    40        0.0963             nan     0.2000   -0.0043
    60        0.0760             nan     0.2000   -0.0029
    80        0.0596             nan     0.2000   -0.0023
   100        0.0493             nan     0.2000   -0.0010
   120        0.0416             nan     0.2000   -0.0047
   140        0.0326             nan     0.2000   -0.0012
   160        0.0281             nan     0.2000   -0.0025
   180        0.0238             nan     0.2000   -0.0032
   200        0.0214             nan     0.2000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5964
     2        0.6905             nan     0.2000    0.2682
     3        0.5021             nan     0.2000    0.1541
     4        0.3911             nan     0.2000    0.0894
     5        0.3202             nan     0.2000    0.0692
     6        0.2694             nan     0.2000    0.0494
     7        0.2333             nan     0.2000    0.0277
     8        0.2048             nan     0.2000    0.0202
     9        0.1859             nan     0.2000   -0.0030
    10        0.1748             nan     0.2000   -0.0029
    20        0.1116             nan     0.2000   -0.0064
    40        0.0624             nan     0.2000   -0.0049
    60        0.0440             nan     0.2000   -0.0033
    80        0.0316             nan     0.2000   -0.0038
   100        0.0254             nan     0.2000   -0.0015
   120        0.0209             nan     0.2000   -0.0021
   140        0.0173             nan     0.2000   -0.0016
   160        0.0141             nan     0.2000   -0.0021
   180        0.0123             nan     0.2000   -0.0007
   200        0.0113             nan     0.2000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6142
     2        0.6808             nan     0.2000    0.2876
     3        0.4843             nan     0.2000    0.1605
     4        0.3687             nan     0.2000    0.0966
     5        0.2941             nan     0.2000    0.0824
     6        0.2307             nan     0.2000    0.0425
     7        0.1977             nan     0.2000    0.0294
     8        0.1713             nan     0.2000    0.0099
     9        0.1553             nan     0.2000    0.0064
    10        0.1408             nan     0.2000    0.0062
    20        0.0770             nan     0.2000   -0.0084
    40        0.0391             nan     0.2000   -0.0043
    60        0.0258             nan     0.2000   -0.0028
    80        0.0187             nan     0.2000   -0.0052
   100        0.0126             nan     0.2000   -0.0021
   120        0.0102             nan     0.2000   -0.0014
   140        0.0080             nan     0.2000   -0.0057
   160        0.0066             nan     0.2000   -0.0018
   180        0.0059             nan     0.2000   -0.0015
   200        0.0052             nan     0.2000   -0.0026

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1813
     2        0.9902             nan     0.0500    0.1493
     3        0.9004             nan     0.0500    0.1262
     4        0.8268             nan     0.0500    0.1056
     5        0.7641             nan     0.0500    0.0907
     6        0.7108             nan     0.0500    0.0788
     7        0.6639             nan     0.0500    0.0677
     8        0.6242             nan     0.0500    0.0581
     9        0.5890             nan     0.0500    0.0504
    10        0.5580             nan     0.0500    0.0464
    20        0.3729             nan     0.0500    0.0143
    40        0.2550             nan     0.0500    0.0064
    60        0.2053             nan     0.0500    0.0009
    80        0.1798             nan     0.0500    0.0004
   100        0.1623             nan     0.0500    0.0007
   120        0.1499             nan     0.0500   -0.0002
   140        0.1394             nan     0.0500   -0.0008
   160        0.1321             nan     0.0500   -0.0015
   180        0.1255             nan     0.0500   -0.0007
   200        0.1203             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1955
     2        0.9865             nan     0.0500    0.1623
     3        0.8920             nan     0.0500    0.1290
     4        0.8152             nan     0.0500    0.1167
     5        0.7452             nan     0.0500    0.0979
     6        0.6862             nan     0.0500    0.0825
     7        0.6336             nan     0.0500    0.0721
     8        0.5883             nan     0.0500    0.0662
     9        0.5486             nan     0.0500    0.0562
    10        0.5142             nan     0.0500    0.0491
    20        0.3109             nan     0.0500    0.0190
    40        0.1863             nan     0.0500    0.0030
    60        0.1470             nan     0.0500    0.0009
    80        0.1226             nan     0.0500   -0.0014
   100        0.1088             nan     0.0500   -0.0013
   120        0.0956             nan     0.0500   -0.0015
   140        0.0867             nan     0.0500   -0.0009
   160        0.0792             nan     0.0500   -0.0012
   180        0.0730             nan     0.0500   -0.0007
   200        0.0679             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2039
     2        0.9788             nan     0.0500    0.1656
     3        0.8815             nan     0.0500    0.1377
     4        0.7988             nan     0.0500    0.1171
     5        0.7288             nan     0.0500    0.1009
     6        0.6665             nan     0.0500    0.0877
     7        0.6131             nan     0.0500    0.0720
     8        0.5682             nan     0.0500    0.0675
     9        0.5257             nan     0.0500    0.0575
    10        0.4895             nan     0.0500    0.0519
    20        0.2785             nan     0.0500    0.0208
    40        0.1538             nan     0.0500    0.0008
    60        0.1168             nan     0.0500    0.0001
    80        0.0960             nan     0.0500    0.0002
   100        0.0819             nan     0.0500   -0.0011
   120        0.0725             nan     0.0500   -0.0004
   140        0.0649             nan     0.0500   -0.0005
   160        0.0581             nan     0.0500   -0.0006
   180        0.0523             nan     0.0500   -0.0010
   200        0.0476             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2068
     2        0.9759             nan     0.0500    0.1692
     3        0.8752             nan     0.0500    0.1470
     4        0.7876             nan     0.0500    0.1275
     5        0.7116             nan     0.0500    0.1022
     6        0.6492             nan     0.0500    0.0906
     7        0.5933             nan     0.0500    0.0730
     8        0.5465             nan     0.0500    0.0719
     9        0.5017             nan     0.0500    0.0567
    10        0.4651             nan     0.0500    0.0526
    20        0.2507             nan     0.0500    0.0150
    40        0.1245             nan     0.0500    0.0004
    60        0.0874             nan     0.0500   -0.0002
    80        0.0676             nan     0.0500   -0.0002
   100        0.0549             nan     0.0500   -0.0002
   120        0.0450             nan     0.0500   -0.0006
   140        0.0382             nan     0.0500   -0.0011
   160        0.0326             nan     0.0500   -0.0004
   180        0.0277             nan     0.0500   -0.0004
   200        0.0242             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3320
     2        0.8972             nan     0.1000    0.2294
     3        0.7574             nan     0.1000    0.1647
     4        0.6566             nan     0.1000    0.1186
     5        0.5802             nan     0.1000    0.0890
     6        0.5214             nan     0.1000    0.0665
     7        0.4749             nan     0.1000    0.0561
     8        0.4371             nan     0.1000    0.0452
     9        0.4065             nan     0.1000    0.0368
    10        0.3815             nan     0.1000    0.0305
    20        0.2559             nan     0.1000    0.0081
    40        0.1821             nan     0.1000    0.0009
    60        0.1508             nan     0.1000   -0.0004
    80        0.1321             nan     0.1000   -0.0018
   100        0.1205             nan     0.1000   -0.0015
   120        0.1128             nan     0.1000   -0.0034
   140        0.1047             nan     0.1000   -0.0018
   160        0.0992             nan     0.1000   -0.0020
   180        0.0951             nan     0.1000   -0.0012
   200        0.0908             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3587
     2        0.8867             nan     0.1000    0.2481
     3        0.7301             nan     0.1000    0.1728
     4        0.6164             nan     0.1000    0.1291
     5        0.5356             nan     0.1000    0.0942
     6        0.4728             nan     0.1000    0.0773
     7        0.4226             nan     0.1000    0.0543
     8        0.3812             nan     0.1000    0.0435
     9        0.3488             nan     0.1000    0.0341
    10        0.3222             nan     0.1000    0.0352
    20        0.1884             nan     0.1000    0.0106
    40        0.1262             nan     0.1000    0.0015
    60        0.0985             nan     0.1000   -0.0010
    80        0.0816             nan     0.1000   -0.0030
   100        0.0691             nan     0.1000   -0.0001
   120        0.0609             nan     0.1000   -0.0023
   140        0.0542             nan     0.1000   -0.0009
   160        0.0478             nan     0.1000   -0.0017
   180        0.0439             nan     0.1000   -0.0003
   200        0.0391             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3696
     2        0.8745             nan     0.1000    0.2513
     3        0.7127             nan     0.1000    0.1842
     4        0.5946             nan     0.1000    0.1298
     5        0.5088             nan     0.1000    0.1016
     6        0.4419             nan     0.1000    0.0767
     7        0.3889             nan     0.1000    0.0634
     8        0.3459             nan     0.1000    0.0488
     9        0.3123             nan     0.1000    0.0413
    10        0.2833             nan     0.1000    0.0326
    20        0.1572             nan     0.1000    0.0030
    40        0.0953             nan     0.1000   -0.0015
    60        0.0728             nan     0.1000   -0.0013
    80        0.0570             nan     0.1000   -0.0017
   100        0.0469             nan     0.1000   -0.0022
   120        0.0387             nan     0.1000   -0.0013
   140        0.0324             nan     0.1000   -0.0004
   160        0.0270             nan     0.1000   -0.0015
   180        0.0228             nan     0.1000   -0.0004
   200        0.0193             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3829
     2        0.8669             nan     0.1000    0.2696
     3        0.7025             nan     0.1000    0.1852
     4        0.5837             nan     0.1000    0.1388
     5        0.4939             nan     0.1000    0.1094
     6        0.4231             nan     0.1000    0.0800
     7        0.3697             nan     0.1000    0.0595
     8        0.3261             nan     0.1000    0.0526
     9        0.2896             nan     0.1000    0.0374
    10        0.2614             nan     0.1000    0.0271
    20        0.1349             nan     0.1000    0.0069
    40        0.0688             nan     0.1000   -0.0035
    60        0.0458             nan     0.1000   -0.0031
    80        0.0326             nan     0.1000   -0.0014
   100        0.0242             nan     0.1000   -0.0006
   120        0.0188             nan     0.1000   -0.0002
   140        0.0150             nan     0.1000   -0.0008
   160        0.0118             nan     0.1000   -0.0003
   180        0.0093             nan     0.1000   -0.0003
   200        0.0074             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5636
     2        0.7336             nan     0.2000    0.2552
     3        0.5560             nan     0.2000    0.1290
     4        0.4588             nan     0.2000    0.0948
     5        0.3888             nan     0.2000    0.0630
     6        0.3451             nan     0.2000    0.0283
     7        0.3197             nan     0.2000    0.0332
     8        0.2932             nan     0.2000    0.0238
     9        0.2724             nan     0.2000    0.0210
    10        0.2546             nan     0.2000    0.0073
    20        0.1800             nan     0.2000    0.0010
    40        0.1349             nan     0.2000    0.0006
    60        0.1106             nan     0.2000   -0.0010
    80        0.1005             nan     0.2000   -0.0052
   100        0.0914             nan     0.2000   -0.0010
   120        0.0840             nan     0.2000   -0.0024
   140        0.0775             nan     0.2000   -0.0032
   160        0.0730             nan     0.2000   -0.0039
   180        0.0693             nan     0.2000   -0.0045
   200        0.0658             nan     0.2000   -0.0058

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5667
     2        0.6964             nan     0.2000    0.2726
     3        0.5126             nan     0.2000    0.1442
     4        0.4040             nan     0.2000    0.0956
     5        0.3335             nan     0.2000    0.0544
     6        0.2854             nan     0.2000    0.0422
     7        0.2526             nan     0.2000    0.0334
     8        0.2247             nan     0.2000    0.0215
     9        0.2019             nan     0.2000    0.0159
    10        0.1875             nan     0.2000    0.0061
    20        0.1238             nan     0.2000   -0.0026
    40        0.0845             nan     0.2000   -0.0005
    60        0.0630             nan     0.2000   -0.0025
    80        0.0493             nan     0.2000   -0.0024
   100        0.0389             nan     0.2000   -0.0019
   120        0.0312             nan     0.2000   -0.0012
   140        0.0264             nan     0.2000   -0.0024
   160        0.0221             nan     0.2000   -0.0015
   180        0.0190             nan     0.2000   -0.0007
   200        0.0161             nan     0.2000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6118
     2        0.6868             nan     0.2000    0.2658
     3        0.4956             nan     0.2000    0.1421
     4        0.3803             nan     0.2000    0.1066
     5        0.3051             nan     0.2000    0.0748
     6        0.2503             nan     0.2000    0.0295
     7        0.2197             nan     0.2000    0.0293
     8        0.1906             nan     0.2000    0.0065
     9        0.1761             nan     0.2000    0.0089
    10        0.1638             nan     0.2000    0.0108
    20        0.0967             nan     0.2000   -0.0021
    40        0.0535             nan     0.2000   -0.0046
    60        0.0372             nan     0.2000   -0.0017
    80        0.0264             nan     0.2000   -0.0017
   100        0.0208             nan     0.2000   -0.0015
   120        0.0156             nan     0.2000   -0.0020
   140        0.0127             nan     0.2000   -0.0005
   160        0.0102             nan     0.2000   -0.0004
   180        0.0082             nan     0.2000   -0.0008
   200        0.0063             nan     0.2000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6154
     2        0.6781             nan     0.2000    0.2895
     3        0.4784             nan     0.2000    0.1649
     4        0.3584             nan     0.2000    0.1085
     5        0.2803             nan     0.2000    0.0697
     6        0.2263             nan     0.2000    0.0179
     7        0.1944             nan     0.2000    0.0322
     8        0.1614             nan     0.2000    0.0173
     9        0.1434             nan     0.2000    0.0098
    10        0.1304             nan     0.2000    0.0024
    20        0.0718             nan     0.2000   -0.0063
    40        0.0397             nan     0.2000   -0.0055
    60        0.0229             nan     0.2000   -0.0036
    80        0.0121             nan     0.2000   -0.0005
   100        0.0079             nan     0.2000   -0.0002
   120        0.0054             nan     0.2000   -0.0004
   140        0.0036             nan     0.2000   -0.0002
   160        0.0024             nan     0.2000   -0.0002
   180        0.0016             nan     0.2000   -0.0001
   200        0.0012             nan     0.2000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1818
     2        0.9953             nan     0.0500    0.1507
     3        0.9066             nan     0.0500    0.1258
     4        0.8320             nan     0.0500    0.1049
     5        0.7685             nan     0.0500    0.0920
     6        0.7132             nan     0.0500    0.0772
     7        0.6671             nan     0.0500    0.0681
     8        0.6247             nan     0.0500    0.0582
     9        0.5896             nan     0.0500    0.0526
    10        0.5570             nan     0.0500    0.0449
    20        0.3757             nan     0.0500    0.0159
    40        0.2564             nan     0.0500    0.0035
    60        0.2090             nan     0.0500    0.0002
    80        0.1818             nan     0.0500    0.0005
   100        0.1629             nan     0.0500    0.0003
   120        0.1512             nan     0.0500    0.0001
   140        0.1422             nan     0.0500   -0.0010
   160        0.1340             nan     0.0500   -0.0013
   180        0.1275             nan     0.0500   -0.0002
   200        0.1222             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1932
     2        0.9836             nan     0.0500    0.1597
     3        0.8909             nan     0.0500    0.1350
     4        0.8105             nan     0.0500    0.1135
     5        0.7414             nan     0.0500    0.0981
     6        0.6826             nan     0.0500    0.0832
     7        0.6328             nan     0.0500    0.0714
     8        0.5872             nan     0.0500    0.0610
     9        0.5492             nan     0.0500    0.0569
    10        0.5144             nan     0.0500    0.0490
    20        0.3121             nan     0.0500    0.0185
    40        0.1873             nan     0.0500    0.0050
    60        0.1486             nan     0.0500   -0.0001
    80        0.1271             nan     0.0500    0.0008
   100        0.1124             nan     0.0500   -0.0008
   120        0.1017             nan     0.0500   -0.0004
   140        0.0925             nan     0.0500   -0.0007
   160        0.0845             nan     0.0500   -0.0009
   180        0.0782             nan     0.0500   -0.0007
   200        0.0727             nan     0.0500   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2010
     2        0.9788             nan     0.0500    0.1624
     3        0.8827             nan     0.0500    0.1384
     4        0.7993             nan     0.0500    0.1151
     5        0.7296             nan     0.0500    0.1016
     6        0.6685             nan     0.0500    0.0871
     7        0.6146             nan     0.0500    0.0771
     8        0.5684             nan     0.0500    0.0649
     9        0.5262             nan     0.0500    0.0537
    10        0.4908             nan     0.0500    0.0492
    20        0.2814             nan     0.0500    0.0149
    40        0.1578             nan     0.0500    0.0044
    60        0.1184             nan     0.0500    0.0004
    80        0.0974             nan     0.0500   -0.0017
   100        0.0845             nan     0.0500   -0.0006
   120        0.0749             nan     0.0500   -0.0008
   140        0.0666             nan     0.0500   -0.0011
   160        0.0606             nan     0.0500   -0.0007
   180        0.0548             nan     0.0500   -0.0005
   200        0.0501             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2119
     2        0.9762             nan     0.0500    0.1694
     3        0.8762             nan     0.0500    0.1425
     4        0.7908             nan     0.0500    0.1232
     5        0.7165             nan     0.0500    0.1042
     6        0.6522             nan     0.0500    0.0910
     7        0.5976             nan     0.0500    0.0796
     8        0.5488             nan     0.0500    0.0698
     9        0.5059             nan     0.0500    0.0594
    10        0.4682             nan     0.0500    0.0507
    20        0.2554             nan     0.0500    0.0144
    40        0.1307             nan     0.0500    0.0008
    60        0.0944             nan     0.0500   -0.0019
    80        0.0734             nan     0.0500   -0.0013
   100        0.0599             nan     0.0500   -0.0011
   120        0.0503             nan     0.0500   -0.0009
   140        0.0432             nan     0.0500   -0.0010
   160        0.0369             nan     0.0500   -0.0002
   180        0.0322             nan     0.0500   -0.0004
   200        0.0286             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3338
     2        0.8987             nan     0.1000    0.2257
     3        0.7570             nan     0.1000    0.1679
     4        0.6553             nan     0.1000    0.1195
     5        0.5793             nan     0.1000    0.0886
     6        0.5185             nan     0.1000    0.0616
     7        0.4725             nan     0.1000    0.0538
     8        0.4363             nan     0.1000    0.0481
     9        0.4057             nan     0.1000    0.0374
    10        0.3807             nan     0.1000    0.0272
    20        0.2529             nan     0.1000    0.0056
    40        0.1797             nan     0.1000    0.0004
    60        0.1517             nan     0.1000   -0.0012
    80        0.1353             nan     0.1000   -0.0004
   100        0.1230             nan     0.1000   -0.0010
   120        0.1133             nan     0.1000   -0.0010
   140        0.1053             nan     0.1000   -0.0030
   160        0.0993             nan     0.1000   -0.0012
   180        0.0950             nan     0.1000   -0.0010
   200        0.0910             nan     0.1000   -0.0000

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3569
     2        0.8803             nan     0.1000    0.2430
     3        0.7294             nan     0.1000    0.1712
     4        0.6212             nan     0.1000    0.1303
     5        0.5386             nan     0.1000    0.0970
     6        0.4757             nan     0.1000    0.0817
     7        0.4246             nan     0.1000    0.0544
     8        0.3860             nan     0.1000    0.0545
     9        0.3508             nan     0.1000    0.0395
    10        0.3232             nan     0.1000    0.0275
    20        0.1936             nan     0.1000    0.0033
    40        0.1283             nan     0.1000   -0.0012
    60        0.1041             nan     0.1000   -0.0036
    80        0.0865             nan     0.1000   -0.0007
   100        0.0742             nan     0.1000   -0.0007
   120        0.0662             nan     0.1000   -0.0006
   140        0.0589             nan     0.1000   -0.0012
   160        0.0531             nan     0.1000   -0.0016
   180        0.0485             nan     0.1000   -0.0011
   200        0.0448             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3599
     2        0.8747             nan     0.1000    0.2494
     3        0.7199             nan     0.1000    0.1822
     4        0.6064             nan     0.1000    0.1376
     5        0.5178             nan     0.1000    0.1016
     6        0.4505             nan     0.1000    0.0750
     7        0.3982             nan     0.1000    0.0653
     8        0.3561             nan     0.1000    0.0473
     9        0.3223             nan     0.1000    0.0426
    10        0.2919             nan     0.1000    0.0287
    20        0.1599             nan     0.1000    0.0034
    40        0.1048             nan     0.1000   -0.0024
    60        0.0818             nan     0.1000   -0.0012
    80        0.0640             nan     0.1000   -0.0019
   100        0.0538             nan     0.1000   -0.0007
   120        0.0454             nan     0.1000   -0.0014
   140        0.0388             nan     0.1000   -0.0004
   160        0.0332             nan     0.1000   -0.0024
   180        0.0288             nan     0.1000   -0.0011
   200        0.0254             nan     0.1000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3888
     2        0.8604             nan     0.1000    0.2596
     3        0.6978             nan     0.1000    0.1835
     4        0.5830             nan     0.1000    0.1365
     5        0.4961             nan     0.1000    0.1081
     6        0.4261             nan     0.1000    0.0825
     7        0.3715             nan     0.1000    0.0664
     8        0.3273             nan     0.1000    0.0521
     9        0.2907             nan     0.1000    0.0400
    10        0.2620             nan     0.1000    0.0331
    20        0.1317             nan     0.1000    0.0034
    40        0.0739             nan     0.1000   -0.0009
    60        0.0500             nan     0.1000   -0.0043
    80        0.0382             nan     0.1000   -0.0011
   100        0.0283             nan     0.1000   -0.0014
   120        0.0229             nan     0.1000   -0.0021
   140        0.0188             nan     0.1000   -0.0012
   160        0.0159             nan     0.1000   -0.0009
   180        0.0132             nan     0.1000   -0.0010
   200        0.0118             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5523
     2        0.7289             nan     0.2000    0.2505
     3        0.5560             nan     0.2000    0.1407
     4        0.4580             nan     0.2000    0.0910
     5        0.3932             nan     0.2000    0.0505
     6        0.3495             nan     0.2000    0.0395
     7        0.3182             nan     0.2000    0.0341
     8        0.2918             nan     0.2000    0.0169
     9        0.2762             nan     0.2000    0.0298
    10        0.2558             nan     0.2000    0.0099
    20        0.1803             nan     0.2000   -0.0000
    40        0.1342             nan     0.2000   -0.0035
    60        0.1148             nan     0.2000   -0.0014
    80        0.0987             nan     0.2000   -0.0030
   100        0.0909             nan     0.2000   -0.0040
   120        0.0824             nan     0.2000   -0.0016
   140        0.0765             nan     0.2000   -0.0006
   160        0.0707             nan     0.2000   -0.0016
   180        0.0672             nan     0.2000   -0.0034
   200        0.0640             nan     0.2000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6099
     2        0.7080             nan     0.2000    0.2831
     3        0.5192             nan     0.2000    0.1611
     4        0.4066             nan     0.2000    0.0964
     5        0.3364             nan     0.2000    0.0682
     6        0.2865             nan     0.2000    0.0480
     7        0.2510             nan     0.2000    0.0214
     8        0.2288             nan     0.2000    0.0221
     9        0.2099             nan     0.2000    0.0119
    10        0.1934             nan     0.2000    0.0110
    20        0.1327             nan     0.2000    0.0034
    40        0.0855             nan     0.2000   -0.0008
    60        0.0648             nan     0.2000   -0.0022
    80        0.0509             nan     0.2000   -0.0036
   100        0.0421             nan     0.2000   -0.0024
   120        0.0357             nan     0.2000   -0.0024
   140        0.0310             nan     0.2000   -0.0024
   160        0.0264             nan     0.2000   -0.0021
   180        0.0240             nan     0.2000   -0.0005
   200        0.0217             nan     0.2000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6052
     2        0.6814             nan     0.2000    0.2672
     3        0.4889             nan     0.2000    0.1542
     4        0.3768             nan     0.2000    0.0836
     5        0.3057             nan     0.2000    0.0828
     6        0.2476             nan     0.2000    0.0450
     7        0.2093             nan     0.2000    0.0232
     8        0.1856             nan     0.2000    0.0067
     9        0.1728             nan     0.2000    0.0078
    10        0.1592             nan     0.2000    0.0058
    20        0.1007             nan     0.2000   -0.0026
    40        0.0650             nan     0.2000   -0.0064
    60        0.0464             nan     0.2000   -0.0044
    80        0.0340             nan     0.2000   -0.0024
   100        0.0263             nan     0.2000   -0.0022
   120        0.0223             nan     0.2000   -0.0009
   140        0.0191             nan     0.2000   -0.0037
   160        0.0172             nan     0.2000   -0.0012
   180        0.0153             nan     0.2000   -0.0027
   200        0.0137             nan     0.2000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6202
     2        0.6725             nan     0.2000    0.3042
     3        0.4714             nan     0.2000    0.1535
     4        0.3541             nan     0.2000    0.0887
     5        0.2847             nan     0.2000    0.0505
     6        0.2346             nan     0.2000    0.0340
     7        0.2024             nan     0.2000    0.0223
     8        0.1764             nan     0.2000    0.0149
     9        0.1559             nan     0.2000    0.0085
    10        0.1372             nan     0.2000    0.0070
    20        0.0763             nan     0.2000   -0.0014
    40        0.0352             nan     0.2000   -0.0055
    60        0.0234             nan     0.2000   -0.0041
    80        0.0167             nan     0.2000   -0.0034
   100        0.0133             nan     0.2000   -0.0027
   120        0.0104             nan     0.2000   -0.0009
   140        0.0086             nan     0.2000   -0.0018
   160        0.0072             nan     0.2000   -0.0018
   180        0.0060             nan     0.2000   -0.0019
   200        0.0055             nan     0.2000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1804
     2        0.9930             nan     0.0500    0.1512
     3        0.9058             nan     0.0500    0.1274
     4        0.8319             nan     0.0500    0.1081
     5        0.7674             nan     0.0500    0.0932
     6        0.7135             nan     0.0500    0.0790
     7        0.6678             nan     0.0500    0.0694
     8        0.6266             nan     0.0500    0.0591
     9        0.5904             nan     0.0500    0.0520
    10        0.5582             nan     0.0500    0.0468
    20        0.3736             nan     0.0500    0.0164
    40        0.2556             nan     0.0500    0.0050
    60        0.2096             nan     0.0500    0.0012
    80        0.1813             nan     0.0500   -0.0002
   100        0.1625             nan     0.0500    0.0012
   120        0.1496             nan     0.0500   -0.0013
   140        0.1379             nan     0.0500   -0.0002
   160        0.1307             nan     0.0500   -0.0000
   180        0.1242             nan     0.0500    0.0001
   200        0.1187             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1952
     2        0.9836             nan     0.0500    0.1614
     3        0.8901             nan     0.0500    0.1363
     4        0.8098             nan     0.0500    0.1147
     5        0.7421             nan     0.0500    0.0996
     6        0.6821             nan     0.0500    0.0847
     7        0.6304             nan     0.0500    0.0734
     8        0.5835             nan     0.0500    0.0632
     9        0.5445             nan     0.0500    0.0544
    10        0.5105             nan     0.0500    0.0498
    20        0.3087             nan     0.0500    0.0177
    40        0.1820             nan     0.0500    0.0031
    60        0.1418             nan     0.0500    0.0017
    80        0.1209             nan     0.0500    0.0007
   100        0.1052             nan     0.0500   -0.0008
   120        0.0951             nan     0.0500   -0.0011
   140        0.0866             nan     0.0500   -0.0003
   160        0.0788             nan     0.0500   -0.0004
   180        0.0722             nan     0.0500   -0.0004
   200        0.0666             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2013
     2        0.9824             nan     0.0500    0.1722
     3        0.8845             nan     0.0500    0.1421
     4        0.8015             nan     0.0500    0.1212
     5        0.7296             nan     0.0500    0.1031
     6        0.6664             nan     0.0500    0.0880
     7        0.6125             nan     0.0500    0.0770
     8        0.5653             nan     0.0500    0.0665
     9        0.5251             nan     0.0500    0.0555
    10        0.4900             nan     0.0500    0.0522
    20        0.2761             nan     0.0500    0.0177
    40        0.1502             nan     0.0500    0.0005
    60        0.1119             nan     0.0500    0.0003
    80        0.0920             nan     0.0500    0.0008
   100        0.0772             nan     0.0500   -0.0013
   120        0.0683             nan     0.0500   -0.0005
   140        0.0591             nan     0.0500   -0.0005
   160        0.0526             nan     0.0500   -0.0010
   180        0.0474             nan     0.0500   -0.0005
   200        0.0425             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2123
     2        0.9755             nan     0.0500    0.1728
     3        0.8741             nan     0.0500    0.1466
     4        0.7884             nan     0.0500    0.1264
     5        0.7137             nan     0.0500    0.1043
     6        0.6502             nan     0.0500    0.0900
     7        0.5949             nan     0.0500    0.0761
     8        0.5481             nan     0.0500    0.0692
     9        0.5047             nan     0.0500    0.0629
    10        0.4655             nan     0.0500    0.0552
    20        0.2490             nan     0.0500    0.0167
    40        0.1234             nan     0.0500    0.0019
    60        0.0836             nan     0.0500   -0.0006
    80        0.0660             nan     0.0500   -0.0013
   100        0.0533             nan     0.0500   -0.0009
   120        0.0438             nan     0.0500   -0.0011
   140        0.0373             nan     0.0500   -0.0007
   160        0.0319             nan     0.0500   -0.0007
   180        0.0273             nan     0.0500   -0.0008
   200        0.0244             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3353
     2        0.8954             nan     0.1000    0.2277
     3        0.7561             nan     0.1000    0.1639
     4        0.6529             nan     0.1000    0.1215
     5        0.5769             nan     0.1000    0.0908
     6        0.5166             nan     0.1000    0.0710
     7        0.4704             nan     0.1000    0.0566
     8        0.4341             nan     0.1000    0.0404
     9        0.4043             nan     0.1000    0.0347
    10        0.3794             nan     0.1000    0.0244
    20        0.2529             nan     0.1000    0.0066
    40        0.1801             nan     0.1000    0.0059
    60        0.1487             nan     0.1000    0.0005
    80        0.1300             nan     0.1000   -0.0008
   100        0.1189             nan     0.1000   -0.0006
   120        0.1086             nan     0.1000   -0.0010
   140        0.1028             nan     0.1000   -0.0026
   160        0.0958             nan     0.1000   -0.0011
   180        0.0901             nan     0.1000   -0.0006
   200        0.0861             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3638
     2        0.8820             nan     0.1000    0.2452
     3        0.7287             nan     0.1000    0.1751
     4        0.6215             nan     0.1000    0.1295
     5        0.5403             nan     0.1000    0.1037
     6        0.4715             nan     0.1000    0.0779
     7        0.4197             nan     0.1000    0.0634
     8        0.3769             nan     0.1000    0.0480
     9        0.3436             nan     0.1000    0.0361
    10        0.3166             nan     0.1000    0.0375
    20        0.1850             nan     0.1000    0.0091
    40        0.1198             nan     0.1000    0.0021
    60        0.0927             nan     0.1000   -0.0001
    80        0.0765             nan     0.1000   -0.0007
   100        0.0644             nan     0.1000   -0.0012
   120        0.0556             nan     0.1000   -0.0004
   140        0.0487             nan     0.1000   -0.0008
   160        0.0437             nan     0.1000   -0.0032
   180        0.0392             nan     0.1000   -0.0010
   200        0.0352             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3748
     2        0.8722             nan     0.1000    0.2593
     3        0.7149             nan     0.1000    0.1855
     4        0.5981             nan     0.1000    0.1323
     5        0.5099             nan     0.1000    0.1023
     6        0.4438             nan     0.1000    0.0841
     7        0.3881             nan     0.1000    0.0671
     8        0.3450             nan     0.1000    0.0500
     9        0.3111             nan     0.1000    0.0366
    10        0.2836             nan     0.1000    0.0353
    20        0.1494             nan     0.1000    0.0044
    40        0.0918             nan     0.1000   -0.0013
    60        0.0681             nan     0.1000   -0.0022
    80        0.0542             nan     0.1000   -0.0011
   100        0.0442             nan     0.1000   -0.0014
   120        0.0378             nan     0.1000   -0.0011
   140        0.0324             nan     0.1000   -0.0015
   160        0.0280             nan     0.1000   -0.0014
   180        0.0241             nan     0.1000   -0.0012
   200        0.0213             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3943
     2        0.8611             nan     0.1000    0.2537
     3        0.7008             nan     0.1000    0.1860
     4        0.5809             nan     0.1000    0.1383
     5        0.4900             nan     0.1000    0.1057
     6        0.4232             nan     0.1000    0.0805
     7        0.3683             nan     0.1000    0.0603
     8        0.3223             nan     0.1000    0.0487
     9        0.2879             nan     0.1000    0.0421
    10        0.2589             nan     0.1000    0.0320
    20        0.1289             nan     0.1000    0.0023
    40        0.0672             nan     0.1000   -0.0014
    60        0.0452             nan     0.1000   -0.0000
    80        0.0333             nan     0.1000   -0.0017
   100        0.0256             nan     0.1000   -0.0008
   120        0.0202             nan     0.1000   -0.0014
   140        0.0166             nan     0.1000   -0.0013
   160        0.0139             nan     0.1000   -0.0015
   180        0.0120             nan     0.1000   -0.0014
   200        0.0102             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5384
     2        0.7203             nan     0.2000    0.2458
     3        0.5566             nan     0.2000    0.1556
     4        0.4560             nan     0.2000    0.0841
     5        0.3908             nan     0.2000    0.0542
     6        0.3467             nan     0.2000    0.0422
     7        0.3149             nan     0.2000    0.0325
     8        0.2915             nan     0.2000    0.0273
     9        0.2699             nan     0.2000    0.0169
    10        0.2547             nan     0.2000    0.0107
    20        0.1784             nan     0.2000    0.0020
    40        0.1311             nan     0.2000   -0.0019
    60        0.1076             nan     0.2000   -0.0064
    80        0.0935             nan     0.2000   -0.0032
   100        0.0860             nan     0.2000   -0.0030
   120        0.0768             nan     0.2000   -0.0036
   140        0.0695             nan     0.2000   -0.0030
   160        0.0630             nan     0.2000   -0.0053
   180        0.0591             nan     0.2000   -0.0028
   200        0.0566             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6010
     2        0.7072             nan     0.2000    0.2791
     3        0.5115             nan     0.2000    0.1575
     4        0.4022             nan     0.2000    0.0940
     5        0.3292             nan     0.2000    0.0593
     6        0.2831             nan     0.2000    0.0493
     7        0.2453             nan     0.2000    0.0377
     8        0.2176             nan     0.2000    0.0188
     9        0.1998             nan     0.2000    0.0089
    10        0.1838             nan     0.2000    0.0091
    20        0.1216             nan     0.2000   -0.0092
    40        0.0834             nan     0.2000   -0.0031
    60        0.0613             nan     0.2000   -0.0048
    80        0.0461             nan     0.2000   -0.0012
   100        0.0366             nan     0.2000   -0.0029
   120        0.0306             nan     0.2000   -0.0014
   140        0.0267             nan     0.2000   -0.0021
   160        0.0234             nan     0.2000   -0.0030
   180        0.0210             nan     0.2000   -0.0014
   200        0.0196             nan     0.2000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6085
     2        0.6860             nan     0.2000    0.2743
     3        0.4837             nan     0.2000    0.1511
     4        0.3704             nan     0.2000    0.0910
     5        0.3003             nan     0.2000    0.0607
     6        0.2525             nan     0.2000    0.0583
     7        0.2091             nan     0.2000    0.0322
     8        0.1813             nan     0.2000    0.0067
     9        0.1645             nan     0.2000   -0.0008
    10        0.1553             nan     0.2000   -0.0002
    20        0.0905             nan     0.2000   -0.0032
    40        0.0560             nan     0.2000   -0.0021
    60        0.0402             nan     0.2000   -0.0020
    80        0.0291             nan     0.2000   -0.0026
   100        0.0221             nan     0.2000   -0.0044
   120        0.0177             nan     0.2000   -0.0022
   140        0.0143             nan     0.2000   -0.0016
   160        0.0118             nan     0.2000   -0.0058
   180        0.0104             nan     0.2000   -0.0023
   200        0.0092             nan     0.2000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6219
     2        0.6753             nan     0.2000    0.2924
     3        0.4688             nan     0.2000    0.1722
     4        0.3441             nan     0.2000    0.0957
     5        0.2714             nan     0.2000    0.0700
     6        0.2200             nan     0.2000    0.0377
     7        0.1829             nan     0.2000    0.0229
     8        0.1602             nan     0.2000    0.0123
     9        0.1432             nan     0.2000   -0.0013
    10        0.1333             nan     0.2000   -0.0007
    20        0.0726             nan     0.2000   -0.0044
    40        0.0356             nan     0.2000   -0.0026
    60        0.0209             nan     0.2000   -0.0056
    80        0.0145             nan     0.2000   -0.0021
   100        0.0111             nan     0.2000   -0.0010
   120        0.0086             nan     0.2000   -0.0020
   140        0.0067             nan     0.2000   -0.0019
   160        0.0054             nan     0.2000   -0.0019
   180        0.0046             nan     0.2000   -0.0002
   200        0.0041             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1787
     2        0.9929             nan     0.0500    0.1481
     3        0.9056             nan     0.0500    0.1235
     4        0.8347             nan     0.0500    0.1053
     5        0.7704             nan     0.0500    0.0899
     6        0.7168             nan     0.0500    0.0749
     7        0.6719             nan     0.0500    0.0671
     8        0.6295             nan     0.0500    0.0584
     9        0.5943             nan     0.0500    0.0502
    10        0.5628             nan     0.0500    0.0446
    20        0.3830             nan     0.0500    0.0156
    40        0.2648             nan     0.0500    0.0052
    60        0.2165             nan     0.0500    0.0020
    80        0.1888             nan     0.0500    0.0012
   100        0.1706             nan     0.0500    0.0013
   120        0.1574             nan     0.0500    0.0005
   140        0.1473             nan     0.0500   -0.0001
   160        0.1398             nan     0.0500   -0.0020
   180        0.1326             nan     0.0500   -0.0007
   200        0.1275             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1922
     2        0.9856             nan     0.0500    0.1575
     3        0.8906             nan     0.0500    0.1314
     4        0.8100             nan     0.0500    0.1101
     5        0.7435             nan     0.0500    0.0960
     6        0.6836             nan     0.0500    0.0834
     7        0.6326             nan     0.0500    0.0705
     8        0.5890             nan     0.0500    0.0604
     9        0.5519             nan     0.0500    0.0537
    10        0.5169             nan     0.0500    0.0479
    20        0.3190             nan     0.0500    0.0178
    40        0.1941             nan     0.0500    0.0026
    60        0.1528             nan     0.0500   -0.0008
    80        0.1315             nan     0.0500   -0.0003
   100        0.1146             nan     0.0500   -0.0008
   120        0.1033             nan     0.0500   -0.0012
   140        0.0941             nan     0.0500   -0.0014
   160        0.0868             nan     0.0500   -0.0010
   180        0.0810             nan     0.0500   -0.0005
   200        0.0750             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1969
     2        0.9819             nan     0.0500    0.1654
     3        0.8835             nan     0.0500    0.1381
     4        0.8015             nan     0.0500    0.1166
     5        0.7298             nan     0.0500    0.0994
     6        0.6681             nan     0.0500    0.0833
     7        0.6159             nan     0.0500    0.0731
     8        0.5704             nan     0.0500    0.0655
     9        0.5292             nan     0.0500    0.0539
    10        0.4946             nan     0.0500    0.0482
    20        0.2902             nan     0.0500    0.0170
    40        0.1631             nan     0.0500    0.0012
    60        0.1220             nan     0.0500    0.0000
    80        0.1000             nan     0.0500   -0.0019
   100        0.0859             nan     0.0500   -0.0001
   120        0.0750             nan     0.0500   -0.0008
   140        0.0668             nan     0.0500   -0.0007
   160        0.0600             nan     0.0500   -0.0001
   180        0.0544             nan     0.0500   -0.0005
   200        0.0497             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2083
     2        0.9771             nan     0.0500    0.1710
     3        0.8754             nan     0.0500    0.1405
     4        0.7912             nan     0.0500    0.1207
     5        0.7191             nan     0.0500    0.1023
     6        0.6563             nan     0.0500    0.0907
     7        0.6012             nan     0.0500    0.0808
     8        0.5518             nan     0.0500    0.0691
     9        0.5094             nan     0.0500    0.0645
    10        0.4698             nan     0.0500    0.0532
    20        0.2554             nan     0.0500    0.0135
    40        0.1323             nan     0.0500    0.0013
    60        0.0922             nan     0.0500   -0.0002
    80        0.0707             nan     0.0500   -0.0007
   100        0.0573             nan     0.0500   -0.0008
   120        0.0479             nan     0.0500   -0.0008
   140        0.0406             nan     0.0500   -0.0007
   160        0.0351             nan     0.0500   -0.0007
   180        0.0301             nan     0.0500   -0.0007
   200        0.0263             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3342
     2        0.9003             nan     0.1000    0.2242
     3        0.7589             nan     0.1000    0.1601
     4        0.6592             nan     0.1000    0.1213
     5        0.5847             nan     0.1000    0.0874
     6        0.5263             nan     0.1000    0.0684
     7        0.4801             nan     0.1000    0.0547
     8        0.4432             nan     0.1000    0.0420
     9        0.4112             nan     0.1000    0.0382
    10        0.3845             nan     0.1000    0.0281
    20        0.2656             nan     0.1000    0.0084
    40        0.1894             nan     0.1000   -0.0009
    60        0.1583             nan     0.1000   -0.0003
    80        0.1407             nan     0.1000   -0.0015
   100        0.1291             nan     0.1000   -0.0015
   120        0.1199             nan     0.1000   -0.0011
   140        0.1110             nan     0.1000   -0.0021
   160        0.1049             nan     0.1000   -0.0015
   180        0.0998             nan     0.1000   -0.0004
   200        0.0956             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3562
     2        0.8844             nan     0.1000    0.2357
     3        0.7372             nan     0.1000    0.1739
     4        0.6302             nan     0.1000    0.1293
     5        0.5471             nan     0.1000    0.0966
     6        0.4829             nan     0.1000    0.0787
     7        0.4305             nan     0.1000    0.0627
     8        0.3904             nan     0.1000    0.0405
     9        0.3589             nan     0.1000    0.0397
    10        0.3299             nan     0.1000    0.0361
    20        0.1956             nan     0.1000    0.0067
    40        0.1301             nan     0.1000   -0.0014
    60        0.1059             nan     0.1000   -0.0011
    80        0.0880             nan     0.1000   -0.0015
   100        0.0754             nan     0.1000   -0.0023
   120        0.0650             nan     0.1000   -0.0015
   140        0.0584             nan     0.1000   -0.0019
   160        0.0522             nan     0.1000   -0.0023
   180        0.0467             nan     0.1000   -0.0011
   200        0.0425             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3672
     2        0.8751             nan     0.1000    0.2524
     3        0.7217             nan     0.1000    0.1767
     4        0.6094             nan     0.1000    0.1392
     5        0.5213             nan     0.1000    0.1057
     6        0.4537             nan     0.1000    0.0796
     7        0.4019             nan     0.1000    0.0559
     8        0.3617             nan     0.1000    0.0493
     9        0.3277             nan     0.1000    0.0395
    10        0.2976             nan     0.1000    0.0401
    20        0.1642             nan     0.1000    0.0046
    40        0.1046             nan     0.1000   -0.0025
    60        0.0781             nan     0.1000   -0.0025
    80        0.0617             nan     0.1000   -0.0015
   100        0.0500             nan     0.1000   -0.0011
   120        0.0410             nan     0.1000   -0.0009
   140        0.0362             nan     0.1000   -0.0007
   160        0.0309             nan     0.1000   -0.0013
   180        0.0274             nan     0.1000   -0.0005
   200        0.0237             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3660
     2        0.8692             nan     0.1000    0.2624
     3        0.7055             nan     0.1000    0.1861
     4        0.5877             nan     0.1000    0.1356
     5        0.4970             nan     0.1000    0.1071
     6        0.4268             nan     0.1000    0.0780
     7        0.3749             nan     0.1000    0.0660
     8        0.3308             nan     0.1000    0.0525
     9        0.2947             nan     0.1000    0.0375
    10        0.2668             nan     0.1000    0.0249
    20        0.1362             nan     0.1000    0.0030
    40        0.0723             nan     0.1000   -0.0015
    60        0.0499             nan     0.1000   -0.0004
    80        0.0359             nan     0.1000   -0.0019
   100        0.0271             nan     0.1000   -0.0012
   120        0.0210             nan     0.1000   -0.0011
   140        0.0170             nan     0.1000   -0.0006
   160        0.0140             nan     0.1000   -0.0010
   180        0.0112             nan     0.1000   -0.0012
   200        0.0092             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5421
     2        0.7322             nan     0.2000    0.2447
     3        0.5637             nan     0.2000    0.1439
     4        0.4663             nan     0.2000    0.0801
     5        0.4046             nan     0.2000    0.0673
     6        0.3597             nan     0.2000    0.0468
     7        0.3256             nan     0.2000    0.0260
     8        0.3036             nan     0.2000    0.0261
     9        0.2839             nan     0.2000    0.0139
    10        0.2708             nan     0.2000    0.0162
    20        0.1903             nan     0.2000   -0.0004
    40        0.1411             nan     0.2000   -0.0025
    60        0.1206             nan     0.2000   -0.0026
    80        0.1072             nan     0.2000   -0.0033
   100        0.0958             nan     0.2000   -0.0025
   120        0.0876             nan     0.2000   -0.0041
   140        0.0800             nan     0.2000   -0.0039
   160        0.0741             nan     0.2000   -0.0010
   180        0.0677             nan     0.2000   -0.0032
   200        0.0650             nan     0.2000   -0.0038

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5773
     2        0.7120             nan     0.2000    0.2776
     3        0.5241             nan     0.2000    0.1412
     4        0.4115             nan     0.2000    0.0771
     5        0.3453             nan     0.2000    0.0784
     6        0.2926             nan     0.2000    0.0461
     7        0.2583             nan     0.2000    0.0197
     8        0.2355             nan     0.2000    0.0164
     9        0.2189             nan     0.2000    0.0110
    10        0.2040             nan     0.2000    0.0058
    20        0.1377             nan     0.2000   -0.0057
    40        0.0886             nan     0.2000   -0.0089
    60        0.0667             nan     0.2000   -0.0032
    80        0.0505             nan     0.2000   -0.0037
   100        0.0420             nan     0.2000   -0.0040
   120        0.0352             nan     0.2000   -0.0023
   140        0.0302             nan     0.2000   -0.0028
   160        0.0256             nan     0.2000   -0.0004
   180        0.0217             nan     0.2000   -0.0013
   200        0.0189             nan     0.2000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5993
     2        0.6902             nan     0.2000    0.2875
     3        0.4933             nan     0.2000    0.1447
     4        0.3850             nan     0.2000    0.0960
     5        0.3148             nan     0.2000    0.0770
     6        0.2576             nan     0.2000    0.0427
     7        0.2239             nan     0.2000    0.0213
     8        0.2009             nan     0.2000    0.0198
     9        0.1811             nan     0.2000    0.0059
    10        0.1665             nan     0.2000    0.0022
    20        0.1093             nan     0.2000   -0.0019
    40        0.0670             nan     0.2000   -0.0012
    60        0.0450             nan     0.2000   -0.0051
    80        0.0328             nan     0.2000   -0.0034
   100        0.0233             nan     0.2000   -0.0010
   120        0.0188             nan     0.2000   -0.0027
   140        0.0156             nan     0.2000   -0.0004
   160        0.0127             nan     0.2000   -0.0028
   180        0.0112             nan     0.2000   -0.0021
   200        0.0100             nan     0.2000   -0.0025

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6055
     2        0.6826             nan     0.2000    0.2800
     3        0.4826             nan     0.2000    0.1709
     4        0.3607             nan     0.2000    0.0917
     5        0.2884             nan     0.2000    0.0470
     6        0.2415             nan     0.2000    0.0373
     7        0.2044             nan     0.2000    0.0177
     8        0.1754             nan     0.2000    0.0193
     9        0.1553             nan     0.2000    0.0049
    10        0.1404             nan     0.2000    0.0004
    20        0.0774             nan     0.2000   -0.0079
    40        0.0371             nan     0.2000   -0.0039
    60        0.0222             nan     0.2000   -0.0018
    80        0.0144             nan     0.2000   -0.0012
   100        0.0104             nan     0.2000   -0.0006
   120        0.0069             nan     0.2000   -0.0011
   140        0.0058             nan     0.2000   -0.0005
   160        0.0039             nan     0.2000   -0.0016
   180        0.0031             nan     0.2000   -0.0017
   200        0.0026             nan     0.2000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1810
     2        0.9927             nan     0.0500    0.1475
     3        0.9068             nan     0.0500    0.1256
     4        0.8332             nan     0.0500    0.1074
     5        0.7703             nan     0.0500    0.0909
     6        0.7157             nan     0.0500    0.0785
     7        0.6684             nan     0.0500    0.0680
     8        0.6267             nan     0.0500    0.0572
     9        0.5901             nan     0.0500    0.0509
    10        0.5578             nan     0.0500    0.0443
    20        0.3773             nan     0.0500    0.0151
    40        0.2580             nan     0.0500    0.0039
    60        0.2129             nan     0.0500    0.0016
    80        0.1850             nan     0.0500    0.0002
   100        0.1683             nan     0.0500    0.0003
   120        0.1555             nan     0.0500   -0.0009
   140        0.1457             nan     0.0500   -0.0001
   160        0.1371             nan     0.0500   -0.0005
   180        0.1308             nan     0.0500   -0.0001
   200        0.1254             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1941
     2        0.9861             nan     0.0500    0.1596
     3        0.8934             nan     0.0500    0.1304
     4        0.8145             nan     0.0500    0.1130
     5        0.7452             nan     0.0500    0.0980
     6        0.6850             nan     0.0500    0.0801
     7        0.6358             nan     0.0500    0.0744
     8        0.5904             nan     0.0500    0.0633
     9        0.5511             nan     0.0500    0.0559
    10        0.5165             nan     0.0500    0.0496
    20        0.3136             nan     0.0500    0.0164
    40        0.1910             nan     0.0500    0.0019
    60        0.1506             nan     0.0500    0.0007
    80        0.1268             nan     0.0500   -0.0009
   100        0.1094             nan     0.0500   -0.0001
   120        0.0991             nan     0.0500   -0.0007
   140        0.0905             nan     0.0500   -0.0002
   160        0.0830             nan     0.0500   -0.0008
   180        0.0776             nan     0.0500   -0.0011
   200        0.0715             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1927
     2        0.9834             nan     0.0500    0.1671
     3        0.8849             nan     0.0500    0.1423
     4        0.8014             nan     0.0500    0.1162
     5        0.7307             nan     0.0500    0.0996
     6        0.6704             nan     0.0500    0.0871
     7        0.6178             nan     0.0500    0.0764
     8        0.5703             nan     0.0500    0.0651
     9        0.5294             nan     0.0500    0.0585
    10        0.4931             nan     0.0500    0.0500
    20        0.2834             nan     0.0500    0.0132
    40        0.1603             nan     0.0500    0.0029
    60        0.1211             nan     0.0500   -0.0007
    80        0.0997             nan     0.0500   -0.0004
   100        0.0843             nan     0.0500   -0.0006
   120        0.0739             nan     0.0500   -0.0010
   140        0.0646             nan     0.0500   -0.0008
   160        0.0583             nan     0.0500   -0.0004
   180        0.0529             nan     0.0500   -0.0006
   200        0.0486             nan     0.0500   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2108
     2        0.9760             nan     0.0500    0.1693
     3        0.8752             nan     0.0500    0.1466
     4        0.7886             nan     0.0500    0.1226
     5        0.7140             nan     0.0500    0.1060
     6        0.6501             nan     0.0500    0.0912
     7        0.5949             nan     0.0500    0.0775
     8        0.5465             nan     0.0500    0.0690
     9        0.5043             nan     0.0500    0.0594
    10        0.4663             nan     0.0500    0.0497
    20        0.2554             nan     0.0500    0.0157
    40        0.1294             nan     0.0500    0.0009
    60        0.0913             nan     0.0500   -0.0010
    80        0.0704             nan     0.0500   -0.0005
   100        0.0582             nan     0.0500   -0.0004
   120        0.0484             nan     0.0500   -0.0013
   140        0.0412             nan     0.0500   -0.0003
   160        0.0358             nan     0.0500   -0.0005
   180        0.0308             nan     0.0500   -0.0008
   200        0.0267             nan     0.0500    0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3320
     2        0.8940             nan     0.1000    0.2211
     3        0.7589             nan     0.1000    0.1626
     4        0.6554             nan     0.1000    0.1191
     5        0.5804             nan     0.1000    0.0879
     6        0.5208             nan     0.1000    0.0696
     7        0.4757             nan     0.1000    0.0532
     8        0.4389             nan     0.1000    0.0464
     9        0.4095             nan     0.1000    0.0364
    10        0.3829             nan     0.1000    0.0314
    20        0.2579             nan     0.1000    0.0046
    40        0.1817             nan     0.1000    0.0003
    60        0.1533             nan     0.1000   -0.0009
    80        0.1348             nan     0.1000   -0.0011
   100        0.1237             nan     0.1000    0.0007
   120        0.1143             nan     0.1000   -0.0015
   140        0.1059             nan     0.1000   -0.0011
   160        0.1018             nan     0.1000   -0.0003
   180        0.0961             nan     0.1000   -0.0005
   200        0.0919             nan     0.1000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3598
     2        0.8853             nan     0.1000    0.2421
     3        0.7350             nan     0.1000    0.1764
     4        0.6241             nan     0.1000    0.1287
     5        0.5408             nan     0.1000    0.0997
     6        0.4771             nan     0.1000    0.0742
     7        0.4257             nan     0.1000    0.0597
     8        0.3854             nan     0.1000    0.0508
     9        0.3513             nan     0.1000    0.0479
    10        0.3206             nan     0.1000    0.0306
    20        0.1913             nan     0.1000    0.0065
    40        0.1248             nan     0.1000   -0.0009
    60        0.0977             nan     0.1000   -0.0013
    80        0.0842             nan     0.1000   -0.0009
   100        0.0741             nan     0.1000   -0.0014
   120        0.0656             nan     0.1000   -0.0007
   140        0.0594             nan     0.1000   -0.0009
   160        0.0536             nan     0.1000   -0.0023
   180        0.0476             nan     0.1000   -0.0009
   200        0.0430             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3566
     2        0.8799             nan     0.1000    0.2585
     3        0.7233             nan     0.1000    0.1840
     4        0.6098             nan     0.1000    0.1388
     5        0.5218             nan     0.1000    0.1025
     6        0.4529             nan     0.1000    0.0785
     7        0.3997             nan     0.1000    0.0594
     8        0.3584             nan     0.1000    0.0510
     9        0.3240             nan     0.1000    0.0398
    10        0.2954             nan     0.1000    0.0292
    20        0.1628             nan     0.1000    0.0061
    40        0.1003             nan     0.1000    0.0004
    60        0.0762             nan     0.1000   -0.0018
    80        0.0590             nan     0.1000   -0.0002
   100        0.0478             nan     0.1000   -0.0009
   120        0.0390             nan     0.1000   -0.0005
   140        0.0334             nan     0.1000   -0.0011
   160        0.0291             nan     0.1000   -0.0009
   180        0.0253             nan     0.1000   -0.0005
   200        0.0228             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3855
     2        0.8637             nan     0.1000    0.2609
     3        0.7008             nan     0.1000    0.1833
     4        0.5838             nan     0.1000    0.1355
     5        0.4947             nan     0.1000    0.1099
     6        0.4232             nan     0.1000    0.0865
     7        0.3673             nan     0.1000    0.0641
     8        0.3246             nan     0.1000    0.0477
     9        0.2895             nan     0.1000    0.0404
    10        0.2601             nan     0.1000    0.0311
    20        0.1343             nan     0.1000    0.0013
    40        0.0727             nan     0.1000   -0.0018
    60        0.0488             nan     0.1000   -0.0013
    80        0.0352             nan     0.1000   -0.0013
   100        0.0277             nan     0.1000   -0.0017
   120        0.0223             nan     0.1000   -0.0003
   140        0.0180             nan     0.1000   -0.0012
   160        0.0150             nan     0.1000   -0.0008
   180        0.0126             nan     0.1000   -0.0004
   200        0.0111             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5500
     2        0.7346             nan     0.2000    0.2591
     3        0.5640             nan     0.2000    0.1517
     4        0.4609             nan     0.2000    0.0782
     5        0.3976             nan     0.2000    0.0652
     6        0.3508             nan     0.2000    0.0356
     7        0.3214             nan     0.2000    0.0331
     8        0.2961             nan     0.2000    0.0119
     9        0.2797             nan     0.2000    0.0173
    10        0.2624             nan     0.2000    0.0248
    20        0.1892             nan     0.2000    0.0023
    40        0.1401             nan     0.2000   -0.0079
    60        0.1191             nan     0.2000   -0.0012
    80        0.1057             nan     0.2000   -0.0044
   100        0.0950             nan     0.2000   -0.0016
   120        0.0891             nan     0.2000   -0.0025
   140        0.0830             nan     0.2000   -0.0035
   160        0.0757             nan     0.2000   -0.0041
   180        0.0720             nan     0.2000   -0.0090
   200        0.0686             nan     0.2000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5802
     2        0.7100             nan     0.2000    0.2661
     3        0.5180             nan     0.2000    0.1575
     4        0.4098             nan     0.2000    0.0967
     5        0.3374             nan     0.2000    0.0519
     6        0.2915             nan     0.2000    0.0349
     7        0.2577             nan     0.2000    0.0274
     8        0.2329             nan     0.2000    0.0140
     9        0.2162             nan     0.2000    0.0146
    10        0.2018             nan     0.2000    0.0152
    20        0.1303             nan     0.2000   -0.0021
    40        0.0847             nan     0.2000   -0.0049
    60        0.0659             nan     0.2000   -0.0047
    80        0.0543             nan     0.2000   -0.0031
   100        0.0453             nan     0.2000   -0.0021
   120        0.0364             nan     0.2000   -0.0037
   140        0.0322             nan     0.2000   -0.0028
   160        0.0284             nan     0.2000   -0.0047
   180        0.0252             nan     0.2000   -0.0018
   200        0.0217             nan     0.2000   -0.0031

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5979
     2        0.6954             nan     0.2000    0.2811
     3        0.5029             nan     0.2000    0.1633
     4        0.3886             nan     0.2000    0.1045
     5        0.3143             nan     0.2000    0.0536
     6        0.2691             nan     0.2000    0.0362
     7        0.2342             nan     0.2000    0.0269
     8        0.2088             nan     0.2000    0.0249
     9        0.1871             nan     0.2000    0.0136
    10        0.1709             nan     0.2000    0.0100
    20        0.1104             nan     0.2000   -0.0100
    40        0.0631             nan     0.2000   -0.0010
    60        0.0457             nan     0.2000   -0.0027
    80        0.0357             nan     0.2000   -0.0030
   100        0.0274             nan     0.2000   -0.0023
   120        0.0220             nan     0.2000    0.0000
   140        0.0187             nan     0.2000   -0.0018
   160        0.0161             nan     0.2000   -0.0025
   180        0.0143             nan     0.2000   -0.0032
   200        0.0125             nan     0.2000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6278
     2        0.6814             nan     0.2000    0.3161
     3        0.4692             nan     0.2000    0.1525
     4        0.3535             nan     0.2000    0.1069
     5        0.2749             nan     0.2000    0.0610
     6        0.2249             nan     0.2000    0.0303
     7        0.1904             nan     0.2000    0.0319
     8        0.1652             nan     0.2000    0.0156
     9        0.1469             nan     0.2000    0.0108
    10        0.1317             nan     0.2000    0.0046
    20        0.0729             nan     0.2000   -0.0034
    40        0.0404             nan     0.2000   -0.0092
    60        0.0237             nan     0.2000   -0.0032
    80        0.0154             nan     0.2000   -0.0031
   100        0.0109             nan     0.2000   -0.0006
   120        0.0083             nan     0.2000   -0.0018
   140        0.0066             nan     0.2000   -0.0004
   160        0.0058             nan     0.2000   -0.0033
   180        0.0048             nan     0.2000   -0.0020
   200        0.0047             nan     0.2000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1771
     2        0.9964             nan     0.0500    0.1501
     3        0.9079             nan     0.0500    0.1248
     4        0.8367             nan     0.0500    0.1063
     5        0.7738             nan     0.0500    0.0908
     6        0.7192             nan     0.0500    0.0770
     7        0.6728             nan     0.0500    0.0664
     8        0.6312             nan     0.0500    0.0594
     9        0.5950             nan     0.0500    0.0515
    10        0.5624             nan     0.0500    0.0460
    20        0.3800             nan     0.0500    0.0168
    40        0.2601             nan     0.0500    0.0031
    60        0.2147             nan     0.0500    0.0002
    80        0.1886             nan     0.0500   -0.0002
   100        0.1704             nan     0.0500   -0.0007
   120        0.1579             nan     0.0500    0.0014
   140        0.1476             nan     0.0500   -0.0004
   160        0.1408             nan     0.0500   -0.0004
   180        0.1348             nan     0.0500   -0.0007
   200        0.1286             nan     0.0500   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1921
     2        0.9857             nan     0.0500    0.1567
     3        0.8946             nan     0.0500    0.1324
     4        0.8169             nan     0.0500    0.1148
     5        0.7489             nan     0.0500    0.0992
     6        0.6899             nan     0.0500    0.0844
     7        0.6378             nan     0.0500    0.0724
     8        0.5929             nan     0.0500    0.0652
     9        0.5533             nan     0.0500    0.0543
    10        0.5201             nan     0.0500    0.0497
    20        0.3183             nan     0.0500    0.0167
    40        0.1901             nan     0.0500    0.0023
    60        0.1506             nan     0.0500    0.0003
    80        0.1297             nan     0.0500    0.0007
   100        0.1140             nan     0.0500   -0.0011
   120        0.1025             nan     0.0500   -0.0009
   140        0.0930             nan     0.0500   -0.0008
   160        0.0847             nan     0.0500   -0.0003
   180        0.0775             nan     0.0500   -0.0004
   200        0.0721             nan     0.0500   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2005
     2        0.9817             nan     0.0500    0.1617
     3        0.8842             nan     0.0500    0.1389
     4        0.7992             nan     0.0500    0.1189
     5        0.7291             nan     0.0500    0.1007
     6        0.6678             nan     0.0500    0.0860
     7        0.6159             nan     0.0500    0.0753
     8        0.5688             nan     0.0500    0.0646
     9        0.5278             nan     0.0500    0.0564
    10        0.4919             nan     0.0500    0.0480
    20        0.2832             nan     0.0500    0.0165
    40        0.1610             nan     0.0500    0.0030
    60        0.1228             nan     0.0500    0.0000
    80        0.1013             nan     0.0500   -0.0004
   100        0.0873             nan     0.0500   -0.0005
   120        0.0773             nan     0.0500   -0.0006
   140        0.0678             nan     0.0500   -0.0010
   160        0.0614             nan     0.0500   -0.0005
   180        0.0560             nan     0.0500   -0.0005
   200        0.0513             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2060
     2        0.9772             nan     0.0500    0.1726
     3        0.8744             nan     0.0500    0.1460
     4        0.7853             nan     0.0500    0.1175
     5        0.7139             nan     0.0500    0.1042
     6        0.6504             nan     0.0500    0.0916
     7        0.5951             nan     0.0500    0.0776
     8        0.5468             nan     0.0500    0.0669
     9        0.5047             nan     0.0500    0.0599
    10        0.4670             nan     0.0500    0.0511
    20        0.2529             nan     0.0500    0.0147
    40        0.1346             nan     0.0500    0.0011
    60        0.0931             nan     0.0500   -0.0009
    80        0.0711             nan     0.0500   -0.0008
   100        0.0578             nan     0.0500   -0.0012
   120        0.0489             nan     0.0500   -0.0006
   140        0.0414             nan     0.0500   -0.0004
   160        0.0360             nan     0.0500   -0.0004
   180        0.0316             nan     0.0500   -0.0006
   200        0.0280             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3315
     2        0.8981             nan     0.1000    0.2251
     3        0.7583             nan     0.1000    0.1572
     4        0.6561             nan     0.1000    0.1140
     5        0.5799             nan     0.1000    0.0896
     6        0.5201             nan     0.1000    0.0718
     7        0.4738             nan     0.1000    0.0561
     8        0.4372             nan     0.1000    0.0456
     9        0.4074             nan     0.1000    0.0298
    10        0.3842             nan     0.1000    0.0301
    20        0.2638             nan     0.1000    0.0078
    40        0.1869             nan     0.1000    0.0005
    60        0.1572             nan     0.1000   -0.0017
    80        0.1411             nan     0.1000   -0.0025
   100        0.1290             nan     0.1000   -0.0006
   120        0.1197             nan     0.1000   -0.0010
   140        0.1128             nan     0.1000   -0.0019
   160        0.1071             nan     0.1000   -0.0019
   180        0.1019             nan     0.1000   -0.0006
   200        0.0968             nan     0.1000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3568
     2        0.8861             nan     0.1000    0.2410
     3        0.7391             nan     0.1000    0.1750
     4        0.6280             nan     0.1000    0.1211
     5        0.5463             nan     0.1000    0.1037
     6        0.4798             nan     0.1000    0.0684
     7        0.4304             nan     0.1000    0.0662
     8        0.3877             nan     0.1000    0.0481
     9        0.3534             nan     0.1000    0.0402
    10        0.3251             nan     0.1000    0.0346
    20        0.1974             nan     0.1000    0.0064
    40        0.1319             nan     0.1000    0.0008
    60        0.1029             nan     0.1000   -0.0018
    80        0.0876             nan     0.1000   -0.0023
   100        0.0759             nan     0.1000   -0.0004
   120        0.0662             nan     0.1000   -0.0011
   140        0.0603             nan     0.1000   -0.0027
   160        0.0548             nan     0.1000   -0.0012
   180        0.0502             nan     0.1000   -0.0023
   200        0.0458             nan     0.1000   -0.0027

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3705
     2        0.8762             nan     0.1000    0.2466
     3        0.7197             nan     0.1000    0.1757
     4        0.6092             nan     0.1000    0.1349
     5        0.5215             nan     0.1000    0.1055
     6        0.4542             nan     0.1000    0.0742
     7        0.4027             nan     0.1000    0.0676
     8        0.3582             nan     0.1000    0.0508
     9        0.3228             nan     0.1000    0.0375
    10        0.2944             nan     0.1000    0.0350
    20        0.1620             nan     0.1000    0.0033
    40        0.1036             nan     0.1000   -0.0006
    60        0.0766             nan     0.1000   -0.0009
    80        0.0622             nan     0.1000   -0.0017
   100        0.0527             nan     0.1000   -0.0030
   120        0.0448             nan     0.1000   -0.0013
   140        0.0377             nan     0.1000   -0.0010
   160        0.0327             nan     0.1000   -0.0008
   180        0.0289             nan     0.1000   -0.0007
   200        0.0263             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3924
     2        0.8641             nan     0.1000    0.2608
     3        0.7028             nan     0.1000    0.1896
     4        0.5830             nan     0.1000    0.1384
     5        0.4944             nan     0.1000    0.1061
     6        0.4254             nan     0.1000    0.0823
     7        0.3707             nan     0.1000    0.0632
     8        0.3273             nan     0.1000    0.0491
     9        0.2917             nan     0.1000    0.0410
    10        0.2629             nan     0.1000    0.0275
    20        0.1356             nan     0.1000    0.0007
    40        0.0750             nan     0.1000   -0.0020
    60        0.0514             nan     0.1000   -0.0029
    80        0.0387             nan     0.1000   -0.0022
   100        0.0298             nan     0.1000   -0.0011
   120        0.0242             nan     0.1000   -0.0010
   140        0.0198             nan     0.1000   -0.0013
   160        0.0167             nan     0.1000   -0.0014
   180        0.0140             nan     0.1000   -0.0005
   200        0.0121             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5329
     2        0.7341             nan     0.2000    0.2484
     3        0.5616             nan     0.2000    0.1452
     4        0.4613             nan     0.2000    0.0846
     5        0.4002             nan     0.2000    0.0601
     6        0.3582             nan     0.2000    0.0237
     7        0.3350             nan     0.2000    0.0363
     8        0.3094             nan     0.2000    0.0424
     9        0.2789             nan     0.2000    0.0126
    10        0.2633             nan     0.2000    0.0110
    20        0.1847             nan     0.2000    0.0012
    40        0.1406             nan     0.2000   -0.0051
    60        0.1182             nan     0.2000   -0.0040
    80        0.1039             nan     0.2000   -0.0039
   100        0.0933             nan     0.2000   -0.0027
   120        0.0860             nan     0.2000   -0.0020
   140        0.0810             nan     0.2000   -0.0056
   160        0.0746             nan     0.2000   -0.0034
   180        0.0709             nan     0.2000   -0.0032
   200        0.0664             nan     0.2000   -0.0023

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5647
     2        0.7009             nan     0.2000    0.2741
     3        0.5168             nan     0.2000    0.1575
     4        0.4081             nan     0.2000    0.0833
     5        0.3437             nan     0.2000    0.0594
     6        0.2969             nan     0.2000    0.0467
     7        0.2605             nan     0.2000    0.0338
     8        0.2290             nan     0.2000    0.0131
     9        0.2120             nan     0.2000    0.0158
    10        0.1972             nan     0.2000    0.0062
    20        0.1295             nan     0.2000   -0.0043
    40        0.0898             nan     0.2000   -0.0040
    60        0.0724             nan     0.2000   -0.0039
    80        0.0566             nan     0.2000   -0.0050
   100        0.0472             nan     0.2000   -0.0021
   120        0.0406             nan     0.2000   -0.0018
   140        0.0349             nan     0.2000   -0.0029
   160        0.0300             nan     0.2000   -0.0011
   180        0.0269             nan     0.2000   -0.0016
   200        0.0247             nan     0.2000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6151
     2        0.6954             nan     0.2000    0.2853
     3        0.4961             nan     0.2000    0.1530
     4        0.3854             nan     0.2000    0.0938
     5        0.3147             nan     0.2000    0.0783
     6        0.2579             nan     0.2000    0.0412
     7        0.2216             nan     0.2000    0.0135
     8        0.2022             nan     0.2000    0.0236
     9        0.1808             nan     0.2000    0.0050
    10        0.1689             nan     0.2000    0.0091
    20        0.1127             nan     0.2000   -0.0057
    40        0.0659             nan     0.2000   -0.0028
    60        0.0447             nan     0.2000   -0.0009
    80        0.0345             nan     0.2000   -0.0015
   100        0.0269             nan     0.2000   -0.0013
   120        0.0220             nan     0.2000   -0.0028
   140        0.0180             nan     0.2000   -0.0036
   160        0.0158             nan     0.2000   -0.0022
   180        0.0137             nan     0.2000   -0.0027
   200        0.0116             nan     0.2000   -0.0023

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6214
     2        0.6720             nan     0.2000    0.2872
     3        0.4771             nan     0.2000    0.1645
     4        0.3597             nan     0.2000    0.0879
     5        0.2888             nan     0.2000    0.0667
     6        0.2373             nan     0.2000    0.0367
     7        0.2046             nan     0.2000    0.0210
     8        0.1808             nan     0.2000    0.0215
     9        0.1583             nan     0.2000    0.0061
    10        0.1437             nan     0.2000   -0.0015
    20        0.0850             nan     0.2000   -0.0015
    40        0.0400             nan     0.2000   -0.0053
    60        0.0231             nan     0.2000   -0.0046
    80        0.0163             nan     0.2000   -0.0040
   100        0.0120             nan     0.2000   -0.0019
   120        0.0093             nan     0.2000   -0.0006
   140        0.0078             nan     0.2000   -0.0022
   160        0.0067             nan     0.2000   -0.0032
   180        0.0052             nan     0.2000   -0.0025
   200        0.0046             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1769
     2        0.9934             nan     0.0500    0.1488
     3        0.9073             nan     0.0500    0.1239
     4        0.8338             nan     0.0500    0.1043
     5        0.7725             nan     0.0500    0.0909
     6        0.7193             nan     0.0500    0.0762
     7        0.6717             nan     0.0500    0.0666
     8        0.6312             nan     0.0500    0.0587
     9        0.5961             nan     0.0500    0.0499
    10        0.5657             nan     0.0500    0.0443
    20        0.3822             nan     0.0500    0.0135
    40        0.2628             nan     0.0500    0.0045
    60        0.2154             nan     0.0500    0.0009
    80        0.1885             nan     0.0500    0.0008
   100        0.1692             nan     0.0500    0.0008
   120        0.1559             nan     0.0500    0.0005
   140        0.1465             nan     0.0500   -0.0006
   160        0.1387             nan     0.0500   -0.0009
   180        0.1312             nan     0.0500   -0.0007
   200        0.1258             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1921
     2        0.9864             nan     0.0500    0.1560
     3        0.8939             nan     0.0500    0.1271
     4        0.8173             nan     0.0500    0.1121
     5        0.7508             nan     0.0500    0.0999
     6        0.6910             nan     0.0500    0.0841
     7        0.6408             nan     0.0500    0.0711
     8        0.5957             nan     0.0500    0.0629
     9        0.5570             nan     0.0500    0.0556
    10        0.5217             nan     0.0500    0.0489
    20        0.3189             nan     0.0500    0.0161
    40        0.1928             nan     0.0500    0.0034
    60        0.1537             nan     0.0500    0.0011
    80        0.1316             nan     0.0500    0.0005
   100        0.1152             nan     0.0500   -0.0003
   120        0.1052             nan     0.0500   -0.0007
   140        0.0955             nan     0.0500   -0.0010
   160        0.0869             nan     0.0500   -0.0010
   180        0.0793             nan     0.0500   -0.0009
   200        0.0739             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1977
     2        0.9842             nan     0.0500    0.1609
     3        0.8871             nan     0.0500    0.1353
     4        0.8055             nan     0.0500    0.1159
     5        0.7336             nan     0.0500    0.0997
     6        0.6723             nan     0.0500    0.0857
     7        0.6185             nan     0.0500    0.0749
     8        0.5734             nan     0.0500    0.0652
     9        0.5331             nan     0.0500    0.0580
    10        0.4960             nan     0.0500    0.0494
    20        0.2879             nan     0.0500    0.0180
    40        0.1622             nan     0.0500    0.0010
    60        0.1239             nan     0.0500    0.0002
    80        0.1039             nan     0.0500   -0.0002
   100        0.0888             nan     0.0500   -0.0005
   120        0.0779             nan     0.0500   -0.0008
   140        0.0686             nan     0.0500   -0.0006
   160        0.0618             nan     0.0500   -0.0016
   180        0.0555             nan     0.0500   -0.0005
   200        0.0509             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2089
     2        0.9759             nan     0.0500    0.1724
     3        0.8748             nan     0.0500    0.1432
     4        0.7890             nan     0.0500    0.1171
     5        0.7158             nan     0.0500    0.1038
     6        0.6524             nan     0.0500    0.0920
     7        0.5972             nan     0.0500    0.0794
     8        0.5483             nan     0.0500    0.0705
     9        0.5059             nan     0.0500    0.0578
    10        0.4684             nan     0.0500    0.0508
    20        0.2589             nan     0.0500    0.0191
    40        0.1354             nan     0.0500    0.0025
    60        0.0946             nan     0.0500   -0.0003
    80        0.0736             nan     0.0500   -0.0012
   100        0.0608             nan     0.0500   -0.0006
   120        0.0506             nan     0.0500   -0.0008
   140        0.0424             nan     0.0500   -0.0005
   160        0.0363             nan     0.0500   -0.0011
   180        0.0319             nan     0.0500   -0.0006
   200        0.0284             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3297
     2        0.9026             nan     0.1000    0.2287
     3        0.7626             nan     0.1000    0.1621
     4        0.6614             nan     0.1000    0.1183
     5        0.5849             nan     0.1000    0.0875
     6        0.5266             nan     0.1000    0.0690
     7        0.4809             nan     0.1000    0.0553
     8        0.4433             nan     0.1000    0.0460
     9        0.4124             nan     0.1000    0.0299
    10        0.3879             nan     0.1000    0.0296
    20        0.2634             nan     0.1000    0.0056
    40        0.1878             nan     0.1000    0.0013
    60        0.1555             nan     0.1000   -0.0019
    80        0.1367             nan     0.1000   -0.0000
   100        0.1244             nan     0.1000   -0.0011
   120        0.1146             nan     0.1000   -0.0007
   140        0.1072             nan     0.1000   -0.0007
   160        0.1009             nan     0.1000   -0.0009
   180        0.0948             nan     0.1000   -0.0012
   200        0.0899             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3446
     2        0.8870             nan     0.1000    0.2404
     3        0.7393             nan     0.1000    0.1737
     4        0.6304             nan     0.1000    0.1303
     5        0.5487             nan     0.1000    0.0980
     6        0.4854             nan     0.1000    0.0682
     7        0.4361             nan     0.1000    0.0680
     8        0.3934             nan     0.1000    0.0553
     9        0.3569             nan     0.1000    0.0361
    10        0.3307             nan     0.1000    0.0318
    20        0.1947             nan     0.1000    0.0052
    40        0.1298             nan     0.1000   -0.0004
    60        0.1007             nan     0.1000   -0.0015
    80        0.0853             nan     0.1000   -0.0006
   100        0.0746             nan     0.1000   -0.0012
   120        0.0657             nan     0.1000   -0.0022
   140        0.0583             nan     0.1000   -0.0006
   160        0.0523             nan     0.1000   -0.0013
   180        0.0473             nan     0.1000   -0.0021
   200        0.0435             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3599
     2        0.8780             nan     0.1000    0.2495
     3        0.7222             nan     0.1000    0.1815
     4        0.6104             nan     0.1000    0.1336
     5        0.5241             nan     0.1000    0.1058
     6        0.4559             nan     0.1000    0.0834
     7        0.4011             nan     0.1000    0.0565
     8        0.3600             nan     0.1000    0.0518
     9        0.3256             nan     0.1000    0.0388
    10        0.2988             nan     0.1000    0.0382
    20        0.1663             nan     0.1000    0.0027
    40        0.1028             nan     0.1000    0.0010
    60        0.0755             nan     0.1000   -0.0004
    80        0.0589             nan     0.1000   -0.0003
   100        0.0490             nan     0.1000   -0.0009
   120        0.0415             nan     0.1000   -0.0016
   140        0.0354             nan     0.1000   -0.0008
   160        0.0310             nan     0.1000   -0.0013
   180        0.0276             nan     0.1000   -0.0019
   200        0.0240             nan     0.1000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3861
     2        0.8633             nan     0.1000    0.2577
     3        0.7025             nan     0.1000    0.1919
     4        0.5816             nan     0.1000    0.1339
     5        0.4939             nan     0.1000    0.1074
     6        0.4237             nan     0.1000    0.0804
     7        0.3705             nan     0.1000    0.0630
     8        0.3278             nan     0.1000    0.0470
     9        0.2931             nan     0.1000    0.0366
    10        0.2659             nan     0.1000    0.0315
    20        0.1399             nan     0.1000    0.0041
    40        0.0748             nan     0.1000   -0.0020
    60        0.0513             nan     0.1000   -0.0028
    80        0.0373             nan     0.1000   -0.0011
   100        0.0287             nan     0.1000   -0.0016
   120        0.0238             nan     0.1000   -0.0015
   140        0.0198             nan     0.1000   -0.0011
   160        0.0162             nan     0.1000   -0.0014
   180        0.0143             nan     0.1000   -0.0005
   200        0.0121             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5475
     2        0.7367             nan     0.2000    0.2563
     3        0.5717             nan     0.2000    0.1415
     4        0.4693             nan     0.2000    0.0734
     5        0.4096             nan     0.2000    0.0523
     6        0.3678             nan     0.2000    0.0284
     7        0.3372             nan     0.2000    0.0319
     8        0.3101             nan     0.2000    0.0232
     9        0.2863             nan     0.2000    0.0190
    10        0.2719             nan     0.2000    0.0110
    20        0.1906             nan     0.2000    0.0063
    40        0.1376             nan     0.2000   -0.0000
    60        0.1170             nan     0.2000   -0.0055
    80        0.1056             nan     0.2000   -0.0010
   100        0.0967             nan     0.2000   -0.0041
   120        0.0869             nan     0.2000   -0.0020
   140        0.0808             nan     0.2000   -0.0019
   160        0.0761             nan     0.2000   -0.0043
   180        0.0710             nan     0.2000   -0.0016
   200        0.0675             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5904
     2        0.7093             nan     0.2000    0.2716
     3        0.5234             nan     0.2000    0.1564
     4        0.4140             nan     0.2000    0.0992
     5        0.3393             nan     0.2000    0.0656
     6        0.2914             nan     0.2000    0.0461
     7        0.2582             nan     0.2000    0.0247
     8        0.2338             nan     0.2000    0.0091
     9        0.2152             nan     0.2000    0.0163
    10        0.1984             nan     0.2000    0.0049
    20        0.1307             nan     0.2000    0.0039
    40        0.0830             nan     0.2000   -0.0065
    60        0.0620             nan     0.2000   -0.0046
    80        0.0500             nan     0.2000   -0.0074
   100        0.0412             nan     0.2000   -0.0018
   120        0.0342             nan     0.2000   -0.0041
   140        0.0304             nan     0.2000   -0.0002
   160        0.0267             nan     0.2000    0.0002
   180        0.0237             nan     0.2000   -0.0030
   200        0.0212             nan     0.2000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5883
     2        0.6945             nan     0.2000    0.2857
     3        0.4976             nan     0.2000    0.1487
     4        0.3858             nan     0.2000    0.0968
     5        0.3123             nan     0.2000    0.0701
     6        0.2606             nan     0.2000    0.0346
     7        0.2275             nan     0.2000    0.0137
     8        0.2051             nan     0.2000    0.0153
     9        0.1870             nan     0.2000    0.0139
    10        0.1696             nan     0.2000    0.0097
    20        0.1076             nan     0.2000    0.0004
    40        0.0657             nan     0.2000   -0.0044
    60        0.0449             nan     0.2000   -0.0025
    80        0.0339             nan     0.2000   -0.0016
   100        0.0284             nan     0.2000   -0.0022
   120        0.0226             nan     0.2000   -0.0031
   140        0.0186             nan     0.2000   -0.0012
   160        0.0161             nan     0.2000   -0.0014
   180        0.0136             nan     0.2000   -0.0021
   200        0.0121             nan     0.2000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6239
     2        0.6778             nan     0.2000    0.2798
     3        0.4755             nan     0.2000    0.1825
     4        0.3536             nan     0.2000    0.1007
     5        0.2797             nan     0.2000    0.0638
     6        0.2282             nan     0.2000    0.0380
     7        0.1929             nan     0.2000    0.0179
     8        0.1723             nan     0.2000    0.0106
     9        0.1524             nan     0.2000   -0.0052
    10        0.1375             nan     0.2000    0.0001
    20        0.0741             nan     0.2000   -0.0060
    40        0.0374             nan     0.2000   -0.0034
    60        0.0238             nan     0.2000   -0.0041
    80        0.0174             nan     0.2000   -0.0008
   100        0.0122             nan     0.2000   -0.0009
   120        0.0096             nan     0.2000   -0.0006
   140        0.0075             nan     0.2000   -0.0022
   160        0.0064             nan     0.2000   -0.0021
   180        0.0057             nan     0.2000   -0.0020
   200        0.0049             nan     0.2000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1780
     2        0.9960             nan     0.0500    0.1509
     3        0.9067             nan     0.0500    0.1257
     4        0.8319             nan     0.0500    0.1060
     5        0.7678             nan     0.0500    0.0902
     6        0.7132             nan     0.0500    0.0774
     7        0.6663             nan     0.0500    0.0655
     8        0.6248             nan     0.0500    0.0585
     9        0.5877             nan     0.0500    0.0507
    10        0.5563             nan     0.0500    0.0427
    20        0.3764             nan     0.0500    0.0158
    40        0.2623             nan     0.0500    0.0023
    60        0.2131             nan     0.0500    0.0023
    80        0.1858             nan     0.0500    0.0000
   100        0.1680             nan     0.0500   -0.0002
   120        0.1555             nan     0.0500    0.0006
   140        0.1442             nan     0.0500   -0.0004
   160        0.1371             nan     0.0500   -0.0007
   180        0.1300             nan     0.0500   -0.0008
   200        0.1252             nan     0.0500   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1928
     2        0.9835             nan     0.0500    0.1589
     3        0.8894             nan     0.0500    0.1337
     4        0.8090             nan     0.0500    0.1106
     5        0.7416             nan     0.0500    0.0968
     6        0.6827             nan     0.0500    0.0831
     7        0.6328             nan     0.0500    0.0716
     8        0.5888             nan     0.0500    0.0613
     9        0.5504             nan     0.0500    0.0542
    10        0.5168             nan     0.0500    0.0498
    20        0.3117             nan     0.0500    0.0169
    40        0.1889             nan     0.0500    0.0035
    60        0.1483             nan     0.0500   -0.0000
    80        0.1265             nan     0.0500   -0.0002
   100        0.1126             nan     0.0500   -0.0010
   120        0.0999             nan     0.0500    0.0001
   140        0.0905             nan     0.0500   -0.0005
   160        0.0828             nan     0.0500   -0.0008
   180        0.0765             nan     0.0500   -0.0003
   200        0.0710             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1963
     2        0.9819             nan     0.0500    0.1670
     3        0.8825             nan     0.0500    0.1368
     4        0.8000             nan     0.0500    0.1179
     5        0.7294             nan     0.0500    0.1018
     6        0.6684             nan     0.0500    0.0867
     7        0.6151             nan     0.0500    0.0730
     8        0.5698             nan     0.0500    0.0659
     9        0.5287             nan     0.0500    0.0596
    10        0.4911             nan     0.0500    0.0513
    20        0.2817             nan     0.0500    0.0160
    40        0.1584             nan     0.0500    0.0022
    60        0.1202             nan     0.0500   -0.0021
    80        0.0983             nan     0.0500   -0.0005
   100        0.0833             nan     0.0500   -0.0010
   120        0.0732             nan     0.0500   -0.0006
   140        0.0655             nan     0.0500   -0.0001
   160        0.0583             nan     0.0500    0.0001
   180        0.0521             nan     0.0500   -0.0008
   200        0.0478             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2034
     2        0.9796             nan     0.0500    0.1744
     3        0.8764             nan     0.0500    0.1438
     4        0.7908             nan     0.0500    0.1215
     5        0.7174             nan     0.0500    0.1024
     6        0.6542             nan     0.0500    0.0913
     7        0.5979             nan     0.0500    0.0772
     8        0.5498             nan     0.0500    0.0709
     9        0.5064             nan     0.0500    0.0608
    10        0.4685             nan     0.0500    0.0518
    20        0.2558             nan     0.0500    0.0150
    40        0.1324             nan     0.0500    0.0015
    60        0.0919             nan     0.0500   -0.0005
    80        0.0713             nan     0.0500   -0.0010
   100        0.0580             nan     0.0500   -0.0010
   120        0.0478             nan     0.0500   -0.0008
   140        0.0405             nan     0.0500   -0.0003
   160        0.0351             nan     0.0500   -0.0005
   180        0.0308             nan     0.0500   -0.0004
   200        0.0269             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3310
     2        0.8950             nan     0.1000    0.2262
     3        0.7616             nan     0.1000    0.1636
     4        0.6573             nan     0.1000    0.1126
     5        0.5804             nan     0.1000    0.0895
     6        0.5215             nan     0.1000    0.0740
     7        0.4749             nan     0.1000    0.0546
     8        0.4390             nan     0.1000    0.0448
     9        0.4067             nan     0.1000    0.0361
    10        0.3817             nan     0.1000    0.0330
    20        0.2583             nan     0.1000    0.0079
    40        0.1853             nan     0.1000    0.0010
    60        0.1544             nan     0.1000   -0.0003
    80        0.1344             nan     0.1000   -0.0013
   100        0.1244             nan     0.1000   -0.0006
   120        0.1166             nan     0.1000   -0.0015
   140        0.1105             nan     0.1000   -0.0011
   160        0.1043             nan     0.1000   -0.0036
   180        0.1002             nan     0.1000   -0.0015
   200        0.0958             nan     0.1000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3556
     2        0.8806             nan     0.1000    0.2366
     3        0.7342             nan     0.1000    0.1744
     4        0.6231             nan     0.1000    0.1246
     5        0.5440             nan     0.1000    0.0967
     6        0.4782             nan     0.1000    0.0824
     7        0.4263             nan     0.1000    0.0595
     8        0.3843             nan     0.1000    0.0518
     9        0.3500             nan     0.1000    0.0448
    10        0.3213             nan     0.1000    0.0295
    20        0.1945             nan     0.1000    0.0094
    40        0.1294             nan     0.1000   -0.0006
    60        0.1041             nan     0.1000   -0.0018
    80        0.0891             nan     0.1000   -0.0027
   100        0.0759             nan     0.1000   -0.0011
   120        0.0668             nan     0.1000   -0.0004
   140        0.0596             nan     0.1000   -0.0017
   160        0.0538             nan     0.1000   -0.0010
   180        0.0482             nan     0.1000   -0.0006
   200        0.0434             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3708
     2        0.8737             nan     0.1000    0.2512
     3        0.7195             nan     0.1000    0.1767
     4        0.6035             nan     0.1000    0.1268
     5        0.5189             nan     0.1000    0.0995
     6        0.4511             nan     0.1000    0.0824
     7        0.3974             nan     0.1000    0.0653
     8        0.3554             nan     0.1000    0.0483
     9        0.3201             nan     0.1000    0.0419
    10        0.2901             nan     0.1000    0.0308
    20        0.1662             nan     0.1000    0.0064
    40        0.1036             nan     0.1000    0.0003
    60        0.0789             nan     0.1000   -0.0012
    80        0.0639             nan     0.1000   -0.0009
   100        0.0527             nan     0.1000    0.0000
   120        0.0441             nan     0.1000   -0.0007
   140        0.0369             nan     0.1000   -0.0021
   160        0.0316             nan     0.1000   -0.0007
   180        0.0271             nan     0.1000   -0.0009
   200        0.0248             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3798
     2        0.8654             nan     0.1000    0.2645
     3        0.7006             nan     0.1000    0.1800
     4        0.5838             nan     0.1000    0.1298
     5        0.4957             nan     0.1000    0.1125
     6        0.4252             nan     0.1000    0.0819
     7        0.3702             nan     0.1000    0.0632
     8        0.3269             nan     0.1000    0.0495
     9        0.2914             nan     0.1000    0.0389
    10        0.2628             nan     0.1000    0.0294
    20        0.1360             nan     0.1000    0.0009
    40        0.0736             nan     0.1000   -0.0015
    60        0.0495             nan     0.1000   -0.0020
    80        0.0362             nan     0.1000   -0.0023
   100        0.0272             nan     0.1000   -0.0014
   120        0.0213             nan     0.1000   -0.0008
   140        0.0170             nan     0.1000   -0.0013
   160        0.0141             nan     0.1000   -0.0019
   180        0.0121             nan     0.1000   -0.0004
   200        0.0102             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5443
     2        0.7299             nan     0.2000    0.2589
     3        0.5619             nan     0.2000    0.1243
     4        0.4630             nan     0.2000    0.0912
     5        0.3930             nan     0.2000    0.0554
     6        0.3489             nan     0.2000    0.0331
     7        0.3196             nan     0.2000    0.0153
     8        0.2993             nan     0.2000    0.0355
     9        0.2744             nan     0.2000    0.0148
    10        0.2604             nan     0.2000    0.0195
    20        0.1883             nan     0.2000    0.0035
    40        0.1378             nan     0.2000   -0.0071
    60        0.1159             nan     0.2000   -0.0079
    80        0.1051             nan     0.2000   -0.0069
   100        0.0941             nan     0.2000   -0.0029
   120        0.0836             nan     0.2000   -0.0058
   140        0.0791             nan     0.2000   -0.0060
   160        0.0729             nan     0.2000   -0.0021
   180        0.0681             nan     0.2000   -0.0017
   200        0.0657             nan     0.2000   -0.0039

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5783
     2        0.7093             nan     0.2000    0.2559
     3        0.5311             nan     0.2000    0.1650
     4        0.4147             nan     0.2000    0.1011
     5        0.3447             nan     0.2000    0.0675
     6        0.2909             nan     0.2000    0.0404
     7        0.2569             nan     0.2000    0.0190
     8        0.2369             nan     0.2000    0.0163
     9        0.2154             nan     0.2000    0.0168
    10        0.1975             nan     0.2000    0.0047
    20        0.1408             nan     0.2000   -0.0013
    40        0.0893             nan     0.2000   -0.0091
    60        0.0666             nan     0.2000   -0.0025
    80        0.0537             nan     0.2000   -0.0036
   100        0.0430             nan     0.2000   -0.0009
   120        0.0370             nan     0.2000   -0.0029
   140        0.0317             nan     0.2000   -0.0019
   160        0.0278             nan     0.2000   -0.0035
   180        0.0252             nan     0.2000   -0.0014
   200        0.0224             nan     0.2000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6147
     2        0.6880             nan     0.2000    0.2848
     3        0.4941             nan     0.2000    0.1580
     4        0.3802             nan     0.2000    0.0931
     5        0.3111             nan     0.2000    0.0721
     6        0.2566             nan     0.2000    0.0388
     7        0.2216             nan     0.2000    0.0308
     8        0.1950             nan     0.2000    0.0095
     9        0.1803             nan     0.2000    0.0048
    10        0.1665             nan     0.2000    0.0030
    20        0.1058             nan     0.2000   -0.0066
    40        0.0640             nan     0.2000   -0.0064
    60        0.0448             nan     0.2000   -0.0034
    80        0.0315             nan     0.2000   -0.0020
   100        0.0249             nan     0.2000   -0.0025
   120        0.0208             nan     0.2000   -0.0023
   140        0.0172             nan     0.2000   -0.0009
   160        0.0144             nan     0.2000   -0.0016
   180        0.0124             nan     0.2000   -0.0007
   200        0.0111             nan     0.2000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6356
     2        0.6674             nan     0.2000    0.2890
     3        0.4693             nan     0.2000    0.1653
     4        0.3542             nan     0.2000    0.1025
     5        0.2791             nan     0.2000    0.0566
     6        0.2309             nan     0.2000    0.0314
     7        0.1991             nan     0.2000    0.0200
     8        0.1722             nan     0.2000    0.0119
     9        0.1534             nan     0.2000   -0.0016
    10        0.1399             nan     0.2000    0.0107
    20        0.0764             nan     0.2000   -0.0059
    40        0.0372             nan     0.2000   -0.0027
    60        0.0216             nan     0.2000   -0.0026
    80        0.0142             nan     0.2000   -0.0009
   100        0.0104             nan     0.2000   -0.0007
   120        0.0083             nan     0.2000   -0.0020
   140        0.0068             nan     0.2000   -0.0028
   160        0.0054             nan     0.2000   -0.0013
   180        0.0045             nan     0.2000   -0.0035
   200        0.0040             nan     0.2000   -0.0031

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1784
     2        0.9916             nan     0.0500    0.1493
     3        0.9072             nan     0.0500    0.1243
     4        0.8336             nan     0.0500    0.1056
     5        0.7723             nan     0.0500    0.0883
     6        0.7187             nan     0.0500    0.0783
     7        0.6719             nan     0.0500    0.0678
     8        0.6317             nan     0.0500    0.0587
     9        0.5965             nan     0.0500    0.0486
    10        0.5656             nan     0.0500    0.0461
    20        0.3821             nan     0.0500    0.0149
    40        0.2617             nan     0.0500    0.0052
    60        0.2117             nan     0.0500    0.0019
    80        0.1825             nan     0.0500   -0.0014
   100        0.1660             nan     0.0500    0.0003
   120        0.1536             nan     0.0500   -0.0002
   140        0.1440             nan     0.0500    0.0001
   160        0.1350             nan     0.0500   -0.0006
   180        0.1283             nan     0.0500   -0.0007
   200        0.1227             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1881
     2        0.9844             nan     0.0500    0.1576
     3        0.8926             nan     0.0500    0.1345
     4        0.8126             nan     0.0500    0.1109
     5        0.7436             nan     0.0500    0.0956
     6        0.6861             nan     0.0500    0.0811
     7        0.6364             nan     0.0500    0.0723
     8        0.5917             nan     0.0500    0.0596
     9        0.5532             nan     0.0500    0.0552
    10        0.5191             nan     0.0500    0.0490
    20        0.3172             nan     0.0500    0.0204
    40        0.1892             nan     0.0500    0.0039
    60        0.1496             nan     0.0500    0.0010
    80        0.1266             nan     0.0500   -0.0031
   100        0.1112             nan     0.0500   -0.0001
   120        0.0993             nan     0.0500   -0.0004
   140        0.0912             nan     0.0500   -0.0007
   160        0.0837             nan     0.0500   -0.0007
   180        0.0768             nan     0.0500   -0.0003
   200        0.0716             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2010
     2        0.9806             nan     0.0500    0.1667
     3        0.8851             nan     0.0500    0.1411
     4        0.8030             nan     0.0500    0.1173
     5        0.7320             nan     0.0500    0.1003
     6        0.6711             nan     0.0500    0.0881
     7        0.6164             nan     0.0500    0.0766
     8        0.5696             nan     0.0500    0.0641
     9        0.5293             nan     0.0500    0.0577
    10        0.4917             nan     0.0500    0.0485
    20        0.2825             nan     0.0500    0.0133
    40        0.1564             nan     0.0500    0.0012
    60        0.1154             nan     0.0500    0.0011
    80        0.0958             nan     0.0500   -0.0018
   100        0.0824             nan     0.0500    0.0000
   120        0.0713             nan     0.0500   -0.0001
   140        0.0633             nan     0.0500   -0.0001
   160        0.0569             nan     0.0500   -0.0006
   180        0.0522             nan     0.0500   -0.0007
   200        0.0475             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2088
     2        0.9750             nan     0.0500    0.1661
     3        0.8747             nan     0.0500    0.1461
     4        0.7889             nan     0.0500    0.1280
     5        0.7132             nan     0.0500    0.1072
     6        0.6488             nan     0.0500    0.0889
     7        0.5947             nan     0.0500    0.0811
     8        0.5458             nan     0.0500    0.0683
     9        0.5015             nan     0.0500    0.0576
    10        0.4648             nan     0.0500    0.0524
    20        0.2521             nan     0.0500    0.0150
    40        0.1314             nan     0.0500    0.0021
    60        0.0896             nan     0.0500   -0.0000
    80        0.0688             nan     0.0500   -0.0008
   100        0.0563             nan     0.0500   -0.0001
   120        0.0476             nan     0.0500   -0.0004
   140        0.0402             nan     0.0500   -0.0006
   160        0.0342             nan     0.0500   -0.0009
   180        0.0298             nan     0.0500   -0.0006
   200        0.0263             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3301
     2        0.8981             nan     0.1000    0.2261
     3        0.7615             nan     0.1000    0.1630
     4        0.6639             nan     0.1000    0.1203
     5        0.5869             nan     0.1000    0.0872
     6        0.5273             nan     0.1000    0.0732
     7        0.4810             nan     0.1000    0.0518
     8        0.4436             nan     0.1000    0.0444
     9        0.4118             nan     0.1000    0.0357
    10        0.3872             nan     0.1000    0.0278
    20        0.2608             nan     0.1000    0.0091
    40        0.1841             nan     0.1000    0.0022
    60        0.1540             nan     0.1000   -0.0019
    80        0.1359             nan     0.1000   -0.0014
   100        0.1244             nan     0.1000   -0.0025
   120        0.1158             nan     0.1000   -0.0015
   140        0.1082             nan     0.1000   -0.0017
   160        0.1001             nan     0.1000   -0.0021
   180        0.0944             nan     0.1000   -0.0015
   200        0.0902             nan     0.1000    0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3551
     2        0.8814             nan     0.1000    0.2364
     3        0.7305             nan     0.1000    0.1753
     4        0.6237             nan     0.1000    0.1282
     5        0.5417             nan     0.1000    0.0925
     6        0.4784             nan     0.1000    0.0754
     7        0.4263             nan     0.1000    0.0569
     8        0.3871             nan     0.1000    0.0461
     9        0.3536             nan     0.1000    0.0424
    10        0.3251             nan     0.1000    0.0281
    20        0.1899             nan     0.1000    0.0011
    40        0.1251             nan     0.1000    0.0002
    60        0.0993             nan     0.1000   -0.0028
    80        0.0829             nan     0.1000   -0.0009
   100        0.0708             nan     0.1000   -0.0013
   120        0.0612             nan     0.1000   -0.0012
   140        0.0559             nan     0.1000   -0.0014
   160        0.0496             nan     0.1000   -0.0014
   180        0.0445             nan     0.1000   -0.0007
   200        0.0401             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3682
     2        0.8751             nan     0.1000    0.2387
     3        0.7204             nan     0.1000    0.1869
     4        0.6051             nan     0.1000    0.1357
     5        0.5186             nan     0.1000    0.1003
     6        0.4501             nan     0.1000    0.0797
     7        0.3989             nan     0.1000    0.0584
     8        0.3568             nan     0.1000    0.0488
     9        0.3214             nan     0.1000    0.0400
    10        0.2937             nan     0.1000    0.0378
    20        0.1602             nan     0.1000    0.0039
    40        0.1005             nan     0.1000   -0.0028
    60        0.0726             nan     0.1000   -0.0023
    80        0.0580             nan     0.1000   -0.0021
   100        0.0481             nan     0.1000   -0.0007
   120        0.0404             nan     0.1000   -0.0011
   140        0.0350             nan     0.1000   -0.0008
   160        0.0305             nan     0.1000   -0.0003
   180        0.0263             nan     0.1000   -0.0008
   200        0.0232             nan     0.1000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3942
     2        0.8622             nan     0.1000    0.2582
     3        0.7011             nan     0.1000    0.1835
     4        0.5839             nan     0.1000    0.1412
     5        0.4926             nan     0.1000    0.1084
     6        0.4218             nan     0.1000    0.0728
     7        0.3691             nan     0.1000    0.0573
     8        0.3276             nan     0.1000    0.0515
     9        0.2897             nan     0.1000    0.0362
    10        0.2618             nan     0.1000    0.0279
    20        0.1289             nan     0.1000    0.0020
    40        0.0683             nan     0.1000   -0.0009
    60        0.0463             nan     0.1000   -0.0022
    80        0.0346             nan     0.1000   -0.0013
   100        0.0265             nan     0.1000   -0.0014
   120        0.0210             nan     0.1000   -0.0013
   140        0.0172             nan     0.1000   -0.0009
   160        0.0141             nan     0.1000   -0.0018
   180        0.0124             nan     0.1000   -0.0018
   200        0.0108             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5385
     2        0.7311             nan     0.2000    0.2468
     3        0.5627             nan     0.2000    0.1426
     4        0.4662             nan     0.2000    0.0827
     5        0.4041             nan     0.2000    0.0634
     6        0.3551             nan     0.2000    0.0396
     7        0.3268             nan     0.2000    0.0422
     8        0.2970             nan     0.2000    0.0141
     9        0.2805             nan     0.2000    0.0117
    10        0.2662             nan     0.2000    0.0134
    20        0.1844             nan     0.2000    0.0003
    40        0.1373             nan     0.2000   -0.0071
    60        0.1126             nan     0.2000   -0.0022
    80        0.0994             nan     0.2000   -0.0035
   100        0.0887             nan     0.2000   -0.0074
   120        0.0802             nan     0.2000   -0.0044
   140        0.0745             nan     0.2000   -0.0023
   160        0.0705             nan     0.2000   -0.0037
   180        0.0647             nan     0.2000   -0.0028
   200        0.0612             nan     0.2000   -0.0024

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5847
     2        0.7015             nan     0.2000    0.2593
     3        0.5153             nan     0.2000    0.1501
     4        0.4110             nan     0.2000    0.0900
     5        0.3393             nan     0.2000    0.0660
     6        0.2901             nan     0.2000    0.0361
     7        0.2573             nan     0.2000    0.0212
     8        0.2336             nan     0.2000    0.0218
     9        0.2144             nan     0.2000    0.0184
    10        0.1986             nan     0.2000    0.0123
    20        0.1267             nan     0.2000   -0.0033
    40        0.0859             nan     0.2000   -0.0034
    60        0.0647             nan     0.2000   -0.0006
    80        0.0500             nan     0.2000   -0.0024
   100        0.0413             nan     0.2000   -0.0033
   120        0.0353             nan     0.2000   -0.0019
   140        0.0285             nan     0.2000   -0.0029
   160        0.0256             nan     0.2000   -0.0033
   180        0.0223             nan     0.2000   -0.0033
   200        0.0202             nan     0.2000   -0.0037

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6046
     2        0.6904             nan     0.2000    0.2807
     3        0.4959             nan     0.2000    0.1685
     4        0.3785             nan     0.2000    0.1090
     5        0.3027             nan     0.2000    0.0557
     6        0.2577             nan     0.2000    0.0335
     7        0.2250             nan     0.2000    0.0280
     8        0.2001             nan     0.2000    0.0069
     9        0.1827             nan     0.2000    0.0015
    10        0.1697             nan     0.2000    0.0117
    20        0.0991             nan     0.2000   -0.0018
    40        0.0597             nan     0.2000   -0.0003
    60        0.0406             nan     0.2000   -0.0023
    80        0.0317             nan     0.2000   -0.0009
   100        0.0252             nan     0.2000   -0.0009
   120        0.0202             nan     0.2000   -0.0024
   140        0.0171             nan     0.2000   -0.0016
   160        0.0151             nan     0.2000   -0.0013
   180        0.0137             nan     0.2000   -0.0031
   200        0.0121             nan     0.2000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6289
     2        0.6713             nan     0.2000    0.2998
     3        0.4686             nan     0.2000    0.1480
     4        0.3578             nan     0.2000    0.1023
     5        0.2788             nan     0.2000    0.0541
     6        0.2348             nan     0.2000    0.0397
     7        0.1974             nan     0.2000    0.0179
     8        0.1735             nan     0.2000    0.0111
     9        0.1566             nan     0.2000    0.0059
    10        0.1436             nan     0.2000   -0.0046
    20        0.0734             nan     0.2000   -0.0045
    40        0.0399             nan     0.2000   -0.0040
    60        0.0215             nan     0.2000   -0.0038
    80        0.0152             nan     0.2000   -0.0028
   100        0.0112             nan     0.2000   -0.0026
   120        0.0094             nan     0.2000   -0.0019
   140        0.0081             nan     0.2000   -0.0062
   160        0.0059             nan     0.2000   -0.0004
   180        0.0050             nan     0.2000   -0.0016
   200        0.0047             nan     0.2000   -0.0019

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1779
     2        0.9961             nan     0.0500    0.1488
     3        0.9091             nan     0.0500    0.1232
     4        0.8352             nan     0.0500    0.1040
     5        0.7727             nan     0.0500    0.0908
     6        0.7198             nan     0.0500    0.0775
     7        0.6729             nan     0.0500    0.0657
     8        0.6314             nan     0.0500    0.0570
     9        0.5967             nan     0.0500    0.0511
    10        0.5659             nan     0.0500    0.0434
    20        0.3858             nan     0.0500    0.0119
    40        0.2685             nan     0.0500    0.0039
    60        0.2192             nan     0.0500    0.0034
    80        0.1916             nan     0.0500    0.0012
   100        0.1751             nan     0.0500    0.0002
   120        0.1628             nan     0.0500   -0.0011
   140        0.1524             nan     0.0500   -0.0018
   160        0.1448             nan     0.0500   -0.0004
   180        0.1370             nan     0.0500   -0.0010
   200        0.1306             nan     0.0500    0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1903
     2        0.9871             nan     0.0500    0.1585
     3        0.8941             nan     0.0500    0.1320
     4        0.8134             nan     0.0500    0.1102
     5        0.7447             nan     0.0500    0.0932
     6        0.6890             nan     0.0500    0.0809
     7        0.6386             nan     0.0500    0.0689
     8        0.5954             nan     0.0500    0.0588
     9        0.5578             nan     0.0500    0.0552
    10        0.5237             nan     0.0500    0.0493
    20        0.3228             nan     0.0500    0.0154
    40        0.1982             nan     0.0500    0.0014
    60        0.1575             nan     0.0500   -0.0002
    80        0.1336             nan     0.0500   -0.0003
   100        0.1172             nan     0.0500   -0.0006
   120        0.1064             nan     0.0500   -0.0006
   140        0.0975             nan     0.0500   -0.0003
   160        0.0892             nan     0.0500   -0.0013
   180        0.0824             nan     0.0500   -0.0002
   200        0.0774             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1955
     2        0.9846             nan     0.0500    0.1646
     3        0.8875             nan     0.0500    0.1394
     4        0.8036             nan     0.0500    0.1150
     5        0.7336             nan     0.0500    0.1020
     6        0.6729             nan     0.0500    0.0831
     7        0.6216             nan     0.0500    0.0752
     8        0.5751             nan     0.0500    0.0669
     9        0.5339             nan     0.0500    0.0535
    10        0.4989             nan     0.0500    0.0517
    20        0.2885             nan     0.0500    0.0187
    40        0.1643             nan     0.0500    0.0018
    60        0.1289             nan     0.0500   -0.0003
    80        0.1055             nan     0.0500   -0.0002
   100        0.0903             nan     0.0500   -0.0002
   120        0.0794             nan     0.0500   -0.0011
   140        0.0707             nan     0.0500   -0.0002
   160        0.0638             nan     0.0500   -0.0006
   180        0.0584             nan     0.0500   -0.0008
   200        0.0544             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2070
     2        0.9782             nan     0.0500    0.1659
     3        0.8790             nan     0.0500    0.1402
     4        0.7944             nan     0.0500    0.1210
     5        0.7203             nan     0.0500    0.1033
     6        0.6555             nan     0.0500    0.0872
     7        0.6014             nan     0.0500    0.0763
     8        0.5533             nan     0.0500    0.0684
     9        0.5104             nan     0.0500    0.0613
    10        0.4724             nan     0.0500    0.0463
    20        0.2612             nan     0.0500    0.0172
    40        0.1356             nan     0.0500   -0.0004
    60        0.0984             nan     0.0500    0.0007
    80        0.0752             nan     0.0500   -0.0010
   100        0.0620             nan     0.0500   -0.0021
   120        0.0515             nan     0.0500   -0.0010
   140        0.0438             nan     0.0500   -0.0005
   160        0.0378             nan     0.0500   -0.0005
   180        0.0334             nan     0.0500   -0.0006
   200        0.0295             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3174
     2        0.8995             nan     0.1000    0.2214
     3        0.7587             nan     0.1000    0.1604
     4        0.6601             nan     0.1000    0.1127
     5        0.5852             nan     0.1000    0.0873
     6        0.5304             nan     0.1000    0.0723
     7        0.4845             nan     0.1000    0.0569
     8        0.4475             nan     0.1000    0.0392
     9        0.4198             nan     0.1000    0.0377
    10        0.3944             nan     0.1000    0.0353
    20        0.2693             nan     0.1000    0.0079
    40        0.1929             nan     0.1000    0.0046
    60        0.1632             nan     0.1000    0.0001
    80        0.1442             nan     0.1000   -0.0013
   100        0.1320             nan     0.1000   -0.0020
   120        0.1241             nan     0.1000   -0.0012
   140        0.1150             nan     0.1000   -0.0005
   160        0.1081             nan     0.1000   -0.0012
   180        0.1022             nan     0.1000   -0.0022
   200        0.0966             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3515
     2        0.8843             nan     0.1000    0.2350
     3        0.7314             nan     0.1000    0.1722
     4        0.6255             nan     0.1000    0.1232
     5        0.5426             nan     0.1000    0.0902
     6        0.4812             nan     0.1000    0.0737
     7        0.4305             nan     0.1000    0.0594
     8        0.3899             nan     0.1000    0.0457
     9        0.3580             nan     0.1000    0.0352
    10        0.3316             nan     0.1000    0.0370
    20        0.1995             nan     0.1000   -0.0007
    40        0.1326             nan     0.1000    0.0015
    60        0.1057             nan     0.1000   -0.0011
    80        0.0874             nan     0.1000   -0.0007
   100        0.0756             nan     0.1000   -0.0008
   120        0.0663             nan     0.1000   -0.0014
   140        0.0593             nan     0.1000   -0.0003
   160        0.0527             nan     0.1000   -0.0005
   180        0.0479             nan     0.1000   -0.0009
   200        0.0439             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3632
     2        0.8765             nan     0.1000    0.2455
     3        0.7253             nan     0.1000    0.1785
     4        0.6097             nan     0.1000    0.1330
     5        0.5245             nan     0.1000    0.1021
     6        0.4570             nan     0.1000    0.0750
     7        0.4043             nan     0.1000    0.0681
     8        0.3593             nan     0.1000    0.0477
     9        0.3261             nan     0.1000    0.0413
    10        0.2970             nan     0.1000    0.0337
    20        0.1670             nan     0.1000    0.0003
    40        0.1049             nan     0.1000   -0.0008
    60        0.0791             nan     0.1000   -0.0024
    80        0.0640             nan     0.1000   -0.0018
   100        0.0523             nan     0.1000   -0.0005
   120        0.0445             nan     0.1000   -0.0005
   140        0.0387             nan     0.1000   -0.0021
   160        0.0340             nan     0.1000   -0.0008
   180        0.0292             nan     0.1000   -0.0007
   200        0.0258             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3674
     2        0.8705             nan     0.1000    0.2583
     3        0.7096             nan     0.1000    0.1880
     4        0.5912             nan     0.1000    0.1426
     5        0.5025             nan     0.1000    0.1063
     6        0.4319             nan     0.1000    0.0893
     7        0.3738             nan     0.1000    0.0616
     8        0.3320             nan     0.1000    0.0504
     9        0.2962             nan     0.1000    0.0381
    10        0.2668             nan     0.1000    0.0326
    20        0.1386             nan     0.1000    0.0025
    40        0.0756             nan     0.1000   -0.0005
    60        0.0530             nan     0.1000   -0.0008
    80        0.0392             nan     0.1000   -0.0029
   100        0.0294             nan     0.1000   -0.0007
   120        0.0237             nan     0.1000   -0.0011
   140        0.0199             nan     0.1000   -0.0009
   160        0.0167             nan     0.1000   -0.0009
   180        0.0141             nan     0.1000   -0.0006
   200        0.0120             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5543
     2        0.7426             nan     0.2000    0.2614
     3        0.5710             nan     0.2000    0.1433
     4        0.4702             nan     0.2000    0.0667
     5        0.4113             nan     0.2000    0.0666
     6        0.3646             nan     0.2000    0.0453
     7        0.3333             nan     0.2000    0.0223
     8        0.3086             nan     0.2000    0.0120
     9        0.2904             nan     0.2000    0.0236
    10        0.2642             nan     0.2000    0.0192
    20        0.1948             nan     0.2000   -0.0058
    40        0.1462             nan     0.2000    0.0005
    60        0.1225             nan     0.2000   -0.0009
    80        0.1103             nan     0.2000   -0.0076
   100        0.1010             nan     0.2000   -0.0044
   120        0.0933             nan     0.2000   -0.0026
   140        0.0866             nan     0.2000   -0.0017
   160        0.0808             nan     0.2000   -0.0037
   180        0.0754             nan     0.2000   -0.0055
   200        0.0711             nan     0.2000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5701
     2        0.7107             nan     0.2000    0.2775
     3        0.5239             nan     0.2000    0.1504
     4        0.4164             nan     0.2000    0.0940
     5        0.3448             nan     0.2000    0.0620
     6        0.2985             nan     0.2000    0.0395
     7        0.2663             nan     0.2000    0.0346
     8        0.2391             nan     0.2000    0.0220
     9        0.2195             nan     0.2000   -0.0106
    10        0.2079             nan     0.2000    0.0084
    20        0.1386             nan     0.2000   -0.0017
    40        0.0946             nan     0.2000   -0.0045
    60        0.0699             nan     0.2000   -0.0019
    80        0.0586             nan     0.2000   -0.0022
   100        0.0465             nan     0.2000   -0.0039
   120        0.0394             nan     0.2000   -0.0013
   140        0.0331             nan     0.2000   -0.0020
   160        0.0276             nan     0.2000   -0.0022
   180        0.0235             nan     0.2000   -0.0036
   200        0.0205             nan     0.2000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5798
     2        0.6840             nan     0.2000    0.2777
     3        0.4954             nan     0.2000    0.1576
     4        0.3843             nan     0.2000    0.0912
     5        0.3139             nan     0.2000    0.0654
     6        0.2646             nan     0.2000    0.0386
     7        0.2284             nan     0.2000    0.0167
     8        0.2052             nan     0.2000    0.0135
     9        0.1880             nan     0.2000    0.0027
    10        0.1753             nan     0.2000    0.0024
    20        0.1066             nan     0.2000   -0.0063
    40        0.0657             nan     0.2000   -0.0061
    60        0.0444             nan     0.2000   -0.0032
    80        0.0336             nan     0.2000   -0.0031
   100        0.0252             nan     0.2000   -0.0020
   120        0.0212             nan     0.2000   -0.0004
   140        0.0169             nan     0.2000   -0.0010
   160        0.0144             nan     0.2000   -0.0006
   180        0.0125             nan     0.2000   -0.0007
   200        0.0112             nan     0.2000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6467
     2        0.6737             nan     0.2000    0.2778
     3        0.4739             nan     0.2000    0.1583
     4        0.3606             nan     0.2000    0.0777
     5        0.2898             nan     0.2000    0.0532
     6        0.2397             nan     0.2000    0.0354
     7        0.2063             nan     0.2000    0.0213
     8        0.1835             nan     0.2000    0.0144
     9        0.1617             nan     0.2000   -0.0010
    10        0.1501             nan     0.2000    0.0009
    20        0.0781             nan     0.2000   -0.0062
    40        0.0383             nan     0.2000   -0.0082
    60        0.0250             nan     0.2000   -0.0018
    80        0.0176             nan     0.2000   -0.0024
   100        0.0126             nan     0.2000   -0.0008
   120        0.0097             nan     0.2000   -0.0021
   140        0.0072             nan     0.2000   -0.0010
   160        0.0064             nan     0.2000   -0.0001
   180        0.0058             nan     0.2000   -0.0011
   200        0.0046             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1821
     2        0.9935             nan     0.0500    0.1514
     3        0.9081             nan     0.0500    0.1266
     4        0.8331             nan     0.0500    0.1073
     5        0.7707             nan     0.0500    0.0913
     6        0.7165             nan     0.0500    0.0793
     7        0.6690             nan     0.0500    0.0679
     8        0.6277             nan     0.0500    0.0591
     9        0.5896             nan     0.0500    0.0513
    10        0.5570             nan     0.0500    0.0452
    20        0.3755             nan     0.0500    0.0162
    40        0.2592             nan     0.0500    0.0050
    60        0.2132             nan     0.0500    0.0019
    80        0.1851             nan     0.0500    0.0001
   100        0.1670             nan     0.0500    0.0013
   120        0.1536             nan     0.0500    0.0001
   140        0.1436             nan     0.0500   -0.0007
   160        0.1351             nan     0.0500   -0.0002
   180        0.1294             nan     0.0500   -0.0002
   200        0.1236             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1928
     2        0.9859             nan     0.0500    0.1592
     3        0.8911             nan     0.0500    0.1359
     4        0.8129             nan     0.0500    0.1137
     5        0.7464             nan     0.0500    0.0983
     6        0.6880             nan     0.0500    0.0864
     7        0.6355             nan     0.0500    0.0747
     8        0.5898             nan     0.0500    0.0648
     9        0.5497             nan     0.0500    0.0571
    10        0.5148             nan     0.0500    0.0500
    20        0.3114             nan     0.0500    0.0173
    40        0.1900             nan     0.0500    0.0023
    60        0.1502             nan     0.0500   -0.0004
    80        0.1261             nan     0.0500    0.0000
   100        0.1104             nan     0.0500    0.0001
   120        0.0998             nan     0.0500   -0.0006
   140        0.0903             nan     0.0500   -0.0004
   160        0.0828             nan     0.0500   -0.0006
   180        0.0766             nan     0.0500   -0.0006
   200        0.0711             nan     0.0500   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2045
     2        0.9793             nan     0.0500    0.1656
     3        0.8804             nan     0.0500    0.1379
     4        0.7949             nan     0.0500    0.1178
     5        0.7245             nan     0.0500    0.1015
     6        0.6645             nan     0.0500    0.0887
     7        0.6107             nan     0.0500    0.0750
     8        0.5639             nan     0.0500    0.0664
     9        0.5212             nan     0.0500    0.0579
    10        0.4854             nan     0.0500    0.0501
    20        0.2742             nan     0.0500    0.0175
    40        0.1548             nan     0.0500    0.0015
    60        0.1144             nan     0.0500   -0.0011
    80        0.0942             nan     0.0500   -0.0012
   100        0.0800             nan     0.0500   -0.0013
   120        0.0696             nan     0.0500   -0.0003
   140        0.0616             nan     0.0500   -0.0009
   160        0.0558             nan     0.0500   -0.0007
   180        0.0504             nan     0.0500   -0.0007
   200        0.0457             nan     0.0500   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2095
     2        0.9752             nan     0.0500    0.1683
     3        0.8741             nan     0.0500    0.1442
     4        0.7874             nan     0.0500    0.1257
     5        0.7124             nan     0.0500    0.1079
     6        0.6476             nan     0.0500    0.0908
     7        0.5918             nan     0.0500    0.0780
     8        0.5437             nan     0.0500    0.0670
     9        0.5018             nan     0.0500    0.0590
    10        0.4655             nan     0.0500    0.0529
    20        0.2525             nan     0.0500    0.0152
    40        0.1281             nan     0.0500    0.0020
    60        0.0880             nan     0.0500    0.0002
    80        0.0677             nan     0.0500   -0.0011
   100        0.0542             nan     0.0500   -0.0006
   120        0.0444             nan     0.0500   -0.0010
   140        0.0376             nan     0.0500   -0.0011
   160        0.0322             nan     0.0500   -0.0007
   180        0.0278             nan     0.0500   -0.0005
   200        0.0241             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3359
     2        0.8999             nan     0.1000    0.2289
     3        0.7608             nan     0.1000    0.1670
     4        0.6590             nan     0.1000    0.1219
     5        0.5824             nan     0.1000    0.0929
     6        0.5236             nan     0.1000    0.0722
     7        0.4752             nan     0.1000    0.0531
     8        0.4399             nan     0.1000    0.0454
     9        0.4083             nan     0.1000    0.0362
    10        0.3829             nan     0.1000    0.0257
    20        0.2612             nan     0.1000    0.0060
    40        0.1885             nan     0.1000    0.0006
    60        0.1551             nan     0.1000   -0.0010
    80        0.1358             nan     0.1000   -0.0007
   100        0.1239             nan     0.1000   -0.0009
   120        0.1142             nan     0.1000   -0.0026
   140        0.1064             nan     0.1000   -0.0002
   160        0.1001             nan     0.1000   -0.0012
   180        0.0945             nan     0.1000   -0.0024
   200        0.0913             nan     0.1000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3478
     2        0.8781             nan     0.1000    0.2387
     3        0.7305             nan     0.1000    0.1777
     4        0.6202             nan     0.1000    0.1294
     5        0.5369             nan     0.1000    0.0990
     6        0.4727             nan     0.1000    0.0688
     7        0.4243             nan     0.1000    0.0637
     8        0.3833             nan     0.1000    0.0497
     9        0.3491             nan     0.1000    0.0347
    10        0.3225             nan     0.1000    0.0416
    20        0.1877             nan     0.1000    0.0053
    40        0.1273             nan     0.1000   -0.0025
    60        0.1020             nan     0.1000   -0.0036
    80        0.0855             nan     0.1000   -0.0037
   100        0.0729             nan     0.1000   -0.0010
   120        0.0627             nan     0.1000   -0.0021
   140        0.0555             nan     0.1000   -0.0013
   160        0.0486             nan     0.1000   -0.0009
   180        0.0436             nan     0.1000   -0.0006
   200        0.0396             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3750
     2        0.8725             nan     0.1000    0.2576
     3        0.7177             nan     0.1000    0.1792
     4        0.6046             nan     0.1000    0.1390
     5        0.5164             nan     0.1000    0.1028
     6        0.4490             nan     0.1000    0.0794
     7        0.3961             nan     0.1000    0.0670
     8        0.3521             nan     0.1000    0.0512
     9        0.3176             nan     0.1000    0.0355
    10        0.2892             nan     0.1000    0.0332
    20        0.1591             nan     0.1000    0.0039
    40        0.0971             nan     0.1000   -0.0017
    60        0.0728             nan     0.1000   -0.0045
    80        0.0586             nan     0.1000   -0.0010
   100        0.0471             nan     0.1000   -0.0023
   120        0.0379             nan     0.1000   -0.0024
   140        0.0323             nan     0.1000   -0.0009
   160        0.0279             nan     0.1000   -0.0010
   180        0.0246             nan     0.1000   -0.0012
   200        0.0215             nan     0.1000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3748
     2        0.8687             nan     0.1000    0.2557
     3        0.7061             nan     0.1000    0.1893
     4        0.5896             nan     0.1000    0.1430
     5        0.4978             nan     0.1000    0.1040
     6        0.4269             nan     0.1000    0.0844
     7        0.3716             nan     0.1000    0.0537
     8        0.3298             nan     0.1000    0.0500
     9        0.2946             nan     0.1000    0.0432
    10        0.2647             nan     0.1000    0.0307
    20        0.1354             nan     0.1000    0.0076
    40        0.0696             nan     0.1000   -0.0006
    60        0.0465             nan     0.1000   -0.0025
    80        0.0343             nan     0.1000   -0.0005
   100        0.0259             nan     0.1000   -0.0012
   120        0.0201             nan     0.1000   -0.0011
   140        0.0159             nan     0.1000   -0.0001
   160        0.0128             nan     0.1000   -0.0012
   180        0.0104             nan     0.1000   -0.0003
   200        0.0086             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5481
     2        0.7295             nan     0.2000    0.2506
     3        0.5540             nan     0.2000    0.1421
     4        0.4560             nan     0.2000    0.0839
     5        0.3946             nan     0.2000    0.0349
     6        0.3577             nan     0.2000    0.0401
     7        0.3153             nan     0.2000    0.0253
     8        0.2916             nan     0.2000    0.0254
     9        0.2696             nan     0.2000    0.0194
    10        0.2540             nan     0.2000    0.0187
    20        0.1788             nan     0.2000   -0.0017
    40        0.1375             nan     0.2000   -0.0046
    60        0.1208             nan     0.2000    0.0005
    80        0.1082             nan     0.2000   -0.0030
   100        0.0956             nan     0.2000   -0.0064
   120        0.0877             nan     0.2000   -0.0024
   140        0.0821             nan     0.2000   -0.0053
   160        0.0726             nan     0.2000   -0.0042
   180        0.0688             nan     0.2000   -0.0019
   200        0.0640             nan     0.2000   -0.0072

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5850
     2        0.6958             nan     0.2000    0.2756
     3        0.5095             nan     0.2000    0.1421
     4        0.4029             nan     0.2000    0.0947
     5        0.3316             nan     0.2000    0.0727
     6        0.2794             nan     0.2000    0.0356
     7        0.2494             nan     0.2000    0.0141
     8        0.2278             nan     0.2000    0.0281
     9        0.2065             nan     0.2000    0.0107
    10        0.1936             nan     0.2000    0.0061
    20        0.1248             nan     0.2000   -0.0023
    40        0.0853             nan     0.2000   -0.0026
    60        0.0661             nan     0.2000   -0.0007
    80        0.0511             nan     0.2000   -0.0039
   100        0.0415             nan     0.2000   -0.0010
   120        0.0348             nan     0.2000   -0.0007
   140        0.0294             nan     0.2000   -0.0010
   160        0.0250             nan     0.2000   -0.0009
   180        0.0223             nan     0.2000   -0.0009
   200        0.0197             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6245
     2        0.6887             nan     0.2000    0.2920
     3        0.4934             nan     0.2000    0.1549
     4        0.3787             nan     0.2000    0.0916
     5        0.3082             nan     0.2000    0.0543
     6        0.2574             nan     0.2000    0.0529
     7        0.2181             nan     0.2000    0.0226
     8        0.1953             nan     0.2000   -0.0002
     9        0.1789             nan     0.2000    0.0082
    10        0.1646             nan     0.2000    0.0070
    20        0.0977             nan     0.2000   -0.0050
    40        0.0593             nan     0.2000   -0.0059
    60        0.0402             nan     0.2000   -0.0028
    80        0.0286             nan     0.2000   -0.0020
   100        0.0209             nan     0.2000   -0.0026
   120        0.0160             nan     0.2000   -0.0014
   140        0.0132             nan     0.2000   -0.0023
   160        0.0113             nan     0.2000   -0.0009
   180        0.0091             nan     0.2000   -0.0007
   200        0.0078             nan     0.2000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6448
     2        0.6695             nan     0.2000    0.2770
     3        0.4676             nan     0.2000    0.1701
     4        0.3546             nan     0.2000    0.0980
     5        0.2806             nan     0.2000    0.0614
     6        0.2243             nan     0.2000    0.0331
     7        0.1921             nan     0.2000    0.0169
     8        0.1710             nan     0.2000    0.0175
     9        0.1506             nan     0.2000    0.0046
    10        0.1377             nan     0.2000   -0.0022
    20        0.0746             nan     0.2000   -0.0056
    40        0.0350             nan     0.2000   -0.0028
    60        0.0205             nan     0.2000   -0.0029
    80        0.0136             nan     0.2000   -0.0006
   100        0.0098             nan     0.2000   -0.0006
   120        0.0070             nan     0.2000   -0.0023
   140        0.0051             nan     0.2000   -0.0020
   160        0.0041             nan     0.2000   -0.0014
   180        0.0034             nan     0.2000   -0.0003
   200        0.0028             nan     0.2000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1842
     2        0.9941             nan     0.0500    0.1519
     3        0.9068             nan     0.0500    0.1265
     4        0.8316             nan     0.0500    0.1078
     5        0.7697             nan     0.0500    0.0925
     6        0.7163             nan     0.0500    0.0779
     7        0.6677             nan     0.0500    0.0687
     8        0.6270             nan     0.0500    0.0589
     9        0.5910             nan     0.0500    0.0516
    10        0.5600             nan     0.0500    0.0455
    20        0.3734             nan     0.0500    0.0148
    40        0.2511             nan     0.0500    0.0031
    60        0.2044             nan     0.0500    0.0015
    80        0.1778             nan     0.0500    0.0002
   100        0.1610             nan     0.0500    0.0001
   120        0.1496             nan     0.0500    0.0003
   140        0.1407             nan     0.0500   -0.0005
   160        0.1335             nan     0.0500   -0.0006
   180        0.1263             nan     0.0500   -0.0003
   200        0.1210             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1852
     2        0.9870             nan     0.0500    0.1624
     3        0.8906             nan     0.0500    0.1351
     4        0.8101             nan     0.0500    0.1139
     5        0.7431             nan     0.0500    0.0969
     6        0.6840             nan     0.0500    0.0845
     7        0.6320             nan     0.0500    0.0732
     8        0.5863             nan     0.0500    0.0608
     9        0.5489             nan     0.0500    0.0543
    10        0.5144             nan     0.0500    0.0471
    20        0.3089             nan     0.0500    0.0148
    40        0.1851             nan     0.0500    0.0043
    60        0.1439             nan     0.0500    0.0001
    80        0.1230             nan     0.0500    0.0001
   100        0.1085             nan     0.0500   -0.0008
   120        0.0991             nan     0.0500   -0.0005
   140        0.0914             nan     0.0500   -0.0007
   160        0.0835             nan     0.0500   -0.0003
   180        0.0777             nan     0.0500   -0.0004
   200        0.0728             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2008
     2        0.9791             nan     0.0500    0.1661
     3        0.8805             nan     0.0500    0.1378
     4        0.7988             nan     0.0500    0.1153
     5        0.7282             nan     0.0500    0.0998
     6        0.6670             nan     0.0500    0.0884
     7        0.6133             nan     0.0500    0.0753
     8        0.5679             nan     0.0500    0.0681
     9        0.5268             nan     0.0500    0.0549
    10        0.4912             nan     0.0500    0.0512
    20        0.2802             nan     0.0500    0.0143
    40        0.1550             nan     0.0500    0.0018
    60        0.1181             nan     0.0500    0.0004
    80        0.0959             nan     0.0500   -0.0002
   100        0.0813             nan     0.0500   -0.0012
   120        0.0710             nan     0.0500   -0.0004
   140        0.0640             nan     0.0500   -0.0006
   160        0.0576             nan     0.0500   -0.0009
   180        0.0523             nan     0.0500   -0.0013
   200        0.0482             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2082
     2        0.9757             nan     0.0500    0.1703
     3        0.8729             nan     0.0500    0.1414
     4        0.7881             nan     0.0500    0.1213
     5        0.7150             nan     0.0500    0.1028
     6        0.6511             nan     0.0500    0.0881
     7        0.5960             nan     0.0500    0.0772
     8        0.5483             nan     0.0500    0.0716
     9        0.5040             nan     0.0500    0.0596
    10        0.4654             nan     0.0500    0.0542
    20        0.2495             nan     0.0500    0.0127
    40        0.1269             nan     0.0500    0.0012
    60        0.0894             nan     0.0500    0.0001
    80        0.0679             nan     0.0500   -0.0007
   100        0.0555             nan     0.0500   -0.0011
   120        0.0463             nan     0.0500   -0.0012
   140        0.0386             nan     0.0500   -0.0010
   160        0.0335             nan     0.0500   -0.0003
   180        0.0294             nan     0.0500   -0.0003
   200        0.0258             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3337
     2        0.8970             nan     0.1000    0.2277
     3        0.7568             nan     0.1000    0.1640
     4        0.6548             nan     0.1000    0.1188
     5        0.5766             nan     0.1000    0.0874
     6        0.5191             nan     0.1000    0.0664
     7        0.4722             nan     0.1000    0.0507
     8        0.4353             nan     0.1000    0.0460
     9        0.4049             nan     0.1000    0.0371
    10        0.3799             nan     0.1000    0.0277
    20        0.2546             nan     0.1000    0.0075
    40        0.1790             nan     0.1000   -0.0015
    60        0.1523             nan     0.1000    0.0009
    80        0.1370             nan     0.1000    0.0025
   100        0.1216             nan     0.1000   -0.0017
   120        0.1131             nan     0.1000   -0.0021
   140        0.1043             nan     0.1000   -0.0013
   160        0.0988             nan     0.1000   -0.0015
   180        0.0945             nan     0.1000   -0.0016
   200        0.0908             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3593
     2        0.8828             nan     0.1000    0.2430
     3        0.7329             nan     0.1000    0.1739
     4        0.6249             nan     0.1000    0.1281
     5        0.5424             nan     0.1000    0.0972
     6        0.4773             nan     0.1000    0.0847
     7        0.4234             nan     0.1000    0.0588
     8        0.3823             nan     0.1000    0.0448
     9        0.3485             nan     0.1000    0.0400
    10        0.3196             nan     0.1000    0.0359
    20        0.1872             nan     0.1000    0.0089
    40        0.1253             nan     0.1000   -0.0016
    60        0.0993             nan     0.1000   -0.0006
    80        0.0848             nan     0.1000   -0.0006
   100        0.0734             nan     0.1000   -0.0002
   120        0.0646             nan     0.1000   -0.0010
   140        0.0564             nan     0.1000   -0.0005
   160        0.0497             nan     0.1000   -0.0016
   180        0.0444             nan     0.1000   -0.0006
   200        0.0405             nan     0.1000   -0.0024

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3731
     2        0.8752             nan     0.1000    0.2500
     3        0.7186             nan     0.1000    0.1800
     4        0.6029             nan     0.1000    0.1360
     5        0.5146             nan     0.1000    0.1068
     6        0.4457             nan     0.1000    0.0816
     7        0.3912             nan     0.1000    0.0624
     8        0.3486             nan     0.1000    0.0488
     9        0.3138             nan     0.1000    0.0416
    10        0.2860             nan     0.1000    0.0334
    20        0.1573             nan     0.1000    0.0077
    40        0.0982             nan     0.1000   -0.0011
    60        0.0727             nan     0.1000   -0.0021
    80        0.0571             nan     0.1000   -0.0023
   100        0.0468             nan     0.1000   -0.0005
   120        0.0387             nan     0.1000   -0.0004
   140        0.0333             nan     0.1000   -0.0012
   160        0.0292             nan     0.1000   -0.0014
   180        0.0256             nan     0.1000   -0.0001
   200        0.0226             nan     0.1000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3861
     2        0.8636             nan     0.1000    0.2667
     3        0.7019             nan     0.1000    0.1866
     4        0.5844             nan     0.1000    0.1406
     5        0.4926             nan     0.1000    0.1070
     6        0.4225             nan     0.1000    0.0815
     7        0.3658             nan     0.1000    0.0628
     8        0.3217             nan     0.1000    0.0442
     9        0.2881             nan     0.1000    0.0394
    10        0.2598             nan     0.1000    0.0316
    20        0.1332             nan     0.1000    0.0044
    40        0.0717             nan     0.1000   -0.0016
    60        0.0486             nan     0.1000   -0.0015
    80        0.0343             nan     0.1000   -0.0014
   100        0.0268             nan     0.1000   -0.0010
   120        0.0216             nan     0.1000   -0.0003
   140        0.0175             nan     0.1000   -0.0004
   160        0.0142             nan     0.1000   -0.0005
   180        0.0122             nan     0.1000   -0.0007
   200        0.0105             nan     0.1000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5550
     2        0.7279             nan     0.2000    0.2485
     3        0.5524             nan     0.2000    0.1467
     4        0.4556             nan     0.2000    0.0882
     5        0.3946             nan     0.2000    0.0534
     6        0.3466             nan     0.2000    0.0492
     7        0.3098             nan     0.2000    0.0351
     8        0.2837             nan     0.2000    0.0259
     9        0.2637             nan     0.2000    0.0066
    10        0.2554             nan     0.2000    0.0163
    20        0.1789             nan     0.2000   -0.0029
    40        0.1339             nan     0.2000   -0.0005
    60        0.1130             nan     0.2000   -0.0015
    80        0.0998             nan     0.2000   -0.0032
   100        0.0912             nan     0.2000   -0.0035
   120        0.0828             nan     0.2000   -0.0025
   140        0.0765             nan     0.2000   -0.0037
   160        0.0713             nan     0.2000   -0.0006
   180        0.0657             nan     0.2000   -0.0037
   200        0.0617             nan     0.2000   -0.0046

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5897
     2        0.7058             nan     0.2000    0.2780
     3        0.5175             nan     0.2000    0.1436
     4        0.4089             nan     0.2000    0.0869
     5        0.3374             nan     0.2000    0.0443
     6        0.2940             nan     0.2000    0.0515
     7        0.2563             nan     0.2000    0.0342
     8        0.2298             nan     0.2000    0.0208
     9        0.2094             nan     0.2000    0.0158
    10        0.1931             nan     0.2000    0.0073
    20        0.1276             nan     0.2000   -0.0021
    40        0.0856             nan     0.2000   -0.0055
    60        0.0676             nan     0.2000   -0.0036
    80        0.0520             nan     0.2000   -0.0024
   100        0.0433             nan     0.2000   -0.0014
   120        0.0351             nan     0.2000    0.0002
   140        0.0294             nan     0.2000   -0.0028
   160        0.0261             nan     0.2000   -0.0002
   180        0.0220             nan     0.2000   -0.0011
   200        0.0198             nan     0.2000   -0.0038

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5997
     2        0.6963             nan     0.2000    0.2818
     3        0.4941             nan     0.2000    0.1574
     4        0.3808             nan     0.2000    0.0996
     5        0.3059             nan     0.2000    0.0610
     6        0.2562             nan     0.2000    0.0512
     7        0.2200             nan     0.2000    0.0294
     8        0.1937             nan     0.2000    0.0199
     9        0.1716             nan     0.2000    0.0135
    10        0.1559             nan     0.2000    0.0059
    20        0.0988             nan     0.2000   -0.0048
    40        0.0628             nan     0.2000   -0.0051
    60        0.0437             nan     0.2000   -0.0042
    80        0.0321             nan     0.2000   -0.0060
   100        0.0257             nan     0.2000   -0.0006
   120        0.0206             nan     0.2000   -0.0022
   140        0.0174             nan     0.2000   -0.0013
   160        0.0151             nan     0.2000   -0.0014
   180        0.0126             nan     0.2000   -0.0015
   200        0.0106             nan     0.2000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6136
     2        0.6760             nan     0.2000    0.3008
     3        0.4661             nan     0.2000    0.1606
     4        0.3500             nan     0.2000    0.0941
     5        0.2754             nan     0.2000    0.0539
     6        0.2262             nan     0.2000    0.0385
     7        0.1852             nan     0.2000    0.0191
     8        0.1641             nan     0.2000    0.0048
     9        0.1494             nan     0.2000    0.0095
    10        0.1338             nan     0.2000    0.0060
    20        0.0709             nan     0.2000   -0.0093
    40        0.0384             nan     0.2000   -0.0021
    60        0.0224             nan     0.2000   -0.0033
    80        0.0165             nan     0.2000   -0.0011
   100        0.0121             nan     0.2000   -0.0011
   120        0.0090             nan     0.2000   -0.0020
   140        0.0076             nan     0.2000   -0.0022
   160        0.0057             nan     0.2000   -0.0039
   180        0.0048             nan     0.2000   -0.0002
   200        0.0042             nan     0.2000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1784
     2        0.9935             nan     0.0500    0.1491
     3        0.9091             nan     0.0500    0.1258
     4        0.8356             nan     0.0500    0.1062
     5        0.7733             nan     0.0500    0.0912
     6        0.7183             nan     0.0500    0.0775
     7        0.6715             nan     0.0500    0.0664
     8        0.6310             nan     0.0500    0.0587
     9        0.5951             nan     0.0500    0.0510
    10        0.5638             nan     0.0500    0.0458
    20        0.3830             nan     0.0500    0.0167
    40        0.2577             nan     0.0500    0.0035
    60        0.2137             nan     0.0500    0.0034
    80        0.1853             nan     0.0500   -0.0003
   100        0.1682             nan     0.0500   -0.0002
   120        0.1561             nan     0.0500   -0.0006
   140        0.1462             nan     0.0500   -0.0006
   160        0.1378             nan     0.0500   -0.0009
   180        0.1315             nan     0.0500    0.0001
   200        0.1265             nan     0.0500   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1903
     2        0.9848             nan     0.0500    0.1580
     3        0.8911             nan     0.0500    0.1340
     4        0.8110             nan     0.0500    0.1130
     5        0.7436             nan     0.0500    0.0924
     6        0.6870             nan     0.0500    0.0832
     7        0.6370             nan     0.0500    0.0720
     8        0.5927             nan     0.0500    0.0628
     9        0.5530             nan     0.0500    0.0566
    10        0.5178             nan     0.0500    0.0476
    20        0.3165             nan     0.0500    0.0174
    40        0.1865             nan     0.0500    0.0020
    60        0.1480             nan     0.0500    0.0019
    80        0.1247             nan     0.0500   -0.0004
   100        0.1101             nan     0.0500   -0.0002
   120        0.0979             nan     0.0500   -0.0007
   140        0.0896             nan     0.0500   -0.0009
   160        0.0811             nan     0.0500   -0.0008
   180        0.0748             nan     0.0500   -0.0010
   200        0.0704             nan     0.0500   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2006
     2        0.9806             nan     0.0500    0.1613
     3        0.8851             nan     0.0500    0.1378
     4        0.8014             nan     0.0500    0.1159
     5        0.7312             nan     0.0500    0.1016
     6        0.6688             nan     0.0500    0.0881
     7        0.6156             nan     0.0500    0.0757
     8        0.5686             nan     0.0500    0.0637
     9        0.5289             nan     0.0500    0.0590
    10        0.4926             nan     0.0500    0.0541
    20        0.2842             nan     0.0500    0.0182
    40        0.1559             nan     0.0500    0.0022
    60        0.1190             nan     0.0500   -0.0003
    80        0.0953             nan     0.0500   -0.0003
   100        0.0824             nan     0.0500   -0.0001
   120        0.0716             nan     0.0500   -0.0003
   140        0.0634             nan     0.0500   -0.0002
   160        0.0566             nan     0.0500   -0.0001
   180        0.0519             nan     0.0500   -0.0011
   200        0.0467             nan     0.0500   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2082
     2        0.9770             nan     0.0500    0.1679
     3        0.8750             nan     0.0500    0.1454
     4        0.7892             nan     0.0500    0.1234
     5        0.7143             nan     0.0500    0.1019
     6        0.6527             nan     0.0500    0.0924
     7        0.5963             nan     0.0500    0.0786
     8        0.5485             nan     0.0500    0.0646
     9        0.5068             nan     0.0500    0.0598
    10        0.4697             nan     0.0500    0.0525
    20        0.2511             nan     0.0500    0.0163
    40        0.1257             nan     0.0500    0.0015
    60        0.0881             nan     0.0500    0.0000
    80        0.0672             nan     0.0500   -0.0010
   100        0.0543             nan     0.0500   -0.0010
   120        0.0453             nan     0.0500   -0.0005
   140        0.0381             nan     0.0500   -0.0007
   160        0.0334             nan     0.0500   -0.0009
   180        0.0293             nan     0.0500   -0.0014
   200        0.0264             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3334
     2        0.9002             nan     0.1000    0.2251
     3        0.7616             nan     0.1000    0.1623
     4        0.6611             nan     0.1000    0.1217
     5        0.5841             nan     0.1000    0.0899
     6        0.5272             nan     0.1000    0.0633
     7        0.4808             nan     0.1000    0.0538
     8        0.4440             nan     0.1000    0.0485
     9        0.4120             nan     0.1000    0.0398
    10        0.3845             nan     0.1000    0.0320
    20        0.2602             nan     0.1000    0.0096
    40        0.1833             nan     0.1000   -0.0001
    60        0.1530             nan     0.1000   -0.0005
    80        0.1357             nan     0.1000   -0.0019
   100        0.1260             nan     0.1000   -0.0005
   120        0.1157             nan     0.1000   -0.0018
   140        0.1080             nan     0.1000   -0.0017
   160        0.1017             nan     0.1000   -0.0008
   180        0.0969             nan     0.1000   -0.0009
   200        0.0913             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3558
     2        0.8815             nan     0.1000    0.2389
     3        0.7345             nan     0.1000    0.1752
     4        0.6230             nan     0.1000    0.1284
     5        0.5387             nan     0.1000    0.0962
     6        0.4764             nan     0.1000    0.0764
     7        0.4266             nan     0.1000    0.0621
     8        0.3846             nan     0.1000    0.0493
     9        0.3492             nan     0.1000    0.0465
    10        0.3179             nan     0.1000    0.0322
    20        0.1880             nan     0.1000    0.0039
    40        0.1243             nan     0.1000    0.0003
    60        0.0990             nan     0.1000   -0.0005
    80        0.0812             nan     0.1000   -0.0015
   100        0.0685             nan     0.1000   -0.0022
   120        0.0590             nan     0.1000   -0.0026
   140        0.0532             nan     0.1000   -0.0005
   160        0.0472             nan     0.1000   -0.0010
   180        0.0422             nan     0.1000   -0.0014
   200        0.0382             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3605
     2        0.8767             nan     0.1000    0.2515
     3        0.7160             nan     0.1000    0.1749
     4        0.6053             nan     0.1000    0.1371
     5        0.5174             nan     0.1000    0.1034
     6        0.4512             nan     0.1000    0.0804
     7        0.3972             nan     0.1000    0.0624
     8        0.3533             nan     0.1000    0.0518
     9        0.3177             nan     0.1000    0.0319
    10        0.2916             nan     0.1000    0.0242
    20        0.1602             nan     0.1000    0.0061
    40        0.0978             nan     0.1000   -0.0016
    60        0.0732             nan     0.1000   -0.0032
    80        0.0590             nan     0.1000   -0.0004
   100        0.0465             nan     0.1000   -0.0007
   120        0.0390             nan     0.1000   -0.0024
   140        0.0337             nan     0.1000   -0.0007
   160        0.0288             nan     0.1000   -0.0006
   180        0.0256             nan     0.1000   -0.0000
   200        0.0221             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3806
     2        0.8618             nan     0.1000    0.2567
     3        0.7027             nan     0.1000    0.1891
     4        0.5839             nan     0.1000    0.1343
     5        0.4936             nan     0.1000    0.1014
     6        0.4280             nan     0.1000    0.0802
     7        0.3734             nan     0.1000    0.0651
     8        0.3290             nan     0.1000    0.0474
     9        0.2942             nan     0.1000    0.0372
    10        0.2659             nan     0.1000    0.0360
    20        0.1358             nan     0.1000    0.0033
    40        0.0705             nan     0.1000   -0.0007
    60        0.0477             nan     0.1000   -0.0012
    80        0.0355             nan     0.1000   -0.0011
   100        0.0272             nan     0.1000   -0.0016
   120        0.0213             nan     0.1000   -0.0003
   140        0.0174             nan     0.1000   -0.0011
   160        0.0151             nan     0.1000    0.0000
   180        0.0121             nan     0.1000   -0.0002
   200        0.0102             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5431
     2        0.7312             nan     0.2000    0.2424
     3        0.5639             nan     0.2000    0.1383
     4        0.4604             nan     0.2000    0.0655
     5        0.4009             nan     0.2000    0.0667
     6        0.3540             nan     0.2000    0.0267
     7        0.3176             nan     0.2000    0.0289
     8        0.2911             nan     0.2000    0.0202
     9        0.2740             nan     0.2000    0.0249
    10        0.2571             nan     0.2000    0.0167
    20        0.1838             nan     0.2000    0.0004
    40        0.1350             nan     0.2000   -0.0009
    60        0.1166             nan     0.2000   -0.0028
    80        0.1008             nan     0.2000   -0.0015
   100        0.0915             nan     0.2000   -0.0028
   120        0.0852             nan     0.2000   -0.0051
   140        0.0773             nan     0.2000   -0.0024
   160        0.0701             nan     0.2000   -0.0025
   180        0.0658             nan     0.2000   -0.0007
   200        0.0617             nan     0.2000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5661
     2        0.7067             nan     0.2000    0.2694
     3        0.5169             nan     0.2000    0.1360
     4        0.4131             nan     0.2000    0.0874
     5        0.3404             nan     0.2000    0.0590
     6        0.2922             nan     0.2000    0.0441
     7        0.2560             nan     0.2000    0.0257
     8        0.2305             nan     0.2000    0.0089
     9        0.2131             nan     0.2000    0.0116
    10        0.1986             nan     0.2000    0.0108
    20        0.1290             nan     0.2000   -0.0029
    40        0.0848             nan     0.2000   -0.0075
    60        0.0595             nan     0.2000   -0.0089
    80        0.0486             nan     0.2000   -0.0041
   100        0.0388             nan     0.2000   -0.0026
   120        0.0318             nan     0.2000   -0.0004
   140        0.0269             nan     0.2000   -0.0014
   160        0.0232             nan     0.2000   -0.0019
   180        0.0201             nan     0.2000   -0.0027
   200        0.0183             nan     0.2000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5893
     2        0.6866             nan     0.2000    0.2763
     3        0.4929             nan     0.2000    0.1567
     4        0.3807             nan     0.2000    0.0899
     5        0.3120             nan     0.2000    0.0487
     6        0.2651             nan     0.2000    0.0517
     7        0.2259             nan     0.2000    0.0125
     8        0.2053             nan     0.2000    0.0224
     9        0.1828             nan     0.2000    0.0082
    10        0.1678             nan     0.2000    0.0092
    20        0.1034             nan     0.2000    0.0001
    40        0.0595             nan     0.2000   -0.0026
    60        0.0420             nan     0.2000   -0.0038
    80        0.0319             nan     0.2000   -0.0012
   100        0.0257             nan     0.2000   -0.0054
   120        0.0201             nan     0.2000   -0.0017
   140        0.0165             nan     0.2000   -0.0025
   160        0.0138             nan     0.2000   -0.0016
   180        0.0120             nan     0.2000   -0.0020
   200        0.0105             nan     0.2000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6228
     2        0.6756             nan     0.2000    0.3071
     3        0.4699             nan     0.2000    0.1570
     4        0.3542             nan     0.2000    0.1067
     5        0.2791             nan     0.2000    0.0586
     6        0.2316             nan     0.2000    0.0405
     7        0.1979             nan     0.2000    0.0239
     8        0.1702             nan     0.2000    0.0047
     9        0.1520             nan     0.2000    0.0063
    10        0.1378             nan     0.2000   -0.0035
    20        0.0723             nan     0.2000   -0.0038
    40        0.0354             nan     0.2000   -0.0030
    60        0.0228             nan     0.2000   -0.0031
    80        0.0154             nan     0.2000   -0.0058
   100        0.0117             nan     0.2000   -0.0037
   120        0.0096             nan     0.2000   -0.0036
   140        0.0078             nan     0.2000   -0.0020
   160        0.0066             nan     0.2000   -0.0020
   180        0.0057             nan     0.2000   -0.0014
   200        0.0054             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1767
     2        0.9938             nan     0.0500    0.1497
     3        0.9070             nan     0.0500    0.1246
     4        0.8325             nan     0.0500    0.1050
     5        0.7699             nan     0.0500    0.0848
     6        0.7181             nan     0.0500    0.0789
     7        0.6711             nan     0.0500    0.0674
     8        0.6300             nan     0.0500    0.0578
     9        0.5945             nan     0.0500    0.0504
    10        0.5634             nan     0.0500    0.0434
    20        0.3837             nan     0.0500    0.0159
    40        0.2670             nan     0.0500    0.0031
    60        0.2211             nan     0.0500    0.0011
    80        0.1939             nan     0.0500    0.0002
   100        0.1758             nan     0.0500    0.0001
   120        0.1617             nan     0.0500   -0.0004
   140        0.1507             nan     0.0500    0.0001
   160        0.1432             nan     0.0500   -0.0004
   180        0.1365             nan     0.0500   -0.0003
   200        0.1315             nan     0.0500   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1925
     2        0.9864             nan     0.0500    0.1588
     3        0.8928             nan     0.0500    0.1335
     4        0.8161             nan     0.0500    0.1133
     5        0.7492             nan     0.0500    0.0944
     6        0.6919             nan     0.0500    0.0846
     7        0.6402             nan     0.0500    0.0709
     8        0.5970             nan     0.0500    0.0642
     9        0.5568             nan     0.0500    0.0551
    10        0.5228             nan     0.0500    0.0485
    20        0.3226             nan     0.0500    0.0137
    40        0.1961             nan     0.0500    0.0047
    60        0.1564             nan     0.0500   -0.0004
    80        0.1346             nan     0.0500   -0.0003
   100        0.1188             nan     0.0500   -0.0001
   120        0.1064             nan     0.0500   -0.0006
   140        0.0976             nan     0.0500   -0.0004
   160        0.0899             nan     0.0500   -0.0005
   180        0.0832             nan     0.0500   -0.0007
   200        0.0774             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1978
     2        0.9821             nan     0.0500    0.1615
     3        0.8854             nan     0.0500    0.1372
     4        0.8030             nan     0.0500    0.1151
     5        0.7332             nan     0.0500    0.0998
     6        0.6722             nan     0.0500    0.0862
     7        0.6199             nan     0.0500    0.0759
     8        0.5738             nan     0.0500    0.0674
     9        0.5322             nan     0.0500    0.0553
    10        0.4966             nan     0.0500    0.0498
    20        0.2864             nan     0.0500    0.0142
    40        0.1658             nan     0.0500    0.0011
    60        0.1272             nan     0.0500   -0.0004
    80        0.1072             nan     0.0500   -0.0006
   100        0.0924             nan     0.0500   -0.0001
   120        0.0822             nan     0.0500   -0.0005
   140        0.0738             nan     0.0500   -0.0011
   160        0.0651             nan     0.0500   -0.0006
   180        0.0596             nan     0.0500   -0.0005
   200        0.0540             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2132
     2        0.9781             nan     0.0500    0.1735
     3        0.8752             nan     0.0500    0.1441
     4        0.7893             nan     0.0500    0.1187
     5        0.7171             nan     0.0500    0.1072
     6        0.6523             nan     0.0500    0.0902
     7        0.5980             nan     0.0500    0.0774
     8        0.5494             nan     0.0500    0.0681
     9        0.5070             nan     0.0500    0.0602
    10        0.4705             nan     0.0500    0.0521
    20        0.2607             nan     0.0500    0.0153
    40        0.1372             nan     0.0500    0.0011
    60        0.0999             nan     0.0500   -0.0011
    80        0.0774             nan     0.0500   -0.0013
   100        0.0634             nan     0.0500   -0.0011
   120        0.0536             nan     0.0500   -0.0005
   140        0.0459             nan     0.0500   -0.0003
   160        0.0392             nan     0.0500   -0.0009
   180        0.0340             nan     0.0500   -0.0009
   200        0.0305             nan     0.0500   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3300
     2        0.8947             nan     0.1000    0.2237
     3        0.7580             nan     0.1000    0.1586
     4        0.6573             nan     0.1000    0.1174
     5        0.5829             nan     0.1000    0.0861
     6        0.5269             nan     0.1000    0.0698
     7        0.4798             nan     0.1000    0.0577
     8        0.4436             nan     0.1000    0.0412
     9        0.4138             nan     0.1000    0.0378
    10        0.3891             nan     0.1000    0.0208
    20        0.2666             nan     0.1000    0.0042
    40        0.1957             nan     0.1000   -0.0002
    60        0.1644             nan     0.1000   -0.0006
    80        0.1444             nan     0.1000   -0.0017
   100        0.1307             nan     0.1000   -0.0009
   120        0.1208             nan     0.1000   -0.0013
   140        0.1154             nan     0.1000   -0.0015
   160        0.1095             nan     0.1000   -0.0011
   180        0.1049             nan     0.1000   -0.0011
   200        0.1000             nan     0.1000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3585
     2        0.8850             nan     0.1000    0.2398
     3        0.7370             nan     0.1000    0.1699
     4        0.6256             nan     0.1000    0.1275
     5        0.5443             nan     0.1000    0.0993
     6        0.4807             nan     0.1000    0.0798
     7        0.4292             nan     0.1000    0.0596
     8        0.3883             nan     0.1000    0.0490
     9        0.3562             nan     0.1000    0.0384
    10        0.3296             nan     0.1000    0.0327
    20        0.1998             nan     0.1000    0.0076
    40        0.1349             nan     0.1000    0.0004
    60        0.1063             nan     0.1000   -0.0009
    80        0.0880             nan     0.1000    0.0009
   100        0.0758             nan     0.1000   -0.0001
   120        0.0662             nan     0.1000   -0.0015
   140        0.0601             nan     0.1000   -0.0021
   160        0.0526             nan     0.1000   -0.0008
   180        0.0479             nan     0.1000   -0.0009
   200        0.0429             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3620
     2        0.8749             nan     0.1000    0.2459
     3        0.7194             nan     0.1000    0.1799
     4        0.6054             nan     0.1000    0.1334
     5        0.5201             nan     0.1000    0.0998
     6        0.4557             nan     0.1000    0.0827
     7        0.4026             nan     0.1000    0.0638
     8        0.3604             nan     0.1000    0.0445
     9        0.3266             nan     0.1000    0.0366
    10        0.2987             nan     0.1000    0.0407
    20        0.1650             nan     0.1000    0.0008
    40        0.1065             nan     0.1000   -0.0007
    60        0.0826             nan     0.1000   -0.0025
    80        0.0660             nan     0.1000   -0.0017
   100        0.0553             nan     0.1000   -0.0017
   120        0.0467             nan     0.1000   -0.0017
   140        0.0409             nan     0.1000   -0.0012
   160        0.0348             nan     0.1000   -0.0010
   180        0.0303             nan     0.1000   -0.0005
   200        0.0270             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3596
     2        0.8723             nan     0.1000    0.2549
     3        0.7153             nan     0.1000    0.1879
     4        0.5939             nan     0.1000    0.1433
     5        0.5011             nan     0.1000    0.1082
     6        0.4300             nan     0.1000    0.0794
     7        0.3757             nan     0.1000    0.0580
     8        0.3333             nan     0.1000    0.0521
     9        0.2974             nan     0.1000    0.0355
    10        0.2695             nan     0.1000    0.0332
    20        0.1407             nan     0.1000    0.0039
    40        0.0768             nan     0.1000   -0.0029
    60        0.0521             nan     0.1000   -0.0020
    80        0.0387             nan     0.1000   -0.0016
   100        0.0309             nan     0.1000   -0.0015
   120        0.0243             nan     0.1000   -0.0011
   140        0.0200             nan     0.1000   -0.0004
   160        0.0168             nan     0.1000   -0.0012
   180        0.0145             nan     0.1000   -0.0012
   200        0.0127             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5473
     2        0.7347             nan     0.2000    0.2371
     3        0.5589             nan     0.2000    0.1182
     4        0.4669             nan     0.2000    0.0944
     5        0.4007             nan     0.2000    0.0573
     6        0.3571             nan     0.2000    0.0370
     7        0.3216             nan     0.2000    0.0328
     8        0.2962             nan     0.2000    0.0085
     9        0.2808             nan     0.2000    0.0162
    10        0.2655             nan     0.2000    0.0194
    20        0.1899             nan     0.2000   -0.0024
    40        0.1468             nan     0.2000   -0.0043
    60        0.1244             nan     0.2000   -0.0004
    80        0.1071             nan     0.2000   -0.0051
   100        0.0976             nan     0.2000   -0.0026
   120        0.0893             nan     0.2000   -0.0034
   140        0.0830             nan     0.2000   -0.0060
   160        0.0762             nan     0.2000   -0.0053
   180        0.0722             nan     0.2000   -0.0011
   200        0.0684             nan     0.2000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5867
     2        0.7104             nan     0.2000    0.2581
     3        0.5269             nan     0.2000    0.1550
     4        0.4184             nan     0.2000    0.0983
     5        0.3416             nan     0.2000    0.0583
     6        0.2965             nan     0.2000    0.0450
     7        0.2621             nan     0.2000    0.0366
     8        0.2336             nan     0.2000    0.0157
     9        0.2165             nan     0.2000    0.0075
    10        0.2017             nan     0.2000    0.0075
    20        0.1382             nan     0.2000    0.0004
    40        0.0906             nan     0.2000   -0.0052
    60        0.0718             nan     0.2000   -0.0056
    80        0.0590             nan     0.2000   -0.0025
   100        0.0478             nan     0.2000   -0.0055
   120        0.0406             nan     0.2000   -0.0010
   140        0.0347             nan     0.2000   -0.0022
   160        0.0311             nan     0.2000   -0.0011
   180        0.0276             nan     0.2000   -0.0021
   200        0.0251             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6034
     2        0.6902             nan     0.2000    0.2835
     3        0.4993             nan     0.2000    0.1617
     4        0.3847             nan     0.2000    0.1021
     5        0.3128             nan     0.2000    0.0561
     6        0.2623             nan     0.2000    0.0402
     7        0.2264             nan     0.2000    0.0215
     8        0.2031             nan     0.2000    0.0107
     9        0.1844             nan     0.2000    0.0073
    10        0.1719             nan     0.2000    0.0027
    20        0.1126             nan     0.2000   -0.0164
    40        0.0683             nan     0.2000   -0.0043
    60        0.0488             nan     0.2000   -0.0023
    80        0.0361             nan     0.2000   -0.0016
   100        0.0278             nan     0.2000   -0.0002
   120        0.0231             nan     0.2000   -0.0023
   140        0.0185             nan     0.2000   -0.0028
   160        0.0153             nan     0.2000   -0.0029
   180        0.0130             nan     0.2000   -0.0027
   200        0.0115             nan     0.2000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6244
     2        0.6759             nan     0.2000    0.2715
     3        0.4713             nan     0.2000    0.1711
     4        0.3514             nan     0.2000    0.0890
     5        0.2837             nan     0.2000    0.0525
     6        0.2371             nan     0.2000    0.0331
     7        0.1984             nan     0.2000    0.0209
     8        0.1759             nan     0.2000    0.0114
     9        0.1596             nan     0.2000    0.0063
    10        0.1466             nan     0.2000   -0.0025
    20        0.0820             nan     0.2000    0.0018
    40        0.0426             nan     0.2000   -0.0074
    60        0.0267             nan     0.2000   -0.0029
    80        0.0181             nan     0.2000   -0.0024
   100        0.0140             nan     0.2000   -0.0017
   120        0.0111             nan     0.2000   -0.0007
   140        0.0082             nan     0.2000   -0.0004
   160        0.0069             nan     0.2000   -0.0016
   180        0.0060             nan     0.2000   -0.0005
   200        0.0053             nan     0.2000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1780
     2        0.9934             nan     0.0500    0.1484
     3        0.9063             nan     0.0500    0.1233
     4        0.8329             nan     0.0500    0.1053
     5        0.7705             nan     0.0500    0.0902
     6        0.7151             nan     0.0500    0.0755
     7        0.6675             nan     0.0500    0.0659
     8        0.6263             nan     0.0500    0.0573
     9        0.5915             nan     0.0500    0.0500
    10        0.5611             nan     0.0500    0.0454
    20        0.3779             nan     0.0500    0.0148
    40        0.2573             nan     0.0500    0.0042
    60        0.2105             nan     0.0500    0.0024
    80        0.1829             nan     0.0500    0.0003
   100        0.1652             nan     0.0500    0.0004
   120        0.1516             nan     0.0500   -0.0000
   140        0.1398             nan     0.0500   -0.0004
   160        0.1322             nan     0.0500   -0.0022
   180        0.1257             nan     0.0500   -0.0002
   200        0.1206             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1887
     2        0.9883             nan     0.0500    0.1590
     3        0.8954             nan     0.0500    0.1351
     4        0.8164             nan     0.0500    0.1144
     5        0.7472             nan     0.0500    0.0956
     6        0.6887             nan     0.0500    0.0853
     7        0.6380             nan     0.0500    0.0730
     8        0.5929             nan     0.0500    0.0649
     9        0.5544             nan     0.0500    0.0560
    10        0.5201             nan     0.0500    0.0491
    20        0.3151             nan     0.0500    0.0184
    40        0.1864             nan     0.0500    0.0028
    60        0.1452             nan     0.0500    0.0008
    80        0.1243             nan     0.0500   -0.0002
   100        0.1098             nan     0.0500   -0.0005
   120        0.0995             nan     0.0500    0.0001
   140        0.0905             nan     0.0500   -0.0009
   160        0.0833             nan     0.0500   -0.0008
   180        0.0771             nan     0.0500   -0.0006
   200        0.0711             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2033
     2        0.9803             nan     0.0500    0.1568
     3        0.8848             nan     0.0500    0.1392
     4        0.8017             nan     0.0500    0.1183
     5        0.7299             nan     0.0500    0.0973
     6        0.6692             nan     0.0500    0.0865
     7        0.6153             nan     0.0500    0.0757
     8        0.5674             nan     0.0500    0.0675
     9        0.5264             nan     0.0500    0.0573
    10        0.4894             nan     0.0500    0.0489
    20        0.2779             nan     0.0500    0.0170
    40        0.1529             nan     0.0500    0.0010
    60        0.1158             nan     0.0500   -0.0003
    80        0.0966             nan     0.0500   -0.0005
   100        0.0831             nan     0.0500   -0.0008
   120        0.0743             nan     0.0500   -0.0011
   140        0.0665             nan     0.0500   -0.0010
   160        0.0601             nan     0.0500   -0.0003
   180        0.0551             nan     0.0500   -0.0005
   200        0.0504             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2094
     2        0.9776             nan     0.0500    0.1759
     3        0.8743             nan     0.0500    0.1406
     4        0.7893             nan     0.0500    0.1253
     5        0.7139             nan     0.0500    0.1043
     6        0.6499             nan     0.0500    0.0938
     7        0.5938             nan     0.0500    0.0791
     8        0.5450             nan     0.0500    0.0681
     9        0.5025             nan     0.0500    0.0622
    10        0.4633             nan     0.0500    0.0540
    20        0.2489             nan     0.0500    0.0150
    40        0.1258             nan     0.0500    0.0000
    60        0.0917             nan     0.0500   -0.0002
    80        0.0702             nan     0.0500   -0.0018
   100        0.0593             nan     0.0500   -0.0007
   120        0.0496             nan     0.0500   -0.0010
   140        0.0419             nan     0.0500   -0.0011
   160        0.0364             nan     0.0500   -0.0013
   180        0.0317             nan     0.0500   -0.0007
   200        0.0279             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3271
     2        0.8980             nan     0.1000    0.2269
     3        0.7626             nan     0.1000    0.1565
     4        0.6623             nan     0.1000    0.1210
     5        0.5859             nan     0.1000    0.0904
     6        0.5268             nan     0.1000    0.0716
     7        0.4822             nan     0.1000    0.0496
     8        0.4466             nan     0.1000    0.0435
     9        0.4141             nan     0.1000    0.0400
    10        0.3874             nan     0.1000    0.0306
    20        0.2641             nan     0.1000    0.0120
    40        0.1845             nan     0.1000   -0.0002
    60        0.1555             nan     0.1000   -0.0002
    80        0.1382             nan     0.1000   -0.0026
   100        0.1251             nan     0.1000    0.0005
   120        0.1135             nan     0.1000   -0.0028
   140        0.1058             nan     0.1000   -0.0006
   160        0.1012             nan     0.1000   -0.0006
   180        0.0960             nan     0.1000   -0.0012
   200        0.0918             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3524
     2        0.8826             nan     0.1000    0.2401
     3        0.7333             nan     0.1000    0.1755
     4        0.6258             nan     0.1000    0.1308
     5        0.5416             nan     0.1000    0.1007
     6        0.4752             nan     0.1000    0.0801
     7        0.4227             nan     0.1000    0.0628
     8        0.3804             nan     0.1000    0.0419
     9        0.3477             nan     0.1000    0.0354
    10        0.3206             nan     0.1000    0.0284
    20        0.1873             nan     0.1000    0.0070
    40        0.1242             nan     0.1000   -0.0000
    60        0.0991             nan     0.1000   -0.0012
    80        0.0812             nan     0.1000   -0.0011
   100        0.0714             nan     0.1000   -0.0008
   120        0.0626             nan     0.1000   -0.0005
   140        0.0546             nan     0.1000   -0.0019
   160        0.0490             nan     0.1000   -0.0013
   180        0.0439             nan     0.1000   -0.0014
   200        0.0400             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3718
     2        0.8753             nan     0.1000    0.2531
     3        0.7181             nan     0.1000    0.1833
     4        0.6036             nan     0.1000    0.1327
     5        0.5169             nan     0.1000    0.0971
     6        0.4507             nan     0.1000    0.0881
     7        0.3919             nan     0.1000    0.0604
     8        0.3488             nan     0.1000    0.0467
     9        0.3152             nan     0.1000    0.0419
    10        0.2849             nan     0.1000    0.0327
    20        0.1562             nan     0.1000    0.0016
    40        0.0985             nan     0.1000   -0.0026
    60        0.0739             nan     0.1000   -0.0033
    80        0.0606             nan     0.1000   -0.0008
   100        0.0487             nan     0.1000   -0.0013
   120        0.0415             nan     0.1000   -0.0004
   140        0.0348             nan     0.1000   -0.0012
   160        0.0305             nan     0.1000   -0.0010
   180        0.0274             nan     0.1000   -0.0005
   200        0.0241             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3793
     2        0.8642             nan     0.1000    0.2536
     3        0.7016             nan     0.1000    0.1933
     4        0.5815             nan     0.1000    0.1471
     5        0.4892             nan     0.1000    0.1101
     6        0.4194             nan     0.1000    0.0806
     7        0.3645             nan     0.1000    0.0639
     8        0.3203             nan     0.1000    0.0546
     9        0.2833             nan     0.1000    0.0406
    10        0.2535             nan     0.1000    0.0317
    20        0.1279             nan     0.1000    0.0036
    40        0.0715             nan     0.1000   -0.0025
    60        0.0489             nan     0.1000   -0.0028
    80        0.0361             nan     0.1000   -0.0022
   100        0.0285             nan     0.1000   -0.0021
   120        0.0230             nan     0.1000   -0.0013
   140        0.0191             nan     0.1000   -0.0013
   160        0.0158             nan     0.1000   -0.0010
   180        0.0134             nan     0.1000   -0.0009
   200        0.0115             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5352
     2        0.7395             nan     0.2000    0.2627
     3        0.5617             nan     0.2000    0.1387
     4        0.4620             nan     0.2000    0.0873
     5        0.4017             nan     0.2000    0.0597
     6        0.3557             nan     0.2000    0.0391
     7        0.3181             nan     0.2000    0.0288
     8        0.2939             nan     0.2000    0.0296
     9        0.2705             nan     0.2000    0.0105
    10        0.2572             nan     0.2000    0.0194
    20        0.1780             nan     0.2000    0.0000
    40        0.1332             nan     0.2000   -0.0070
    60        0.1099             nan     0.2000   -0.0016
    80        0.0999             nan     0.2000   -0.0085
   100        0.0905             nan     0.2000   -0.0019
   120        0.0836             nan     0.2000   -0.0013
   140        0.0758             nan     0.2000   -0.0023
   160        0.0723             nan     0.2000   -0.0028
   180        0.0678             nan     0.2000   -0.0008
   200        0.0647             nan     0.2000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5746
     2        0.7088             nan     0.2000    0.2754
     3        0.5218             nan     0.2000    0.1595
     4        0.4103             nan     0.2000    0.1032
     5        0.3378             nan     0.2000    0.0604
     6        0.2886             nan     0.2000    0.0512
     7        0.2504             nan     0.2000    0.0174
     8        0.2270             nan     0.2000    0.0242
     9        0.2069             nan     0.2000    0.0122
    10        0.1933             nan     0.2000    0.0069
    20        0.1244             nan     0.2000    0.0003
    40        0.0879             nan     0.2000   -0.0048
    60        0.0668             nan     0.2000   -0.0018
    80        0.0555             nan     0.2000   -0.0030
   100        0.0443             nan     0.2000   -0.0041
   120        0.0383             nan     0.2000   -0.0045
   140        0.0335             nan     0.2000   -0.0007
   160        0.0281             nan     0.2000   -0.0048
   180        0.0249             nan     0.2000   -0.0034
   200        0.0217             nan     0.2000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6074
     2        0.6845             nan     0.2000    0.2813
     3        0.4898             nan     0.2000    0.1648
     4        0.3792             nan     0.2000    0.0993
     5        0.3072             nan     0.2000    0.0802
     6        0.2519             nan     0.2000    0.0429
     7        0.2135             nan     0.2000    0.0097
     8        0.1947             nan     0.2000    0.0173
     9        0.1761             nan     0.2000   -0.0166
    10        0.1699             nan     0.2000    0.0149
    20        0.1074             nan     0.2000   -0.0114
    40        0.0671             nan     0.2000   -0.0007
    60        0.0454             nan     0.2000   -0.0018
    80        0.0343             nan     0.2000   -0.0048
   100        0.0246             nan     0.2000   -0.0052
   120        0.0199             nan     0.2000   -0.0013
   140        0.0167             nan     0.2000   -0.0018
   160        0.0144             nan     0.2000   -0.0001
   180        0.0125             nan     0.2000   -0.0001
   200        0.0118             nan     0.2000   -0.0070

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6220
     2        0.6718             nan     0.2000    0.2939
     3        0.4657             nan     0.2000    0.1710
     4        0.3464             nan     0.2000    0.1022
     5        0.2713             nan     0.2000    0.0593
     6        0.2243             nan     0.2000    0.0307
     7        0.1934             nan     0.2000    0.0275
     8        0.1677             nan     0.2000    0.0109
     9        0.1490             nan     0.2000    0.0056
    10        0.1343             nan     0.2000    0.0006
    20        0.0748             nan     0.2000   -0.0078
    40        0.0385             nan     0.2000   -0.0073
    60        0.0234             nan     0.2000   -0.0057
    80        0.0165             nan     0.2000   -0.0028
   100        0.0114             nan     0.2000   -0.0023
   120        0.0085             nan     0.2000   -0.0025
   140        0.0073             nan     0.2000   -0.0043
   160        0.0060             nan     0.2000   -0.0003
   180        0.0050             nan     0.2000   -0.0004
   200        0.0044             nan     0.2000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1814
     2        0.9938             nan     0.0500    0.1517
     3        0.9091             nan     0.0500    0.1263
     4        0.8345             nan     0.0500    0.1069
     5        0.7732             nan     0.0500    0.0926
     6        0.7191             nan     0.0500    0.0797
     7        0.6725             nan     0.0500    0.0686
     8        0.6302             nan     0.0500    0.0582
     9        0.5921             nan     0.0500    0.0490
    10        0.5615             nan     0.0500    0.0450
    20        0.3792             nan     0.0500    0.0163
    40        0.2606             nan     0.0500    0.0038
    60        0.2130             nan     0.0500    0.0012
    80        0.1851             nan     0.0500    0.0016
   100        0.1662             nan     0.0500   -0.0011
   120        0.1527             nan     0.0500    0.0005
   140        0.1419             nan     0.0500   -0.0006
   160        0.1340             nan     0.0500   -0.0007
   180        0.1274             nan     0.0500   -0.0005
   200        0.1211             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1904
     2        0.9858             nan     0.0500    0.1609
     3        0.8897             nan     0.0500    0.1342
     4        0.8103             nan     0.0500    0.1140
     5        0.7420             nan     0.0500    0.0954
     6        0.6833             nan     0.0500    0.0827
     7        0.6324             nan     0.0500    0.0708
     8        0.5878             nan     0.0500    0.0625
     9        0.5484             nan     0.0500    0.0506
    10        0.5151             nan     0.0500    0.0468
    20        0.3159             nan     0.0500    0.0159
    40        0.1908             nan     0.0500    0.0027
    60        0.1497             nan     0.0500    0.0007
    80        0.1262             nan     0.0500    0.0005
   100        0.1101             nan     0.0500    0.0001
   120        0.0984             nan     0.0500   -0.0001
   140        0.0895             nan     0.0500   -0.0001
   160        0.0824             nan     0.0500   -0.0003
   180        0.0766             nan     0.0500   -0.0004
   200        0.0715             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1996
     2        0.9825             nan     0.0500    0.1668
     3        0.8846             nan     0.0500    0.1393
     4        0.8038             nan     0.0500    0.1196
     5        0.7323             nan     0.0500    0.1006
     6        0.6696             nan     0.0500    0.0860
     7        0.6174             nan     0.0500    0.0756
     8        0.5706             nan     0.0500    0.0668
     9        0.5303             nan     0.0500    0.0568
    10        0.4952             nan     0.0500    0.0508
    20        0.2844             nan     0.0500    0.0191
    40        0.1597             nan     0.0500    0.0014
    60        0.1194             nan     0.0500    0.0004
    80        0.0970             nan     0.0500   -0.0009
   100        0.0833             nan     0.0500   -0.0004
   120        0.0731             nan     0.0500   -0.0005
   140        0.0649             nan     0.0500   -0.0001
   160        0.0584             nan     0.0500   -0.0004
   180        0.0531             nan     0.0500   -0.0007
   200        0.0488             nan     0.0500   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2027
     2        0.9784             nan     0.0500    0.1750
     3        0.8760             nan     0.0500    0.1435
     4        0.7903             nan     0.0500    0.1251
     5        0.7183             nan     0.0500    0.1101
     6        0.6535             nan     0.0500    0.0893
     7        0.5996             nan     0.0500    0.0758
     8        0.5521             nan     0.0500    0.0675
     9        0.5093             nan     0.0500    0.0599
    10        0.4707             nan     0.0500    0.0522
    20        0.2561             nan     0.0500    0.0151
    40        0.1311             nan     0.0500    0.0016
    60        0.0906             nan     0.0500   -0.0004
    80        0.0702             nan     0.0500   -0.0004
   100        0.0574             nan     0.0500   -0.0004
   120        0.0484             nan     0.0500   -0.0007
   140        0.0406             nan     0.0500   -0.0007
   160        0.0349             nan     0.0500   -0.0004
   180        0.0302             nan     0.0500   -0.0008
   200        0.0259             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3323
     2        0.8970             nan     0.1000    0.2296
     3        0.7595             nan     0.1000    0.1611
     4        0.6595             nan     0.1000    0.1209
     5        0.5849             nan     0.1000    0.0946
     6        0.5243             nan     0.1000    0.0721
     7        0.4784             nan     0.1000    0.0561
     8        0.4424             nan     0.1000    0.0434
     9        0.4122             nan     0.1000    0.0362
    10        0.3857             nan     0.1000    0.0340
    20        0.2597             nan     0.1000    0.0060
    40        0.1818             nan     0.1000   -0.0002
    60        0.1510             nan     0.1000   -0.0027
    80        0.1346             nan     0.1000   -0.0007
   100        0.1226             nan     0.1000   -0.0016
   120        0.1126             nan     0.1000    0.0002
   140        0.1060             nan     0.1000   -0.0004
   160        0.1005             nan     0.1000   -0.0018
   180        0.0946             nan     0.1000   -0.0010
   200        0.0892             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3568
     2        0.8847             nan     0.1000    0.2396
     3        0.7368             nan     0.1000    0.1741
     4        0.6253             nan     0.1000    0.1330
     5        0.5399             nan     0.1000    0.1000
     6        0.4764             nan     0.1000    0.0733
     7        0.4278             nan     0.1000    0.0648
     8        0.3858             nan     0.1000    0.0520
     9        0.3515             nan     0.1000    0.0421
    10        0.3243             nan     0.1000    0.0347
    20        0.1903             nan     0.1000    0.0056
    40        0.1257             nan     0.1000    0.0006
    60        0.0960             nan     0.1000   -0.0015
    80        0.0810             nan     0.1000    0.0002
   100        0.0705             nan     0.1000   -0.0005
   120        0.0605             nan     0.1000   -0.0010
   140        0.0533             nan     0.1000   -0.0034
   160        0.0481             nan     0.1000   -0.0007
   180        0.0439             nan     0.1000   -0.0009
   200        0.0390             nan     0.1000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3663
     2        0.8762             nan     0.1000    0.2478
     3        0.7218             nan     0.1000    0.1791
     4        0.6066             nan     0.1000    0.1362
     5        0.5193             nan     0.1000    0.1009
     6        0.4505             nan     0.1000    0.0808
     7        0.3983             nan     0.1000    0.0654
     8        0.3568             nan     0.1000    0.0485
     9        0.3216             nan     0.1000    0.0378
    10        0.2928             nan     0.1000    0.0366
    20        0.1612             nan     0.1000    0.0032
    40        0.1000             nan     0.1000   -0.0032
    60        0.0748             nan     0.1000   -0.0013
    80        0.0590             nan     0.1000   -0.0005
   100        0.0473             nan     0.1000   -0.0007
   120        0.0396             nan     0.1000   -0.0009
   140        0.0332             nan     0.1000   -0.0013
   160        0.0288             nan     0.1000   -0.0008
   180        0.0242             nan     0.1000   -0.0005
   200        0.0210             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3796
     2        0.8651             nan     0.1000    0.2573
     3        0.7013             nan     0.1000    0.1843
     4        0.5842             nan     0.1000    0.1440
     5        0.4958             nan     0.1000    0.1004
     6        0.4282             nan     0.1000    0.0826
     7        0.3739             nan     0.1000    0.0677
     8        0.3290             nan     0.1000    0.0500
     9        0.2933             nan     0.1000    0.0356
    10        0.2655             nan     0.1000    0.0257
    20        0.1317             nan     0.1000    0.0007
    40        0.0733             nan     0.1000   -0.0017
    60        0.0477             nan     0.1000   -0.0017
    80        0.0342             nan     0.1000   -0.0024
   100        0.0258             nan     0.1000   -0.0012
   120        0.0192             nan     0.1000   -0.0008
   140        0.0149             nan     0.1000   -0.0007
   160        0.0121             nan     0.1000   -0.0005
   180        0.0095             nan     0.1000   -0.0005
   200        0.0075             nan     0.1000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5590
     2        0.7386             nan     0.2000    0.2576
     3        0.5625             nan     0.2000    0.1405
     4        0.4633             nan     0.2000    0.0845
     5        0.4010             nan     0.2000    0.0567
     6        0.3573             nan     0.2000    0.0321
     7        0.3300             nan     0.2000    0.0349
     8        0.3031             nan     0.2000    0.0347
     9        0.2803             nan     0.2000    0.0173
    10        0.2664             nan     0.2000    0.0182
    20        0.1838             nan     0.2000   -0.0006
    40        0.1329             nan     0.2000   -0.0059
    60        0.1124             nan     0.2000   -0.0041
    80        0.0991             nan     0.2000   -0.0019
   100        0.0910             nan     0.2000   -0.0029
   120        0.0834             nan     0.2000   -0.0075
   140        0.0770             nan     0.2000   -0.0024
   160        0.0703             nan     0.2000   -0.0022
   180        0.0652             nan     0.2000   -0.0041
   200        0.0624             nan     0.2000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5582
     2        0.7034             nan     0.2000    0.2724
     3        0.5177             nan     0.2000    0.1423
     4        0.4136             nan     0.2000    0.1009
     5        0.3413             nan     0.2000    0.0520
     6        0.2980             nan     0.2000    0.0385
     7        0.2635             nan     0.2000    0.0386
     8        0.2351             nan     0.2000    0.0296
     9        0.2122             nan     0.2000    0.0134
    10        0.1967             nan     0.2000    0.0085
    20        0.1307             nan     0.2000    0.0015
    40        0.0865             nan     0.2000   -0.0071
    60        0.0636             nan     0.2000   -0.0024
    80        0.0520             nan     0.2000   -0.0013
   100        0.0407             nan     0.2000   -0.0035
   120        0.0326             nan     0.2000   -0.0013
   140        0.0280             nan     0.2000   -0.0017
   160        0.0217             nan     0.2000   -0.0028
   180        0.0181             nan     0.2000   -0.0003
   200        0.0159             nan     0.2000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6137
     2        0.6851             nan     0.2000    0.2788
     3        0.4916             nan     0.2000    0.1573
     4        0.3786             nan     0.2000    0.0855
     5        0.3100             nan     0.2000    0.0671
     6        0.2599             nan     0.2000    0.0318
     7        0.2206             nan     0.2000    0.0301
     8        0.1947             nan     0.2000    0.0089
     9        0.1762             nan     0.2000    0.0103
    10        0.1615             nan     0.2000    0.0045
    20        0.1034             nan     0.2000   -0.0041
    40        0.0579             nan     0.2000   -0.0038
    60        0.0406             nan     0.2000   -0.0024
    80        0.0289             nan     0.2000   -0.0023
   100        0.0226             nan     0.2000   -0.0001
   120        0.0169             nan     0.2000   -0.0005
   140        0.0126             nan     0.2000   -0.0008
   160        0.0106             nan     0.2000   -0.0003
   180        0.0084             nan     0.2000   -0.0006
   200        0.0068             nan     0.2000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6327
     2        0.6699             nan     0.2000    0.2816
     3        0.4769             nan     0.2000    0.1587
     4        0.3622             nan     0.2000    0.1019
     5        0.2857             nan     0.2000    0.0705
     6        0.2348             nan     0.2000    0.0399
     7        0.1978             nan     0.2000    0.0273
     8        0.1686             nan     0.2000    0.0098
     9        0.1516             nan     0.2000    0.0050
    10        0.1380             nan     0.2000    0.0080
    20        0.0762             nan     0.2000   -0.0022
    40        0.0398             nan     0.2000   -0.0066
    60        0.0224             nan     0.2000   -0.0053
    80        0.0130             nan     0.2000   -0.0009
   100        0.0085             nan     0.2000   -0.0005
   120        0.0060             nan     0.2000   -0.0008
   140        0.0037             nan     0.2000   -0.0005
   160        0.0029             nan     0.2000   -0.0007
   180        0.0020             nan     0.2000   -0.0002
   200        0.0013             nan     0.2000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1798
     2        0.9916             nan     0.0500    0.1499
     3        0.9028             nan     0.0500    0.1245
     4        0.8282             nan     0.0500    0.1058
     5        0.7675             nan     0.0500    0.0918
     6        0.7143             nan     0.0500    0.0776
     7        0.6674             nan     0.0500    0.0644
     8        0.6279             nan     0.0500    0.0600
     9        0.5915             nan     0.0500    0.0510
    10        0.5589             nan     0.0500    0.0474
    20        0.3749             nan     0.0500    0.0159
    40        0.2551             nan     0.0500    0.0013
    60        0.2111             nan     0.0500    0.0009
    80        0.1863             nan     0.0500    0.0007
   100        0.1692             nan     0.0500    0.0006
   120        0.1561             nan     0.0500   -0.0005
   140        0.1457             nan     0.0500   -0.0007
   160        0.1379             nan     0.0500    0.0007
   180        0.1308             nan     0.0500   -0.0004
   200        0.1253             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1932
     2        0.9873             nan     0.0500    0.1595
     3        0.8947             nan     0.0500    0.1354
     4        0.8140             nan     0.0500    0.1122
     5        0.7469             nan     0.0500    0.0977
     6        0.6872             nan     0.0500    0.0837
     7        0.6371             nan     0.0500    0.0732
     8        0.5913             nan     0.0500    0.0644
     9        0.5520             nan     0.0500    0.0565
    10        0.5171             nan     0.0500    0.0491
    20        0.3132             nan     0.0500    0.0156
    40        0.1897             nan     0.0500    0.0043
    60        0.1483             nan     0.0500    0.0004
    80        0.1261             nan     0.0500   -0.0009
   100        0.1109             nan     0.0500   -0.0006
   120        0.0988             nan     0.0500   -0.0012
   140        0.0909             nan     0.0500   -0.0008
   160        0.0841             nan     0.0500   -0.0005
   180        0.0787             nan     0.0500   -0.0012
   200        0.0724             nan     0.0500   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2005
     2        0.9835             nan     0.0500    0.1666
     3        0.8852             nan     0.0500    0.1395
     4        0.8015             nan     0.0500    0.1199
     5        0.7304             nan     0.0500    0.1027
     6        0.6686             nan     0.0500    0.0884
     7        0.6157             nan     0.0500    0.0744
     8        0.5708             nan     0.0500    0.0630
     9        0.5312             nan     0.0500    0.0591
    10        0.4940             nan     0.0500    0.0518
    20        0.2845             nan     0.0500    0.0140
    40        0.1563             nan     0.0500    0.0020
    60        0.1181             nan     0.0500   -0.0003
    80        0.0976             nan     0.0500   -0.0012
   100        0.0836             nan     0.0500   -0.0011
   120        0.0722             nan     0.0500   -0.0014
   140        0.0648             nan     0.0500   -0.0006
   160        0.0591             nan     0.0500   -0.0008
   180        0.0531             nan     0.0500   -0.0004
   200        0.0476             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2042
     2        0.9781             nan     0.0500    0.1742
     3        0.8756             nan     0.0500    0.1458
     4        0.7898             nan     0.0500    0.1225
     5        0.7154             nan     0.0500    0.1035
     6        0.6519             nan     0.0500    0.0883
     7        0.5961             nan     0.0500    0.0746
     8        0.5482             nan     0.0500    0.0686
     9        0.5062             nan     0.0500    0.0561
    10        0.4694             nan     0.0500    0.0496
    20        0.2549             nan     0.0500    0.0168
    40        0.1289             nan     0.0500    0.0016
    60        0.0917             nan     0.0500   -0.0004
    80        0.0725             nan     0.0500   -0.0009
   100        0.0585             nan     0.0500   -0.0003
   120        0.0480             nan     0.0500   -0.0012
   140        0.0409             nan     0.0500   -0.0007
   160        0.0356             nan     0.0500    0.0002
   180        0.0303             nan     0.0500   -0.0006
   200        0.0263             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3331
     2        0.8979             nan     0.1000    0.2281
     3        0.7581             nan     0.1000    0.1656
     4        0.6598             nan     0.1000    0.1212
     5        0.5807             nan     0.1000    0.0938
     6        0.5223             nan     0.1000    0.0735
     7        0.4762             nan     0.1000    0.0533
     8        0.4373             nan     0.1000    0.0385
     9        0.4076             nan     0.1000    0.0412
    10        0.3820             nan     0.1000    0.0268
    20        0.2626             nan     0.1000    0.0078
    40        0.1873             nan     0.1000   -0.0013
    60        0.1584             nan     0.1000    0.0003
    80        0.1402             nan     0.1000    0.0004
   100        0.1267             nan     0.1000   -0.0019
   120        0.1176             nan     0.1000   -0.0028
   140        0.1102             nan     0.1000   -0.0012
   160        0.1050             nan     0.1000   -0.0008
   180        0.1007             nan     0.1000   -0.0009
   200        0.0964             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3563
     2        0.8849             nan     0.1000    0.2445
     3        0.7339             nan     0.1000    0.1714
     4        0.6243             nan     0.1000    0.1291
     5        0.5405             nan     0.1000    0.0937
     6        0.4779             nan     0.1000    0.0780
     7        0.4267             nan     0.1000    0.0636
     8        0.3857             nan     0.1000    0.0557
     9        0.3501             nan     0.1000    0.0387
    10        0.3236             nan     0.1000    0.0323
    20        0.1929             nan     0.1000    0.0032
    40        0.1296             nan     0.1000   -0.0042
    60        0.1035             nan     0.1000   -0.0009
    80        0.0856             nan     0.1000   -0.0027
   100        0.0733             nan     0.1000   -0.0007
   120        0.0654             nan     0.1000   -0.0016
   140        0.0596             nan     0.1000   -0.0015
   160        0.0528             nan     0.1000   -0.0017
   180        0.0485             nan     0.1000   -0.0015
   200        0.0441             nan     0.1000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3627
     2        0.8751             nan     0.1000    0.2557
     3        0.7169             nan     0.1000    0.1858
     4        0.6035             nan     0.1000    0.1314
     5        0.5166             nan     0.1000    0.1099
     6        0.4469             nan     0.1000    0.0800
     7        0.3952             nan     0.1000    0.0559
     8        0.3550             nan     0.1000    0.0491
     9        0.3202             nan     0.1000    0.0373
    10        0.2923             nan     0.1000    0.0333
    20        0.1596             nan     0.1000    0.0048
    40        0.1002             nan     0.1000   -0.0009
    60        0.0734             nan     0.1000   -0.0015
    80        0.0584             nan     0.1000   -0.0008
   100        0.0497             nan     0.1000   -0.0013
   120        0.0428             nan     0.1000   -0.0016
   140        0.0365             nan     0.1000   -0.0012
   160        0.0316             nan     0.1000   -0.0013
   180        0.0274             nan     0.1000   -0.0004
   200        0.0243             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3794
     2        0.8655             nan     0.1000    0.2494
     3        0.7087             nan     0.1000    0.1881
     4        0.5877             nan     0.1000    0.1473
     5        0.4925             nan     0.1000    0.1055
     6        0.4213             nan     0.1000    0.0775
     7        0.3683             nan     0.1000    0.0635
     8        0.3255             nan     0.1000    0.0491
     9        0.2909             nan     0.1000    0.0367
    10        0.2605             nan     0.1000    0.0297
    20        0.1301             nan     0.1000    0.0037
    40        0.0728             nan     0.1000   -0.0024
    60        0.0512             nan     0.1000   -0.0021
    80        0.0368             nan     0.1000   -0.0012
   100        0.0284             nan     0.1000   -0.0014
   120        0.0226             nan     0.1000   -0.0014
   140        0.0181             nan     0.1000   -0.0023
   160        0.0151             nan     0.1000   -0.0004
   180        0.0127             nan     0.1000   -0.0010
   200        0.0113             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5520
     2        0.7322             nan     0.2000    0.2541
     3        0.5561             nan     0.2000    0.1421
     4        0.4516             nan     0.2000    0.0795
     5        0.3924             nan     0.2000    0.0457
     6        0.3487             nan     0.2000    0.0462
     7        0.3151             nan     0.2000    0.0145
     8        0.2951             nan     0.2000    0.0238
     9        0.2755             nan     0.2000    0.0234
    10        0.2569             nan     0.2000    0.0138
    20        0.1808             nan     0.2000   -0.0004
    40        0.1324             nan     0.2000   -0.0013
    60        0.1096             nan     0.2000   -0.0025
    80        0.0975             nan     0.2000   -0.0063
   100        0.0897             nan     0.2000   -0.0004
   120        0.0842             nan     0.2000   -0.0055
   140        0.0802             nan     0.2000   -0.0013
   160        0.0752             nan     0.2000   -0.0043
   180        0.0703             nan     0.2000   -0.0013
   200        0.0652             nan     0.2000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5863
     2        0.6993             nan     0.2000    0.2669
     3        0.5116             nan     0.2000    0.1592
     4        0.4015             nan     0.2000    0.0946
     5        0.3333             nan     0.2000    0.0573
     6        0.2898             nan     0.2000    0.0357
     7        0.2557             nan     0.2000    0.0364
     8        0.2263             nan     0.2000    0.0123
     9        0.2049             nan     0.2000    0.0129
    10        0.1923             nan     0.2000    0.0089
    20        0.1303             nan     0.2000   -0.0034
    40        0.0852             nan     0.2000   -0.0043
    60        0.0644             nan     0.2000   -0.0027
    80        0.0509             nan     0.2000   -0.0018
   100        0.0427             nan     0.2000   -0.0039
   120        0.0357             nan     0.2000   -0.0048
   140        0.0305             nan     0.2000   -0.0030
   160        0.0259             nan     0.2000   -0.0023
   180        0.0222             nan     0.2000   -0.0011
   200        0.0194             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6084
     2        0.6867             nan     0.2000    0.2836
     3        0.4907             nan     0.2000    0.1630
     4        0.3798             nan     0.2000    0.0972
     5        0.3073             nan     0.2000    0.0572
     6        0.2571             nan     0.2000    0.0333
     7        0.2224             nan     0.2000    0.0365
     8        0.1961             nan     0.2000    0.0179
     9        0.1774             nan     0.2000   -0.0055
    10        0.1656             nan     0.2000    0.0115
    20        0.1059             nan     0.2000   -0.0063
    40        0.0645             nan     0.2000   -0.0053
    60        0.0437             nan     0.2000   -0.0050
    80        0.0339             nan     0.2000   -0.0019
   100        0.0264             nan     0.2000   -0.0041
   120        0.0211             nan     0.2000   -0.0007
   140        0.0174             nan     0.2000   -0.0027
   160        0.0150             nan     0.2000   -0.0024
   180        0.0129             nan     0.2000   -0.0011
   200        0.0113             nan     0.2000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6368
     2        0.6638             nan     0.2000    0.2948
     3        0.4664             nan     0.2000    0.1563
     4        0.3486             nan     0.2000    0.0964
     5        0.2748             nan     0.2000    0.0610
     6        0.2254             nan     0.2000    0.0291
     7        0.1935             nan     0.2000    0.0158
     8        0.1723             nan     0.2000    0.0237
     9        0.1488             nan     0.2000    0.0070
    10        0.1361             nan     0.2000    0.0098
    20        0.0745             nan     0.2000   -0.0059
    40        0.0379             nan     0.2000   -0.0037
    60        0.0228             nan     0.2000   -0.0023
    80        0.0149             nan     0.2000   -0.0014
   100        0.0114             nan     0.2000   -0.0021
   120        0.0094             nan     0.2000   -0.0015
   140        0.0079             nan     0.2000   -0.0005
   160        0.0064             nan     0.2000   -0.0007
   180        0.0052             nan     0.2000   -0.0025
   200        0.0046             nan     0.2000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1783
     2        0.9938             nan     0.0500    0.1465
     3        0.9077             nan     0.0500    0.1228
     4        0.8342             nan     0.0500    0.1046
     5        0.7712             nan     0.0500    0.0875
     6        0.7154             nan     0.0500    0.0760
     7        0.6688             nan     0.0500    0.0626
     8        0.6303             nan     0.0500    0.0572
     9        0.5943             nan     0.0500    0.0501
    10        0.5634             nan     0.0500    0.0438
    20        0.3843             nan     0.0500    0.0099
    40        0.2667             nan     0.0500    0.0057
    60        0.2202             nan     0.0500    0.0016
    80        0.1918             nan     0.0500    0.0004
   100        0.1728             nan     0.0500   -0.0001
   120        0.1589             nan     0.0500   -0.0003
   140        0.1492             nan     0.0500   -0.0005
   160        0.1420             nan     0.0500   -0.0003
   180        0.1340             nan     0.0500   -0.0001
   200        0.1283             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1878
     2        0.9860             nan     0.0500    0.1593
     3        0.8911             nan     0.0500    0.1323
     4        0.8140             nan     0.0500    0.1114
     5        0.7475             nan     0.0500    0.0962
     6        0.6890             nan     0.0500    0.0821
     7        0.6400             nan     0.0500    0.0712
     8        0.5957             nan     0.0500    0.0621
     9        0.5562             nan     0.0500    0.0545
    10        0.5217             nan     0.0500    0.0477
    20        0.3217             nan     0.0500    0.0202
    40        0.1964             nan     0.0500    0.0035
    60        0.1537             nan     0.0500    0.0010
    80        0.1319             nan     0.0500   -0.0009
   100        0.1162             nan     0.0500    0.0005
   120        0.1043             nan     0.0500   -0.0017
   140        0.0951             nan     0.0500   -0.0012
   160        0.0870             nan     0.0500   -0.0004
   180        0.0803             nan     0.0500    0.0000
   200        0.0751             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1947
     2        0.9846             nan     0.0500    0.1604
     3        0.8877             nan     0.0500    0.1398
     4        0.8042             nan     0.0500    0.1170
     5        0.7341             nan     0.0500    0.0985
     6        0.6724             nan     0.0500    0.0832
     7        0.6212             nan     0.0500    0.0735
     8        0.5758             nan     0.0500    0.0644
     9        0.5358             nan     0.0500    0.0585
    10        0.4995             nan     0.0500    0.0503
    20        0.2869             nan     0.0500    0.0138
    40        0.1623             nan     0.0500    0.0019
    60        0.1238             nan     0.0500   -0.0002
    80        0.1010             nan     0.0500    0.0000
   100        0.0847             nan     0.0500   -0.0004
   120        0.0729             nan     0.0500   -0.0006
   140        0.0639             nan     0.0500   -0.0008
   160        0.0581             nan     0.0500   -0.0002
   180        0.0525             nan     0.0500   -0.0008
   200        0.0475             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2094
     2        0.9766             nan     0.0500    0.1647
     3        0.8771             nan     0.0500    0.1452
     4        0.7911             nan     0.0500    0.1232
     5        0.7176             nan     0.0500    0.1040
     6        0.6546             nan     0.0500    0.0901
     7        0.5997             nan     0.0500    0.0740
     8        0.5519             nan     0.0500    0.0648
     9        0.5106             nan     0.0500    0.0595
    10        0.4724             nan     0.0500    0.0535
    20        0.2588             nan     0.0500    0.0156
    40        0.1333             nan     0.0500    0.0015
    60        0.0958             nan     0.0500   -0.0006
    80        0.0730             nan     0.0500   -0.0006
   100        0.0586             nan     0.0500   -0.0015
   120        0.0497             nan     0.0500   -0.0005
   140        0.0421             nan     0.0500   -0.0002
   160        0.0367             nan     0.0500   -0.0004
   180        0.0314             nan     0.0500   -0.0008
   200        0.0273             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3253
     2        0.9009             nan     0.1000    0.2253
     3        0.7655             nan     0.1000    0.1613
     4        0.6644             nan     0.1000    0.1170
     5        0.5924             nan     0.1000    0.0900
     6        0.5335             nan     0.1000    0.0702
     7        0.4879             nan     0.1000    0.0543
     8        0.4513             nan     0.1000    0.0446
     9        0.4211             nan     0.1000    0.0396
    10        0.3947             nan     0.1000    0.0277
    20        0.2675             nan     0.1000    0.0047
    40        0.1909             nan     0.1000   -0.0007
    60        0.1616             nan     0.1000    0.0012
    80        0.1440             nan     0.1000   -0.0004
   100        0.1290             nan     0.1000   -0.0013
   120        0.1210             nan     0.1000   -0.0002
   140        0.1124             nan     0.1000   -0.0014
   160        0.1056             nan     0.1000   -0.0006
   180        0.0998             nan     0.1000   -0.0007
   200        0.0961             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3513
     2        0.8867             nan     0.1000    0.2324
     3        0.7373             nan     0.1000    0.1704
     4        0.6286             nan     0.1000    0.1292
     5        0.5458             nan     0.1000    0.0942
     6        0.4832             nan     0.1000    0.0749
     7        0.4333             nan     0.1000    0.0643
     8        0.3902             nan     0.1000    0.0452
     9        0.3577             nan     0.1000    0.0400
    10        0.3298             nan     0.1000    0.0375
    20        0.2001             nan     0.1000    0.0057
    40        0.1299             nan     0.1000   -0.0010
    60        0.1021             nan     0.1000   -0.0028
    80        0.0856             nan     0.1000   -0.0014
   100        0.0747             nan     0.1000   -0.0013
   120        0.0667             nan     0.1000   -0.0023
   140        0.0581             nan     0.1000   -0.0024
   160        0.0516             nan     0.1000   -0.0006
   180        0.0462             nan     0.1000   -0.0014
   200        0.0413             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3610
     2        0.8754             nan     0.1000    0.2480
     3        0.7210             nan     0.1000    0.1761
     4        0.6073             nan     0.1000    0.1309
     5        0.5199             nan     0.1000    0.0932
     6        0.4562             nan     0.1000    0.0688
     7        0.4066             nan     0.1000    0.0575
     8        0.3664             nan     0.1000    0.0594
     9        0.3278             nan     0.1000    0.0348
    10        0.2988             nan     0.1000    0.0343
    20        0.1628             nan     0.1000    0.0039
    40        0.1010             nan     0.1000   -0.0033
    60        0.0756             nan     0.1000   -0.0006
    80        0.0625             nan     0.1000   -0.0023
   100        0.0514             nan     0.1000   -0.0029
   120        0.0438             nan     0.1000   -0.0019
   140        0.0358             nan     0.1000   -0.0008
   160        0.0312             nan     0.1000   -0.0025
   180        0.0274             nan     0.1000   -0.0004
   200        0.0243             nan     0.1000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3826
     2        0.8662             nan     0.1000    0.2508
     3        0.7060             nan     0.1000    0.1847
     4        0.5875             nan     0.1000    0.1292
     5        0.5001             nan     0.1000    0.1039
     6        0.4315             nan     0.1000    0.0775
     7        0.3773             nan     0.1000    0.0598
     8        0.3342             nan     0.1000    0.0493
     9        0.2987             nan     0.1000    0.0367
    10        0.2715             nan     0.1000    0.0336
    20        0.1345             nan     0.1000    0.0012
    40        0.0719             nan     0.1000   -0.0025
    60        0.0507             nan     0.1000   -0.0018
    80        0.0359             nan     0.1000   -0.0009
   100        0.0274             nan     0.1000   -0.0008
   120        0.0214             nan     0.1000   -0.0012
   140        0.0172             nan     0.1000   -0.0010
   160        0.0139             nan     0.1000   -0.0009
   180        0.0116             nan     0.1000   -0.0004
   200        0.0093             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5402
     2        0.7350             nan     0.2000    0.2381
     3        0.5664             nan     0.2000    0.1480
     4        0.4701             nan     0.2000    0.0844
     5        0.4096             nan     0.2000    0.0450
     6        0.3649             nan     0.2000    0.0529
     7        0.3266             nan     0.2000    0.0190
     8        0.3047             nan     0.2000    0.0172
     9        0.2851             nan     0.2000    0.0247
    10        0.2665             nan     0.2000    0.0154
    20        0.1926             nan     0.2000    0.0031
    40        0.1406             nan     0.2000   -0.0000
    60        0.1144             nan     0.2000   -0.0016
    80        0.1010             nan     0.2000   -0.0049
   100        0.0920             nan     0.2000   -0.0034
   120        0.0837             nan     0.2000   -0.0009
   140        0.0788             nan     0.2000   -0.0001
   160        0.0725             nan     0.2000   -0.0035
   180        0.0676             nan     0.2000   -0.0014
   200        0.0629             nan     0.2000   -0.0029

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5612
     2        0.6989             nan     0.2000    0.2521
     3        0.5158             nan     0.2000    0.1415
     4        0.4116             nan     0.2000    0.0790
     5        0.3457             nan     0.2000    0.0661
     6        0.2950             nan     0.2000    0.0402
     7        0.2607             nan     0.2000    0.0181
     8        0.2394             nan     0.2000    0.0256
     9        0.2166             nan     0.2000    0.0088
    10        0.2023             nan     0.2000   -0.0008
    20        0.1313             nan     0.2000   -0.0084
    40        0.0879             nan     0.2000   -0.0017
    60        0.0628             nan     0.2000   -0.0031
    80        0.0501             nan     0.2000   -0.0048
   100        0.0419             nan     0.2000   -0.0029
   120        0.0361             nan     0.2000   -0.0013
   140        0.0297             nan     0.2000   -0.0006
   160        0.0253             nan     0.2000   -0.0026
   180        0.0218             nan     0.2000   -0.0036
   200        0.0195             nan     0.2000   -0.0026

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6041
     2        0.6914             nan     0.2000    0.2822
     3        0.4970             nan     0.2000    0.1545
     4        0.3845             nan     0.2000    0.1017
     5        0.3132             nan     0.2000    0.0568
     6        0.2648             nan     0.2000    0.0345
     7        0.2329             nan     0.2000    0.0194
     8        0.2102             nan     0.2000    0.0099
     9        0.1905             nan     0.2000    0.0205
    10        0.1711             nan     0.2000    0.0105
    20        0.1068             nan     0.2000   -0.0031
    40        0.0616             nan     0.2000   -0.0025
    60        0.0437             nan     0.2000   -0.0029
    80        0.0322             nan     0.2000   -0.0048
   100        0.0243             nan     0.2000   -0.0015
   120        0.0188             nan     0.2000   -0.0016
   140        0.0162             nan     0.2000   -0.0008
   160        0.0130             nan     0.2000   -0.0014
   180        0.0113             nan     0.2000   -0.0015
   200        0.0098             nan     0.2000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6223
     2        0.6693             nan     0.2000    0.2826
     3        0.4696             nan     0.2000    0.1563
     4        0.3562             nan     0.2000    0.0856
     5        0.2866             nan     0.2000    0.0533
     6        0.2376             nan     0.2000    0.0421
     7        0.2013             nan     0.2000    0.0225
     8        0.1777             nan     0.2000    0.0197
     9        0.1555             nan     0.2000    0.0037
    10        0.1439             nan     0.2000    0.0048
    20        0.0817             nan     0.2000   -0.0046
    40        0.0397             nan     0.2000   -0.0081
    60        0.0225             nan     0.2000   -0.0016
    80        0.0158             nan     0.2000   -0.0007
   100        0.0113             nan     0.2000   -0.0013
   120        0.0078             nan     0.2000   -0.0012
   140        0.0057             nan     0.2000   -0.0007
   160        0.0046             nan     0.2000   -0.0017
   180        0.0037             nan     0.2000   -0.0027
   200        0.0030             nan     0.2000   -0.0029

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1811
     2        0.9931             nan     0.0500    0.1505
     3        0.9064             nan     0.0500    0.1260
     4        0.8300             nan     0.0500    0.1071
     5        0.7675             nan     0.0500    0.0917
     6        0.7121             nan     0.0500    0.0794
     7        0.6643             nan     0.0500    0.0666
     8        0.6237             nan     0.0500    0.0598
     9        0.5867             nan     0.0500    0.0498
    10        0.5537             nan     0.0500    0.0458
    20        0.3726             nan     0.0500    0.0155
    40        0.2546             nan     0.0500    0.0061
    60        0.2072             nan     0.0500    0.0005
    80        0.1808             nan     0.0500    0.0003
   100        0.1622             nan     0.0500   -0.0002
   120        0.1497             nan     0.0500   -0.0004
   140        0.1407             nan     0.0500   -0.0009
   160        0.1336             nan     0.0500   -0.0015
   180        0.1266             nan     0.0500   -0.0003
   200        0.1214             nan     0.0500   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1955
     2        0.9853             nan     0.0500    0.1623
     3        0.8907             nan     0.0500    0.1332
     4        0.8107             nan     0.0500    0.1132
     5        0.7434             nan     0.0500    0.0968
     6        0.6835             nan     0.0500    0.0849
     7        0.6326             nan     0.0500    0.0760
     8        0.5867             nan     0.0500    0.0611
     9        0.5473             nan     0.0500    0.0564
    10        0.5127             nan     0.0500    0.0503
    20        0.3123             nan     0.0500    0.0153
    40        0.1873             nan     0.0500    0.0014
    60        0.1494             nan     0.0500   -0.0026
    80        0.1283             nan     0.0500    0.0002
   100        0.1122             nan     0.0500   -0.0004
   120        0.1016             nan     0.0500   -0.0015
   140        0.0929             nan     0.0500   -0.0002
   160        0.0857             nan     0.0500    0.0004
   180        0.0786             nan     0.0500   -0.0003
   200        0.0724             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1972
     2        0.9812             nan     0.0500    0.1680
     3        0.8809             nan     0.0500    0.1412
     4        0.7979             nan     0.0500    0.1182
     5        0.7286             nan     0.0500    0.0995
     6        0.6682             nan     0.0500    0.0861
     7        0.6149             nan     0.0500    0.0749
     8        0.5685             nan     0.0500    0.0646
     9        0.5277             nan     0.0500    0.0592
    10        0.4907             nan     0.0500    0.0502
    20        0.2803             nan     0.0500    0.0145
    40        0.1578             nan     0.0500    0.0001
    60        0.1204             nan     0.0500   -0.0006
    80        0.0997             nan     0.0500   -0.0013
   100        0.0869             nan     0.0500   -0.0009
   120        0.0764             nan     0.0500   -0.0005
   140        0.0685             nan     0.0500   -0.0005
   160        0.0619             nan     0.0500   -0.0004
   180        0.0568             nan     0.0500   -0.0006
   200        0.0516             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2098
     2        0.9762             nan     0.0500    0.1712
     3        0.8745             nan     0.0500    0.1448
     4        0.7882             nan     0.0500    0.1257
     5        0.7139             nan     0.0500    0.1035
     6        0.6498             nan     0.0500    0.0895
     7        0.5944             nan     0.0500    0.0777
     8        0.5454             nan     0.0500    0.0661
     9        0.5034             nan     0.0500    0.0592
    10        0.4660             nan     0.0500    0.0520
    20        0.2524             nan     0.0500    0.0182
    40        0.1311             nan     0.0500    0.0027
    60        0.0910             nan     0.0500   -0.0012
    80        0.0710             nan     0.0500   -0.0012
   100        0.0579             nan     0.0500   -0.0011
   120        0.0486             nan     0.0500   -0.0015
   140        0.0414             nan     0.0500   -0.0009
   160        0.0362             nan     0.0500   -0.0010
   180        0.0320             nan     0.0500   -0.0005
   200        0.0283             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3316
     2        0.8909             nan     0.1000    0.2230
     3        0.7496             nan     0.1000    0.1600
     4        0.6474             nan     0.1000    0.1181
     5        0.5704             nan     0.1000    0.0910
     6        0.5123             nan     0.1000    0.0683
     7        0.4668             nan     0.1000    0.0477
     8        0.4319             nan     0.1000    0.0425
     9        0.4009             nan     0.1000    0.0283
    10        0.3773             nan     0.1000    0.0262
    20        0.2531             nan     0.1000    0.0055
    40        0.1810             nan     0.1000    0.0016
    60        0.1499             nan     0.1000   -0.0021
    80        0.1323             nan     0.1000   -0.0027
   100        0.1221             nan     0.1000   -0.0017
   120        0.1151             nan     0.1000   -0.0018
   140        0.1079             nan     0.1000   -0.0016
   160        0.1030             nan     0.1000   -0.0019
   180        0.0977             nan     0.1000   -0.0020
   200        0.0935             nan     0.1000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3580
     2        0.8804             nan     0.1000    0.2465
     3        0.7308             nan     0.1000    0.1768
     4        0.6185             nan     0.1000    0.1308
     5        0.5344             nan     0.1000    0.0950
     6        0.4692             nan     0.1000    0.0715
     7        0.4202             nan     0.1000    0.0564
     8        0.3805             nan     0.1000    0.0515
     9        0.3443             nan     0.1000    0.0357
    10        0.3161             nan     0.1000    0.0354
    20        0.1878             nan     0.1000    0.0042
    40        0.1269             nan     0.1000   -0.0003
    60        0.1002             nan     0.1000   -0.0027
    80        0.0854             nan     0.1000   -0.0041
   100        0.0746             nan     0.1000   -0.0006
   120        0.0657             nan     0.1000   -0.0019
   140        0.0573             nan     0.1000   -0.0012
   160        0.0524             nan     0.1000   -0.0015
   180        0.0470             nan     0.1000   -0.0007
   200        0.0439             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3720
     2        0.8726             nan     0.1000    0.2525
     3        0.7147             nan     0.1000    0.1822
     4        0.6008             nan     0.1000    0.1384
     5        0.5145             nan     0.1000    0.1060
     6        0.4458             nan     0.1000    0.0761
     7        0.3935             nan     0.1000    0.0599
     8        0.3508             nan     0.1000    0.0475
     9        0.3172             nan     0.1000    0.0467
    10        0.2858             nan     0.1000    0.0302
    20        0.1555             nan     0.1000    0.0057
    40        0.0995             nan     0.1000   -0.0017
    60        0.0770             nan     0.1000   -0.0015
    80        0.0620             nan     0.1000   -0.0021
   100        0.0516             nan     0.1000   -0.0011
   120        0.0430             nan     0.1000   -0.0016
   140        0.0370             nan     0.1000   -0.0011
   160        0.0322             nan     0.1000   -0.0009
   180        0.0281             nan     0.1000   -0.0015
   200        0.0251             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3877
     2        0.8602             nan     0.1000    0.2585
     3        0.6993             nan     0.1000    0.1814
     4        0.5846             nan     0.1000    0.1323
     5        0.4986             nan     0.1000    0.1105
     6        0.4240             nan     0.1000    0.0807
     7        0.3693             nan     0.1000    0.0599
     8        0.3275             nan     0.1000    0.0492
     9        0.2905             nan     0.1000    0.0391
    10        0.2616             nan     0.1000    0.0339
    20        0.1346             nan     0.1000    0.0030
    40        0.0739             nan     0.1000   -0.0009
    60        0.0516             nan     0.1000   -0.0020
    80        0.0404             nan     0.1000   -0.0032
   100        0.0312             nan     0.1000   -0.0015
   120        0.0241             nan     0.1000   -0.0009
   140        0.0200             nan     0.1000   -0.0015
   160        0.0167             nan     0.1000   -0.0008
   180        0.0146             nan     0.1000   -0.0007
   200        0.0125             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5486
     2        0.7288             nan     0.2000    0.2515
     3        0.5536             nan     0.2000    0.1378
     4        0.4515             nan     0.2000    0.0849
     5        0.3896             nan     0.2000    0.0630
     6        0.3457             nan     0.2000    0.0424
     7        0.3152             nan     0.2000    0.0299
     8        0.2898             nan     0.2000    0.0217
     9        0.2709             nan     0.2000    0.0169
    10        0.2569             nan     0.2000    0.0067
    20        0.1826             nan     0.2000    0.0036
    40        0.1373             nan     0.2000   -0.0003
    60        0.1156             nan     0.2000    0.0014
    80        0.0993             nan     0.2000   -0.0039
   100        0.0916             nan     0.2000   -0.0032
   120        0.0842             nan     0.2000   -0.0041
   140        0.0785             nan     0.2000   -0.0017
   160        0.0734             nan     0.2000   -0.0064
   180        0.0694             nan     0.2000   -0.0007
   200        0.0655             nan     0.2000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5841
     2        0.7006             nan     0.2000    0.2768
     3        0.5096             nan     0.2000    0.1460
     4        0.4048             nan     0.2000    0.0992
     5        0.3345             nan     0.2000    0.0415
     6        0.2895             nan     0.2000    0.0313
     7        0.2582             nan     0.2000    0.0349
     8        0.2298             nan     0.2000    0.0276
     9        0.2075             nan     0.2000    0.0093
    10        0.1917             nan     0.2000    0.0145
    20        0.1301             nan     0.2000   -0.0049
    40        0.0901             nan     0.2000   -0.0018
    60        0.0660             nan     0.2000   -0.0030
    80        0.0537             nan     0.2000   -0.0021
   100        0.0441             nan     0.2000   -0.0010
   120        0.0361             nan     0.2000   -0.0057
   140        0.0327             nan     0.2000   -0.0017
   160        0.0281             nan     0.2000   -0.0011
   180        0.0246             nan     0.2000   -0.0012
   200        0.0222             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6052
     2        0.6784             nan     0.2000    0.2744
     3        0.4895             nan     0.2000    0.1620
     4        0.3753             nan     0.2000    0.0811
     5        0.3067             nan     0.2000    0.0551
     6        0.2596             nan     0.2000    0.0420
     7        0.2242             nan     0.2000    0.0198
     8        0.2006             nan     0.2000    0.0108
     9        0.1826             nan     0.2000    0.0070
    10        0.1689             nan     0.2000    0.0095
    20        0.1031             nan     0.2000   -0.0049
    40        0.0623             nan     0.2000   -0.0036
    60        0.0426             nan     0.2000   -0.0029
    80        0.0325             nan     0.2000   -0.0037
   100        0.0261             nan     0.2000   -0.0037
   120        0.0217             nan     0.2000   -0.0024
   140        0.0188             nan     0.2000   -0.0004
   160        0.0157             nan     0.2000   -0.0035
   180        0.0139             nan     0.2000   -0.0027
   200        0.0129             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6531
     2        0.6692             nan     0.2000    0.2950
     3        0.4661             nan     0.2000    0.1616
     4        0.3538             nan     0.2000    0.1080
     5        0.2799             nan     0.2000    0.0458
     6        0.2358             nan     0.2000    0.0476
     7        0.1971             nan     0.2000    0.0234
     8        0.1731             nan     0.2000    0.0164
     9        0.1553             nan     0.2000    0.0098
    10        0.1396             nan     0.2000   -0.0097
    20        0.0822             nan     0.2000   -0.0105
    40        0.0410             nan     0.2000   -0.0039
    60        0.0261             nan     0.2000   -0.0018
    80        0.0179             nan     0.2000   -0.0040
   100        0.0131             nan     0.2000   -0.0050
   120        0.0100             nan     0.2000   -0.0020
   140        0.0084             nan     0.2000   -0.0013
   160        0.0068             nan     0.2000   -0.0016
   180        0.0066             nan     0.2000   -0.0014
   200        0.0054             nan     0.2000   -0.0022

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1778
     2        0.9948             nan     0.0500    0.1464
     3        0.9055             nan     0.0500    0.1231
     4        0.8344             nan     0.0500    0.1023
     5        0.7712             nan     0.0500    0.0911
     6        0.7176             nan     0.0500    0.0757
     7        0.6715             nan     0.0500    0.0664
     8        0.6299             nan     0.0500    0.0573
     9        0.5928             nan     0.0500    0.0499
    10        0.5618             nan     0.0500    0.0448
    20        0.3857             nan     0.0500    0.0166
    40        0.2677             nan     0.0500    0.0018
    60        0.2176             nan     0.0500    0.0013
    80        0.1917             nan     0.0500    0.0004
   100        0.1743             nan     0.0500    0.0000
   120        0.1617             nan     0.0500   -0.0003
   140        0.1519             nan     0.0500    0.0002
   160        0.1430             nan     0.0500   -0.0013
   180        0.1358             nan     0.0500   -0.0003
   200        0.1305             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1900
     2        0.9863             nan     0.0500    0.1560
     3        0.8917             nan     0.0500    0.1339
     4        0.8137             nan     0.0500    0.1123
     5        0.7456             nan     0.0500    0.0963
     6        0.6867             nan     0.0500    0.0815
     7        0.6364             nan     0.0500    0.0685
     8        0.5931             nan     0.0500    0.0605
     9        0.5550             nan     0.0500    0.0553
    10        0.5204             nan     0.0500    0.0472
    20        0.3193             nan     0.0500    0.0175
    40        0.1955             nan     0.0500    0.0009
    60        0.1556             nan     0.0500    0.0017
    80        0.1332             nan     0.0500    0.0008
   100        0.1184             nan     0.0500   -0.0002
   120        0.1066             nan     0.0500   -0.0006
   140        0.0973             nan     0.0500   -0.0011
   160        0.0889             nan     0.0500   -0.0007
   180        0.0820             nan     0.0500   -0.0009
   200        0.0767             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1978
     2        0.9798             nan     0.0500    0.1644
     3        0.8822             nan     0.0500    0.1347
     4        0.8019             nan     0.0500    0.1178
     5        0.7309             nan     0.0500    0.0999
     6        0.6690             nan     0.0500    0.0875
     7        0.6164             nan     0.0500    0.0761
     8        0.5695             nan     0.0500    0.0631
     9        0.5288             nan     0.0500    0.0571
    10        0.4936             nan     0.0500    0.0520
    20        0.2834             nan     0.0500    0.0140
    40        0.1619             nan     0.0500    0.0011
    60        0.1231             nan     0.0500   -0.0005
    80        0.1036             nan     0.0500   -0.0013
   100        0.0892             nan     0.0500   -0.0014
   120        0.0784             nan     0.0500   -0.0003
   140        0.0700             nan     0.0500   -0.0010
   160        0.0627             nan     0.0500   -0.0005
   180        0.0573             nan     0.0500   -0.0011
   200        0.0521             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2117
     2        0.9756             nan     0.0500    0.1678
     3        0.8768             nan     0.0500    0.1412
     4        0.7923             nan     0.0500    0.1203
     5        0.7186             nan     0.0500    0.1016
     6        0.6555             nan     0.0500    0.0881
     7        0.6013             nan     0.0500    0.0763
     8        0.5532             nan     0.0500    0.0705
     9        0.5098             nan     0.0500    0.0593
    10        0.4715             nan     0.0500    0.0514
    20        0.2595             nan     0.0500    0.0136
    40        0.1357             nan     0.0500    0.0020
    60        0.0965             nan     0.0500   -0.0001
    80        0.0752             nan     0.0500   -0.0008
   100        0.0620             nan     0.0500   -0.0006
   120        0.0521             nan     0.0500   -0.0007
   140        0.0443             nan     0.0500   -0.0008
   160        0.0387             nan     0.0500   -0.0011
   180        0.0340             nan     0.0500   -0.0011
   200        0.0298             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3240
     2        0.9005             nan     0.1000    0.2228
     3        0.7609             nan     0.1000    0.1638
     4        0.6610             nan     0.1000    0.1155
     5        0.5863             nan     0.1000    0.0872
     6        0.5253             nan     0.1000    0.0727
     7        0.4803             nan     0.1000    0.0557
     8        0.4439             nan     0.1000    0.0385
     9        0.4153             nan     0.1000    0.0363
    10        0.3895             nan     0.1000    0.0324
    20        0.2674             nan     0.1000    0.0082
    40        0.1933             nan     0.1000    0.0014
    60        0.1627             nan     0.1000   -0.0003
    80        0.1445             nan     0.1000   -0.0015
   100        0.1330             nan     0.1000   -0.0022
   120        0.1222             nan     0.1000   -0.0005
   140        0.1139             nan     0.1000   -0.0010
   160        0.1063             nan     0.1000   -0.0010
   180        0.1012             nan     0.1000   -0.0010
   200        0.0957             nan     0.1000   -0.0025

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3484
     2        0.8877             nan     0.1000    0.2396
     3        0.7427             nan     0.1000    0.1787
     4        0.6311             nan     0.1000    0.1280
     5        0.5481             nan     0.1000    0.1016
     6        0.4825             nan     0.1000    0.0735
     7        0.4322             nan     0.1000    0.0606
     8        0.3918             nan     0.1000    0.0484
     9        0.3579             nan     0.1000    0.0408
    10        0.3292             nan     0.1000    0.0339
    20        0.2021             nan     0.1000    0.0093
    40        0.1388             nan     0.1000   -0.0014
    60        0.1121             nan     0.1000   -0.0006
    80        0.0937             nan     0.1000   -0.0015
   100        0.0811             nan     0.1000   -0.0011
   120        0.0715             nan     0.1000   -0.0023
   140        0.0629             nan     0.1000   -0.0011
   160        0.0568             nan     0.1000   -0.0026
   180        0.0525             nan     0.1000   -0.0014
   200        0.0478             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3587
     2        0.8746             nan     0.1000    0.2510
     3        0.7196             nan     0.1000    0.1785
     4        0.6056             nan     0.1000    0.1309
     5        0.5206             nan     0.1000    0.1060
     6        0.4514             nan     0.1000    0.0807
     7        0.3972             nan     0.1000    0.0622
     8        0.3558             nan     0.1000    0.0489
     9        0.3222             nan     0.1000    0.0410
    10        0.2926             nan     0.1000    0.0314
    20        0.1660             nan     0.1000    0.0052
    40        0.1021             nan     0.1000   -0.0024
    60        0.0771             nan     0.1000   -0.0003
    80        0.0627             nan     0.1000   -0.0008
   100        0.0525             nan     0.1000   -0.0007
   120        0.0440             nan     0.1000   -0.0046
   140        0.0385             nan     0.1000   -0.0013
   160        0.0342             nan     0.1000   -0.0012
   180        0.0306             nan     0.1000   -0.0006
   200        0.0275             nan     0.1000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3812
     2        0.8645             nan     0.1000    0.2582
     3        0.7065             nan     0.1000    0.1797
     4        0.5903             nan     0.1000    0.1390
     5        0.5002             nan     0.1000    0.1082
     6        0.4297             nan     0.1000    0.0780
     7        0.3767             nan     0.1000    0.0623
     8        0.3335             nan     0.1000    0.0542
     9        0.2978             nan     0.1000    0.0372
    10        0.2688             nan     0.1000    0.0298
    20        0.1407             nan     0.1000    0.0069
    40        0.0773             nan     0.1000   -0.0037
    60        0.0534             nan     0.1000   -0.0019
    80        0.0396             nan     0.1000   -0.0016
   100        0.0297             nan     0.1000   -0.0009
   120        0.0240             nan     0.1000   -0.0014
   140        0.0193             nan     0.1000   -0.0015
   160        0.0163             nan     0.1000   -0.0012
   180        0.0137             nan     0.1000   -0.0017
   200        0.0118             nan     0.1000   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5191
     2        0.7334             nan     0.2000    0.2529
     3        0.5660             nan     0.2000    0.1425
     4        0.4674             nan     0.2000    0.0884
     5        0.4051             nan     0.2000    0.0549
     6        0.3641             nan     0.2000    0.0356
     7        0.3335             nan     0.2000    0.0336
     8        0.3062             nan     0.2000    0.0300
     9        0.2848             nan     0.2000    0.0066
    10        0.2705             nan     0.2000    0.0128
    20        0.1943             nan     0.2000   -0.0009
    40        0.1472             nan     0.2000   -0.0061
    60        0.1253             nan     0.2000   -0.0070
    80        0.1110             nan     0.2000   -0.0028
   100        0.0996             nan     0.2000   -0.0032
   120        0.0913             nan     0.2000   -0.0043
   140        0.0839             nan     0.2000   -0.0028
   160        0.0776             nan     0.2000   -0.0055
   180        0.0720             nan     0.2000   -0.0043
   200        0.0661             nan     0.2000   -0.0023

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5643
     2        0.7050             nan     0.2000    0.2615
     3        0.5253             nan     0.2000    0.1526
     4        0.4157             nan     0.2000    0.0783
     5        0.3506             nan     0.2000    0.0634
     6        0.3000             nan     0.2000    0.0427
     7        0.2658             nan     0.2000    0.0248
     8        0.2409             nan     0.2000    0.0216
     9        0.2236             nan     0.2000    0.0178
    10        0.2082             nan     0.2000    0.0094
    20        0.1370             nan     0.2000   -0.0035
    40        0.0961             nan     0.2000   -0.0084
    60        0.0771             nan     0.2000    0.0004
    80        0.0609             nan     0.2000   -0.0039
   100        0.0494             nan     0.2000   -0.0034
   120        0.0428             nan     0.2000   -0.0018
   140        0.0373             nan     0.2000   -0.0035
   160        0.0313             nan     0.2000   -0.0026
   180        0.0268             nan     0.2000   -0.0036
   200        0.0236             nan     0.2000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5889
     2        0.6992             nan     0.2000    0.2825
     3        0.5026             nan     0.2000    0.1637
     4        0.3835             nan     0.2000    0.0936
     5        0.3089             nan     0.2000    0.0539
     6        0.2604             nan     0.2000    0.0362
     7        0.2279             nan     0.2000    0.0342
     8        0.1993             nan     0.2000    0.0110
     9        0.1837             nan     0.2000    0.0190
    10        0.1669             nan     0.2000    0.0107
    20        0.1143             nan     0.2000   -0.0048
    40        0.0697             nan     0.2000   -0.0042
    60        0.0500             nan     0.2000   -0.0034
    80        0.0383             nan     0.2000   -0.0012
   100        0.0290             nan     0.2000   -0.0030
   120        0.0236             nan     0.2000   -0.0055
   140        0.0197             nan     0.2000   -0.0007
   160        0.0166             nan     0.2000   -0.0025
   180        0.0140             nan     0.2000   -0.0030
   200        0.0118             nan     0.2000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6340
     2        0.6708             nan     0.2000    0.2842
     3        0.4670             nan     0.2000    0.1659
     4        0.3530             nan     0.2000    0.0946
     5        0.2815             nan     0.2000    0.0436
     6        0.2378             nan     0.2000    0.0223
     7        0.2058             nan     0.2000    0.0108
     8        0.1817             nan     0.2000    0.0206
     9        0.1582             nan     0.2000    0.0155
    10        0.1414             nan     0.2000    0.0087
    20        0.0802             nan     0.2000   -0.0074
    40        0.0401             nan     0.2000   -0.0025
    60        0.0244             nan     0.2000   -0.0030
    80        0.0172             nan     0.2000   -0.0035
   100        0.0123             nan     0.2000   -0.0017
   120        0.0095             nan     0.2000   -0.0036
   140        0.0074             nan     0.2000   -0.0016
   160        0.0061             nan     0.2000   -0.0029
   180        0.0055             nan     0.2000   -0.0023
   200        0.0050             nan     0.2000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1791
     2        0.9940             nan     0.0500    0.1451
     3        0.9048             nan     0.0500    0.1241
     4        0.8301             nan     0.0500    0.1042
     5        0.7687             nan     0.0500    0.0879
     6        0.7162             nan     0.0500    0.0762
     7        0.6706             nan     0.0500    0.0672
     8        0.6308             nan     0.0500    0.0600
     9        0.5940             nan     0.0500    0.0512
    10        0.5610             nan     0.0500    0.0451
    20        0.3803             nan     0.0500    0.0165
    40        0.2574             nan     0.0500    0.0019
    60        0.2102             nan     0.0500    0.0013
    80        0.1831             nan     0.0500   -0.0003
   100        0.1650             nan     0.0500   -0.0009
   120        0.1518             nan     0.0500   -0.0011
   140        0.1426             nan     0.0500   -0.0006
   160        0.1355             nan     0.0500   -0.0006
   180        0.1274             nan     0.0500   -0.0018
   200        0.1217             nan     0.0500    0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1917
     2        0.9856             nan     0.0500    0.1585
     3        0.8912             nan     0.0500    0.1322
     4        0.8104             nan     0.0500    0.1079
     5        0.7425             nan     0.0500    0.0959
     6        0.6853             nan     0.0500    0.0835
     7        0.6348             nan     0.0500    0.0693
     8        0.5907             nan     0.0500    0.0620
     9        0.5514             nan     0.0500    0.0557
    10        0.5154             nan     0.0500    0.0490
    20        0.3132             nan     0.0500    0.0169
    40        0.1887             nan     0.0500    0.0041
    60        0.1489             nan     0.0500    0.0023
    80        0.1248             nan     0.0500   -0.0006
   100        0.1092             nan     0.0500    0.0005
   120        0.0983             nan     0.0500   -0.0003
   140        0.0882             nan     0.0500   -0.0004
   160        0.0797             nan     0.0500   -0.0008
   180        0.0736             nan     0.0500   -0.0011
   200        0.0686             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2016
     2        0.9819             nan     0.0500    0.1601
     3        0.8857             nan     0.0500    0.1381
     4        0.8025             nan     0.0500    0.1159
     5        0.7329             nan     0.0500    0.1007
     6        0.6725             nan     0.0500    0.0849
     7        0.6209             nan     0.0500    0.0776
     8        0.5735             nan     0.0500    0.0659
     9        0.5331             nan     0.0500    0.0589
    10        0.4963             nan     0.0500    0.0532
    20        0.2848             nan     0.0500    0.0161
    40        0.1567             nan     0.0500    0.0020
    60        0.1163             nan     0.0500   -0.0002
    80        0.0972             nan     0.0500   -0.0007
   100        0.0821             nan     0.0500   -0.0010
   120        0.0729             nan     0.0500   -0.0007
   140        0.0647             nan     0.0500   -0.0009
   160        0.0584             nan     0.0500   -0.0002
   180        0.0529             nan     0.0500   -0.0004
   200        0.0486             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2102
     2        0.9756             nan     0.0500    0.1707
     3        0.8748             nan     0.0500    0.1473
     4        0.7878             nan     0.0500    0.1220
     5        0.7137             nan     0.0500    0.1015
     6        0.6504             nan     0.0500    0.0898
     7        0.5970             nan     0.0500    0.0779
     8        0.5491             nan     0.0500    0.0677
     9        0.5061             nan     0.0500    0.0600
    10        0.4691             nan     0.0500    0.0556
    20        0.2545             nan     0.0500    0.0162
    40        0.1287             nan     0.0500    0.0009
    60        0.0878             nan     0.0500   -0.0000
    80        0.0668             nan     0.0500   -0.0009
   100        0.0541             nan     0.0500   -0.0002
   120        0.0439             nan     0.0500   -0.0007
   140        0.0372             nan     0.0500   -0.0005
   160        0.0322             nan     0.0500   -0.0003
   180        0.0275             nan     0.0500   -0.0003
   200        0.0243             nan     0.0500   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3296
     2        0.8970             nan     0.1000    0.2210
     3        0.7570             nan     0.1000    0.1632
     4        0.6575             nan     0.1000    0.1194
     5        0.5809             nan     0.1000    0.0865
     6        0.5222             nan     0.1000    0.0697
     7        0.4776             nan     0.1000    0.0533
     8        0.4422             nan     0.1000    0.0472
     9        0.4123             nan     0.1000    0.0365
    10        0.3865             nan     0.1000    0.0253
    20        0.2570             nan     0.1000    0.0068
    40        0.1829             nan     0.1000    0.0003
    60        0.1552             nan     0.1000   -0.0005
    80        0.1354             nan     0.1000   -0.0012
   100        0.1225             nan     0.1000    0.0001
   120        0.1130             nan     0.1000   -0.0020
   140        0.1059             nan     0.1000   -0.0028
   160        0.0999             nan     0.1000   -0.0005
   180        0.0943             nan     0.1000   -0.0022
   200        0.0901             nan     0.1000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3517
     2        0.8857             nan     0.1000    0.2443
     3        0.7358             nan     0.1000    0.1715
     4        0.6239             nan     0.1000    0.1302
     5        0.5416             nan     0.1000    0.0986
     6        0.4744             nan     0.1000    0.0791
     7        0.4238             nan     0.1000    0.0575
     8        0.3834             nan     0.1000    0.0497
     9        0.3494             nan     0.1000    0.0406
    10        0.3217             nan     0.1000    0.0270
    20        0.1893             nan     0.1000    0.0043
    40        0.1272             nan     0.1000    0.0006
    60        0.0966             nan     0.1000   -0.0005
    80        0.0820             nan     0.1000   -0.0021
   100        0.0704             nan     0.1000   -0.0024
   120        0.0617             nan     0.1000   -0.0017
   140        0.0555             nan     0.1000   -0.0006
   160        0.0492             nan     0.1000   -0.0015
   180        0.0437             nan     0.1000   -0.0012
   200        0.0393             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3672
     2        0.8724             nan     0.1000    0.2473
     3        0.7166             nan     0.1000    0.1813
     4        0.6018             nan     0.1000    0.1343
     5        0.5146             nan     0.1000    0.0962
     6        0.4499             nan     0.1000    0.0805
     7        0.3976             nan     0.1000    0.0685
     8        0.3529             nan     0.1000    0.0552
     9        0.3165             nan     0.1000    0.0432
    10        0.2857             nan     0.1000    0.0327
    20        0.1606             nan     0.1000    0.0092
    40        0.0981             nan     0.1000   -0.0037
    60        0.0744             nan     0.1000   -0.0016
    80        0.0592             nan     0.1000   -0.0027
   100        0.0493             nan     0.1000   -0.0005
   120        0.0423             nan     0.1000   -0.0011
   140        0.0359             nan     0.1000   -0.0008
   160        0.0311             nan     0.1000   -0.0025
   180        0.0267             nan     0.1000   -0.0008
   200        0.0234             nan     0.1000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3781
     2        0.8615             nan     0.1000    0.2614
     3        0.7012             nan     0.1000    0.1818
     4        0.5855             nan     0.1000    0.1490
     5        0.4932             nan     0.1000    0.1085
     6        0.4224             nan     0.1000    0.0870
     7        0.3656             nan     0.1000    0.0598
     8        0.3234             nan     0.1000    0.0504
     9        0.2891             nan     0.1000    0.0369
    10        0.2578             nan     0.1000    0.0341
    20        0.1274             nan     0.1000    0.0036
    40        0.0668             nan     0.1000   -0.0004
    60        0.0442             nan     0.1000   -0.0018
    80        0.0330             nan     0.1000   -0.0014
   100        0.0247             nan     0.1000   -0.0003
   120        0.0190             nan     0.1000   -0.0009
   140        0.0154             nan     0.1000   -0.0007
   160        0.0126             nan     0.1000   -0.0003
   180        0.0103             nan     0.1000   -0.0003
   200        0.0084             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5479
     2        0.7353             nan     0.2000    0.2602
     3        0.5649             nan     0.2000    0.1464
     4        0.4613             nan     0.2000    0.0919
     5        0.4001             nan     0.2000    0.0541
     6        0.3558             nan     0.2000    0.0457
     7        0.3191             nan     0.2000    0.0250
     8        0.2984             nan     0.2000    0.0254
     9        0.2778             nan     0.2000    0.0263
    10        0.2597             nan     0.2000    0.0145
    20        0.1835             nan     0.2000    0.0033
    40        0.1391             nan     0.2000   -0.0063
    60        0.1187             nan     0.2000   -0.0062
    80        0.1067             nan     0.2000   -0.0030
   100        0.0929             nan     0.2000   -0.0000
   120        0.0846             nan     0.2000   -0.0037
   140        0.0773             nan     0.2000   -0.0029
   160        0.0719             nan     0.2000   -0.0022
   180        0.0666             nan     0.2000   -0.0019
   200        0.0619             nan     0.2000   -0.0072

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5782
     2        0.7032             nan     0.2000    0.2765
     3        0.5170             nan     0.2000    0.1549
     4        0.4059             nan     0.2000    0.0905
     5        0.3377             nan     0.2000    0.0550
     6        0.2895             nan     0.2000    0.0463
     7        0.2540             nan     0.2000    0.0308
     8        0.2268             nan     0.2000    0.0190
     9        0.2094             nan     0.2000    0.0057
    10        0.1965             nan     0.2000    0.0073
    20        0.1317             nan     0.2000   -0.0098
    40        0.0807             nan     0.2000   -0.0042
    60        0.0639             nan     0.2000   -0.0025
    80        0.0491             nan     0.2000   -0.0098
   100        0.0397             nan     0.2000   -0.0016
   120        0.0337             nan     0.2000   -0.0019
   140        0.0289             nan     0.2000   -0.0025
   160        0.0243             nan     0.2000    0.0001
   180        0.0211             nan     0.2000   -0.0015
   200        0.0181             nan     0.2000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6033
     2        0.6874             nan     0.2000    0.2880
     3        0.4931             nan     0.2000    0.1609
     4        0.3755             nan     0.2000    0.0984
     5        0.3044             nan     0.2000    0.0667
     6        0.2546             nan     0.2000    0.0432
     7        0.2187             nan     0.2000    0.0394
     8        0.1892             nan     0.2000    0.0116
     9        0.1731             nan     0.2000    0.0059
    10        0.1543             nan     0.2000   -0.0010
    20        0.1007             nan     0.2000   -0.0071
    40        0.0607             nan     0.2000   -0.0036
    60        0.0454             nan     0.2000   -0.0027
    80        0.0328             nan     0.2000   -0.0012
   100        0.0248             nan     0.2000   -0.0015
   120        0.0190             nan     0.2000   -0.0011
   140        0.0152             nan     0.2000   -0.0011
   160        0.0127             nan     0.2000   -0.0019
   180        0.0109             nan     0.2000   -0.0028
   200        0.0087             nan     0.2000   -0.0025

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6202
     2        0.6768             nan     0.2000    0.3088
     3        0.4634             nan     0.2000    0.1682
     4        0.3453             nan     0.2000    0.0926
     5        0.2755             nan     0.2000    0.0649
     6        0.2264             nan     0.2000    0.0421
     7        0.1877             nan     0.2000    0.0290
     8        0.1613             nan     0.2000    0.0028
     9        0.1443             nan     0.2000    0.0019
    10        0.1317             nan     0.2000   -0.0009
    20        0.0682             nan     0.2000   -0.0048
    40        0.0366             nan     0.2000   -0.0007
    60        0.0226             nan     0.2000   -0.0041
    80        0.0141             nan     0.2000   -0.0021
   100        0.0103             nan     0.2000   -0.0010
   120        0.0074             nan     0.2000   -0.0004
   140        0.0060             nan     0.2000   -0.0006
   160        0.0048             nan     0.2000   -0.0016
   180        0.0039             nan     0.2000   -0.0000
   200        0.0030             nan     0.2000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1764
     2        0.9933             nan     0.0500    0.1468
     3        0.9061             nan     0.0500    0.1247
     4        0.8346             nan     0.0500    0.1025
     5        0.7708             nan     0.0500    0.0892
     6        0.7168             nan     0.0500    0.0756
     7        0.6706             nan     0.0500    0.0656
     8        0.6298             nan     0.0500    0.0569
     9        0.5945             nan     0.0500    0.0504
    10        0.5632             nan     0.0500    0.0437
    20        0.3825             nan     0.0500    0.0154
    40        0.2631             nan     0.0500    0.0045
    60        0.2153             nan     0.0500    0.0035
    80        0.1884             nan     0.0500    0.0003
   100        0.1708             nan     0.0500   -0.0001
   120        0.1574             nan     0.0500    0.0002
   140        0.1464             nan     0.0500   -0.0005
   160        0.1381             nan     0.0500   -0.0004
   180        0.1310             nan     0.0500   -0.0001
   200        0.1251             nan     0.0500   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1905
     2        0.9870             nan     0.0500    0.1578
     3        0.8912             nan     0.0500    0.1306
     4        0.8135             nan     0.0500    0.1111
     5        0.7463             nan     0.0500    0.0942
     6        0.6884             nan     0.0500    0.0829
     7        0.6382             nan     0.0500    0.0718
     8        0.5927             nan     0.0500    0.0614
     9        0.5544             nan     0.0500    0.0565
    10        0.5196             nan     0.0500    0.0483
    20        0.3199             nan     0.0500    0.0202
    40        0.1942             nan     0.0500    0.0037
    60        0.1488             nan     0.0500    0.0011
    80        0.1265             nan     0.0500   -0.0001
   100        0.1097             nan     0.0500   -0.0008
   120        0.0988             nan     0.0500   -0.0007
   140        0.0899             nan     0.0500    0.0001
   160        0.0824             nan     0.0500   -0.0006
   180        0.0755             nan     0.0500   -0.0008
   200        0.0700             nan     0.0500   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1960
     2        0.9829             nan     0.0500    0.1611
     3        0.8889             nan     0.0500    0.1391
     4        0.8056             nan     0.0500    0.1187
     5        0.7344             nan     0.0500    0.1043
     6        0.6725             nan     0.0500    0.0865
     7        0.6183             nan     0.0500    0.0714
     8        0.5720             nan     0.0500    0.0649
     9        0.5319             nan     0.0500    0.0563
    10        0.4965             nan     0.0500    0.0487
    20        0.2897             nan     0.0500    0.0104
    40        0.1590             nan     0.0500    0.0016
    60        0.1187             nan     0.0500    0.0001
    80        0.0972             nan     0.0500   -0.0019
   100        0.0820             nan     0.0500   -0.0002
   120        0.0722             nan     0.0500    0.0002
   140        0.0649             nan     0.0500   -0.0011
   160        0.0577             nan     0.0500   -0.0011
   180        0.0522             nan     0.0500   -0.0008
   200        0.0472             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2071
     2        0.9772             nan     0.0500    0.1728
     3        0.8762             nan     0.0500    0.1456
     4        0.7893             nan     0.0500    0.1227
     5        0.7163             nan     0.0500    0.1043
     6        0.6533             nan     0.0500    0.0896
     7        0.5995             nan     0.0500    0.0788
     8        0.5516             nan     0.0500    0.0675
     9        0.5088             nan     0.0500    0.0581
    10        0.4733             nan     0.0500    0.0513
    20        0.2572             nan     0.0500    0.0153
    40        0.1295             nan     0.0500    0.0025
    60        0.0908             nan     0.0500    0.0001
    80        0.0703             nan     0.0500   -0.0004
   100        0.0578             nan     0.0500   -0.0018
   120        0.0479             nan     0.0500   -0.0007
   140        0.0400             nan     0.0500   -0.0006
   160        0.0349             nan     0.0500   -0.0004
   180        0.0306             nan     0.0500   -0.0011
   200        0.0265             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3250
     2        0.8999             nan     0.1000    0.2212
     3        0.7618             nan     0.1000    0.1601
     4        0.6599             nan     0.1000    0.1179
     5        0.5858             nan     0.1000    0.0885
     6        0.5267             nan     0.1000    0.0698
     7        0.4799             nan     0.1000    0.0530
     8        0.4429             nan     0.1000    0.0472
     9        0.4121             nan     0.1000    0.0284
    10        0.3906             nan     0.1000    0.0260
    20        0.2660             nan     0.1000    0.0076
    40        0.1880             nan     0.1000    0.0011
    60        0.1548             nan     0.1000   -0.0004
    80        0.1352             nan     0.1000   -0.0019
   100        0.1228             nan     0.1000   -0.0017
   120        0.1122             nan     0.1000   -0.0010
   140        0.1061             nan     0.1000   -0.0016
   160        0.0969             nan     0.1000   -0.0019
   180        0.0922             nan     0.1000   -0.0003
   200        0.0852             nan     0.1000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3459
     2        0.8829             nan     0.1000    0.2379
     3        0.7350             nan     0.1000    0.1717
     4        0.6258             nan     0.1000    0.1271
     5        0.5475             nan     0.1000    0.0925
     6        0.4827             nan     0.1000    0.0773
     7        0.4321             nan     0.1000    0.0545
     8        0.3939             nan     0.1000    0.0473
     9        0.3591             nan     0.1000    0.0447
    10        0.3289             nan     0.1000    0.0355
    20        0.1944             nan     0.1000    0.0062
    40        0.1325             nan     0.1000    0.0012
    60        0.1020             nan     0.1000   -0.0015
    80        0.0841             nan     0.1000   -0.0004
   100        0.0722             nan     0.1000   -0.0006
   120        0.0624             nan     0.1000   -0.0016
   140        0.0568             nan     0.1000   -0.0016
   160        0.0496             nan     0.1000   -0.0011
   180        0.0449             nan     0.1000   -0.0013
   200        0.0409             nan     0.1000   -0.0002

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3662
     2        0.8737             nan     0.1000    0.2437
     3        0.7182             nan     0.1000    0.1770
     4        0.6077             nan     0.1000    0.1367
     5        0.5180             nan     0.1000    0.1015
     6        0.4506             nan     0.1000    0.0787
     7        0.3980             nan     0.1000    0.0615
     8        0.3564             nan     0.1000    0.0525
     9        0.3187             nan     0.1000    0.0408
    10        0.2902             nan     0.1000    0.0283
    20        0.1614             nan     0.1000    0.0087
    40        0.0980             nan     0.1000   -0.0005
    60        0.0719             nan     0.1000   -0.0007
    80        0.0585             nan     0.1000   -0.0015
   100        0.0466             nan     0.1000   -0.0012
   120        0.0395             nan     0.1000   -0.0009
   140        0.0344             nan     0.1000   -0.0013
   160        0.0293             nan     0.1000   -0.0013
   180        0.0254             nan     0.1000   -0.0001
   200        0.0225             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3804
     2        0.8665             nan     0.1000    0.2692
     3        0.7022             nan     0.1000    0.1800
     4        0.5844             nan     0.1000    0.1386
     5        0.4943             nan     0.1000    0.1065
     6        0.4264             nan     0.1000    0.0772
     7        0.3743             nan     0.1000    0.0630
     8        0.3298             nan     0.1000    0.0497
     9        0.2945             nan     0.1000    0.0361
    10        0.2663             nan     0.1000    0.0252
    20        0.1348             nan     0.1000    0.0028
    40        0.0726             nan     0.1000   -0.0010
    60        0.0512             nan     0.1000   -0.0017
    80        0.0367             nan     0.1000   -0.0004
   100        0.0278             nan     0.1000   -0.0020
   120        0.0223             nan     0.1000   -0.0007
   140        0.0180             nan     0.1000   -0.0010
   160        0.0153             nan     0.1000   -0.0007
   180        0.0128             nan     0.1000   -0.0013
   200        0.0113             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5548
     2        0.7400             nan     0.2000    0.2515
     3        0.5669             nan     0.2000    0.1356
     4        0.4711             nan     0.2000    0.0947
     5        0.3995             nan     0.2000    0.0600
     6        0.3562             nan     0.2000    0.0333
     7        0.3268             nan     0.2000    0.0234
     8        0.3004             nan     0.2000    0.0307
     9        0.2797             nan     0.2000    0.0124
    10        0.2622             nan     0.2000    0.0159
    20        0.1934             nan     0.2000    0.0015
    40        0.1376             nan     0.2000   -0.0033
    60        0.1134             nan     0.2000   -0.0040
    80        0.1031             nan     0.2000   -0.0041
   100        0.0894             nan     0.2000   -0.0018
   120        0.0815             nan     0.2000   -0.0010
   140        0.0750             nan     0.2000   -0.0038
   160        0.0695             nan     0.2000   -0.0033
   180        0.0625             nan     0.2000   -0.0015
   200        0.0594             nan     0.2000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5741
     2        0.7099             nan     0.2000    0.2686
     3        0.5286             nan     0.2000    0.1640
     4        0.4173             nan     0.2000    0.1131
     5        0.3389             nan     0.2000    0.0603
     6        0.2934             nan     0.2000    0.0512
     7        0.2566             nan     0.2000    0.0283
     8        0.2315             nan     0.2000    0.0253
     9        0.2108             nan     0.2000    0.0081
    10        0.1986             nan     0.2000    0.0070
    20        0.1309             nan     0.2000   -0.0062
    40        0.0856             nan     0.2000   -0.0024
    60        0.0610             nan     0.2000   -0.0079
    80        0.0513             nan     0.2000   -0.0038
   100        0.0433             nan     0.2000   -0.0015
   120        0.0355             nan     0.2000   -0.0014
   140        0.0299             nan     0.2000   -0.0012
   160        0.0268             nan     0.2000   -0.0013
   180        0.0229             nan     0.2000   -0.0019
   200        0.0197             nan     0.2000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6040
     2        0.6901             nan     0.2000    0.2763
     3        0.5005             nan     0.2000    0.1626
     4        0.3861             nan     0.2000    0.1119
     5        0.3091             nan     0.2000    0.0615
     6        0.2614             nan     0.2000    0.0474
     7        0.2202             nan     0.2000    0.0072
     8        0.2004             nan     0.2000    0.0257
     9        0.1778             nan     0.2000    0.0122
    10        0.1618             nan     0.2000    0.0019
    20        0.1008             nan     0.2000   -0.0011
    40        0.0562             nan     0.2000   -0.0056
    60        0.0396             nan     0.2000   -0.0014
    80        0.0288             nan     0.2000   -0.0012
   100        0.0237             nan     0.2000   -0.0004
   120        0.0187             nan     0.2000   -0.0025
   140        0.0148             nan     0.2000   -0.0021
   160        0.0126             nan     0.2000   -0.0011
   180        0.0114             nan     0.2000   -0.0033
   200        0.0106             nan     0.2000   -0.0034

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6146
     2        0.6763             nan     0.2000    0.2888
     3        0.4765             nan     0.2000    0.1712
     4        0.3573             nan     0.2000    0.0930
     5        0.2853             nan     0.2000    0.0561
     6        0.2369             nan     0.2000    0.0459
     7        0.1964             nan     0.2000    0.0191
     8        0.1722             nan     0.2000    0.0086
     9        0.1555             nan     0.2000    0.0026
    10        0.1369             nan     0.2000    0.0006
    20        0.0729             nan     0.2000   -0.0046
    40        0.0373             nan     0.2000   -0.0033
    60        0.0220             nan     0.2000   -0.0008
    80        0.0148             nan     0.2000   -0.0014
   100        0.0109             nan     0.2000   -0.0009
   120        0.0087             nan     0.2000   -0.0017
   140        0.0068             nan     0.2000   -0.0023
   160        0.0061             nan     0.2000   -0.0050
   180        0.0053             nan     0.2000   -0.0044
   200        0.0044             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1812
     2        0.9942             nan     0.0500    0.1491
     3        0.9066             nan     0.0500    0.1226
     4        0.8320             nan     0.0500    0.1053
     5        0.7679             nan     0.0500    0.0900
     6        0.7144             nan     0.0500    0.0785
     7        0.6673             nan     0.0500    0.0675
     8        0.6259             nan     0.0500    0.0584
     9        0.5902             nan     0.0500    0.0510
    10        0.5590             nan     0.0500    0.0460
    20        0.3788             nan     0.0500    0.0163
    40        0.2579             nan     0.0500    0.0028
    60        0.2116             nan     0.0500    0.0010
    80        0.1834             nan     0.0500   -0.0005
   100        0.1674             nan     0.0500   -0.0001
   120        0.1540             nan     0.0500   -0.0018
   140        0.1440             nan     0.0500   -0.0004
   160        0.1358             nan     0.0500   -0.0010
   180        0.1291             nan     0.0500   -0.0005
   200        0.1237             nan     0.0500   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1941
     2        0.9871             nan     0.0500    0.1576
     3        0.8914             nan     0.0500    0.1332
     4        0.8123             nan     0.0500    0.1143
     5        0.7455             nan     0.0500    0.0981
     6        0.6874             nan     0.0500    0.0838
     7        0.6358             nan     0.0500    0.0718
     8        0.5925             nan     0.0500    0.0626
     9        0.5521             nan     0.0500    0.0569
    10        0.5171             nan     0.0500    0.0507
    20        0.3148             nan     0.0500    0.0159
    40        0.1862             nan     0.0500    0.0030
    60        0.1466             nan     0.0500   -0.0001
    80        0.1243             nan     0.0500   -0.0008
   100        0.1114             nan     0.0500    0.0007
   120        0.1003             nan     0.0500    0.0002
   140        0.0903             nan     0.0500   -0.0008
   160        0.0832             nan     0.0500   -0.0008
   180        0.0771             nan     0.0500   -0.0012
   200        0.0721             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1988
     2        0.9817             nan     0.0500    0.1665
     3        0.8844             nan     0.0500    0.1352
     4        0.8018             nan     0.0500    0.1197
     5        0.7300             nan     0.0500    0.1026
     6        0.6682             nan     0.0500    0.0875
     7        0.6144             nan     0.0500    0.0761
     8        0.5680             nan     0.0500    0.0650
     9        0.5273             nan     0.0500    0.0558
    10        0.4908             nan     0.0500    0.0515
    20        0.2819             nan     0.0500    0.0129
    40        0.1559             nan     0.0500    0.0020
    60        0.1169             nan     0.0500   -0.0000
    80        0.0951             nan     0.0500   -0.0006
   100        0.0806             nan     0.0500   -0.0009
   120        0.0711             nan     0.0500   -0.0004
   140        0.0634             nan     0.0500   -0.0008
   160        0.0568             nan     0.0500   -0.0005
   180        0.0514             nan     0.0500   -0.0006
   200        0.0470             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2089
     2        0.9766             nan     0.0500    0.1737
     3        0.8743             nan     0.0500    0.1417
     4        0.7874             nan     0.0500    0.1226
     5        0.7131             nan     0.0500    0.1031
     6        0.6507             nan     0.0500    0.0923
     7        0.5950             nan     0.0500    0.0777
     8        0.5461             nan     0.0500    0.0691
     9        0.5037             nan     0.0500    0.0625
    10        0.4653             nan     0.0500    0.0529
    20        0.2512             nan     0.0500    0.0175
    40        0.1272             nan     0.0500    0.0010
    60        0.0893             nan     0.0500   -0.0006
    80        0.0683             nan     0.0500    0.0000
   100        0.0554             nan     0.0500   -0.0014
   120        0.0459             nan     0.0500   -0.0007
   140        0.0387             nan     0.0500   -0.0004
   160        0.0337             nan     0.0500   -0.0007
   180        0.0294             nan     0.0500   -0.0004
   200        0.0265             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3321
     2        0.9019             nan     0.1000    0.2315
     3        0.7662             nan     0.1000    0.1643
     4        0.6655             nan     0.1000    0.1231
     5        0.5831             nan     0.1000    0.0900
     6        0.5254             nan     0.1000    0.0669
     7        0.4792             nan     0.1000    0.0579
     8        0.4406             nan     0.1000    0.0468
     9        0.4105             nan     0.1000    0.0375
    10        0.3861             nan     0.1000    0.0310
    20        0.2575             nan     0.1000    0.0062
    40        0.1829             nan     0.1000    0.0020
    60        0.1523             nan     0.1000   -0.0009
    80        0.1362             nan     0.1000   -0.0024
   100        0.1223             nan     0.1000   -0.0010
   120        0.1128             nan     0.1000   -0.0017
   140        0.1060             nan     0.1000   -0.0022
   160        0.0996             nan     0.1000   -0.0022
   180        0.0943             nan     0.1000   -0.0009
   200        0.0899             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3540
     2        0.8810             nan     0.1000    0.2426
     3        0.7310             nan     0.1000    0.1728
     4        0.6210             nan     0.1000    0.1286
     5        0.5411             nan     0.1000    0.0955
     6        0.4760             nan     0.1000    0.0738
     7        0.4257             nan     0.1000    0.0609
     8        0.3849             nan     0.1000    0.0448
     9        0.3531             nan     0.1000    0.0458
    10        0.3229             nan     0.1000    0.0359
    20        0.1907             nan     0.1000    0.0058
    40        0.1285             nan     0.1000   -0.0020
    60        0.1033             nan     0.1000   -0.0009
    80        0.0870             nan     0.1000   -0.0019
   100        0.0760             nan     0.1000   -0.0002
   120        0.0659             nan     0.1000   -0.0017
   140        0.0567             nan     0.1000   -0.0007
   160        0.0508             nan     0.1000   -0.0020
   180        0.0460             nan     0.1000   -0.0022
   200        0.0422             nan     0.1000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3619
     2        0.8759             nan     0.1000    0.2455
     3        0.7188             nan     0.1000    0.1815
     4        0.6082             nan     0.1000    0.1353
     5        0.5214             nan     0.1000    0.1033
     6        0.4531             nan     0.1000    0.0821
     7        0.3987             nan     0.1000    0.0629
     8        0.3570             nan     0.1000    0.0500
     9        0.3212             nan     0.1000    0.0347
    10        0.2934             nan     0.1000    0.0440
    20        0.1579             nan     0.1000    0.0024
    40        0.0977             nan     0.1000   -0.0004
    60        0.0724             nan     0.1000    0.0001
    80        0.0583             nan     0.1000   -0.0010
   100        0.0465             nan     0.1000   -0.0005
   120        0.0388             nan     0.1000   -0.0007
   140        0.0337             nan     0.1000   -0.0007
   160        0.0297             nan     0.1000   -0.0011
   180        0.0259             nan     0.1000   -0.0009
   200        0.0232             nan     0.1000   -0.0022

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3739
     2        0.8666             nan     0.1000    0.2614
     3        0.7070             nan     0.1000    0.1818
     4        0.5897             nan     0.1000    0.1405
     5        0.4976             nan     0.1000    0.1018
     6        0.4294             nan     0.1000    0.0830
     7        0.3739             nan     0.1000    0.0611
     8        0.3313             nan     0.1000    0.0557
     9        0.2943             nan     0.1000    0.0382
    10        0.2665             nan     0.1000    0.0341
    20        0.1336             nan     0.1000    0.0006
    40        0.0728             nan     0.1000   -0.0008
    60        0.0477             nan     0.1000   -0.0021
    80        0.0331             nan     0.1000   -0.0017
   100        0.0255             nan     0.1000   -0.0023
   120        0.0207             nan     0.1000   -0.0011
   140        0.0166             nan     0.1000   -0.0018
   160        0.0139             nan     0.1000   -0.0012
   180        0.0119             nan     0.1000   -0.0014
   200        0.0102             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5514
     2        0.7351             nan     0.2000    0.2485
     3        0.5611             nan     0.2000    0.1274
     4        0.4611             nan     0.2000    0.0876
     5        0.3963             nan     0.2000    0.0644
     6        0.3523             nan     0.2000    0.0337
     7        0.3202             nan     0.2000    0.0170
     8        0.2957             nan     0.2000    0.0272
     9        0.2762             nan     0.2000    0.0144
    10        0.2650             nan     0.2000    0.0156
    20        0.1860             nan     0.2000    0.0027
    40        0.1353             nan     0.2000    0.0013
    60        0.1140             nan     0.2000   -0.0039
    80        0.1007             nan     0.2000   -0.0039
   100        0.0912             nan     0.2000   -0.0027
   120        0.0841             nan     0.2000   -0.0025
   140        0.0781             nan     0.2000   -0.0045
   160        0.0718             nan     0.2000   -0.0049
   180        0.0656             nan     0.2000   -0.0032
   200        0.0609             nan     0.2000   -0.0027

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5941
     2        0.7059             nan     0.2000    0.2814
     3        0.5143             nan     0.2000    0.1433
     4        0.4103             nan     0.2000    0.0841
     5        0.3433             nan     0.2000    0.0655
     6        0.2880             nan     0.2000    0.0220
     7        0.2518             nan     0.2000    0.0213
     8        0.2235             nan     0.2000    0.0227
     9        0.2040             nan     0.2000    0.0077
    10        0.1877             nan     0.2000    0.0005
    20        0.1291             nan     0.2000   -0.0025
    40        0.0896             nan     0.2000    0.0009
    60        0.0633             nan     0.2000   -0.0065
    80        0.0478             nan     0.2000   -0.0043
   100        0.0379             nan     0.2000   -0.0023
   120        0.0316             nan     0.2000   -0.0023
   140        0.0289             nan     0.2000   -0.0022
   160        0.0254             nan     0.2000   -0.0037
   180        0.0228             nan     0.2000   -0.0041
   200        0.0203             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6210
     2        0.6867             nan     0.2000    0.2843
     3        0.4959             nan     0.2000    0.1546
     4        0.3822             nan     0.2000    0.1056
     5        0.3072             nan     0.2000    0.0839
     6        0.2474             nan     0.2000    0.0313
     7        0.2170             nan     0.2000    0.0260
     8        0.1931             nan     0.2000    0.0106
     9        0.1767             nan     0.2000    0.0139
    10        0.1612             nan     0.2000    0.0073
    20        0.1007             nan     0.2000   -0.0078
    40        0.0623             nan     0.2000   -0.0015
    60        0.0413             nan     0.2000   -0.0040
    80        0.0305             nan     0.2000   -0.0051
   100        0.0236             nan     0.2000   -0.0015
   120        0.0198             nan     0.2000   -0.0010
   140        0.0163             nan     0.2000   -0.0039
   160        0.0139             nan     0.2000   -0.0019
   180        0.0123             nan     0.2000   -0.0028
   200        0.0101             nan     0.2000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6103
     2        0.6712             nan     0.2000    0.2968
     3        0.4683             nan     0.2000    0.1677
     4        0.3509             nan     0.2000    0.1053
     5        0.2753             nan     0.2000    0.0576
     6        0.2250             nan     0.2000    0.0190
     7        0.1948             nan     0.2000    0.0281
     8        0.1664             nan     0.2000    0.0086
     9        0.1497             nan     0.2000   -0.0029
    10        0.1385             nan     0.2000    0.0118
    20        0.0666             nan     0.2000   -0.0058
    40        0.0364             nan     0.2000   -0.0017
    60        0.0221             nan     0.2000   -0.0034
    80        0.0147             nan     0.2000   -0.0016
   100        0.0113             nan     0.2000   -0.0021
   120        0.0097             nan     0.2000   -0.0009
   140        0.0075             nan     0.2000   -0.0030
   160        0.0059             nan     0.2000   -0.0019
   180        0.0051             nan     0.2000   -0.0028
   200        0.0044             nan     0.2000   -0.0029

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1747
     2        0.9933             nan     0.0500    0.1481
     3        0.9079             nan     0.0500    0.1267
     4        0.8365             nan     0.0500    0.1069
     5        0.7738             nan     0.0500    0.0914
     6        0.7201             nan     0.0500    0.0773
     7        0.6717             nan     0.0500    0.0665
     8        0.6303             nan     0.0500    0.0575
     9        0.5937             nan     0.0500    0.0509
    10        0.5628             nan     0.0500    0.0452
    20        0.3827             nan     0.0500    0.0153
    40        0.2586             nan     0.0500    0.0046
    60        0.2126             nan     0.0500    0.0021
    80        0.1848             nan     0.0500    0.0008
   100        0.1677             nan     0.0500    0.0001
   120        0.1545             nan     0.0500   -0.0000
   140        0.1455             nan     0.0500   -0.0011
   160        0.1372             nan     0.0500   -0.0004
   180        0.1301             nan     0.0500   -0.0004
   200        0.1247             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1883
     2        0.9844             nan     0.0500    0.1571
     3        0.8912             nan     0.0500    0.1337
     4        0.8114             nan     0.0500    0.1128
     5        0.7451             nan     0.0500    0.0970
     6        0.6882             nan     0.0500    0.0836
     7        0.6374             nan     0.0500    0.0729
     8        0.5929             nan     0.0500    0.0626
     9        0.5532             nan     0.0500    0.0542
    10        0.5188             nan     0.0500    0.0484
    20        0.3171             nan     0.0500    0.0175
    40        0.1890             nan     0.0500    0.0027
    60        0.1477             nan     0.0500    0.0009
    80        0.1256             nan     0.0500   -0.0010
   100        0.1104             nan     0.0500   -0.0003
   120        0.0987             nan     0.0500   -0.0006
   140        0.0900             nan     0.0500   -0.0010
   160        0.0823             nan     0.0500   -0.0012
   180        0.0757             nan     0.0500   -0.0008
   200        0.0696             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1940
     2        0.9824             nan     0.0500    0.1666
     3        0.8850             nan     0.0500    0.1371
     4        0.8037             nan     0.0500    0.1182
     5        0.7336             nan     0.0500    0.0979
     6        0.6733             nan     0.0500    0.0878
     7        0.6183             nan     0.0500    0.0749
     8        0.5726             nan     0.0500    0.0666
     9        0.5319             nan     0.0500    0.0563
    10        0.4964             nan     0.0500    0.0570
    20        0.2834             nan     0.0500    0.0208
    40        0.1567             nan     0.0500    0.0027
    60        0.1189             nan     0.0500    0.0001
    80        0.0986             nan     0.0500   -0.0004
   100        0.0842             nan     0.0500   -0.0012
   120        0.0746             nan     0.0500   -0.0006
   140        0.0655             nan     0.0500   -0.0011
   160        0.0586             nan     0.0500   -0.0007
   180        0.0525             nan     0.0500   -0.0006
   200        0.0482             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2061
     2        0.9768             nan     0.0500    0.1689
     3        0.8770             nan     0.0500    0.1435
     4        0.7910             nan     0.0500    0.1234
     5        0.7174             nan     0.0500    0.1070
     6        0.6527             nan     0.0500    0.0865
     7        0.5982             nan     0.0500    0.0782
     8        0.5486             nan     0.0500    0.0702
     9        0.5044             nan     0.0500    0.0590
    10        0.4658             nan     0.0500    0.0531
    20        0.2548             nan     0.0500    0.0189
    40        0.1297             nan     0.0500    0.0006
    60        0.0893             nan     0.0500    0.0005
    80        0.0682             nan     0.0500   -0.0000
   100        0.0555             nan     0.0500   -0.0006
   120        0.0462             nan     0.0500   -0.0005
   140        0.0391             nan     0.0500    0.0000
   160        0.0332             nan     0.0500   -0.0008
   180        0.0286             nan     0.0500   -0.0004
   200        0.0251             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3300
     2        0.8994             nan     0.1000    0.2271
     3        0.7609             nan     0.1000    0.1622
     4        0.6613             nan     0.1000    0.1186
     5        0.5866             nan     0.1000    0.0902
     6        0.5270             nan     0.1000    0.0722
     7        0.4809             nan     0.1000    0.0549
     8        0.4442             nan     0.1000    0.0485
     9        0.4125             nan     0.1000    0.0378
    10        0.3868             nan     0.1000    0.0316
    20        0.2629             nan     0.1000    0.0055
    40        0.1865             nan     0.1000    0.0031
    60        0.1546             nan     0.1000   -0.0019
    80        0.1360             nan     0.1000   -0.0033
   100        0.1250             nan     0.1000   -0.0011
   120        0.1147             nan     0.1000   -0.0007
   140        0.1082             nan     0.1000   -0.0023
   160        0.1020             nan     0.1000   -0.0013
   180        0.0968             nan     0.1000   -0.0021
   200        0.0917             nan     0.1000   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3529
     2        0.8840             nan     0.1000    0.2431
     3        0.7366             nan     0.1000    0.1706
     4        0.6288             nan     0.1000    0.1313
     5        0.5469             nan     0.1000    0.0983
     6        0.4844             nan     0.1000    0.0793
     7        0.4324             nan     0.1000    0.0634
     8        0.3884             nan     0.1000    0.0482
     9        0.3548             nan     0.1000    0.0413
    10        0.3267             nan     0.1000    0.0309
    20        0.1884             nan     0.1000    0.0043
    40        0.1228             nan     0.1000   -0.0002
    60        0.0984             nan     0.1000   -0.0006
    80        0.0848             nan     0.1000   -0.0004
   100        0.0736             nan     0.1000   -0.0009
   120        0.0647             nan     0.1000   -0.0003
   140        0.0576             nan     0.1000   -0.0013
   160        0.0522             nan     0.1000   -0.0006
   180        0.0460             nan     0.1000   -0.0025
   200        0.0412             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3639
     2        0.8788             nan     0.1000    0.2451
     3        0.7244             nan     0.1000    0.1804
     4        0.6113             nan     0.1000    0.1370
     5        0.5218             nan     0.1000    0.0999
     6        0.4530             nan     0.1000    0.0695
     7        0.4031             nan     0.1000    0.0649
     8        0.3605             nan     0.1000    0.0563
     9        0.3223             nan     0.1000    0.0382
    10        0.2927             nan     0.1000    0.0317
    20        0.1589             nan     0.1000    0.0076
    40        0.0962             nan     0.1000   -0.0014
    60        0.0720             nan     0.1000   -0.0008
    80        0.0574             nan     0.1000   -0.0006
   100        0.0465             nan     0.1000   -0.0022
   120        0.0390             nan     0.1000   -0.0016
   140        0.0341             nan     0.1000   -0.0008
   160        0.0296             nan     0.1000   -0.0006
   180        0.0257             nan     0.1000   -0.0009
   200        0.0224             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3879
     2        0.8617             nan     0.1000    0.2647
     3        0.6996             nan     0.1000    0.1803
     4        0.5848             nan     0.1000    0.1343
     5        0.4966             nan     0.1000    0.1024
     6        0.4272             nan     0.1000    0.0749
     7        0.3746             nan     0.1000    0.0661
     8        0.3306             nan     0.1000    0.0564
     9        0.2922             nan     0.1000    0.0436
    10        0.2624             nan     0.1000    0.0307
    20        0.1340             nan     0.1000    0.0019
    40        0.0728             nan     0.1000   -0.0029
    60        0.0496             nan     0.1000   -0.0001
    80        0.0365             nan     0.1000   -0.0027
   100        0.0283             nan     0.1000   -0.0014
   120        0.0226             nan     0.1000   -0.0017
   140        0.0184             nan     0.1000   -0.0011
   160        0.0152             nan     0.1000   -0.0011
   180        0.0125             nan     0.1000   -0.0009
   200        0.0102             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5377
     2        0.7271             nan     0.2000    0.2418
     3        0.5551             nan     0.2000    0.1451
     4        0.4571             nan     0.2000    0.0882
     5        0.3964             nan     0.2000    0.0645
     6        0.3539             nan     0.2000    0.0352
     7        0.3240             nan     0.2000    0.0284
     8        0.3009             nan     0.2000    0.0176
     9        0.2777             nan     0.2000    0.0246
    10        0.2598             nan     0.2000    0.0199
    20        0.1821             nan     0.2000   -0.0006
    40        0.1391             nan     0.2000   -0.0047
    60        0.1175             nan     0.2000   -0.0072
    80        0.1052             nan     0.2000   -0.0014
   100        0.0958             nan     0.2000   -0.0008
   120        0.0891             nan     0.2000   -0.0031
   140        0.0814             nan     0.2000   -0.0020
   160        0.0753             nan     0.2000   -0.0021
   180        0.0703             nan     0.2000   -0.0039
   200        0.0666             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5954
     2        0.7104             nan     0.2000    0.2732
     3        0.5201             nan     0.2000    0.1554
     4        0.4122             nan     0.2000    0.0942
     5        0.3404             nan     0.2000    0.0455
     6        0.2951             nan     0.2000    0.0365
     7        0.2618             nan     0.2000    0.0260
     8        0.2302             nan     0.2000    0.0253
     9        0.2096             nan     0.2000    0.0097
    10        0.1949             nan     0.2000   -0.0018
    20        0.1271             nan     0.2000    0.0001
    40        0.0843             nan     0.2000   -0.0033
    60        0.0636             nan     0.2000   -0.0045
    80        0.0520             nan     0.2000   -0.0033
   100        0.0425             nan     0.2000   -0.0032
   120        0.0353             nan     0.2000   -0.0013
   140        0.0286             nan     0.2000   -0.0035
   160        0.0249             nan     0.2000   -0.0021
   180        0.0212             nan     0.2000   -0.0019
   200        0.0193             nan     0.2000   -0.0024

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5915
     2        0.6910             nan     0.2000    0.2852
     3        0.4883             nan     0.2000    0.1556
     4        0.3755             nan     0.2000    0.0900
     5        0.3080             nan     0.2000    0.0669
     6        0.2570             nan     0.2000    0.0390
     7        0.2259             nan     0.2000    0.0256
     8        0.2026             nan     0.2000    0.0212
     9        0.1834             nan     0.2000    0.0105
    10        0.1689             nan     0.2000    0.0160
    20        0.0985             nan     0.2000   -0.0070
    40        0.0608             nan     0.2000   -0.0055
    60        0.0408             nan     0.2000   -0.0018
    80        0.0298             nan     0.2000   -0.0016
   100        0.0235             nan     0.2000   -0.0022
   120        0.0184             nan     0.2000   -0.0004
   140        0.0150             nan     0.2000   -0.0011
   160        0.0118             nan     0.2000   -0.0020
   180        0.0099             nan     0.2000   -0.0017
   200        0.0085             nan     0.2000   -0.0019

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6047
     2        0.6828             nan     0.2000    0.3077
     3        0.4737             nan     0.2000    0.1726
     4        0.3517             nan     0.2000    0.0999
     5        0.2735             nan     0.2000    0.0637
     6        0.2245             nan     0.2000    0.0324
     7        0.1941             nan     0.2000    0.0321
     8        0.1686             nan     0.2000    0.0111
     9        0.1517             nan     0.2000    0.0057
    10        0.1366             nan     0.2000    0.0006
    20        0.0761             nan     0.2000   -0.0070
    40        0.0395             nan     0.2000   -0.0018
    60        0.0228             nan     0.2000   -0.0026
    80        0.0152             nan     0.2000   -0.0008
   100        0.0103             nan     0.2000   -0.0021
   120        0.0079             nan     0.2000   -0.0020
   140        0.0057             nan     0.2000   -0.0027
   160        0.0043             nan     0.2000   -0.0002
   180        0.0034             nan     0.2000   -0.0020
   200        0.0028             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1794
     2        0.9915             nan     0.0500    0.1484
     3        0.9037             nan     0.0500    0.1232
     4        0.8310             nan     0.0500    0.1040
     5        0.7680             nan     0.0500    0.0900
     6        0.7149             nan     0.0500    0.0775
     7        0.6673             nan     0.0500    0.0668
     8        0.6269             nan     0.0500    0.0581
     9        0.5907             nan     0.0500    0.0505
    10        0.5592             nan     0.0500    0.0437
    20        0.3804             nan     0.0500    0.0158
    40        0.2619             nan     0.0500    0.0035
    60        0.2133             nan     0.0500    0.0022
    80        0.1847             nan     0.0500    0.0004
   100        0.1661             nan     0.0500   -0.0028
   120        0.1542             nan     0.0500   -0.0006
   140        0.1429             nan     0.0500   -0.0001
   160        0.1350             nan     0.0500   -0.0008
   180        0.1292             nan     0.0500   -0.0005
   200        0.1246             nan     0.0500   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1941
     2        0.9877             nan     0.0500    0.1583
     3        0.8945             nan     0.0500    0.1329
     4        0.8150             nan     0.0500    0.1144
     5        0.7461             nan     0.0500    0.0959
     6        0.6867             nan     0.0500    0.0795
     7        0.6366             nan     0.0500    0.0715
     8        0.5907             nan     0.0500    0.0623
     9        0.5525             nan     0.0500    0.0527
    10        0.5189             nan     0.0500    0.0481
    20        0.3180             nan     0.0500    0.0157
    40        0.1893             nan     0.0500    0.0026
    60        0.1497             nan     0.0500    0.0004
    80        0.1261             nan     0.0500   -0.0010
   100        0.1126             nan     0.0500    0.0004
   120        0.1009             nan     0.0500   -0.0004
   140        0.0915             nan     0.0500   -0.0004
   160        0.0844             nan     0.0500   -0.0004
   180        0.0778             nan     0.0500   -0.0009
   200        0.0725             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1994
     2        0.9815             nan     0.0500    0.1672
     3        0.8831             nan     0.0500    0.1388
     4        0.8002             nan     0.0500    0.1164
     5        0.7288             nan     0.0500    0.0997
     6        0.6674             nan     0.0500    0.0857
     7        0.6137             nan     0.0500    0.0776
     8        0.5656             nan     0.0500    0.0652
     9        0.5248             nan     0.0500    0.0575
    10        0.4886             nan     0.0500    0.0499
    20        0.2804             nan     0.0500    0.0178
    40        0.1583             nan     0.0500    0.0027
    60        0.1195             nan     0.0500   -0.0017
    80        0.0992             nan     0.0500   -0.0005
   100        0.0852             nan     0.0500   -0.0007
   120        0.0737             nan     0.0500   -0.0007
   140        0.0662             nan     0.0500   -0.0006
   160        0.0600             nan     0.0500   -0.0006
   180        0.0540             nan     0.0500   -0.0004
   200        0.0492             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2077
     2        0.9759             nan     0.0500    0.1718
     3        0.8737             nan     0.0500    0.1383
     4        0.7891             nan     0.0500    0.1195
     5        0.7159             nan     0.0500    0.1017
     6        0.6530             nan     0.0500    0.0868
     7        0.5996             nan     0.0500    0.0799
     8        0.5501             nan     0.0500    0.0715
     9        0.5069             nan     0.0500    0.0591
    10        0.4697             nan     0.0500    0.0544
    20        0.2561             nan     0.0500    0.0162
    40        0.1315             nan     0.0500    0.0021
    60        0.0926             nan     0.0500   -0.0004
    80        0.0721             nan     0.0500   -0.0009
   100        0.0587             nan     0.0500   -0.0014
   120        0.0498             nan     0.0500   -0.0009
   140        0.0435             nan     0.0500   -0.0009
   160        0.0379             nan     0.0500   -0.0009
   180        0.0327             nan     0.0500   -0.0010
   200        0.0291             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3305
     2        0.8946             nan     0.1000    0.2215
     3        0.7525             nan     0.1000    0.1577
     4        0.6535             nan     0.1000    0.1166
     5        0.5787             nan     0.1000    0.0853
     6        0.5203             nan     0.1000    0.0650
     7        0.4752             nan     0.1000    0.0545
     8        0.4386             nan     0.1000    0.0423
     9        0.4079             nan     0.1000    0.0311
    10        0.3858             nan     0.1000    0.0228
    20        0.2609             nan     0.1000    0.0058
    40        0.1863             nan     0.1000   -0.0004
    60        0.1560             nan     0.1000   -0.0018
    80        0.1379             nan     0.1000   -0.0031
   100        0.1260             nan     0.1000   -0.0010
   120        0.1152             nan     0.1000   -0.0027
   140        0.1091             nan     0.1000   -0.0015
   160        0.1050             nan     0.1000    0.0001
   180        0.0983             nan     0.1000   -0.0018
   200        0.0942             nan     0.1000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3448
     2        0.8891             nan     0.1000    0.2458
     3        0.7384             nan     0.1000    0.1750
     4        0.6253             nan     0.1000    0.1287
     5        0.5388             nan     0.1000    0.0972
     6        0.4749             nan     0.1000    0.0765
     7        0.4227             nan     0.1000    0.0546
     8        0.3844             nan     0.1000    0.0453
     9        0.3513             nan     0.1000    0.0391
    10        0.3235             nan     0.1000    0.0329
    20        0.1915             nan     0.1000    0.0060
    40        0.1264             nan     0.1000    0.0005
    60        0.1028             nan     0.1000   -0.0018
    80        0.0841             nan     0.1000   -0.0004
   100        0.0730             nan     0.1000   -0.0015
   120        0.0645             nan     0.1000   -0.0012
   140        0.0572             nan     0.1000   -0.0014
   160        0.0515             nan     0.1000   -0.0017
   180        0.0460             nan     0.1000   -0.0010
   200        0.0422             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3612
     2        0.8777             nan     0.1000    0.2474
     3        0.7201             nan     0.1000    0.1855
     4        0.6069             nan     0.1000    0.1304
     5        0.5217             nan     0.1000    0.1039
     6        0.4533             nan     0.1000    0.0781
     7        0.4016             nan     0.1000    0.0655
     8        0.3579             nan     0.1000    0.0460
     9        0.3249             nan     0.1000    0.0357
    10        0.2962             nan     0.1000    0.0423
    20        0.1574             nan     0.1000    0.0022
    40        0.1020             nan     0.1000   -0.0007
    60        0.0789             nan     0.1000   -0.0016
    80        0.0626             nan     0.1000   -0.0022
   100        0.0540             nan     0.1000   -0.0018
   120        0.0455             nan     0.1000   -0.0014
   140        0.0391             nan     0.1000   -0.0016
   160        0.0344             nan     0.1000   -0.0014
   180        0.0297             nan     0.1000   -0.0007
   200        0.0256             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3880
     2        0.8630             nan     0.1000    0.2601
     3        0.7018             nan     0.1000    0.1868
     4        0.5838             nan     0.1000    0.1387
     5        0.4928             nan     0.1000    0.1092
     6        0.4227             nan     0.1000    0.0798
     7        0.3680             nan     0.1000    0.0617
     8        0.3256             nan     0.1000    0.0543
     9        0.2883             nan     0.1000    0.0386
    10        0.2614             nan     0.1000    0.0309
    20        0.1328             nan     0.1000    0.0023
    40        0.0749             nan     0.1000   -0.0023
    60        0.0508             nan     0.1000   -0.0026
    80        0.0391             nan     0.1000   -0.0019
   100        0.0299             nan     0.1000   -0.0010
   120        0.0231             nan     0.1000   -0.0001
   140        0.0190             nan     0.1000   -0.0006
   160        0.0159             nan     0.1000   -0.0010
   180        0.0135             nan     0.1000   -0.0020
   200        0.0118             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5466
     2        0.7324             nan     0.2000    0.2499
     3        0.5628             nan     0.2000    0.1439
     4        0.4643             nan     0.2000    0.0849
     5        0.3990             nan     0.2000    0.0644
     6        0.3540             nan     0.2000    0.0465
     7        0.3204             nan     0.2000    0.0309
     8        0.2956             nan     0.2000    0.0197
     9        0.2787             nan     0.2000    0.0262
    10        0.2540             nan     0.2000    0.0065
    20        0.1812             nan     0.2000    0.0039
    40        0.1352             nan     0.2000   -0.0028
    60        0.1163             nan     0.2000   -0.0018
    80        0.1013             nan     0.2000   -0.0031
   100        0.0932             nan     0.2000   -0.0030
   120        0.0854             nan     0.2000   -0.0022
   140        0.0803             nan     0.2000   -0.0023
   160        0.0752             nan     0.2000   -0.0025
   180        0.0700             nan     0.2000   -0.0022
   200        0.0660             nan     0.2000   -0.0024

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5828
     2        0.6987             nan     0.2000    0.2686
     3        0.5136             nan     0.2000    0.1363
     4        0.4064             nan     0.2000    0.0935
     5        0.3388             nan     0.2000    0.0578
     6        0.2913             nan     0.2000    0.0425
     7        0.2530             nan     0.2000    0.0354
     8        0.2255             nan     0.2000    0.0159
     9        0.2088             nan     0.2000    0.0223
    10        0.1906             nan     0.2000   -0.0010
    20        0.1278             nan     0.2000    0.0005
    40        0.0861             nan     0.2000   -0.0019
    60        0.0683             nan     0.2000   -0.0015
    80        0.0533             nan     0.2000   -0.0035
   100        0.0421             nan     0.2000   -0.0029
   120        0.0363             nan     0.2000   -0.0012
   140        0.0310             nan     0.2000   -0.0018
   160        0.0274             nan     0.2000   -0.0014
   180        0.0237             nan     0.2000   -0.0011
   200        0.0206             nan     0.2000   -0.0008

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5851
     2        0.6924             nan     0.2000    0.2759
     3        0.4974             nan     0.2000    0.1606
     4        0.3838             nan     0.2000    0.0988
     5        0.3134             nan     0.2000    0.0723
     6        0.2607             nan     0.2000    0.0508
     7        0.2222             nan     0.2000    0.0249
     8        0.1986             nan     0.2000    0.0150
     9        0.1792             nan     0.2000    0.0077
    10        0.1637             nan     0.2000    0.0030
    20        0.1054             nan     0.2000   -0.0053
    40        0.0671             nan     0.2000   -0.0011
    60        0.0471             nan     0.2000   -0.0025
    80        0.0367             nan     0.2000   -0.0044
   100        0.0289             nan     0.2000   -0.0034
   120        0.0244             nan     0.2000   -0.0045
   140        0.0194             nan     0.2000   -0.0010
   160        0.0152             nan     0.2000   -0.0029
   180        0.0132             nan     0.2000   -0.0009
   200        0.0121             nan     0.2000   -0.0027

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6144
     2        0.6771             nan     0.2000    0.3053
     3        0.4728             nan     0.2000    0.1645
     4        0.3562             nan     0.2000    0.0948
     5        0.2833             nan     0.2000    0.0605
     6        0.2358             nan     0.2000    0.0431
     7        0.1984             nan     0.2000    0.0283
     8        0.1713             nan     0.2000    0.0082
     9        0.1534             nan     0.2000    0.0040
    10        0.1408             nan     0.2000   -0.0081
    20        0.0762             nan     0.2000   -0.0027
    40        0.0412             nan     0.2000   -0.0049
    60        0.0249             nan     0.2000   -0.0019
    80        0.0163             nan     0.2000   -0.0021
   100        0.0124             nan     0.2000   -0.0047
   120        0.0097             nan     0.2000   -0.0020
   140        0.0081             nan     0.2000   -0.0024
   160        0.0069             nan     0.2000   -0.0029
   180        0.0055             nan     0.2000   -0.0004
   200        0.0047             nan     0.2000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1814
     2        0.9913             nan     0.0500    0.1492
     3        0.9037             nan     0.0500    0.1258
     4        0.8310             nan     0.0500    0.1061
     5        0.7678             nan     0.0500    0.0917
     6        0.7138             nan     0.0500    0.0793
     7        0.6672             nan     0.0500    0.0683
     8        0.6259             nan     0.0500    0.0588
     9        0.5892             nan     0.0500    0.0523
    10        0.5584             nan     0.0500    0.0439
    20        0.3762             nan     0.0500    0.0157
    40        0.2586             nan     0.0500    0.0029
    60        0.2124             nan     0.0500    0.0006
    80        0.1873             nan     0.0500   -0.0001
   100        0.1704             nan     0.0500   -0.0010
   120        0.1570             nan     0.0500   -0.0008
   140        0.1477             nan     0.0500   -0.0005
   160        0.1400             nan     0.0500   -0.0007
   180        0.1336             nan     0.0500   -0.0015
   200        0.1277             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1935
     2        0.9822             nan     0.0500    0.1602
     3        0.8882             nan     0.0500    0.1331
     4        0.8105             nan     0.0500    0.1129
     5        0.7421             nan     0.0500    0.0972
     6        0.6852             nan     0.0500    0.0849
     7        0.6345             nan     0.0500    0.0737
     8        0.5888             nan     0.0500    0.0608
     9        0.5491             nan     0.0500    0.0545
    10        0.5143             nan     0.0500    0.0510
    20        0.3152             nan     0.0500    0.0170
    40        0.1929             nan     0.0500    0.0030
    60        0.1533             nan     0.0500   -0.0000
    80        0.1311             nan     0.0500   -0.0002
   100        0.1147             nan     0.0500   -0.0006
   120        0.1034             nan     0.0500    0.0001
   140        0.0931             nan     0.0500   -0.0005
   160        0.0855             nan     0.0500    0.0001
   180        0.0792             nan     0.0500   -0.0007
   200        0.0737             nan     0.0500   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2038
     2        0.9817             nan     0.0500    0.1656
     3        0.8841             nan     0.0500    0.1361
     4        0.8021             nan     0.0500    0.1205
     5        0.7297             nan     0.0500    0.1011
     6        0.6680             nan     0.0500    0.0886
     7        0.6159             nan     0.0500    0.0733
     8        0.5693             nan     0.0500    0.0666
     9        0.5279             nan     0.0500    0.0587
    10        0.4916             nan     0.0500    0.0519
    20        0.2811             nan     0.0500    0.0156
    40        0.1592             nan     0.0500    0.0029
    60        0.1198             nan     0.0500    0.0009
    80        0.0987             nan     0.0500   -0.0009
   100        0.0845             nan     0.0500   -0.0018
   120        0.0737             nan     0.0500    0.0002
   140        0.0649             nan     0.0500   -0.0006
   160        0.0584             nan     0.0500   -0.0008
   180        0.0533             nan     0.0500   -0.0005
   200        0.0489             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2069
     2        0.9775             nan     0.0500    0.1705
     3        0.8759             nan     0.0500    0.1459
     4        0.7885             nan     0.0500    0.1243
     5        0.7154             nan     0.0500    0.1013
     6        0.6518             nan     0.0500    0.0907
     7        0.5965             nan     0.0500    0.0765
     8        0.5491             nan     0.0500    0.0671
     9        0.5065             nan     0.0500    0.0552
    10        0.4690             nan     0.0500    0.0511
    20        0.2560             nan     0.0500    0.0165
    40        0.1320             nan     0.0500    0.0013
    60        0.0931             nan     0.0500   -0.0006
    80        0.0712             nan     0.0500   -0.0008
   100        0.0583             nan     0.0500   -0.0014
   120        0.0491             nan     0.0500   -0.0005
   140        0.0412             nan     0.0500   -0.0010
   160        0.0350             nan     0.0500   -0.0005
   180        0.0300             nan     0.0500   -0.0008
   200        0.0265             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3332
     2        0.8986             nan     0.1000    0.2300
     3        0.7628             nan     0.1000    0.1636
     4        0.6553             nan     0.1000    0.1190
     5        0.5782             nan     0.1000    0.0894
     6        0.5198             nan     0.1000    0.0715
     7        0.4729             nan     0.1000    0.0564
     8        0.4370             nan     0.1000    0.0444
     9        0.4072             nan     0.1000    0.0351
    10        0.3825             nan     0.1000    0.0307
    20        0.2605             nan     0.1000    0.0058
    40        0.1864             nan     0.1000    0.0014
    60        0.1574             nan     0.1000   -0.0006
    80        0.1417             nan     0.1000   -0.0005
   100        0.1301             nan     0.1000   -0.0007
   120        0.1195             nan     0.1000   -0.0018
   140        0.1115             nan     0.1000   -0.0007
   160        0.1051             nan     0.1000   -0.0013
   180        0.0979             nan     0.1000   -0.0018
   200        0.0933             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3614
     2        0.8815             nan     0.1000    0.2435
     3        0.7312             nan     0.1000    0.1773
     4        0.6200             nan     0.1000    0.1303
     5        0.5372             nan     0.1000    0.1034
     6        0.4697             nan     0.1000    0.0800
     7        0.4193             nan     0.1000    0.0587
     8        0.3789             nan     0.1000    0.0494
     9        0.3450             nan     0.1000    0.0380
    10        0.3176             nan     0.1000    0.0308
    20        0.1930             nan     0.1000    0.0056
    40        0.1318             nan     0.1000   -0.0012
    60        0.1071             nan     0.1000   -0.0001
    80        0.0890             nan     0.1000   -0.0019
   100        0.0744             nan     0.1000   -0.0001
   120        0.0651             nan     0.1000   -0.0003
   140        0.0579             nan     0.1000   -0.0016
   160        0.0517             nan     0.1000   -0.0010
   180        0.0467             nan     0.1000   -0.0008
   200        0.0428             nan     0.1000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3651
     2        0.8736             nan     0.1000    0.2504
     3        0.7172             nan     0.1000    0.1772
     4        0.6042             nan     0.1000    0.1370
     5        0.5152             nan     0.1000    0.1028
     6        0.4490             nan     0.1000    0.0829
     7        0.3943             nan     0.1000    0.0628
     8        0.3519             nan     0.1000    0.0466
     9        0.3171             nan     0.1000    0.0405
    10        0.2889             nan     0.1000    0.0374
    20        0.1638             nan     0.1000    0.0083
    40        0.1016             nan     0.1000   -0.0021
    60        0.0770             nan     0.1000   -0.0011
    80        0.0609             nan     0.1000   -0.0025
   100        0.0504             nan     0.1000   -0.0011
   120        0.0419             nan     0.1000   -0.0023
   140        0.0356             nan     0.1000   -0.0020
   160        0.0297             nan     0.1000   -0.0008
   180        0.0263             nan     0.1000   -0.0010
   200        0.0230             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3701
     2        0.8657             nan     0.1000    0.2476
     3        0.7078             nan     0.1000    0.1852
     4        0.5909             nan     0.1000    0.1312
     5        0.5044             nan     0.1000    0.0990
     6        0.4354             nan     0.1000    0.0816
     7        0.3792             nan     0.1000    0.0666
     8        0.3330             nan     0.1000    0.0518
     9        0.2988             nan     0.1000    0.0428
    10        0.2667             nan     0.1000    0.0357
    20        0.1328             nan     0.1000    0.0035
    40        0.0732             nan     0.1000   -0.0015
    60        0.0493             nan     0.1000   -0.0016
    80        0.0368             nan     0.1000   -0.0014
   100        0.0283             nan     0.1000   -0.0007
   120        0.0222             nan     0.1000   -0.0007
   140        0.0181             nan     0.1000   -0.0013
   160        0.0146             nan     0.1000   -0.0011
   180        0.0121             nan     0.1000   -0.0011
   200        0.0102             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5530
     2        0.7299             nan     0.2000    0.2561
     3        0.5566             nan     0.2000    0.1472
     4        0.4561             nan     0.2000    0.0896
     5        0.3965             nan     0.2000    0.0553
     6        0.3517             nan     0.2000    0.0341
     7        0.3182             nan     0.2000    0.0375
     8        0.2921             nan     0.2000    0.0212
     9        0.2734             nan     0.2000    0.0129
    10        0.2587             nan     0.2000    0.0169
    20        0.1851             nan     0.2000    0.0015
    40        0.1392             nan     0.2000   -0.0018
    60        0.1175             nan     0.2000   -0.0028
    80        0.1048             nan     0.2000   -0.0009
   100        0.0942             nan     0.2000   -0.0005
   120        0.0839             nan     0.2000   -0.0021
   140        0.0789             nan     0.2000   -0.0048
   160        0.0724             nan     0.2000   -0.0021
   180        0.0707             nan     0.2000   -0.0056
   200        0.0666             nan     0.2000   -0.0033

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5800
     2        0.7015             nan     0.2000    0.2671
     3        0.5129             nan     0.2000    0.1561
     4        0.4005             nan     0.2000    0.0853
     5        0.3330             nan     0.2000    0.0581
     6        0.2857             nan     0.2000    0.0480
     7        0.2482             nan     0.2000    0.0230
     8        0.2233             nan     0.2000    0.0159
     9        0.2081             nan     0.2000    0.0015
    10        0.1964             nan     0.2000    0.0069
    20        0.1377             nan     0.2000   -0.0027
    40        0.0918             nan     0.2000   -0.0059
    60        0.0708             nan     0.2000   -0.0051
    80        0.0557             nan     0.2000   -0.0049
   100        0.0460             nan     0.2000   -0.0034
   120        0.0378             nan     0.2000   -0.0023
   140        0.0327             nan     0.2000   -0.0021
   160        0.0288             nan     0.2000   -0.0024
   180        0.0244             nan     0.2000   -0.0011
   200        0.0215             nan     0.2000   -0.0031

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5993
     2        0.6810             nan     0.2000    0.2750
     3        0.4859             nan     0.2000    0.1534
     4        0.3750             nan     0.2000    0.0934
     5        0.3042             nan     0.2000    0.0581
     6        0.2549             nan     0.2000    0.0356
     7        0.2229             nan     0.2000    0.0306
     8        0.1955             nan     0.2000    0.0090
     9        0.1775             nan     0.2000    0.0050
    10        0.1666             nan     0.2000    0.0013
    20        0.1108             nan     0.2000   -0.0014
    40        0.0681             nan     0.2000   -0.0033
    60        0.0480             nan     0.2000   -0.0085
    80        0.0354             nan     0.2000   -0.0032
   100        0.0262             nan     0.2000   -0.0028
   120        0.0204             nan     0.2000   -0.0021
   140        0.0167             nan     0.2000   -0.0036
   160        0.0128             nan     0.2000   -0.0007
   180        0.0107             nan     0.2000   -0.0002
   200        0.0092             nan     0.2000   -0.0016

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6156
     2        0.6813             nan     0.2000    0.3074
     3        0.4746             nan     0.2000    0.1705
     4        0.3539             nan     0.2000    0.0864
     5        0.2812             nan     0.2000    0.0504
     6        0.2349             nan     0.2000    0.0343
     7        0.2012             nan     0.2000    0.0177
     8        0.1769             nan     0.2000    0.0184
     9        0.1565             nan     0.2000    0.0021
    10        0.1416             nan     0.2000   -0.0108
    20        0.0808             nan     0.2000   -0.0014
    40        0.0400             nan     0.2000   -0.0044
    60        0.0232             nan     0.2000   -0.0028
    80        0.0153             nan     0.2000   -0.0022
   100        0.0107             nan     0.2000   -0.0011
   120        0.0078             nan     0.2000   -0.0005
   140        0.0057             nan     0.2000   -0.0007
   160        0.0044             nan     0.2000   -0.0002
   180        0.0035             nan     0.2000   -0.0002
   200        0.0039             nan     0.2000   -0.0200

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1782
     2        0.9965             nan     0.0500    0.1483
     3        0.9080             nan     0.0500    0.1230
     4        0.8337             nan     0.0500    0.1066
     5        0.7729             nan     0.0500    0.0910
     6        0.7189             nan     0.0500    0.0764
     7        0.6730             nan     0.0500    0.0672
     8        0.6300             nan     0.0500    0.0573
     9        0.5958             nan     0.0500    0.0515
    10        0.5643             nan     0.0500    0.0449
    20        0.3835             nan     0.0500    0.0154
    40        0.2660             nan     0.0500    0.0033
    60        0.2161             nan     0.0500    0.0014
    80        0.1897             nan     0.0500    0.0025
   100        0.1709             nan     0.0500   -0.0011
   120        0.1584             nan     0.0500   -0.0006
   140        0.1488             nan     0.0500   -0.0007
   160        0.1416             nan     0.0500   -0.0005
   180        0.1359             nan     0.0500   -0.0000
   200        0.1306             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1938
     2        0.9860             nan     0.0500    0.1582
     3        0.8927             nan     0.0500    0.1312
     4        0.8131             nan     0.0500    0.1086
     5        0.7483             nan     0.0500    0.0975
     6        0.6910             nan     0.0500    0.0828
     7        0.6415             nan     0.0500    0.0715
     8        0.5974             nan     0.0500    0.0629
     9        0.5580             nan     0.0500    0.0563
    10        0.5226             nan     0.0500    0.0485
    20        0.3206             nan     0.0500    0.0167
    40        0.1934             nan     0.0500    0.0038
    60        0.1532             nan     0.0500    0.0002
    80        0.1310             nan     0.0500   -0.0003
   100        0.1160             nan     0.0500   -0.0010
   120        0.1041             nan     0.0500   -0.0003
   140        0.0945             nan     0.0500   -0.0009
   160        0.0867             nan     0.0500   -0.0015
   180        0.0801             nan     0.0500   -0.0006
   200        0.0755             nan     0.0500   -0.0004

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1948
     2        0.9844             nan     0.0500    0.1656
     3        0.8859             nan     0.0500    0.1387
     4        0.8052             nan     0.0500    0.1173
     5        0.7367             nan     0.0500    0.0990
     6        0.6752             nan     0.0500    0.0880
     7        0.6215             nan     0.0500    0.0730
     8        0.5759             nan     0.0500    0.0647
     9        0.5354             nan     0.0500    0.0590
    10        0.4986             nan     0.0500    0.0487
    20        0.2883             nan     0.0500    0.0203
    40        0.1620             nan     0.0500    0.0016
    60        0.1225             nan     0.0500   -0.0003
    80        0.1024             nan     0.0500   -0.0011
   100        0.0888             nan     0.0500   -0.0002
   120        0.0774             nan     0.0500   -0.0011
   140        0.0682             nan     0.0500   -0.0009
   160        0.0608             nan     0.0500   -0.0006
   180        0.0554             nan     0.0500   -0.0005
   200        0.0504             nan     0.0500   -0.0000

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2065
     2        0.9765             nan     0.0500    0.1728
     3        0.8759             nan     0.0500    0.1407
     4        0.7912             nan     0.0500    0.1199
     5        0.7177             nan     0.0500    0.1043
     6        0.6543             nan     0.0500    0.0920
     7        0.5994             nan     0.0500    0.0812
     8        0.5506             nan     0.0500    0.0668
     9        0.5082             nan     0.0500    0.0584
    10        0.4720             nan     0.0500    0.0538
    20        0.2585             nan     0.0500    0.0144
    40        0.1363             nan     0.0500    0.0028
    60        0.0956             nan     0.0500   -0.0006
    80        0.0739             nan     0.0500   -0.0008
   100        0.0608             nan     0.0500   -0.0004
   120        0.0501             nan     0.0500   -0.0005
   140        0.0431             nan     0.0500   -0.0005
   160        0.0372             nan     0.0500   -0.0009
   180        0.0327             nan     0.0500   -0.0007
   200        0.0287             nan     0.0500   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3275
     2        0.8950             nan     0.1000    0.2241
     3        0.7600             nan     0.1000    0.1598
     4        0.6583             nan     0.1000    0.1121
     5        0.5865             nan     0.1000    0.0924
     6        0.5286             nan     0.1000    0.0701
     7        0.4841             nan     0.1000    0.0553
     8        0.4475             nan     0.1000    0.0463
     9        0.4166             nan     0.1000    0.0316
    10        0.3895             nan     0.1000    0.0283
    20        0.2665             nan     0.1000    0.0082
    40        0.1879             nan     0.1000    0.0019
    60        0.1574             nan     0.1000   -0.0004
    80        0.1409             nan     0.1000   -0.0007
   100        0.1296             nan     0.1000   -0.0006
   120        0.1206             nan     0.1000   -0.0007
   140        0.1121             nan     0.1000   -0.0019
   160        0.1053             nan     0.1000   -0.0007
   180        0.1005             nan     0.1000   -0.0014
   200        0.0966             nan     0.1000   -0.0028

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3519
     2        0.8812             nan     0.1000    0.2416
     3        0.7344             nan     0.1000    0.1720
     4        0.6248             nan     0.1000    0.1247
     5        0.5422             nan     0.1000    0.0949
     6        0.4798             nan     0.1000    0.0717
     7        0.4303             nan     0.1000    0.0601
     8        0.3895             nan     0.1000    0.0452
     9        0.3583             nan     0.1000    0.0450
    10        0.3274             nan     0.1000    0.0338
    20        0.1946             nan     0.1000    0.0106
    40        0.1291             nan     0.1000   -0.0023
    60        0.1025             nan     0.1000   -0.0034
    80        0.0853             nan     0.1000   -0.0013
   100        0.0725             nan     0.1000   -0.0006
   120        0.0636             nan     0.1000   -0.0017
   140        0.0568             nan     0.1000   -0.0009
   160        0.0512             nan     0.1000   -0.0013
   180        0.0476             nan     0.1000   -0.0006
   200        0.0432             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3634
     2        0.8811             nan     0.1000    0.2546
     3        0.7232             nan     0.1000    0.1834
     4        0.6077             nan     0.1000    0.1388
     5        0.5190             nan     0.1000    0.1008
     6        0.4510             nan     0.1000    0.0783
     7        0.3998             nan     0.1000    0.0608
     8        0.3576             nan     0.1000    0.0560
     9        0.3213             nan     0.1000    0.0365
    10        0.2938             nan     0.1000    0.0370
    20        0.1634             nan     0.1000    0.0017
    40        0.1051             nan     0.1000   -0.0012
    60        0.0793             nan     0.1000   -0.0014
    80        0.0638             nan     0.1000   -0.0012
   100        0.0528             nan     0.1000   -0.0001
   120        0.0445             nan     0.1000   -0.0019
   140        0.0379             nan     0.1000   -0.0017
   160        0.0331             nan     0.1000   -0.0008
   180        0.0292             nan     0.1000   -0.0008
   200        0.0260             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3680
     2        0.8678             nan     0.1000    0.2582
     3        0.7068             nan     0.1000    0.1877
     4        0.5877             nan     0.1000    0.1342
     5        0.4982             nan     0.1000    0.0999
     6        0.4326             nan     0.1000    0.0783
     7        0.3798             nan     0.1000    0.0607
     8        0.3364             nan     0.1000    0.0449
     9        0.3019             nan     0.1000    0.0408
    10        0.2720             nan     0.1000    0.0350
    20        0.1406             nan     0.1000    0.0003
    40        0.0767             nan     0.1000    0.0002
    60        0.0533             nan     0.1000   -0.0021
    80        0.0373             nan     0.1000   -0.0012
   100        0.0285             nan     0.1000   -0.0019
   120        0.0232             nan     0.1000   -0.0011
   140        0.0189             nan     0.1000   -0.0015
   160        0.0161             nan     0.1000   -0.0018
   180        0.0138             nan     0.1000   -0.0008
   200        0.0117             nan     0.1000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5609
     2        0.7462             nan     0.2000    0.2649
     3        0.5729             nan     0.2000    0.1330
     4        0.4707             nan     0.2000    0.0845
     5        0.4080             nan     0.2000    0.0645
     6        0.3621             nan     0.2000    0.0374
     7        0.3318             nan     0.2000    0.0387
     8        0.2969             nan     0.2000    0.0240
     9        0.2786             nan     0.2000    0.0195
    10        0.2636             nan     0.2000    0.0237
    20        0.1853             nan     0.2000   -0.0033
    40        0.1437             nan     0.2000   -0.0081
    60        0.1269             nan     0.2000   -0.0014
    80        0.1108             nan     0.2000   -0.0024
   100        0.0999             nan     0.2000   -0.0027
   120        0.0935             nan     0.2000   -0.0036
   140        0.0855             nan     0.2000   -0.0054
   160        0.0797             nan     0.2000   -0.0076
   180        0.0742             nan     0.2000   -0.0083
   200        0.0683             nan     0.2000   -0.0015

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5887
     2        0.7106             nan     0.2000    0.2673
     3        0.5247             nan     0.2000    0.1639
     4        0.4136             nan     0.2000    0.0868
     5        0.3445             nan     0.2000    0.0667
     6        0.2946             nan     0.2000    0.0495
     7        0.2566             nan     0.2000    0.0310
     8        0.2318             nan     0.2000    0.0080
     9        0.2167             nan     0.2000    0.0093
    10        0.2011             nan     0.2000    0.0051
    20        0.1424             nan     0.2000   -0.0047
    40        0.0957             nan     0.2000   -0.0042
    60        0.0716             nan     0.2000   -0.0013
    80        0.0580             nan     0.2000   -0.0057
   100        0.0479             nan     0.2000   -0.0053
   120        0.0394             nan     0.2000   -0.0027
   140        0.0345             nan     0.2000   -0.0017
   160        0.0290             nan     0.2000   -0.0030
   180        0.0256             nan     0.2000   -0.0025
   200        0.0232             nan     0.2000   -0.0023

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6098
     2        0.6861             nan     0.2000    0.2685
     3        0.4920             nan     0.2000    0.1338
     4        0.3805             nan     0.2000    0.0934
     5        0.3106             nan     0.2000    0.0667
     6        0.2584             nan     0.2000    0.0375
     7        0.2254             nan     0.2000    0.0227
     8        0.2011             nan     0.2000    0.0141
     9        0.1842             nan     0.2000    0.0079
    10        0.1699             nan     0.2000    0.0052
    20        0.1067             nan     0.2000   -0.0047
    40        0.0658             nan     0.2000   -0.0013
    60        0.0438             nan     0.2000   -0.0073
    80        0.0322             nan     0.2000   -0.0026
   100        0.0240             nan     0.2000   -0.0017
   120        0.0195             nan     0.2000   -0.0023
   140        0.0166             nan     0.2000   -0.0028
   160        0.0143             nan     0.2000   -0.0031
   180        0.0126             nan     0.2000   -0.0019
   200        0.0108             nan     0.2000   -0.0022

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6174
     2        0.6755             nan     0.2000    0.2735
     3        0.4815             nan     0.2000    0.1733
     4        0.3627             nan     0.2000    0.0954
     5        0.2917             nan     0.2000    0.0590
     6        0.2399             nan     0.2000    0.0214
     7        0.2109             nan     0.2000    0.0240
     8        0.1790             nan     0.2000    0.0035
     9        0.1567             nan     0.2000    0.0084
    10        0.1392             nan     0.2000    0.0087
    20        0.0761             nan     0.2000   -0.0067
    40        0.0385             nan     0.2000   -0.0050
    60        0.0241             nan     0.2000   -0.0023
    80        0.0163             nan     0.2000   -0.0023
   100        0.0119             nan     0.2000   -0.0072
   120        0.0095             nan     0.2000   -0.0025
   140        0.0076             nan     0.2000   -0.0041
   160        0.0065             nan     0.2000   -0.0014
   180        0.0055             nan     0.2000   -0.0000
   200        0.0048             nan     0.2000   -0.0041

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1808
     2        0.9933             nan     0.0500    0.1484
     3        0.9060             nan     0.0500    0.1254
     4        0.8298             nan     0.0500    0.1061
     5        0.7657             nan     0.0500    0.0899
     6        0.7116             nan     0.0500    0.0770
     7        0.6648             nan     0.0500    0.0649
     8        0.6236             nan     0.0500    0.0588
     9        0.5870             nan     0.0500    0.0505
    10        0.5564             nan     0.0500    0.0452
    20        0.3761             nan     0.0500    0.0135
    40        0.2567             nan     0.0500    0.0061
    60        0.2112             nan     0.0500    0.0003
    80        0.1859             nan     0.0500    0.0005
   100        0.1667             nan     0.0500    0.0001
   120        0.1553             nan     0.0500   -0.0011
   140        0.1464             nan     0.0500   -0.0001
   160        0.1381             nan     0.0500    0.0006
   180        0.1311             nan     0.0500   -0.0008
   200        0.1264             nan     0.0500   -0.0012

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1936
     2        0.9858             nan     0.0500    0.1574
     3        0.8929             nan     0.0500    0.1342
     4        0.8130             nan     0.0500    0.1159
     5        0.7422             nan     0.0500    0.1005
     6        0.6831             nan     0.0500    0.0830
     7        0.6308             nan     0.0500    0.0738
     8        0.5852             nan     0.0500    0.0627
     9        0.5472             nan     0.0500    0.0556
    10        0.5121             nan     0.0500    0.0481
    20        0.3115             nan     0.0500    0.0151
    40        0.1902             nan     0.0500    0.0013
    60        0.1524             nan     0.0500   -0.0006
    80        0.1295             nan     0.0500   -0.0003
   100        0.1153             nan     0.0500   -0.0005
   120        0.1034             nan     0.0500   -0.0012
   140        0.0929             nan     0.0500    0.0003
   160        0.0845             nan     0.0500   -0.0016
   180        0.0779             nan     0.0500   -0.0008
   200        0.0728             nan     0.0500   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2023
     2        0.9812             nan     0.0500    0.1636
     3        0.8853             nan     0.0500    0.1415
     4        0.8027             nan     0.0500    0.1208
     5        0.7321             nan     0.0500    0.1015
     6        0.6709             nan     0.0500    0.0886
     7        0.6171             nan     0.0500    0.0778
     8        0.5694             nan     0.0500    0.0664
     9        0.5281             nan     0.0500    0.0570
    10        0.4924             nan     0.0500    0.0510
    20        0.2807             nan     0.0500    0.0189
    40        0.1572             nan     0.0500    0.0021
    60        0.1185             nan     0.0500   -0.0000
    80        0.0985             nan     0.0500   -0.0028
   100        0.0857             nan     0.0500   -0.0011
   120        0.0762             nan     0.0500   -0.0008
   140        0.0674             nan     0.0500   -0.0013
   160        0.0605             nan     0.0500   -0.0014
   180        0.0555             nan     0.0500   -0.0003
   200        0.0501             nan     0.0500   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2057
     2        0.9765             nan     0.0500    0.1724
     3        0.8763             nan     0.0500    0.1443
     4        0.7903             nan     0.0500    0.1228
     5        0.7173             nan     0.0500    0.1035
     6        0.6534             nan     0.0500    0.0861
     7        0.5994             nan     0.0500    0.0802
     8        0.5507             nan     0.0500    0.0691
     9        0.5079             nan     0.0500    0.0627
    10        0.4699             nan     0.0500    0.0543
    20        0.2529             nan     0.0500    0.0162
    40        0.1338             nan     0.0500    0.0011
    60        0.0938             nan     0.0500   -0.0016
    80        0.0721             nan     0.0500   -0.0013
   100        0.0592             nan     0.0500   -0.0013
   120        0.0499             nan     0.0500   -0.0009
   140        0.0425             nan     0.0500   -0.0004
   160        0.0366             nan     0.0500   -0.0003
   180        0.0313             nan     0.0500   -0.0005
   200        0.0278             nan     0.0500   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3323
     2        0.8980             nan     0.1000    0.2287
     3        0.7567             nan     0.1000    0.1624
     4        0.6553             nan     0.1000    0.1202
     5        0.5777             nan     0.1000    0.0899
     6        0.5194             nan     0.1000    0.0687
     7        0.4759             nan     0.1000    0.0568
     8        0.4396             nan     0.1000    0.0428
     9        0.4089             nan     0.1000    0.0389
    10        0.3840             nan     0.1000    0.0272
    20        0.2588             nan     0.1000    0.0097
    40        0.1861             nan     0.1000    0.0012
    60        0.1569             nan     0.1000    0.0003
    80        0.1413             nan     0.1000   -0.0001
   100        0.1281             nan     0.1000   -0.0021
   120        0.1198             nan     0.1000   -0.0017
   140        0.1110             nan     0.1000   -0.0006
   160        0.1051             nan     0.1000   -0.0008
   180        0.0994             nan     0.1000   -0.0002
   200        0.0958             nan     0.1000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3574
     2        0.8787             nan     0.1000    0.2378
     3        0.7278             nan     0.1000    0.1696
     4        0.6178             nan     0.1000    0.1271
     5        0.5348             nan     0.1000    0.0926
     6        0.4718             nan     0.1000    0.0755
     7        0.4215             nan     0.1000    0.0598
     8        0.3807             nan     0.1000    0.0505
     9        0.3470             nan     0.1000    0.0421
    10        0.3181             nan     0.1000    0.0286
    20        0.1913             nan     0.1000    0.0079
    40        0.1310             nan     0.1000    0.0000
    60        0.1036             nan     0.1000   -0.0018
    80        0.0863             nan     0.1000   -0.0015
   100        0.0740             nan     0.1000   -0.0027
   120        0.0635             nan     0.1000   -0.0015
   140        0.0587             nan     0.1000   -0.0011
   160        0.0522             nan     0.1000   -0.0005
   180        0.0469             nan     0.1000   -0.0002
   200        0.0430             nan     0.1000   -0.0014

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3755
     2        0.8731             nan     0.1000    0.2543
     3        0.7178             nan     0.1000    0.1839
     4        0.6034             nan     0.1000    0.1356
     5        0.5182             nan     0.1000    0.1047
     6        0.4492             nan     0.1000    0.0820
     7        0.3976             nan     0.1000    0.0671
     8        0.3518             nan     0.1000    0.0473
     9        0.3181             nan     0.1000    0.0445
    10        0.2878             nan     0.1000    0.0343
    20        0.1598             nan     0.1000    0.0074
    40        0.1020             nan     0.1000   -0.0009
    60        0.0751             nan     0.1000   -0.0017
    80        0.0585             nan     0.1000   -0.0016
   100        0.0480             nan     0.1000   -0.0010
   120        0.0405             nan     0.1000   -0.0007
   140        0.0346             nan     0.1000   -0.0016
   160        0.0302             nan     0.1000   -0.0021
   180        0.0268             nan     0.1000   -0.0006
   200        0.0242             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3673
     2        0.8695             nan     0.1000    0.2684
     3        0.7054             nan     0.1000    0.1921
     4        0.5861             nan     0.1000    0.1469
     5        0.4936             nan     0.1000    0.1086
     6        0.4237             nan     0.1000    0.0809
     7        0.3700             nan     0.1000    0.0594
     8        0.3263             nan     0.1000    0.0475
     9        0.2925             nan     0.1000    0.0391
    10        0.2648             nan     0.1000    0.0267
    20        0.1311             nan     0.1000    0.0034
    40        0.0750             nan     0.1000   -0.0024
    60        0.0526             nan     0.1000   -0.0039
    80        0.0400             nan     0.1000   -0.0028
   100        0.0300             nan     0.1000   -0.0024
   120        0.0239             nan     0.1000   -0.0014
   140        0.0195             nan     0.1000   -0.0009
   160        0.0162             nan     0.1000   -0.0016
   180        0.0137             nan     0.1000   -0.0008
   200        0.0119             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5515
     2        0.7345             nan     0.2000    0.2579
     3        0.5572             nan     0.2000    0.1317
     4        0.4586             nan     0.2000    0.0674
     5        0.3976             nan     0.2000    0.0659
     6        0.3536             nan     0.2000    0.0283
     7        0.3170             nan     0.2000    0.0328
     8        0.2927             nan     0.2000    0.0204
     9        0.2749             nan     0.2000    0.0110
    10        0.2594             nan     0.2000    0.0129
    20        0.1836             nan     0.2000    0.0026
    40        0.1358             nan     0.2000   -0.0032
    60        0.1167             nan     0.2000   -0.0021
    80        0.1058             nan     0.2000   -0.0048
   100        0.0963             nan     0.2000   -0.0011
   120        0.0882             nan     0.2000   -0.0041
   140        0.0801             nan     0.2000   -0.0072
   160        0.0730             nan     0.2000   -0.0013
   180        0.0685             nan     0.2000   -0.0018
   200        0.0645             nan     0.2000   -0.0020

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5878
     2        0.7010             nan     0.2000    0.2636
     3        0.5159             nan     0.2000    0.1568
     4        0.4055             nan     0.2000    0.0962
     5        0.3335             nan     0.2000    0.0551
     6        0.2897             nan     0.2000    0.0467
     7        0.2557             nan     0.2000    0.0273
     8        0.2265             nan     0.2000    0.0166
     9        0.2100             nan     0.2000    0.0073
    10        0.1963             nan     0.2000    0.0185
    20        0.1331             nan     0.2000    0.0026
    40        0.0884             nan     0.2000   -0.0047
    60        0.0674             nan     0.2000   -0.0034
    80        0.0532             nan     0.2000   -0.0048
   100        0.0445             nan     0.2000   -0.0021
   120        0.0371             nan     0.2000   -0.0027
   140        0.0313             nan     0.2000   -0.0005
   160        0.0272             nan     0.2000   -0.0017
   180        0.0236             nan     0.2000   -0.0011
   200        0.0209             nan     0.2000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6007
     2        0.6933             nan     0.2000    0.2832
     3        0.5004             nan     0.2000    0.1721
     4        0.3786             nan     0.2000    0.0902
     5        0.3097             nan     0.2000    0.0676
     6        0.2589             nan     0.2000    0.0305
     7        0.2258             nan     0.2000    0.0024
     8        0.2007             nan     0.2000    0.0189
     9        0.1801             nan     0.2000    0.0063
    10        0.1661             nan     0.2000    0.0004
    20        0.1075             nan     0.2000    0.0008
    40        0.0659             nan     0.2000   -0.0072
    60        0.0461             nan     0.2000   -0.0045
    80        0.0338             nan     0.2000   -0.0033
   100        0.0274             nan     0.2000   -0.0000
   120        0.0213             nan     0.2000   -0.0012
   140        0.0185             nan     0.2000   -0.0010
   160        0.0156             nan     0.2000   -0.0008
   180        0.0140             nan     0.2000   -0.0026
   200        0.0121             nan     0.2000   -0.0025

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6153
     2        0.6801             nan     0.2000    0.2844
     3        0.4772             nan     0.2000    0.1554
     4        0.3614             nan     0.2000    0.0899
     5        0.2895             nan     0.2000    0.0590
     6        0.2375             nan     0.2000    0.0311
     7        0.2049             nan     0.2000    0.0180
     8        0.1681             nan     0.2000    0.0083
     9        0.1494             nan     0.2000    0.0099
    10        0.1346             nan     0.2000   -0.0038
    20        0.0760             nan     0.2000   -0.0015
    40        0.0376             nan     0.2000   -0.0057
    60        0.0242             nan     0.2000   -0.0039
    80        0.0166             nan     0.2000   -0.0036
   100        0.0134             nan     0.2000   -0.0017
   120        0.0096             nan     0.2000   -0.0015
   140        0.0080             nan     0.2000   -0.0011
   160        0.0065             nan     0.2000   -0.0024
   180        0.0054             nan     0.2000   -0.0014
   200        0.0054             nan     0.2000   -0.0032

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1852
     2        0.9925             nan     0.0500    0.1530
     3        0.9051             nan     0.0500    0.1254
     4        0.8307             nan     0.0500    0.1086
     5        0.7660             nan     0.0500    0.0906
     6        0.7096             nan     0.0500    0.0807
     7        0.6616             nan     0.0500    0.0689
     8        0.6194             nan     0.0500    0.0607
     9        0.5833             nan     0.0500    0.0527
    10        0.5514             nan     0.0500    0.0449
    20        0.3684             nan     0.0500    0.0122
    40        0.2521             nan     0.0500    0.0035
    60        0.2061             nan     0.0500    0.0005
    80        0.1794             nan     0.0500    0.0010
   100        0.1620             nan     0.0500   -0.0006
   120        0.1486             nan     0.0500   -0.0002
   140        0.1400             nan     0.0500    0.0008
   160        0.1312             nan     0.0500   -0.0005
   180        0.1246             nan     0.0500   -0.0005
   200        0.1187             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1942
     2        0.9842             nan     0.0500    0.1618
     3        0.8897             nan     0.0500    0.1339
     4        0.8099             nan     0.0500    0.1140
     5        0.7419             nan     0.0500    0.0979
     6        0.6828             nan     0.0500    0.0853
     7        0.6299             nan     0.0500    0.0734
     8        0.5850             nan     0.0500    0.0604
     9        0.5468             nan     0.0500    0.0563
    10        0.5117             nan     0.0500    0.0494
    20        0.3103             nan     0.0500    0.0182
    40        0.1853             nan     0.0500    0.0004
    60        0.1445             nan     0.0500    0.0009
    80        0.1228             nan     0.0500    0.0000
   100        0.1077             nan     0.0500    0.0003
   120        0.0963             nan     0.0500   -0.0005
   140        0.0880             nan     0.0500   -0.0003
   160        0.0812             nan     0.0500   -0.0010
   180        0.0749             nan     0.0500   -0.0006
   200        0.0691             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2048
     2        0.9796             nan     0.0500    0.1693
     3        0.8820             nan     0.0500    0.1416
     4        0.7983             nan     0.0500    0.1198
     5        0.7268             nan     0.0500    0.1028
     6        0.6649             nan     0.0500    0.0824
     7        0.6136             nan     0.0500    0.0768
     8        0.5657             nan     0.0500    0.0685
     9        0.5232             nan     0.0500    0.0575
    10        0.4880             nan     0.0500    0.0517
    20        0.2790             nan     0.0500    0.0142
    40        0.1545             nan     0.0500    0.0001
    60        0.1149             nan     0.0500   -0.0007
    80        0.0939             nan     0.0500   -0.0012
   100        0.0811             nan     0.0500   -0.0013
   120        0.0714             nan     0.0500   -0.0006
   140        0.0634             nan     0.0500   -0.0011
   160        0.0570             nan     0.0500   -0.0007
   180        0.0513             nan     0.0500   -0.0000
   200        0.0460             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2117
     2        0.9744             nan     0.0500    0.1741
     3        0.8731             nan     0.0500    0.1452
     4        0.7868             nan     0.0500    0.1230
     5        0.7118             nan     0.0500    0.1049
     6        0.6487             nan     0.0500    0.0914
     7        0.5933             nan     0.0500    0.0776
     8        0.5461             nan     0.0500    0.0660
     9        0.5037             nan     0.0500    0.0588
    10        0.4662             nan     0.0500    0.0537
    20        0.2510             nan     0.0500    0.0161
    40        0.1269             nan     0.0500    0.0010
    60        0.0874             nan     0.0500   -0.0013
    80        0.0674             nan     0.0500   -0.0011
   100        0.0557             nan     0.0500   -0.0001
   120        0.0464             nan     0.0500   -0.0026
   140        0.0399             nan     0.0500   -0.0005
   160        0.0342             nan     0.0500   -0.0007
   180        0.0293             nan     0.0500   -0.0007
   200        0.0255             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3396
     2        0.8926             nan     0.1000    0.2270
     3        0.7502             nan     0.1000    0.1660
     4        0.6475             nan     0.1000    0.1182
     5        0.5729             nan     0.1000    0.0938
     6        0.5158             nan     0.1000    0.0700
     7        0.4702             nan     0.1000    0.0557
     8        0.4321             nan     0.1000    0.0447
     9        0.4010             nan     0.1000    0.0303
    10        0.3794             nan     0.1000    0.0288
    20        0.2546             nan     0.1000    0.0074
    40        0.1851             nan     0.1000    0.0023
    60        0.1514             nan     0.1000   -0.0017
    80        0.1316             nan     0.1000   -0.0025
   100        0.1204             nan     0.1000   -0.0011
   120        0.1102             nan     0.1000   -0.0007
   140        0.1024             nan     0.1000   -0.0015
   160        0.0962             nan     0.1000   -0.0020
   180        0.0920             nan     0.1000   -0.0014
   200        0.0873             nan     0.1000   -0.0021

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3579
     2        0.8788             nan     0.1000    0.2432
     3        0.7299             nan     0.1000    0.1741
     4        0.6230             nan     0.1000    0.1351
     5        0.5393             nan     0.1000    0.0980
     6        0.4760             nan     0.1000    0.0732
     7        0.4230             nan     0.1000    0.0576
     8        0.3818             nan     0.1000    0.0475
     9        0.3480             nan     0.1000    0.0419
    10        0.3196             nan     0.1000    0.0309
    20        0.1873             nan     0.1000    0.0061
    40        0.1250             nan     0.1000    0.0006
    60        0.0965             nan     0.1000   -0.0018
    80        0.0809             nan     0.1000   -0.0002
   100        0.0675             nan     0.1000   -0.0023
   120        0.0595             nan     0.1000   -0.0011
   140        0.0527             nan     0.1000   -0.0017
   160        0.0482             nan     0.1000   -0.0015
   180        0.0426             nan     0.1000   -0.0009
   200        0.0380             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3685
     2        0.8729             nan     0.1000    0.2548
     3        0.7146             nan     0.1000    0.1800
     4        0.5999             nan     0.1000    0.1311
     5        0.5119             nan     0.1000    0.1011
     6        0.4456             nan     0.1000    0.0792
     7        0.3921             nan     0.1000    0.0629
     8        0.3491             nan     0.1000    0.0438
     9        0.3166             nan     0.1000    0.0414
    10        0.2866             nan     0.1000    0.0257
    20        0.1554             nan     0.1000    0.0041
    40        0.0968             nan     0.1000   -0.0011
    60        0.0726             nan     0.1000   -0.0005
    80        0.0577             nan     0.1000   -0.0014
   100        0.0477             nan     0.1000   -0.0014
   120        0.0397             nan     0.1000   -0.0006
   140        0.0333             nan     0.1000   -0.0006
   160        0.0287             nan     0.1000   -0.0011
   180        0.0236             nan     0.1000   -0.0010
   200        0.0212             nan     0.1000   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3846
     2        0.8657             nan     0.1000    0.2614
     3        0.7031             nan     0.1000    0.1895
     4        0.5803             nan     0.1000    0.1414
     5        0.4919             nan     0.1000    0.1028
     6        0.4257             nan     0.1000    0.0844
     7        0.3703             nan     0.1000    0.0678
     8        0.3232             nan     0.1000    0.0532
     9        0.2875             nan     0.1000    0.0421
    10        0.2579             nan     0.1000    0.0296
    20        0.1289             nan     0.1000    0.0016
    40        0.0714             nan     0.1000   -0.0054
    60        0.0467             nan     0.1000   -0.0010
    80        0.0339             nan     0.1000   -0.0008
   100        0.0254             nan     0.1000   -0.0012
   120        0.0195             nan     0.1000   -0.0004
   140        0.0148             nan     0.1000   -0.0010
   160        0.0121             nan     0.1000   -0.0003
   180        0.0101             nan     0.1000   -0.0006
   200        0.0084             nan     0.1000   -0.0003

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5544
     2        0.7205             nan     0.2000    0.2489
     3        0.5459             nan     0.2000    0.1318
     4        0.4475             nan     0.2000    0.0874
     5        0.3858             nan     0.2000    0.0485
     6        0.3431             nan     0.2000    0.0400
     7        0.3130             nan     0.2000    0.0354
     8        0.2873             nan     0.2000    0.0270
     9        0.2675             nan     0.2000    0.0144
    10        0.2549             nan     0.2000    0.0103
    20        0.1751             nan     0.2000   -0.0014
    40        0.1317             nan     0.2000    0.0022
    60        0.1104             nan     0.2000   -0.0044
    80        0.0976             nan     0.2000   -0.0001
   100        0.0880             nan     0.2000   -0.0026
   120        0.0795             nan     0.2000   -0.0021
   140        0.0720             nan     0.2000   -0.0014
   160        0.0653             nan     0.2000   -0.0044
   180        0.0608             nan     0.2000   -0.0086
   200        0.0564             nan     0.2000   -0.0032

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5939
     2        0.7025             nan     0.2000    0.2816
     3        0.5123             nan     0.2000    0.1504
     4        0.3989             nan     0.2000    0.0962
     5        0.3294             nan     0.2000    0.0578
     6        0.2793             nan     0.2000    0.0391
     7        0.2460             nan     0.2000    0.0191
     8        0.2248             nan     0.2000    0.0193
     9        0.2066             nan     0.2000    0.0099
    10        0.1903             nan     0.2000    0.0119
    20        0.1229             nan     0.2000   -0.0062
    40        0.0873             nan     0.2000   -0.0046
    60        0.0650             nan     0.2000   -0.0072
    80        0.0519             nan     0.2000   -0.0068
   100        0.0423             nan     0.2000   -0.0021
   120        0.0350             nan     0.2000   -0.0040
   140        0.0294             nan     0.2000   -0.0017
   160        0.0262             nan     0.2000   -0.0012
   180        0.0226             nan     0.2000   -0.0022
   200        0.0195             nan     0.2000   -0.0013

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5991
     2        0.6895             nan     0.2000    0.2910
     3        0.4905             nan     0.2000    0.1631
     4        0.3768             nan     0.2000    0.0954
     5        0.3062             nan     0.2000    0.0536
     6        0.2599             nan     0.2000    0.0549
     7        0.2190             nan     0.2000    0.0183
     8        0.1956             nan     0.2000    0.0198
     9        0.1731             nan     0.2000   -0.0012
    10        0.1619             nan     0.2000   -0.0124
    20        0.0971             nan     0.2000   -0.0047
    40        0.0607             nan     0.2000   -0.0021
    60        0.0417             nan     0.2000   -0.0044
    80        0.0308             nan     0.2000   -0.0028
   100        0.0230             nan     0.2000   -0.0032
   120        0.0180             nan     0.2000   -0.0009
   140        0.0147             nan     0.2000   -0.0017
   160        0.0113             nan     0.2000   -0.0012
   180        0.0093             nan     0.2000   -0.0003
   200        0.0083             nan     0.2000   -0.0018

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5962
     2        0.6817             nan     0.2000    0.2893
     3        0.4778             nan     0.2000    0.1549
     4        0.3613             nan     0.2000    0.1105
     5        0.2803             nan     0.2000    0.0657
     6        0.2318             nan     0.2000    0.0388
     7        0.1941             nan     0.2000    0.0147
     8        0.1710             nan     0.2000    0.0105
     9        0.1518             nan     0.2000   -0.0117
    10        0.1414             nan     0.2000    0.0060
    20        0.0698             nan     0.2000   -0.0068
    40        0.0344             nan     0.2000   -0.0023
    60        0.0218             nan     0.2000   -0.0017
    80        0.0133             nan     0.2000   -0.0035
   100        0.0097             nan     0.2000   -0.0004
   120        0.0069             nan     0.2000   -0.0030
   140        0.0056             nan     0.2000   -0.0008
   160        0.0045             nan     0.2000   -0.0000
   180        0.0037             nan     0.2000   -0.0010
   200        0.0028             nan     0.2000   -0.0001

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1784
     2        0.9934             nan     0.0500    0.1479
     3        0.9086             nan     0.0500    0.1244
     4        0.8356             nan     0.0500    0.1058
     5        0.7729             nan     0.0500    0.0894
     6        0.7192             nan     0.0500    0.0776
     7        0.6720             nan     0.0500    0.0669
     8        0.6325             nan     0.0500    0.0573
     9        0.5969             nan     0.0500    0.0516
    10        0.5655             nan     0.0500    0.0447
    20        0.3851             nan     0.0500    0.0153
    40        0.2673             nan     0.0500    0.0039
    60        0.2201             nan     0.0500    0.0016
    80        0.1942             nan     0.0500   -0.0010
   100        0.1769             nan     0.0500    0.0003
   120        0.1640             nan     0.0500   -0.0000
   140        0.1526             nan     0.0500   -0.0006
   160        0.1435             nan     0.0500   -0.0007
   180        0.1377             nan     0.0500   -0.0006
   200        0.1315             nan     0.0500   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1920
     2        0.9852             nan     0.0500    0.1585
     3        0.8902             nan     0.0500    0.1321
     4        0.8116             nan     0.0500    0.1119
     5        0.7443             nan     0.0500    0.0951
     6        0.6863             nan     0.0500    0.0827
     7        0.6356             nan     0.0500    0.0708
     8        0.5902             nan     0.0500    0.0624
     9        0.5519             nan     0.0500    0.0536
    10        0.5175             nan     0.0500    0.0474
    20        0.3172             nan     0.0500    0.0173
    40        0.1963             nan     0.0500    0.0012
    60        0.1579             nan     0.0500    0.0009
    80        0.1348             nan     0.0500   -0.0007
   100        0.1187             nan     0.0500   -0.0006
   120        0.1056             nan     0.0500   -0.0001
   140        0.0960             nan     0.0500   -0.0011
   160        0.0879             nan     0.0500   -0.0004
   180        0.0824             nan     0.0500   -0.0005
   200        0.0764             nan     0.0500   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.1991
     2        0.9841             nan     0.0500    0.1635
     3        0.8883             nan     0.0500    0.1416
     4        0.8042             nan     0.0500    0.1152
     5        0.7334             nan     0.0500    0.0997
     6        0.6718             nan     0.0500    0.0881
     7        0.6178             nan     0.0500    0.0757
     8        0.5714             nan     0.0500    0.0651
     9        0.5309             nan     0.0500    0.0561
    10        0.4952             nan     0.0500    0.0503
    20        0.2876             nan     0.0500    0.0174
    40        0.1639             nan     0.0500    0.0015
    60        0.1215             nan     0.0500   -0.0015
    80        0.1025             nan     0.0500   -0.0004
   100        0.0883             nan     0.0500   -0.0010
   120        0.0787             nan     0.0500   -0.0007
   140        0.0703             nan     0.0500   -0.0014
   160        0.0633             nan     0.0500   -0.0010
   180        0.0566             nan     0.0500   -0.0009
   200        0.0518             nan     0.0500   -0.0007

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2047
     2        0.9783             nan     0.0500    0.1658
     3        0.8785             nan     0.0500    0.1447
     4        0.7920             nan     0.0500    0.1241
     5        0.7178             nan     0.0500    0.1029
     6        0.6541             nan     0.0500    0.0926
     7        0.5975             nan     0.0500    0.0773
     8        0.5498             nan     0.0500    0.0682
     9        0.5067             nan     0.0500    0.0574
    10        0.4706             nan     0.0500    0.0513
    20        0.2574             nan     0.0500    0.0148
    40        0.1364             nan     0.0500    0.0019
    60        0.0967             nan     0.0500   -0.0002
    80        0.0765             nan     0.0500   -0.0008
   100        0.0627             nan     0.0500   -0.0007
   120        0.0532             nan     0.0500   -0.0004
   140        0.0447             nan     0.0500   -0.0012
   160        0.0384             nan     0.0500   -0.0010
   180        0.0337             nan     0.0500   -0.0004
   200        0.0300             nan     0.0500   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3335
     2        0.9058             nan     0.1000    0.2271
     3        0.7682             nan     0.1000    0.1637
     4        0.6681             nan     0.1000    0.1234
     5        0.5899             nan     0.1000    0.0937
     6        0.5330             nan     0.1000    0.0697
     7        0.4862             nan     0.1000    0.0567
     8        0.4492             nan     0.1000    0.0447
     9        0.4170             nan     0.1000    0.0366
    10        0.3928             nan     0.1000    0.0300
    20        0.2650             nan     0.1000    0.0054
    40        0.1905             nan     0.1000    0.0012
    60        0.1607             nan     0.1000   -0.0026
    80        0.1425             nan     0.1000   -0.0010
   100        0.1311             nan     0.1000   -0.0002
   120        0.1230             nan     0.1000   -0.0013
   140        0.1162             nan     0.1000   -0.0007
   160        0.1108             nan     0.1000   -0.0008
   180        0.1061             nan     0.1000   -0.0018
   200        0.1017             nan     0.1000   -0.0011

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3442
     2        0.8846             nan     0.1000    0.2345
     3        0.7400             nan     0.1000    0.1761
     4        0.6268             nan     0.1000    0.1291
     5        0.5440             nan     0.1000    0.0966
     6        0.4790             nan     0.1000    0.0716
     7        0.4281             nan     0.1000    0.0613
     8        0.3855             nan     0.1000    0.0471
     9        0.3527             nan     0.1000    0.0330
    10        0.3275             nan     0.1000    0.0321
    20        0.1978             nan     0.1000    0.0053
    40        0.1329             nan     0.1000   -0.0007
    60        0.1040             nan     0.1000   -0.0020
    80        0.0885             nan     0.1000    0.0000
   100        0.0755             nan     0.1000   -0.0008
   120        0.0673             nan     0.1000   -0.0005
   140        0.0601             nan     0.1000   -0.0023
   160        0.0538             nan     0.1000   -0.0002
   180        0.0493             nan     0.1000   -0.0012
   200        0.0454             nan     0.1000   -0.0010

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3629
     2        0.8786             nan     0.1000    0.2528
     3        0.7220             nan     0.1000    0.1764
     4        0.6070             nan     0.1000    0.1323
     5        0.5204             nan     0.1000    0.1017
     6        0.4540             nan     0.1000    0.0799
     7        0.4011             nan     0.1000    0.0659
     8        0.3571             nan     0.1000    0.0484
     9        0.3227             nan     0.1000    0.0326
    10        0.2958             nan     0.1000    0.0320
    20        0.1659             nan     0.1000   -0.0008
    40        0.1063             nan     0.1000   -0.0018
    60        0.0791             nan     0.1000   -0.0007
    80        0.0618             nan     0.1000   -0.0021
   100        0.0511             nan     0.1000   -0.0018
   120        0.0441             nan     0.1000   -0.0019
   140        0.0374             nan     0.1000   -0.0009
   160        0.0325             nan     0.1000   -0.0003
   180        0.0282             nan     0.1000   -0.0013
   200        0.0246             nan     0.1000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.1000    0.3789
     2        0.8688             nan     0.1000    0.2541
     3        0.7100             nan     0.1000    0.1870
     4        0.5925             nan     0.1000    0.1341
     5        0.5053             nan     0.1000    0.1006
     6        0.4391             nan     0.1000    0.0912
     7        0.3794             nan     0.1000    0.0615
     8        0.3351             nan     0.1000    0.0515
     9        0.3005             nan     0.1000    0.0401
    10        0.2706             nan     0.1000    0.0305
    20        0.1356             nan     0.1000    0.0048
    40        0.0774             nan     0.1000   -0.0023
    60        0.0546             nan     0.1000   -0.0029
    80        0.0420             nan     0.1000   -0.0013
   100        0.0324             nan     0.1000   -0.0016
   120        0.0248             nan     0.1000   -0.0016
   140        0.0197             nan     0.1000   -0.0006
   160        0.0161             nan     0.1000   -0.0015
   180        0.0136             nan     0.1000   -0.0012
   200        0.0121             nan     0.1000   -0.0005

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5367
     2        0.7312             nan     0.2000    0.2435
     3        0.5619             nan     0.2000    0.1352
     4        0.4648             nan     0.2000    0.0828
     5        0.4048             nan     0.2000    0.0565
     6        0.3596             nan     0.2000    0.0412
     7        0.3256             nan     0.2000    0.0187
     8        0.3019             nan     0.2000    0.0232
     9        0.2855             nan     0.2000    0.0207
    10        0.2686             nan     0.2000    0.0059
    20        0.1927             nan     0.2000   -0.0012
    40        0.1445             nan     0.2000   -0.0044
    60        0.1259             nan     0.2000   -0.0009
    80        0.1087             nan     0.2000   -0.0020
   100        0.1003             nan     0.2000   -0.0014
   120        0.0921             nan     0.2000   -0.0048
   140        0.0853             nan     0.2000   -0.0012
   160        0.0792             nan     0.2000   -0.0047
   180        0.0747             nan     0.2000   -0.0040
   200        0.0707             nan     0.2000   -0.0043

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5947
     2        0.7097             nan     0.2000    0.2598
     3        0.5214             nan     0.2000    0.1449
     4        0.4155             nan     0.2000    0.0865
     5        0.3476             nan     0.2000    0.0711
     6        0.2971             nan     0.2000    0.0369
     7        0.2631             nan     0.2000    0.0313
     8        0.2392             nan     0.2000    0.0179
     9        0.2196             nan     0.2000    0.0094
    10        0.2050             nan     0.2000    0.0041
    20        0.1436             nan     0.2000   -0.0063
    40        0.0949             nan     0.2000   -0.0010
    60        0.0702             nan     0.2000   -0.0010
    80        0.0590             nan     0.2000   -0.0041
   100        0.0489             nan     0.2000   -0.0045
   120        0.0411             nan     0.2000   -0.0016
   140        0.0350             nan     0.2000   -0.0012
   160        0.0294             nan     0.2000   -0.0047
   180        0.0254             nan     0.2000   -0.0025
   200        0.0224             nan     0.2000   -0.0017

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.5998
     2        0.6934             nan     0.2000    0.2801
     3        0.5007             nan     0.2000    0.1594
     4        0.3863             nan     0.2000    0.0935
     5        0.3154             nan     0.2000    0.0584
     6        0.2685             nan     0.2000    0.0503
     7        0.2279             nan     0.2000    0.0195
     8        0.2013             nan     0.2000    0.0106
     9        0.1871             nan     0.2000    0.0170
    10        0.1706             nan     0.2000    0.0038
    20        0.1026             nan     0.2000   -0.0043
    40        0.0663             nan     0.2000   -0.0037
    60        0.0463             nan     0.2000   -0.0043
    80        0.0339             nan     0.2000   -0.0050
   100        0.0256             nan     0.2000   -0.0009
   120        0.0205             nan     0.2000   -0.0024
   140        0.0166             nan     0.2000   -0.0030
   160        0.0138             nan     0.2000   -0.0038
   180        0.0125             nan     0.2000   -0.0004
   200        0.0113             nan     0.2000   -0.0009

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.2000    0.6079
     2        0.6795             nan     0.2000    0.2853
     3        0.4832             nan     0.2000    0.1547
     4        0.3652             nan     0.2000    0.0963
     5        0.2877             nan     0.2000    0.0619
     6        0.2339             nan     0.2000    0.0303
     7        0.2025             nan     0.2000    0.0239
     8        0.1775             nan     0.2000    0.0169
     9        0.1568             nan     0.2000    0.0085
    10        0.1411             nan     0.2000    0.0027
    20        0.0785             nan     0.2000   -0.0034
    40        0.0412             nan     0.2000   -0.0075
    60        0.0249             nan     0.2000   -0.0047
    80        0.0181             nan     0.2000   -0.0032
   100        0.0129             nan     0.2000   -0.0022
   120        0.0102             nan     0.2000   -0.0026
   140        0.0086             nan     0.2000   -0.0014
   160        0.0071             nan     0.2000   -0.0018
   180        0.0062             nan     0.2000   -0.0014
   200        0.0052             nan     0.2000   -0.0030

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 6: DS.1 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0500    0.2107
     2        0.9754             nan     0.0500    0.1699
     3        0.8737             nan     0.0500    0.1391
     4        0.7898             nan     0.0500    0.1211
     5        0.7170             nan     0.0500    0.1025
     6        0.6524             nan     0.0500    0.0948
     7        0.5953             nan     0.0500    0.0784
     8        0.5479             nan     0.0500    0.0677
     9        0.5055             nan     0.0500    0.0616
    10        0.4674             nan     0.0500    0.0520
    20        0.2543             nan     0.0500    0.0172
    40        0.1320             nan     0.0500    0.0016
    60        0.0941             nan     0.0500    0.0006
    80        0.0729             nan     0.0500   -0.0019
   100        0.0605             nan     0.0500   -0.0004
   120        0.0506             nan     0.0500   -0.0005
   140        0.0442             nan     0.0500   -0.0006
   160        0.0384             nan     0.0500   -0.0006
   180        0.0338             nan     0.0500   -0.0002
   200        0.0293             nan     0.0500   -0.0011

</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">CTG_SGB_fit</span>
<span class="n">CTG_SGB_fit</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Stochastic Gradient Boosting 

1488 samples
  21 predictor
   3 classes: &#39;1&#39;, &#39;2&#39;, &#39;3&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 1339, 1340, 1340, 1340, 1339, 1339, ... 
Resampling results across tuning parameters:

  shrinkage  interaction.depth  n.trees  Accuracy   Kappa    
  0.05       1                   50      0.9284809  0.8029071
  0.05       1                  100      0.9369437  0.8319579
  0.05       1                  200      0.9412563  0.8457081
  0.05       2                   50      0.9403076  0.8390957
  0.05       2                  100      0.9486480  0.8639538
  0.05       2                  200      0.9528137  0.8756518
  0.05       3                   50      0.9442130  0.8508967
  0.05       3                  100      0.9495867  0.8674647
  0.05       3                  200      0.9533569  0.8778308
  0.05       5                   50      0.9489156  0.8644937
  0.05       5                  100      0.9530803  0.8768165
  0.05       5                  200      0.9546893  0.8814651
  0.10       1                   50      0.9364122  0.8305092
  0.10       1                  100      0.9411139  0.8452717
  0.10       1                  200      0.9471607  0.8617558
  0.10       2                   50      0.9454210  0.8554662
  0.10       2                  100      0.9497228  0.8681655
  0.10       2                  200      0.9537506  0.8791248
  0.10       3                   50      0.9487832  0.8653314
  0.10       3                  100      0.9510650  0.8720298
  0.10       3                  200      0.9536100  0.8790533
  0.10       5                   50      0.9512020  0.8722972
  0.10       5                  100      0.9532218  0.8777657
  0.10       5                  200      0.9537487  0.8795358
  0.20       1                   50      0.9423292  0.8483676
  0.20       1                  100      0.9444788  0.8555715
  0.20       1                  200      0.9444760  0.8556752
  0.20       2                   50      0.9495760  0.8679208
  0.20       2                  100      0.9524092  0.8759730
  0.20       2                  200      0.9514714  0.8740082
  0.20       3                   50      0.9505245  0.8705693
  0.20       3                  100      0.9520019  0.8747370
  0.20       3                  200      0.9521416  0.8752740
  0.20       5                   50      0.9495768  0.8684120
  0.20       5                  100      0.9524002  0.8759847
  0.20       5                  200      0.9530767  0.8779786

Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
Accuracy was used to select the optimal model using the largest value.
The final values used for the model were n.trees = 200, interaction.depth =
 5, shrinkage = 0.05 and n.minobsinnode = 10.</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Lasso Prediction</span>
<span class="n">CTG_Lasso_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">CTG_lasso_fit</span><span class="p">,</span> <span class="n">test_CTG</span><span class="p">)</span>
<span class="n">CM_Lasso</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">CTG_Lasso_predict</span><span class="p">,</span> <span class="n">test_CTG</span><span class="o">$</span><span class="n">NSP</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_Lasso</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_Lasso</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">CM_Lasso</span>
<span class="n">Accuracy_Lasso</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_Lasso</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Accuracy_Lasso</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction   1   2   3
         1 364   4  21
         2 111  12  16
         3  57   0  53

Overall Statistics
                                          
               Accuracy : 0.6724          
                 95% CI : (0.6345, 0.7087)
    No Information Rate : 0.8339          
    P-Value [Acc &gt; NIR] : 1               
                                          
                  Kappa : 0.2906          
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          

Statistics by Class:

                     Class: 1 Class: 2 Class: 3
Sensitivity            0.6842  0.75000  0.58889
Specificity            0.7642  0.79582  0.89599
Pos Pred Value         0.9357  0.08633  0.48182
Neg Pred Value         0.3253  0.99198  0.92992
Prevalence             0.8339  0.02508  0.14107
Detection Rate         0.5705  0.01881  0.08307
Detection Prevalence   0.6097  0.21787  0.17241
Balanced Accuracy      0.7242  0.77291  0.74244</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<strong>Accuracy:</strong> 0.6724
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Decision Tree Prediction</span>
<span class="n">CTG_DT_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">CTG_DT_fit1</span><span class="p">,</span> <span class="n">test_CTG</span><span class="p">)</span>
<span class="n">CM_DT</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">CTG_DT_predict</span><span class="p">,</span> <span class="n">test_CTG</span><span class="o">$</span><span class="n">NSP</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_DT</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_DT</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">CM_DT</span>
<span class="n">Accuracy_DT</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_DT</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Accuracy_DT</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction   1   2   3
         1 363   7  15
         2 160   9  68
         3   9   0   7

Overall Statistics
                                          
               Accuracy : 0.594           
                 95% CI : (0.5548, 0.6324)
    No Information Rate : 0.8339          
    P-Value [Acc &gt; NIR] : 1               
                                          
                  Kappa : 0.1612          
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          

Statistics by Class:

                     Class: 1 Class: 2 Class: 3
Sensitivity            0.6823  0.56250  0.07778
Specificity            0.7925  0.63344  0.98358
Pos Pred Value         0.9429  0.03797  0.43750
Neg Pred Value         0.3320  0.98254  0.86656
Prevalence             0.8339  0.02508  0.14107
Detection Rate         0.5690  0.01411  0.01097
Detection Prevalence   0.6034  0.37147  0.02508
Balanced Accuracy      0.7374  0.59797  0.53068</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<strong>Accuracy:</strong> 0.594
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[60]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Random Forest Prediction</span>
<span class="n">CTG_RF_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">CTG_RF_fit</span><span class="p">,</span> <span class="n">test_CTG</span><span class="p">)</span>
<span class="n">CM_RF</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">CTG_RF_predict</span><span class="p">,</span> <span class="n">test_CTG</span><span class="o">$</span><span class="n">NSP</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_RF</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_RF</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">CM_RF</span>
<span class="n">Accuracy_RF</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Accuracy_RF</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction   1   2   3
         1 382   6  25
         2 143  10  55
         3   7   0  10

Overall Statistics
                                          
               Accuracy : 0.6301          
                 95% CI : (0.5913, 0.6677)
    No Information Rate : 0.8339          
    P-Value [Acc &gt; NIR] : 1               
                                          
                  Kappa : 0.1748          
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          

Statistics by Class:

                     Class: 1 Class: 2 Class: 3
Sensitivity            0.7180  0.62500  0.11111
Specificity            0.7075  0.68167  0.98723
Pos Pred Value         0.9249  0.04808  0.58824
Neg Pred Value         0.3333  0.98605  0.87118
Prevalence             0.8339  0.02508  0.14107
Detection Rate         0.5987  0.01567  0.01567
Detection Prevalence   0.6473  0.32602  0.02665
Balanced Accuracy      0.7128  0.65334  0.54917</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<strong>Accuracy:</strong> 0.6301
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Stochastic Gradient Boosting Prediction</span>
<span class="n">CTG_SGB_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">CTG_SGB_fit</span><span class="p">,</span> <span class="n">test_CTG</span><span class="p">)</span>
<span class="n">CM_SGB</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">CTG_SGB_predict</span><span class="p">,</span> <span class="n">test_CTG</span><span class="o">$</span><span class="n">NSP</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_SGB</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_SGB</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">CM_SGB</span>
<span class="n">Accuracy_SGB</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_SGB</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Accuracy_SGB</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction   1   2   3
         1 381   5  16
         2 144  11  58
         3   7   0  16

Overall Statistics
                                          
               Accuracy : 0.6395          
                 95% CI : (0.6009, 0.6768)
    No Information Rate : 0.8339          
    P-Value [Acc &gt; NIR] : 1               
                                          
                  Kappa : 0.2182          
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          

Statistics by Class:

                     Class: 1 Class: 2 Class: 3
Sensitivity            0.7162  0.68750  0.17778
Specificity            0.8019  0.67524  0.98723
Pos Pred Value         0.9478  0.05164  0.69565
Neg Pred Value         0.3602  0.98824  0.87967
Prevalence             0.8339  0.02508  0.14107
Detection Rate         0.5972  0.01724  0.02508
Detection Prevalence   0.6301  0.33386  0.03605
Balanced Accuracy      0.7590  0.68137  0.58250</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<strong>Accuracy:</strong> 0.6395
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h6 id="Training-Accuracy-for-Each-Model">Training Accuracy for Each Model<a class="anchor-link" href="#Training-Accuracy-for-Each-Model">&#182;</a></h6><p>Accuracy obtained from Training sets for each model</p>
<p>Lasso Accuracy 0.9027</p>
<p>Decision Tree Accuracy 0.9423</p>
<p>Random Forest Accuracy 0.9455</p>
<p>Stochastic Gradient Boosting Accuracy 0.9547</p>
<p>Best Accuracy obtained with Stochastic Gradient Boosting model for training set</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">A</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Lasso Model Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_Lasso</span><span class="p">)</span>
<span class="n">B</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Decision Tree Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_DT</span><span class="p">)</span>
<span class="n">C</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Random Forest Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_RF</span><span class="p">)</span>
<span class="n">D</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Stochastic Gradient Boosting Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_SGB</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[1] &#34;Lasso Model Test Accuracy is 0.6724&#34;
[1] &#34;Decision Tree Test Accuracy is 0.594&#34;
[1] &#34;Random Forest Test Accuracy is 0.6301&#34;
[1] &#34;Stochastic Gradient Boosting Test Accuracy is 0.6395&#34;
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h6 id="Comments">Comments<a class="anchor-link" href="#Comments">&#182;</a></h6><p>We obtained the best accuracy from Stochastic Gradient Boosting model during the training.
We obtained more than %90 accuracy for each model for the training set. Whereas the prediction accuracy for each model is around %60 for each model. The best accuracy is obtained with the Lasso Model for predictions as 0.6724 whereas, it was the lowest (0.9027) for the training set. There is probably an overfitting issue and selecting different parameters with lower accuracies may give better results.</p>
<p>Lasso has better accuracy between classes. The other methods have problems predicting the class 3. Sensitivity and Balanced Accuracy for class 3 is low for Decision Tree, Random Forest and Stochastic Gradient Boosting models.</p>
<p>Our Kappa values for training set seems promising but they lowered for each model on the test data. Kappa value is important for class imbalance problems, best Kappa value is obtained with Lasso Model prediction which is 0.2906.</p>
<p>The dataset is three class set which is a multi-class classification and also there is a class imbalance, class 1 is dominant in the sets.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Dataset-2---Student-Performance-Data-Set">Dataset 2 - Student Performance Data Set<a class="anchor-link" href="#Dataset-2---Student-Performance-Data-Set">&#182;</a></h1>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p><a href="https://archive.ics.uci.edu/ml/datasets/student%2Bperformance">https://archive.ics.uci.edu/ml/datasets/student%2Bperformance</a></p>
<h5 id="Data-Set-Information:">Data Set Information:<a class="anchor-link" href="#Data-Set-Information:">&#182;</a></h5><p>This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).</p>
<h5 id="Attribute-Information:">Attribute Information:<a class="anchor-link" href="#Attribute-Information:">&#182;</a></h5><h1 id="Attributes-for-both-student-mat.csv-(Math-course)-and-student-por.csv-(Portuguese-language-course)-datasets:">Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:<a class="anchor-link" href="#Attributes-for-both-student-mat.csv-(Math-course)-and-student-por.csv-(Portuguese-language-course)-datasets:">&#182;</a></h1><p>1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)</p>
<p>2 sex - student's sex (binary: 'F' - female or 'M' - male)</p>
<p>3 age - student's age (numeric: from 15 to 22)</p>
<p>4 address - student's home address type (binary: 'U' - urban or 'R' - rural)</p>
<p>5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)</p>
<p>6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)</p>
<p>7 Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)</p>
<p>8 Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)</p>
<p>9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')</p>
<p>10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')</p>
<p>11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')</p>
<p>12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')</p>
<p>13 traveltime - home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour)</p>
<p>14 studytime - weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours)</p>
<p>15 failures - number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4)</p>
<p>16 schoolsup - extra educational support (binary: yes or no)</p>
<p>17 famsup - family educational support (binary: yes or no)</p>
<p>18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)</p>
<p>19 activities - extra-curricular activities (binary: yes or no)</p>
<p>20 nursery - attended nursery school (binary: yes or no)</p>
<p>21 higher - wants to take higher education (binary: yes or no)</p>
<p>22 internet - Internet access at home (binary: yes or no)</p>
<p>23 romantic - with a romantic relationship (binary: yes or no)</p>
<p>24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)</p>
<p>25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)</p>
<p>26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)</p>
<p>27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)</p>
<p>28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)</p>
<p>29 health - current health status (numeric: from 1 - very bad to 5 - very good)</p>
<p>30 absences - number of school absences (numeric: from 0 to 93)</p>
<h1 id="these-grades-are-related-with-the-course-subject,-Math-or-Portuguese:">these grades are related with the course subject, Math or Portuguese:<a class="anchor-link" href="#these-grades-are-related-with-the-course-subject,-Math-or-Portuguese:">&#182;</a></h1><p>31 G1 - first period grade (numeric: from 0 to 20)</p>
<p>31 G2 - second period grade (numeric: from 0 to 20)</p>
<p>32 G3 - final grade (numeric: from 0 to 20, output target)</p>
<h5 id="Relevant-Papers:">Relevant Papers:<a class="anchor-link" href="#Relevant-Papers:">&#182;</a></h5><p>P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.
Available at: [<a href="http://www3.dsi.uminho.pt/pcortez/student.pdf">http://www3.dsi.uminho.pt/pcortez/student.pdf</a>]</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="For-the-analysis">For the analysis<a class="anchor-link" href="#For-the-analysis">&#182;</a></h4><p>Portuguese language (por) dataset is used.
G1 and G2 which correspond to the 1st and 2nd period grades, removed.</p>
<p>This dataset has some number of categorical or ordinal features.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[86]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#read the data</span>
<span class="n">data_Por</span> <span class="o">=</span> <span class="nf">read.csv</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="s">&quot;student-por.csv&quot;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span><span class="s">&quot;;&quot;</span><span class="p">)</span>
<span class="n">data_Por</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">data_Por</span><span class="p">)</span>
<span class="c1"># we will predict G3 the final grade. G1 and G2 are term grades they will be removed. If not G1 and G2 will influence the predictions the most...</span>
<span class="n">data_Por</span> <span class="o">&lt;-</span> <span class="n">data_Por</span><span class="p">[</span><span class="o">!</span><span class="nf">names</span><span class="p">(</span><span class="n">data_Por</span><span class="p">)</span> <span class="o">%in%</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;G1&quot;</span><span class="p">,</span> <span class="s">&quot;G2&quot;</span><span class="p">)]</span> 
<span class="n">m</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">data_Por</span><span class="p">)</span>
<span class="n">n</span><span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="m">0.7</span>
<span class="n">train_Por</span> <span class="o">=</span> <span class="n">data_Por</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">,]</span>
<span class="n">test_Por</span> <span class="o">=</span> <span class="n">data_Por</span><span class="p">[(</span><span class="n">n</span><span class="m">+1</span><span class="p">)</span><span class="o">:</span><span class="n">m</span><span class="p">,]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[94]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 1 - Lasso Regression</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">636</span><span class="p">)</span>
<span class="n">lambda_seq</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="m">6</span><span class="p">))</span> <span class="c1">#tried several times but we are asked to use 6 different lamda (I rerun the code)</span>
<span class="n">n_repeats</span><span class="o">=</span><span class="m">5</span>
<span class="n">n_folds</span><span class="o">=</span><span class="m">10</span>
<span class="n">lasso_grid</span> <span class="o">=</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">lambda</span><span class="o">=</span><span class="n">lambda_seq</span><span class="p">)</span>
<span class="n">lasso_control</span><span class="o">=</span><span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span>                        
<span class="n">POR_lasso_fit</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">G3</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">train_Por</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s">&quot;glmnet&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">lasso_grid</span><span class="p">,</span><span class="n">trControl</span> <span class="o">=</span> <span class="n">lasso_control</span><span class="p">)</span> 
<span class="n">POR_lasso_fit</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>glmnet 

454 samples
 30 predictor

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 409, 409, 408, 408, 408, 409, ... 
Resampling results across tuning parameters:

  lambda  RMSE      Rsquared   MAE     
  0.0010  2.256017  0.3118606  1.740278
  0.0208  2.236903  0.3159995  1.725898
  0.0406  2.226382  0.3186499  1.719890
  0.0604  2.222004  0.3199148  1.718576
  0.0802  2.225427  0.3180072  1.723861
  0.1000  2.233388  0.3142128  1.732532

Tuning parameter &#39;alpha&#39; was held constant at a value of 1
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were alpha = 1 and lambda = 0.0604.</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 2 - Decision Trees</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">636</span><span class="p">)</span>

<span class="n">DT_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span> 
<span class="n">DT_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">cp</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.01</span><span class="p">,</span><span class="m">0.02</span><span class="p">,</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.005</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="m">0.07</span><span class="p">))</span> <span class="c1"># cp by default 0.01, I change by both increasing and decreasing</span>

<span class="c1"># minbucket is originaly &quot;20/3 = 7&quot; so I tried original &quot;7&quot;, increase to &quot;20&quot;, decrease to &quot;2&quot;...</span>
<span class="n">POR_DT_fit1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">G3</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_Por</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">7</span><span class="p">))</span>

<span class="n">POR_DT_fit2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">G3</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_Por</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">20</span><span class="p">))</span>

<span class="n">POR_DT_fit3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">G3</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_Por</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">2</span><span class="p">))</span>

<span class="n">POR_DT_fit1</span>
<span class="n">POR_DT_fit2</span>
<span class="n">POR_DT_fit3</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

454 samples
 30 predictor

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 409, 409, 408, 408, 408, 409, ... 
Resampling results across tuning parameters:

  cp     RMSE      Rsquared   MAE     
  0.005  2.524814  0.2029084  1.977879
  0.010  2.430637  0.2234841  1.886290
  0.020  2.335305  0.2631176  1.843834
  0.050  2.428160  0.1954637  1.892111
  0.070  2.484702  0.1581318  1.955545
  0.100  2.484702  0.1581318  1.955545

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.02.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

454 samples
 30 predictor

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 408, 409, 410, 408, 408, 409, ... 
Resampling results across tuning parameters:

  cp     RMSE      Rsquared   MAE     
  0.005  2.418561  0.2155793  1.877287
  0.010  2.414951  0.2137086  1.878293
  0.020  2.411703  0.2112132  1.889751
  0.050  2.469105  0.1741489  1.940596
  0.070  2.468011  0.1741489  1.940607
  0.100  2.468011  0.1741489  1.940607

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.02.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

454 samples
 30 predictor

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 408, 409, 408, 408, 408, 408, ... 
Resampling results across tuning parameters:

  cp     RMSE      Rsquared   MAE     
  0.005  2.785237  0.1631965  2.137286
  0.010  2.519534  0.2145775  1.924913
  0.020  2.419212  0.2458287  1.875784
  0.050  2.427390  0.1963208  1.890905
  0.070  2.481002  0.1601684  1.949874
  0.100  2.481002  0.1601684  1.949874

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.02.</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h6 id="-"> <a class="anchor-link" href="#-">&#182;</a></h6><p>Best RMSE is obtained with minbucket=7, so POR_DT_fit1 is selected.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">plot</span><span class="p">(</span><span class="n">POR_DT_fit1</span><span class="o">$</span><span class="n">finalModel</span><span class="p">)</span>
<span class="nf">text</span><span class="p">(</span><span class="n">POR_DT_fit1</span><span class="o">$</span><span class="n">finalModel</span><span class="p">,</span> <span class="n">all</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">cex</span><span class="o">=</span><span class="n">.</span><span class="m">8</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAABlBMVEUAAAD///+l2Z/dAAAA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"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 3 - Random Forest</span>

<span class="n">RF_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">mtry</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">7</span><span class="p">,</span><span class="m">9</span><span class="p">,</span><span class="m">11</span><span class="p">))</span> <span class="c1"># default value is 5 I change by both increasing and decreasing</span>
<span class="n">RF_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span> 
<span class="n">POR_RF_fit</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">G3</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_Por</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rf&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">RF_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">RF_control</span><span class="p">)</span>
<span class="n">POR_RF_fit</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">POR_RF_fit</span><span class="p">)</span>
<span class="n">POR_RF_fit</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Random Forest 

454 samples
 30 predictor

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 408, 409, 410, 408, 408, 409, ... 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared   MAE     
   1    2.429052  0.3196940  1.894665
   3    2.264470  0.3352537  1.746246
   5    2.236688  0.3344849  1.722534
   7    2.221124  0.3348259  1.708848
   9    2.217762  0.3331970  1.706630
  11    2.219915  0.3297236  1.711745

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 9.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>
Call:
 randomForest(x = x, y = y, mtry = param$mtry) 
               Type of random forest: regression
                     Number of trees: 500
No. of variables tried at each split: 9

          Mean of squared residuals: 4.921669
                    % Var explained: 32.51</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAgP9NTU1oaGh8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"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 4 - Stochastic Gradient Boosting</span>

<span class="c1"># interaction.depth default is 1 tried 2,3 and 5, n.trees default is 100 I change by both increasing and decreasing, </span>
<span class="c1"># shrinkage default is 0.1 I change by both increasing and decreasing</span>
<span class="n">SGB_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">interaction.depth</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">),</span> <span class="n">n.trees</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">200</span><span class="p">,</span><span class="m">50</span><span class="p">),</span><span class="n">shrinkage</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="m">0.2</span><span class="p">),</span><span class="n">n.minobsinnode</span> <span class="o">=</span><span class="m">10</span><span class="p">)</span>
<span class="n">SGB_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span> 
<span class="n">POR_SGB_fit</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">G3</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train_Por</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;gbm&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">SGB_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">SGB_control</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2023             nan     0.0500    0.1279
     2        7.0743             nan     0.0500    0.0940
     3        6.9749             nan     0.0500    0.0768
     4        6.8988             nan     0.0500    0.0982
     5        6.8136             nan     0.0500    0.0845
     6        6.7319             nan     0.0500    0.0860
     7        6.6435             nan     0.0500    0.0708
     8        6.5489             nan     0.0500    0.0718
     9        6.4731             nan     0.0500    0.0762
    10        6.4052             nan     0.0500    0.0606
    20        5.9134             nan     0.0500    0.0194
    40        5.4022             nan     0.0500   -0.0067
    60        5.0822             nan     0.0500    0.0088
    80        4.8591             nan     0.0500   -0.0034
   100        4.6859             nan     0.0500   -0.0025
   120        4.5658             nan     0.0500   -0.0032
   140        4.4659             nan     0.0500   -0.0059
   160        4.3968             nan     0.0500   -0.0084
   180        4.3182             nan     0.0500   -0.0025
   200        4.2570             nan     0.0500   -0.0114

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1712             nan     0.0500    0.1160
     2        7.0528             nan     0.0500    0.1348
     3        6.9163             nan     0.0500    0.1339
     4        6.7830             nan     0.0500    0.1374
     5        6.6482             nan     0.0500    0.1072
     6        6.5480             nan     0.0500    0.0920
     7        6.4551             nan     0.0500    0.0790
     8        6.3889             nan     0.0500    0.0118
     9        6.2901             nan     0.0500    0.0573
    10        6.2014             nan     0.0500    0.0686
    20        5.5889             nan     0.0500    0.0278
    40        4.9441             nan     0.0500    0.0125
    60        4.5167             nan     0.0500    0.0009
    80        4.2535             nan     0.0500   -0.0192
   100        4.0488             nan     0.0500   -0.0044
   120        3.9059             nan     0.0500   -0.0163
   140        3.7782             nan     0.0500   -0.0072
   160        3.7025             nan     0.0500   -0.0074
   180        3.5898             nan     0.0500    0.0009
   200        3.5098             nan     0.0500   -0.0044

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1267             nan     0.0500    0.1876
     2        6.9728             nan     0.0500    0.1669
     3        6.8178             nan     0.0500    0.0932
     4        6.6913             nan     0.0500    0.1282
     5        6.5600             nan     0.0500    0.1014
     6        6.4638             nan     0.0500    0.0722
     7        6.3346             nan     0.0500    0.0728
     8        6.2034             nan     0.0500    0.0628
     9        6.1162             nan     0.0500    0.0688
    10        6.0295             nan     0.0500    0.0367
    20        5.2994             nan     0.0500    0.0208
    40        4.5806             nan     0.0500   -0.0038
    60        4.1519             nan     0.0500   -0.0048
    80        3.8589             nan     0.0500   -0.0043
   100        3.6554             nan     0.0500   -0.0134
   120        3.5116             nan     0.0500   -0.0150
   140        3.3761             nan     0.0500   -0.0066
   160        3.2708             nan     0.0500   -0.0180
   180        3.1791             nan     0.0500   -0.0181
   200        3.0840             nan     0.0500   -0.0075

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1082             nan     0.0500    0.2306
     2        6.9339             nan     0.0500    0.1677
     3        6.7541             nan     0.0500    0.1470
     4        6.5671             nan     0.0500    0.1494
     5        6.4517             nan     0.0500    0.0523
     6        6.3148             nan     0.0500    0.0802
     7        6.1702             nan     0.0500    0.1209
     8        6.0352             nan     0.0500    0.1205
     9        5.9235             nan     0.0500    0.0797
    10        5.8539             nan     0.0500    0.0257
    20        5.0235             nan     0.0500    0.0155
    40        4.1670             nan     0.0500    0.0015
    60        3.6222             nan     0.0500    0.0035
    80        3.2978             nan     0.0500   -0.0058
   100        3.0409             nan     0.0500    0.0033
   120        2.8517             nan     0.0500   -0.0237
   140        2.6697             nan     0.0500   -0.0062
   160        2.5104             nan     0.0500   -0.0112
   180        2.3745             nan     0.0500   -0.0075
   200        2.2475             nan     0.0500   -0.0058

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1221             nan     0.1000    0.2043
     2        6.8569             nan     0.1000    0.2471
     3        6.6462             nan     0.1000    0.1695
     4        6.5014             nan     0.1000    0.1191
     5        6.4007             nan     0.1000    0.0504
     6        6.2644             nan     0.1000    0.1273
     7        6.2064             nan     0.1000    0.0123
     8        6.0929             nan     0.1000    0.0941
     9        6.0064             nan     0.1000    0.0809
    10        5.9334             nan     0.1000    0.0609
    20        5.4288             nan     0.1000    0.0144
    40        4.8751             nan     0.1000    0.0041
    60        4.5447             nan     0.1000   -0.0049
    80        4.3588             nan     0.1000   -0.0259
   100        4.2256             nan     0.1000   -0.0136
   120        4.1375             nan     0.1000   -0.0124
   140        4.0831             nan     0.1000   -0.0171
   160        4.0393             nan     0.1000   -0.0162
   180        3.9968             nan     0.1000   -0.0015
   200        3.9673             nan     0.1000   -0.0246

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9758             nan     0.1000    0.2683
     2        6.7577             nan     0.1000    0.1338
     3        6.5269             nan     0.1000    0.2376
     4        6.3428             nan     0.1000    0.1955
     5        6.1962             nan     0.1000    0.1415
     6        6.0498             nan     0.1000    0.1339
     7        5.9216             nan     0.1000    0.0464
     8        5.8097             nan     0.1000    0.0804
     9        5.6808             nan     0.1000    0.0812
    10        5.5770             nan     0.1000    0.0469
    20        4.9318             nan     0.1000   -0.0040
    40        4.3560             nan     0.1000    0.0011
    60        4.0486             nan     0.1000    0.0005
    80        3.8156             nan     0.1000   -0.0117
   100        3.6484             nan     0.1000   -0.0011
   120        3.4948             nan     0.1000   -0.0080
   140        3.3847             nan     0.1000   -0.0008
   160        3.2509             nan     0.1000   -0.0195
   180        3.1181             nan     0.1000   -0.0045
   200        3.0126             nan     0.1000   -0.0122

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9834             nan     0.1000    0.3606
     2        6.7036             nan     0.1000    0.2657
     3        6.4268             nan     0.1000    0.2080
     4        6.1732             nan     0.1000    0.1998
     5        5.9937             nan     0.1000    0.1526
     6        5.8012             nan     0.1000    0.1584
     7        5.6682             nan     0.1000    0.0784
     8        5.5526             nan     0.1000    0.0578
     9        5.4275             nan     0.1000    0.0512
    10        5.3136             nan     0.1000    0.0269
    20        4.5367             nan     0.1000    0.0006
    40        3.8965             nan     0.1000   -0.0064
    60        3.5339             nan     0.1000   -0.0149
    80        3.3376             nan     0.1000   -0.0274
   100        3.1304             nan     0.1000   -0.0205
   120        2.9644             nan     0.1000   -0.0117
   140        2.8298             nan     0.1000   -0.0174
   160        2.6770             nan     0.1000   -0.0217
   180        2.5546             nan     0.1000   -0.0209
   200        2.4473             nan     0.1000   -0.0123

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9186             nan     0.1000    0.3746
     2        6.6554             nan     0.1000    0.1948
     3        6.3058             nan     0.1000    0.3179
     4        6.0447             nan     0.1000    0.1709
     5        5.7831             nan     0.1000    0.1692
     6        5.5608             nan     0.1000    0.1756
     7        5.3747             nan     0.1000    0.1040
     8        5.2355             nan     0.1000    0.0700
     9        5.0518             nan     0.1000    0.0973
    10        4.9374             nan     0.1000    0.0364
    20        4.1992             nan     0.1000   -0.0077
    40        3.4535             nan     0.1000   -0.0460
    60        2.9944             nan     0.1000   -0.0147
    80        2.6517             nan     0.1000   -0.0168
   100        2.3937             nan     0.1000   -0.0061
   120        2.1534             nan     0.1000   -0.0283
   140        1.9244             nan     0.1000   -0.0062
   160        1.7684             nan     0.1000   -0.0119
   180        1.6027             nan     0.1000   -0.0149
   200        1.4626             nan     0.1000   -0.0112

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8680             nan     0.2000    0.3488
     2        6.5368             nan     0.2000    0.2800
     3        6.3941             nan     0.2000   -0.0240
     4        6.2764             nan     0.2000   -0.0005
     5        5.9635             nan     0.2000    0.1838
     6        5.8336             nan     0.2000    0.0545
     7        5.6913             nan     0.2000    0.1194
     8        5.5508             nan     0.2000    0.0994
     9        5.4732             nan     0.2000    0.0665
    10        5.3483             nan     0.2000    0.0743
    20        4.7970             nan     0.2000    0.0279
    40        4.3587             nan     0.2000   -0.0166
    60        4.1576             nan     0.2000   -0.0470
    80        4.0592             nan     0.2000   -0.0301
   100        3.9909             nan     0.2000   -0.0128
   120        3.9459             nan     0.2000   -0.0318
   140        3.9073             nan     0.2000   -0.0502
   160        3.9139             nan     0.2000   -0.0517
   180        3.8886             nan     0.2000   -0.0277
   200        3.8896             nan     0.2000   -0.0385

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7894             nan     0.2000    0.4132
     2        6.3947             nan     0.2000    0.3387
     3        6.0383             nan     0.2000    0.2769
     4        5.7510             nan     0.2000    0.2139
     5        5.4633             nan     0.2000    0.1586
     6        5.3173             nan     0.2000    0.1048
     7        5.1537             nan     0.2000    0.0251
     8        5.0717             nan     0.2000    0.0335
     9        4.9466             nan     0.2000    0.0748
    10        4.8187             nan     0.2000   -0.0871
    20        4.2552             nan     0.2000   -0.0690
    40        3.7168             nan     0.2000   -0.0155
    60        3.4761             nan     0.2000   -0.0531
    80        3.2070             nan     0.2000   -0.0435
   100        3.0399             nan     0.2000   -0.0259
   120        2.8591             nan     0.2000   -0.0656
   140        2.6982             nan     0.2000   -0.0019
   160        2.5822             nan     0.2000   -0.0351
   180        2.4604             nan     0.2000   -0.0323
   200        2.3452             nan     0.2000   -0.0088

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7326             nan     0.2000    0.4254
     2        6.2470             nan     0.2000    0.4447
     3        5.8395             nan     0.2000    0.3810
     4        5.5272             nan     0.2000    0.2512
     5        5.2798             nan     0.2000    0.2022
     6        5.1206             nan     0.2000    0.0247
     7        4.9828             nan     0.2000    0.0641
     8        4.8305             nan     0.2000    0.1047
     9        4.6653             nan     0.2000    0.0324
    10        4.5617             nan     0.2000    0.0227
    20        3.9037             nan     0.2000   -0.0192
    40        3.3723             nan     0.2000   -0.0053
    60        2.9224             nan     0.2000   -0.0053
    80        2.6522             nan     0.2000   -0.0582
   100        2.3691             nan     0.2000   -0.0186
   120        2.1945             nan     0.2000   -0.0292
   140        2.0263             nan     0.2000   -0.0293
   160        1.8344             nan     0.2000   -0.0349
   180        1.7004             nan     0.2000   -0.0564
   200        1.5613             nan     0.2000   -0.0267

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5545             nan     0.2000    0.5502
     2        6.0678             nan     0.2000    0.3241
     3        5.6723             nan     0.2000    0.2872
     4        5.3235             nan     0.2000    0.1794
     5        5.0289             nan     0.2000    0.2613
     6        4.7587             nan     0.2000    0.1177
     7        4.6199             nan     0.2000    0.0895
     8        4.5014             nan     0.2000   -0.0627
     9        4.3796             nan     0.2000   -0.0205
    10        4.2276             nan     0.2000    0.0083
    20        3.4863             nan     0.2000   -0.0668
    40        2.7062             nan     0.2000   -0.0339
    60        2.1416             nan     0.2000   -0.0424
    80        1.7797             nan     0.2000   -0.0195
   100        1.4582             nan     0.2000   -0.0137
   120        1.2579             nan     0.2000   -0.0172
   140        1.1288             nan     0.2000   -0.0243
   160        0.9578             nan     0.2000   -0.0111
   180        0.8392             nan     0.2000   -0.0179
   200        0.7344             nan     0.2000   -0.0240

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.4056             nan     0.0500    0.1024
     2        7.2797             nan     0.0500    0.1274
     3        7.1686             nan     0.0500    0.0935
     4        7.0631             nan     0.0500    0.0932
     5        6.9669             nan     0.0500    0.0844
     6        6.8970             nan     0.0500    0.0740
     7        6.7941             nan     0.0500    0.0696
     8        6.7544             nan     0.0500    0.0227
     9        6.6710             nan     0.0500    0.0557
    10        6.5973             nan     0.0500    0.0439
    20        6.1145             nan     0.0500    0.0276
    40        5.5668             nan     0.0500    0.0092
    60        5.2042             nan     0.0500    0.0027
    80        4.9747             nan     0.0500    0.0045
   100        4.7884             nan     0.0500    0.0011
   120        4.6439             nan     0.0500   -0.0083
   140        4.5314             nan     0.0500    0.0026
   160        4.4280             nan     0.0500   -0.0068
   180        4.3568             nan     0.0500   -0.0059
   200        4.3079             nan     0.0500   -0.0188

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3805             nan     0.0500    0.1276
     2        7.2389             nan     0.0500    0.1038
     3        7.0982             nan     0.0500    0.1080
     4        6.9579             nan     0.0500    0.1129
     5        6.8495             nan     0.0500    0.0893
     6        6.7486             nan     0.0500    0.0988
     7        6.6367             nan     0.0500    0.0900
     8        6.5396             nan     0.0500    0.0866
     9        6.4771             nan     0.0500    0.0273
    10        6.3912             nan     0.0500    0.0707
    20        5.7475             nan     0.0500    0.0308
    40        5.0037             nan     0.0500    0.0007
    60        4.6007             nan     0.0500    0.0067
    80        4.3342             nan     0.0500   -0.0014
   100        4.1511             nan     0.0500   -0.0071
   120        4.0005             nan     0.0500   -0.0093
   140        3.9019             nan     0.0500   -0.0094
   160        3.8025             nan     0.0500   -0.0130
   180        3.7169             nan     0.0500   -0.0069
   200        3.6410             nan     0.0500   -0.0238

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3352             nan     0.0500    0.1559
     2        7.1706             nan     0.0500    0.1129
     3        7.0066             nan     0.0500    0.1545
     4        6.8689             nan     0.0500    0.1122
     5        6.7328             nan     0.0500    0.1394
     6        6.6140             nan     0.0500    0.0798
     7        6.4827             nan     0.0500    0.1000
     8        6.3632             nan     0.0500    0.1033
     9        6.2709             nan     0.0500    0.0493
    10        6.1892             nan     0.0500    0.0742
    20        5.4776             nan     0.0500    0.0307
    40        4.7331             nan     0.0500    0.0119
    60        4.3273             nan     0.0500   -0.0034
    80        4.0369             nan     0.0500   -0.0176
   100        3.8303             nan     0.0500   -0.0049
   120        3.6650             nan     0.0500   -0.0061
   140        3.5069             nan     0.0500   -0.0016
   160        3.3888             nan     0.0500   -0.0249
   180        3.2940             nan     0.0500   -0.0108
   200        3.1942             nan     0.0500   -0.0133

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2766             nan     0.0500    0.1979
     2        7.0788             nan     0.0500    0.1517
     3        6.8568             nan     0.0500    0.1507
     4        6.7019             nan     0.0500    0.1493
     5        6.5410             nan     0.0500    0.1181
     6        6.4143             nan     0.0500    0.1332
     7        6.2736             nan     0.0500    0.0875
     8        6.1514             nan     0.0500    0.0757
     9        6.0332             nan     0.0500    0.1136
    10        5.9485             nan     0.0500    0.0619
    20        5.1721             nan     0.0500    0.0211
    40        4.3164             nan     0.0500    0.0037
    60        3.8243             nan     0.0500    0.0050
    80        3.4875             nan     0.0500   -0.0225
   100        3.2624             nan     0.0500    0.0029
   120        3.0371             nan     0.0500   -0.0102
   140        2.8433             nan     0.0500   -0.0103
   160        2.6854             nan     0.0500   -0.0199
   180        2.5245             nan     0.0500   -0.0139
   200        2.4013             nan     0.0500   -0.0068

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2505             nan     0.1000    0.1937
     2        7.0779             nan     0.1000    0.1719
     3        6.9602             nan     0.1000    0.0344
     4        6.7959             nan     0.1000    0.1479
     5        6.6201             nan     0.1000    0.1260
     6        6.5152             nan     0.1000    0.0747
     7        6.3912             nan     0.1000    0.1368
     8        6.2964             nan     0.1000    0.1119
     9        6.1895             nan     0.1000    0.0802
    10        6.1009             nan     0.1000    0.0559
    20        5.5909             nan     0.1000   -0.0132
    40        4.9311             nan     0.1000   -0.0163
    60        4.6078             nan     0.1000   -0.0018
    80        4.4223             nan     0.1000   -0.0173
   100        4.3232             nan     0.1000   -0.0081
   120        4.2363             nan     0.1000   -0.0013
   140        4.1706             nan     0.1000   -0.0225
   160        4.1169             nan     0.1000   -0.0097
   180        4.0883             nan     0.1000   -0.0187
   200        4.0691             nan     0.1000   -0.0135

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2209             nan     0.1000    0.2684
     2        6.9939             nan     0.1000    0.1675
     3        6.8014             nan     0.1000    0.1731
     4        6.6102             nan     0.1000    0.1638
     5        6.4409             nan     0.1000    0.1561
     6        6.2413             nan     0.1000    0.1450
     7        6.0904             nan     0.1000    0.1206
     8        5.9481             nan     0.1000    0.0534
     9        5.8670             nan     0.1000    0.0144
    10        5.8124             nan     0.1000   -0.0048
    20        5.0171             nan     0.1000    0.0320
    40        4.3515             nan     0.1000   -0.0234
    60        4.0762             nan     0.1000   -0.0161
    80        3.8841             nan     0.1000   -0.0200
   100        3.7118             nan     0.1000   -0.0211
   120        3.5422             nan     0.1000   -0.0165
   140        3.4409             nan     0.1000    0.0076
   160        3.3165             nan     0.1000   -0.0159
   180        3.2165             nan     0.1000   -0.0199
   200        3.1425             nan     0.1000   -0.0114

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2205             nan     0.1000    0.2741
     2        6.8708             nan     0.1000    0.2785
     3        6.6111             nan     0.1000    0.2428
     4        6.3702             nan     0.1000    0.1828
     5        6.1857             nan     0.1000    0.1470
     6        5.9914             nan     0.1000    0.1072
     7        5.8565             nan     0.1000    0.0684
     8        5.7332             nan     0.1000    0.0613
     9        5.6093             nan     0.1000    0.1015
    10        5.4689             nan     0.1000    0.1323
    20        4.7517             nan     0.1000    0.0026
    40        4.0818             nan     0.1000   -0.0306
    60        3.7239             nan     0.1000   -0.0084
    80        3.4486             nan     0.1000   -0.0377
   100        3.2321             nan     0.1000   -0.0076
   120        3.0535             nan     0.1000   -0.0248
   140        2.8895             nan     0.1000   -0.0139
   160        2.7594             nan     0.1000   -0.0206
   180        2.6437             nan     0.1000   -0.0293
   200        2.5211             nan     0.1000   -0.0216

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1036             nan     0.1000    0.3031
     2        6.7226             nan     0.1000    0.2091
     3        6.3822             nan     0.1000    0.2496
     4        6.1259             nan     0.1000    0.1803
     5        5.8558             nan     0.1000    0.2325
     6        5.6121             nan     0.1000    0.1633
     7        5.4372             nan     0.1000    0.1106
     8        5.2292             nan     0.1000    0.1383
     9        5.1077             nan     0.1000    0.0588
    10        5.0041             nan     0.1000   -0.0279
    20        4.2218             nan     0.1000   -0.0012
    40        3.4744             nan     0.1000   -0.0072
    60        3.0245             nan     0.1000   -0.0484
    80        2.7036             nan     0.1000   -0.0282
   100        2.4108             nan     0.1000   -0.0336
   120        2.1847             nan     0.1000   -0.0213
   140        2.0151             nan     0.1000   -0.0228
   160        1.8313             nan     0.1000   -0.0300
   180        1.6959             nan     0.1000   -0.0213
   200        1.5517             nan     0.1000   -0.0147

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0482             nan     0.2000    0.4297
     2        6.7154             nan     0.2000    0.2351
     3        6.4881             nan     0.2000    0.1024
     4        6.2087             nan     0.2000    0.1610
     5        6.0374             nan     0.2000    0.1426
     6        5.9208             nan     0.2000    0.1012
     7        5.8087             nan     0.2000    0.0725
     8        5.7355             nan     0.2000   -0.0012
     9        5.6459             nan     0.2000    0.0166
    10        5.5199             nan     0.2000    0.0782
    20        4.9920             nan     0.2000    0.0044
    40        4.4690             nan     0.2000   -0.0278
    60        4.2830             nan     0.2000   -0.0211
    80        4.1514             nan     0.2000   -0.0017
   100        4.1228             nan     0.2000   -0.0402
   120        4.0498             nan     0.2000   -0.0284
   140        4.0215             nan     0.2000   -0.0270
   160        3.9806             nan     0.2000   -0.0125
   180        3.9691             nan     0.2000   -0.0187
   200        3.9570             nan     0.2000   -0.0305

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8921             nan     0.2000    0.5331
     2        6.5451             nan     0.2000    0.3227
     3        6.1789             nan     0.2000    0.1858
     4        5.8313             nan     0.2000    0.2317
     5        5.6228             nan     0.2000    0.1246
     6        5.4515             nan     0.2000    0.0915
     7        5.3116             nan     0.2000    0.0664
     8        5.2107             nan     0.2000    0.0105
     9        5.1368             nan     0.2000    0.0344
    10        5.0355             nan     0.2000    0.0492
    20        4.3707             nan     0.2000   -0.0884
    40        3.9198             nan     0.2000   -0.0352
    60        3.6624             nan     0.2000   -0.0282
    80        3.3843             nan     0.2000   -0.0257
   100        3.1980             nan     0.2000   -0.0354
   120        3.0603             nan     0.2000   -0.0245
   140        2.9124             nan     0.2000   -0.0104
   160        2.8165             nan     0.2000   -0.0329
   180        2.7286             nan     0.2000   -0.0180
   200        2.6555             nan     0.2000   -0.0377

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8959             nan     0.2000    0.4526
     2        6.4484             nan     0.2000    0.3264
     3        6.1047             nan     0.2000    0.1919
     4        5.9014             nan     0.2000    0.1175
     5        5.6643             nan     0.2000    0.1392
     6        5.3707             nan     0.2000    0.2552
     7        5.2109             nan     0.2000    0.0617
     8        5.0854             nan     0.2000    0.0532
     9        4.9688             nan     0.2000   -0.0525
    10        4.8506             nan     0.2000    0.0653
    20        4.1842             nan     0.2000   -0.0330
    40        3.5774             nan     0.2000   -0.0738
    60        3.1804             nan     0.2000   -0.0445
    80        2.8678             nan     0.2000   -0.0278
   100        2.6251             nan     0.2000   -0.0516
   120        2.3873             nan     0.2000   -0.0376
   140        2.2041             nan     0.2000   -0.0294
   160        2.0294             nan     0.2000   -0.0324
   180        1.8843             nan     0.2000   -0.0182
   200        1.7243             nan     0.2000   -0.0102

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8031             nan     0.2000    0.5354
     2        6.1900             nan     0.2000    0.4749
     3        5.8183             nan     0.2000    0.2566
     4        5.4474             nan     0.2000    0.2066
     5        5.2035             nan     0.2000    0.1420
     6        4.9588             nan     0.2000    0.0724
     7        4.6994             nan     0.2000    0.0662
     8        4.6038             nan     0.2000   -0.0715
     9        4.4490             nan     0.2000    0.0344
    10        4.3061             nan     0.2000   -0.0083
    20        3.6223             nan     0.2000   -0.1047
    40        2.8708             nan     0.2000   -0.0542
    60        2.2354             nan     0.2000   -0.0422
    80        1.8501             nan     0.2000   -0.0483
   100        1.5676             nan     0.2000   -0.0228
   120        1.3389             nan     0.2000   -0.0485
   140        1.1331             nan     0.2000   -0.0212
   160        0.9928             nan     0.2000   -0.0133
   180        0.8694             nan     0.2000   -0.0333
   200        0.7706             nan     0.2000   -0.0060

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2046             nan     0.0500    0.1171
     2        7.0709             nan     0.0500    0.0949
     3        6.9630             nan     0.0500    0.1025
     4        6.8931             nan     0.0500    0.0667
     5        6.8138             nan     0.0500    0.0650
     6        6.7539             nan     0.0500    0.0640
     7        6.6806             nan     0.0500    0.0746
     8        6.6074             nan     0.0500    0.0449
     9        6.5517             nan     0.0500    0.0634
    10        6.4884             nan     0.0500    0.0572
    20        6.0706             nan     0.0500    0.0039
    40        5.5716             nan     0.0500    0.0050
    60        5.2346             nan     0.0500    0.0018
    80        5.0010             nan     0.0500   -0.0036
   100        4.8354             nan     0.0500   -0.0066
   120        4.6756             nan     0.0500    0.0012
   140        4.5749             nan     0.0500   -0.0075
   160        4.4858             nan     0.0500   -0.0039
   180        4.4178             nan     0.0500   -0.0089
   200        4.3532             nan     0.0500   -0.0109

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2084             nan     0.0500    0.1263
     2        7.0790             nan     0.0500    0.1219
     3        6.9570             nan     0.0500    0.1086
     4        6.8455             nan     0.0500    0.1057
     5        6.7291             nan     0.0500    0.0847
     6        6.6284             nan     0.0500    0.0552
     7        6.5339             nan     0.0500    0.0749
     8        6.4500             nan     0.0500    0.0822
     9        6.3645             nan     0.0500    0.0448
    10        6.2906             nan     0.0500    0.0543
    20        5.7290             nan     0.0500    0.0078
    40        5.0902             nan     0.0500    0.0062
    60        4.7265             nan     0.0500    0.0030
    80        4.4421             nan     0.0500    0.0016
   100        4.2693             nan     0.0500   -0.0081
   120        4.1094             nan     0.0500   -0.0013
   140        3.9702             nan     0.0500   -0.0008
   160        3.8958             nan     0.0500   -0.0062
   180        3.8053             nan     0.0500   -0.0187
   200        3.7147             nan     0.0500   -0.0087

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1577             nan     0.0500    0.1262
     2        6.9847             nan     0.0500    0.1537
     3        6.8303             nan     0.0500    0.1068
     4        6.7134             nan     0.0500    0.0898
     5        6.5849             nan     0.0500    0.1019
     6        6.4773             nan     0.0500    0.0801
     7        6.3804             nan     0.0500    0.0843
     8        6.2750             nan     0.0500    0.0915
     9        6.1776             nan     0.0500    0.0399
    10        6.1008             nan     0.0500    0.0538
    20        5.4612             nan     0.0500    0.0308
    40        4.7410             nan     0.0500    0.0142
    60        4.3119             nan     0.0500   -0.0042
    80        4.0374             nan     0.0500   -0.0094
   100        3.8369             nan     0.0500   -0.0150
   120        3.6656             nan     0.0500   -0.0101
   140        3.5049             nan     0.0500   -0.0042
   160        3.3985             nan     0.0500   -0.0118
   180        3.2917             nan     0.0500   -0.0124
   200        3.1943             nan     0.0500   -0.0040

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1227             nan     0.0500    0.1178
     2        6.9416             nan     0.0500    0.1047
     3        6.7478             nan     0.0500    0.1122
     4        6.5963             nan     0.0500    0.0480
     5        6.4623             nan     0.0500    0.0648
     6        6.3073             nan     0.0500    0.1137
     7        6.1729             nan     0.0500    0.0688
     8        6.0560             nan     0.0500    0.1043
     9        5.9812             nan     0.0500    0.0686
    10        5.8649             nan     0.0500    0.0685
    20        5.1007             nan     0.0500    0.0156
    40        4.2754             nan     0.0500    0.0015
    60        3.7902             nan     0.0500   -0.0240
    80        3.4680             nan     0.0500   -0.0059
   100        3.2190             nan     0.0500   -0.0103
   120        3.0110             nan     0.0500   -0.0146
   140        2.8164             nan     0.0500   -0.0053
   160        2.6607             nan     0.0500   -0.0133
   180        2.4970             nan     0.0500    0.0003
   200        2.3358             nan     0.0500   -0.0129

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0693             nan     0.1000    0.1727
     2        6.8874             nan     0.1000    0.1765
     3        6.7376             nan     0.1000    0.1812
     4        6.5936             nan     0.1000    0.1004
     5        6.4933             nan     0.1000    0.0984
     6        6.3828             nan     0.1000    0.0925
     7        6.3395             nan     0.1000   -0.0162
     8        6.2317             nan     0.1000    0.0703
     9        6.1468             nan     0.1000    0.0331
    10        6.0705             nan     0.1000    0.0654
    20        5.5449             nan     0.1000    0.0094
    40        5.0040             nan     0.1000   -0.0077
    60        4.6958             nan     0.1000    0.0080
    80        4.5101             nan     0.1000   -0.0127
   100        4.3711             nan     0.1000   -0.0233
   120        4.3090             nan     0.1000   -0.0042
   140        4.2384             nan     0.1000   -0.0199
   160        4.1891             nan     0.1000   -0.0129
   180        4.1572             nan     0.1000   -0.0132
   200        4.1277             nan     0.1000   -0.0046

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0181             nan     0.1000    0.2410
     2        6.8335             nan     0.1000    0.1442
     3        6.6715             nan     0.1000    0.1030
     4        6.4861             nan     0.1000    0.0626
     5        6.3273             nan     0.1000    0.0711
     6        6.2191             nan     0.1000    0.0863
     7        6.0822             nan     0.1000    0.0847
     8        5.9567             nan     0.1000    0.0677
     9        5.8659             nan     0.1000    0.0637
    10        5.7724             nan     0.1000    0.0511
    20        5.0549             nan     0.1000    0.0018
    40        4.3714             nan     0.1000    0.0020
    60        4.0439             nan     0.1000   -0.0157
    80        3.8313             nan     0.1000   -0.0069
   100        3.6667             nan     0.1000   -0.0236
   120        3.5570             nan     0.1000   -0.0175
   140        3.4603             nan     0.1000   -0.0161
   160        3.3290             nan     0.1000   -0.0150
   180        3.2051             nan     0.1000   -0.0074
   200        3.0851             nan     0.1000   -0.0149

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0016             nan     0.1000    0.2752
     2        6.6950             nan     0.1000    0.2294
     3        6.4547             nan     0.1000    0.1652
     4        6.2140             nan     0.1000    0.1932
     5        6.0174             nan     0.1000    0.1018
     6        5.8778             nan     0.1000    0.0828
     7        5.7599             nan     0.1000    0.0113
     8        5.6415             nan     0.1000   -0.0016
     9        5.5289             nan     0.1000    0.0150
    10        5.4424             nan     0.1000    0.0638
    20        4.6825             nan     0.1000    0.0104
    40        4.0212             nan     0.1000   -0.0382
    60        3.6742             nan     0.1000   -0.0340
    80        3.3911             nan     0.1000   -0.0308
   100        3.2112             nan     0.1000   -0.0315
   120        3.0370             nan     0.1000   -0.0463
   140        2.8791             nan     0.1000   -0.0345
   160        2.7873             nan     0.1000   -0.0180
   180        2.6701             nan     0.1000   -0.0247
   200        2.5837             nan     0.1000   -0.0193

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8999             nan     0.1000    0.3236
     2        6.5810             nan     0.1000    0.1706
     3        6.3140             nan     0.1000    0.1813
     4        6.0572             nan     0.1000    0.1615
     5        5.8475             nan     0.1000    0.1117
     6        5.6691             nan     0.1000    0.1485
     7        5.5514             nan     0.1000    0.0462
     8        5.3894             nan     0.1000    0.0960
     9        5.2495             nan     0.1000    0.0574
    10        5.1261             nan     0.1000    0.0461
    20        4.3689             nan     0.1000   -0.0009
    40        3.5959             nan     0.1000   -0.0209
    60        3.0869             nan     0.1000   -0.0377
    80        2.7463             nan     0.1000   -0.0270
   100        2.4676             nan     0.1000   -0.0237
   120        2.2298             nan     0.1000   -0.0125
   140        2.0014             nan     0.1000   -0.0062
   160        1.8388             nan     0.1000   -0.0232
   180        1.6863             nan     0.1000   -0.0394
   200        1.5460             nan     0.1000   -0.0148

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0245             nan     0.2000    0.3117
     2        6.5781             nan     0.2000    0.3238
     3        6.4288             nan     0.2000    0.1520
     4        6.2211             nan     0.2000    0.1292
     5        6.0198             nan     0.2000    0.1735
     6        5.8976             nan     0.2000    0.1161
     7        5.7884             nan     0.2000    0.0265
     8        5.7048             nan     0.2000    0.0007
     9        5.6122             nan     0.2000    0.0117
    10        5.5721             nan     0.2000   -0.0403
    20        5.0413             nan     0.2000    0.0208
    40        4.5211             nan     0.2000    0.0108
    60        4.3704             nan     0.2000   -0.0478
    80        4.2396             nan     0.2000   -0.0209
   100        4.1417             nan     0.2000   -0.0263
   120        4.1004             nan     0.2000   -0.0295
   140        4.0836             nan     0.2000   -0.0207
   160        4.0717             nan     0.2000   -0.0274
   180        4.0684             nan     0.2000   -0.0231
   200        4.0623             nan     0.2000   -0.0376

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8056             nan     0.2000    0.5452
     2        6.4289             nan     0.2000    0.3420
     3        6.1575             nan     0.2000    0.1639
     4        5.9480             nan     0.2000    0.1831
     5        5.7595             nan     0.2000    0.0835
     6        5.5853             nan     0.2000    0.0430
     7        5.4860             nan     0.2000   -0.0000
     8        5.3051             nan     0.2000    0.1821
     9        5.2270             nan     0.2000   -0.0386
    10        5.1280             nan     0.2000   -0.0090
    20        4.4760             nan     0.2000   -0.0194
    40        3.9068             nan     0.2000   -0.0232
    60        3.6461             nan     0.2000   -0.0327
    80        3.4690             nan     0.2000   -0.0367
   100        3.3381             nan     0.2000   -0.0418
   120        3.1382             nan     0.2000   -0.0043
   140        3.0366             nan     0.2000   -0.0409
   160        2.9185             nan     0.2000   -0.0248
   180        2.7603             nan     0.2000   -0.0219
   200        2.6350             nan     0.2000   -0.0491

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6200             nan     0.2000    0.5314
     2        6.2189             nan     0.2000    0.3574
     3        6.0101             nan     0.2000    0.1151
     4        5.7455             nan     0.2000    0.2429
     5        5.5007             nan     0.2000    0.1457
     6        5.3305             nan     0.2000    0.0293
     7        5.1859             nan     0.2000    0.0573
     8        5.0442             nan     0.2000    0.0788
     9        4.9097             nan     0.2000   -0.0039
    10        4.8545             nan     0.2000   -0.0894
    20        4.2148             nan     0.2000    0.0372
    40        3.4694             nan     0.2000   -0.0589
    60        3.0551             nan     0.2000   -0.0791
    80        2.7470             nan     0.2000   -0.0397
   100        2.5080             nan     0.2000   -0.0597
   120        2.2956             nan     0.2000   -0.0225
   140        2.1335             nan     0.2000   -0.0340
   160        1.9777             nan     0.2000   -0.0485
   180        1.8243             nan     0.2000   -0.0358
   200        1.6804             nan     0.2000   -0.0305

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6628             nan     0.2000    0.5107
     2        6.2084             nan     0.2000    0.3097
     3        5.7973             nan     0.2000    0.3179
     4        5.4781             nan     0.2000    0.1934
     5        5.1787             nan     0.2000    0.2318
     6        4.9578             nan     0.2000    0.0129
     7        4.8408             nan     0.2000   -0.0269
     8        4.6654             nan     0.2000    0.0560
     9        4.5081             nan     0.2000   -0.0455
    10        4.3929             nan     0.2000   -0.0266
    20        3.6855             nan     0.2000   -0.0506
    40        2.8878             nan     0.2000   -0.0438
    60        2.3976             nan     0.2000   -0.0476
    80        1.9325             nan     0.2000   -0.0596
   100        1.6388             nan     0.2000   -0.0629
   120        1.4176             nan     0.2000   -0.0271
   140        1.2287             nan     0.2000   -0.0359
   160        1.0605             nan     0.2000   -0.0361
   180        0.9028             nan     0.2000   -0.0076
   200        0.7982             nan     0.2000   -0.0317

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3714             nan     0.0500    0.1326
     2        7.2308             nan     0.0500    0.1176
     3        7.1344             nan     0.0500    0.0911
     4        7.0391             nan     0.0500    0.0662
     5        6.9473             nan     0.0500    0.0802
     6        6.8638             nan     0.0500    0.0557
     7        6.8034             nan     0.0500    0.0419
     8        6.7140             nan     0.0500    0.0544
     9        6.6300             nan     0.0500    0.0377
    10        6.5762             nan     0.0500    0.0460
    20        6.1291             nan     0.0500    0.0009
    40        5.5614             nan     0.0500   -0.0049
    60        5.2059             nan     0.0500    0.0087
    80        4.9361             nan     0.0500    0.0039
   100        4.7258             nan     0.0500   -0.0026
   120        4.5878             nan     0.0500   -0.0058
   140        4.4715             nan     0.0500   -0.0032
   160        4.3846             nan     0.0500   -0.0013
   180        4.3168             nan     0.0500   -0.0060
   200        4.2675             nan     0.0500   -0.0006

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3409             nan     0.0500    0.1254
     2        7.2129             nan     0.0500    0.1366
     3        7.0826             nan     0.0500    0.1098
     4        6.9670             nan     0.0500    0.1136
     5        6.8528             nan     0.0500    0.1159
     6        6.7362             nan     0.0500    0.0772
     7        6.6356             nan     0.0500    0.0798
     8        6.5323             nan     0.0500    0.0647
     9        6.4362             nan     0.0500    0.0500
    10        6.3452             nan     0.0500    0.0715
    20        5.6938             nan     0.0500    0.0177
    40        4.9727             nan     0.0500    0.0200
    60        4.5967             nan     0.0500    0.0010
    80        4.2896             nan     0.0500   -0.0301
   100        4.0969             nan     0.0500   -0.0059
   120        3.9384             nan     0.0500   -0.0043
   140        3.8421             nan     0.0500   -0.0027
   160        3.7315             nan     0.0500   -0.0110
   180        3.6497             nan     0.0500   -0.0124
   200        3.5651             nan     0.0500   -0.0083

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3138             nan     0.0500    0.1112
     2        7.1354             nan     0.0500    0.1319
     3        6.9699             nan     0.0500    0.1387
     4        6.8235             nan     0.0500    0.1622
     5        6.6725             nan     0.0500    0.1302
     6        6.5386             nan     0.0500    0.1071
     7        6.4215             nan     0.0500    0.0887
     8        6.3272             nan     0.0500    0.0856
     9        6.2274             nan     0.0500    0.0547
    10        6.1340             nan     0.0500    0.0747
    20        5.4482             nan     0.0500    0.0648
    40        4.6492             nan     0.0500    0.0131
    60        4.1993             nan     0.0500    0.0037
    80        3.9091             nan     0.0500   -0.0151
   100        3.7093             nan     0.0500   -0.0095
   120        3.5345             nan     0.0500   -0.0125
   140        3.3923             nan     0.0500   -0.0121
   160        3.2879             nan     0.0500   -0.0120
   180        3.1686             nan     0.0500   -0.0195
   200        3.0721             nan     0.0500   -0.0179

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2774             nan     0.0500    0.1678
     2        7.1207             nan     0.0500    0.1307
     3        6.9588             nan     0.0500    0.1155
     4        6.7930             nan     0.0500    0.1317
     5        6.6592             nan     0.0500    0.1137
     6        6.5111             nan     0.0500    0.1271
     7        6.3764             nan     0.0500    0.1326
     8        6.2359             nan     0.0500    0.1201
     9        6.0847             nan     0.0500    0.0763
    10        5.9516             nan     0.0500    0.0991
    20        5.0652             nan     0.0500    0.0369
    40        4.1377             nan     0.0500    0.0061
    60        3.6591             nan     0.0500   -0.0013
    80        3.3580             nan     0.0500   -0.0084
   100        3.1385             nan     0.0500   -0.0356
   120        2.9148             nan     0.0500   -0.0073
   140        2.7332             nan     0.0500   -0.0051
   160        2.5542             nan     0.0500   -0.0185
   180        2.4045             nan     0.0500   -0.0101
   200        2.2604             nan     0.0500   -0.0079

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2069             nan     0.1000    0.2586
     2        7.0199             nan     0.1000    0.1594
     3        6.8507             nan     0.1000    0.1571
     4        6.6584             nan     0.1000    0.1840
     5        6.5314             nan     0.1000    0.0566
     6        6.4447             nan     0.1000    0.0880
     7        6.3534             nan     0.1000   -0.0040
     8        6.2678             nan     0.1000    0.0776
     9        6.2024             nan     0.1000    0.0358
    10        6.1404             nan     0.1000    0.0521
    20        5.5759             nan     0.1000    0.0077
    40        4.9619             nan     0.1000    0.0034
    60        4.5877             nan     0.1000    0.0043
    80        4.4342             nan     0.1000   -0.0189
   100        4.2814             nan     0.1000   -0.0094
   120        4.1982             nan     0.1000   -0.0104
   140        4.1543             nan     0.1000   -0.0187
   160        4.0753             nan     0.1000   -0.0096
   180        4.0429             nan     0.1000   -0.0134
   200        4.0090             nan     0.1000   -0.0129

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1916             nan     0.1000    0.2734
     2        6.9583             nan     0.1000    0.2679
     3        6.7237             nan     0.1000    0.1755
     4        6.4855             nan     0.1000    0.2031
     5        6.3355             nan     0.1000    0.1362
     6        6.1457             nan     0.1000    0.0781
     7        6.0291             nan     0.1000    0.1066
     8        5.9654             nan     0.1000    0.0123
     9        5.8881             nan     0.1000   -0.0067
    10        5.7525             nan     0.1000    0.1097
    20        5.0549             nan     0.1000    0.0210
    40        4.3199             nan     0.1000   -0.0120
    60        3.9768             nan     0.1000   -0.0126
    80        3.7416             nan     0.1000   -0.0068
   100        3.5866             nan     0.1000   -0.0201
   120        3.4701             nan     0.1000   -0.0196
   140        3.3727             nan     0.1000   -0.0132
   160        3.2585             nan     0.1000   -0.0122
   180        3.1704             nan     0.1000   -0.0026
   200        3.0979             nan     0.1000   -0.0191

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1343             nan     0.1000    0.3747
     2        6.8117             nan     0.1000    0.3174
     3        6.5086             nan     0.1000    0.2503
     4        6.2560             nan     0.1000    0.1606
     5        6.0833             nan     0.1000    0.1540
     6        5.9601             nan     0.1000    0.0888
     7        5.8587             nan     0.1000    0.0528
     8        5.7479             nan     0.1000    0.0752
     9        5.6107             nan     0.1000    0.0299
    10        5.4648             nan     0.1000    0.1298
    20        4.6660             nan     0.1000    0.0177
    40        3.9890             nan     0.1000   -0.0220
    60        3.6477             nan     0.1000   -0.0148
    80        3.3622             nan     0.1000   -0.0357
   100        3.1474             nan     0.1000   -0.0212
   120        2.9725             nan     0.1000   -0.0083
   140        2.8198             nan     0.1000   -0.0159
   160        2.6816             nan     0.1000   -0.0248
   180        2.5704             nan     0.1000   -0.0173
   200        2.4664             nan     0.1000   -0.0079

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0639             nan     0.1000    0.2964
     2        6.7375             nan     0.1000    0.2837
     3        6.4149             nan     0.1000    0.2295
     4        6.2231             nan     0.1000    0.1054
     5        5.9863             nan     0.1000    0.1428
     6        5.7288             nan     0.1000    0.1332
     7        5.5081             nan     0.1000    0.1947
     8        5.3651             nan     0.1000    0.0577
     9        5.1931             nan     0.1000    0.0626
    10        5.0802             nan     0.1000    0.0033
    20        4.2242             nan     0.1000    0.0051
    40        3.4170             nan     0.1000   -0.0084
    60        2.9611             nan     0.1000    0.0054
    80        2.6789             nan     0.1000   -0.0421
   100        2.4476             nan     0.1000   -0.0225
   120        2.2262             nan     0.1000   -0.0220
   140        2.0300             nan     0.1000   -0.0079
   160        1.8494             nan     0.1000   -0.0036
   180        1.6825             nan     0.1000   -0.0224
   200        1.5451             nan     0.1000   -0.0206

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0721             nan     0.2000    0.4230
     2        6.7214             nan     0.2000    0.3298
     3        6.6367             nan     0.2000   -0.0222
     4        6.5041             nan     0.2000    0.0789
     5        6.2717             nan     0.2000    0.1567
     6        6.0380             nan     0.2000    0.1364
     7        5.9048             nan     0.2000    0.0767
     8        5.7373             nan     0.2000    0.1418
     9        5.6836             nan     0.2000    0.0108
    10        5.5888             nan     0.2000    0.0600
    20        4.9193             nan     0.2000    0.0013
    40        4.3717             nan     0.2000   -0.0189
    60        4.2106             nan     0.2000   -0.0307
    80        4.1096             nan     0.2000   -0.0183
   100        4.0291             nan     0.2000   -0.0378
   120        4.0121             nan     0.2000   -0.0419
   140        3.9814             nan     0.2000   -0.0458
   160        3.9185             nan     0.2000   -0.0224
   180        3.9099             nan     0.2000   -0.0311
   200        3.9053             nan     0.2000   -0.0471

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9018             nan     0.2000    0.3558
     2        6.4272             nan     0.2000    0.3581
     3        6.1625             nan     0.2000    0.1181
     4        5.9434             nan     0.2000    0.2120
     5        5.7138             nan     0.2000    0.2197
     6        5.5742             nan     0.2000    0.0840
     7        5.3837             nan     0.2000    0.1818
     8        5.2589             nan     0.2000    0.0201
     9        5.1738             nan     0.2000    0.0211
    10        5.0300             nan     0.2000    0.0486
    20        4.3760             nan     0.2000   -0.0090
    40        3.9185             nan     0.2000   -0.0320
    60        3.5683             nan     0.2000   -0.0547
    80        3.3584             nan     0.2000   -0.0235
   100        3.2474             nan     0.2000   -0.0177
   120        3.1063             nan     0.2000   -0.0196
   140        2.9589             nan     0.2000   -0.0398
   160        2.8065             nan     0.2000   -0.0499
   180        2.6727             nan     0.2000   -0.0340
   200        2.5974             nan     0.2000   -0.0309

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7928             nan     0.2000    0.6786
     2        6.3491             nan     0.2000    0.1056
     3        5.9448             nan     0.2000    0.2789
     4        5.6010             nan     0.2000    0.2336
     5        5.4233             nan     0.2000    0.1137
     6        5.2005             nan     0.2000    0.1296
     7        4.9702             nan     0.2000    0.1486
     8        4.8812             nan     0.2000   -0.0227
     9        4.7383             nan     0.2000    0.0779
    10        4.6099             nan     0.2000   -0.0495
    20        4.0139             nan     0.2000   -0.0429
    40        3.3610             nan     0.2000   -0.0499
    60        2.9839             nan     0.2000   -0.0325
    80        2.6833             nan     0.2000   -0.0353
   100        2.3843             nan     0.2000   -0.0397
   120        2.2214             nan     0.2000   -0.0721
   140        2.1199             nan     0.2000   -0.0622
   160        1.9396             nan     0.2000   -0.0302
   180        1.7803             nan     0.2000   -0.0314
   200        1.6911             nan     0.2000   -0.0367

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7483             nan     0.2000    0.6815
     2        6.1236             nan     0.2000    0.6543
     3        5.7580             nan     0.2000    0.2972
     4        5.5001             nan     0.2000    0.1221
     5        5.2023             nan     0.2000    0.1489
     6        4.9427             nan     0.2000    0.1133
     7        4.7714             nan     0.2000   -0.0118
     8        4.5852             nan     0.2000   -0.0320
     9        4.4681             nan     0.2000   -0.0364
    10        4.3564             nan     0.2000   -0.0047
    20        3.5077             nan     0.2000   -0.0828
    40        2.7436             nan     0.2000   -0.0187
    60        2.3586             nan     0.2000   -0.0518
    80        1.9646             nan     0.2000   -0.0387
   100        1.6915             nan     0.2000   -0.0398
   120        1.4377             nan     0.2000   -0.0446
   140        1.2344             nan     0.2000   -0.0093
   160        1.0855             nan     0.2000   -0.0185
   180        0.9509             nan     0.2000   -0.0137
   200        0.8412             nan     0.2000   -0.0107

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5660             nan     0.0500    0.0932
     2        6.4620             nan     0.0500    0.0933
     3        6.3816             nan     0.0500    0.0552
     4        6.2845             nan     0.0500    0.0914
     5        6.2058             nan     0.0500    0.0551
     6        6.1427             nan     0.0500    0.0623
     7        6.0666             nan     0.0500    0.0448
     8        6.0102             nan     0.0500    0.0612
     9        5.9521             nan     0.0500    0.0558
    10        5.9004             nan     0.0500    0.0538
    20        5.5078             nan     0.0500    0.0354
    40        5.0755             nan     0.0500    0.0040
    60        4.8123             nan     0.0500   -0.0019
    80        4.6053             nan     0.0500   -0.0006
   100        4.4554             nan     0.0500    0.0024
   120        4.3179             nan     0.0500   -0.0028
   140        4.2240             nan     0.0500   -0.0033
   160        4.1511             nan     0.0500   -0.0082
   180        4.0915             nan     0.0500   -0.0044
   200        4.0294             nan     0.0500   -0.0065

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5526             nan     0.0500    0.0996
     2        6.4061             nan     0.0500    0.1240
     3        6.3028             nan     0.0500    0.0916
     4        6.1656             nan     0.0500    0.1040
     5        6.0348             nan     0.0500    0.1142
     6        5.9576             nan     0.0500    0.0877
     7        5.8930             nan     0.0500    0.0309
     8        5.8271             nan     0.0500    0.0444
     9        5.7465             nan     0.0500    0.0551
    10        5.6802             nan     0.0500    0.0312
    20        5.1711             nan     0.0500   -0.0000
    40        4.6020             nan     0.0500    0.0127
    60        4.2833             nan     0.0500   -0.0042
    80        4.0419             nan     0.0500    0.0007
   100        3.8630             nan     0.0500   -0.0176
   120        3.7431             nan     0.0500   -0.0088
   140        3.6333             nan     0.0500   -0.0171
   160        3.5477             nan     0.0500   -0.0088
   180        3.4562             nan     0.0500   -0.0084
   200        3.3909             nan     0.0500   -0.0046

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4937             nan     0.0500    0.1849
     2        6.3661             nan     0.0500    0.1291
     3        6.2353             nan     0.0500    0.0933
     4        6.1247             nan     0.0500    0.0949
     5        6.0226             nan     0.0500    0.1015
     6        5.9309             nan     0.0500    0.0573
     7        5.8360             nan     0.0500    0.0805
     8        5.7388             nan     0.0500    0.0683
     9        5.6635             nan     0.0500    0.0362
    10        5.5808             nan     0.0500    0.0660
    20        4.9941             nan     0.0500    0.0288
    40        4.3371             nan     0.0500   -0.0024
    60        3.9602             nan     0.0500    0.0005
    80        3.7242             nan     0.0500   -0.0075
   100        3.5555             nan     0.0500   -0.0167
   120        3.3951             nan     0.0500   -0.0074
   140        3.2495             nan     0.0500   -0.0077
   160        3.1477             nan     0.0500   -0.0199
   180        3.0594             nan     0.0500   -0.0134
   200        2.9774             nan     0.0500   -0.0056

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4954             nan     0.0500    0.1526
     2        6.3645             nan     0.0500    0.0918
     3        6.2353             nan     0.0500    0.0760
     4        6.0723             nan     0.0500    0.1525
     5        5.9425             nan     0.0500    0.0725
     6        5.8367             nan     0.0500    0.0321
     7        5.7105             nan     0.0500    0.1161
     8        5.5707             nan     0.0500    0.1065
     9        5.4712             nan     0.0500    0.0801
    10        5.3643             nan     0.0500    0.0884
    20        4.6375             nan     0.0500    0.0252
    40        3.9176             nan     0.0500   -0.0161
    60        3.5059             nan     0.0500   -0.0193
    80        3.1931             nan     0.0500   -0.0065
   100        2.9635             nan     0.0500   -0.0080
   120        2.7547             nan     0.0500   -0.0135
   140        2.6022             nan     0.0500   -0.0160
   160        2.4407             nan     0.0500   -0.0092
   180        2.3010             nan     0.0500   -0.0075
   200        2.1711             nan     0.0500   -0.0088

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4640             nan     0.1000    0.1619
     2        6.3177             nan     0.1000    0.1663
     3        6.1459             nan     0.1000    0.1652
     4        5.9803             nan     0.1000    0.1627
     5        5.8977             nan     0.1000    0.0795
     6        5.7957             nan     0.1000    0.1011
     7        5.7187             nan     0.1000    0.0387
     8        5.6305             nan     0.1000    0.0316
     9        5.5800             nan     0.1000    0.0290
    10        5.5164             nan     0.1000    0.0353
    20        5.0633             nan     0.1000    0.0221
    40        4.5962             nan     0.1000    0.0048
    60        4.3122             nan     0.1000   -0.0016
    80        4.1539             nan     0.1000   -0.0200
   100        4.0388             nan     0.1000   -0.0155
   120        3.9549             nan     0.1000   -0.0089
   140        3.8830             nan     0.1000   -0.0031
   160        3.8408             nan     0.1000   -0.0136
   180        3.8165             nan     0.1000   -0.0096
   200        3.7942             nan     0.1000   -0.0129

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4630             nan     0.1000    0.2049
     2        6.2630             nan     0.1000    0.2144
     3        6.0160             nan     0.1000    0.2124
     4        5.8541             nan     0.1000    0.1084
     5        5.6681             nan     0.1000    0.1579
     6        5.5585             nan     0.1000    0.1042
     7        5.4564             nan     0.1000    0.0903
     8        5.3502             nan     0.1000    0.0592
     9        5.2608             nan     0.1000    0.0769
    10        5.1739             nan     0.1000    0.0339
    20        4.6809             nan     0.1000    0.0119
    40        4.0332             nan     0.1000    0.0027
    60        3.7460             nan     0.1000   -0.0210
    80        3.5447             nan     0.1000   -0.0239
   100        3.4021             nan     0.1000   -0.0115
   120        3.2669             nan     0.1000   -0.0156
   140        3.1774             nan     0.1000   -0.0199
   160        3.0802             nan     0.1000   -0.0337
   180        2.9703             nan     0.1000   -0.0172
   200        2.8806             nan     0.1000   -0.0223

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4166             nan     0.1000    0.1858
     2        6.1832             nan     0.1000    0.2103
     3        5.9950             nan     0.1000    0.1261
     4        5.7854             nan     0.1000    0.1733
     5        5.6103             nan     0.1000    0.1578
     6        5.4856             nan     0.1000    0.0556
     7        5.3330             nan     0.1000    0.1266
     8        5.1841             nan     0.1000    0.0661
     9        5.0852             nan     0.1000    0.0717
    10        4.9857             nan     0.1000    0.0333
    20        4.3013             nan     0.1000    0.0164
    40        3.7188             nan     0.1000   -0.0092
    60        3.4019             nan     0.1000   -0.0190
    80        3.1932             nan     0.1000   -0.0156
   100        2.9834             nan     0.1000   -0.0224
   120        2.8423             nan     0.1000    0.0018
   140        2.7057             nan     0.1000   -0.0153
   160        2.5751             nan     0.1000   -0.0108
   180        2.4375             nan     0.1000   -0.0193
   200        2.3058             nan     0.1000   -0.0118

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4000             nan     0.1000    0.2825
     2        6.0959             nan     0.1000    0.2384
     3        5.8362             nan     0.1000    0.1308
     4        5.5665             nan     0.1000    0.1837
     5        5.3782             nan     0.1000    0.1001
     6        5.2168             nan     0.1000    0.1113
     7        5.0190             nan     0.1000    0.1180
     8        4.8942             nan     0.1000    0.0546
     9        4.7718             nan     0.1000   -0.0075
    10        4.6751             nan     0.1000    0.0204
    20        4.0010             nan     0.1000   -0.0206
    40        3.2483             nan     0.1000   -0.0183
    60        2.8242             nan     0.1000   -0.0169
    80        2.4754             nan     0.1000   -0.0264
   100        2.2385             nan     0.1000   -0.0205
   120        2.0256             nan     0.1000   -0.0134
   140        1.8080             nan     0.1000   -0.0141
   160        1.6543             nan     0.1000   -0.0250
   180        1.5285             nan     0.1000   -0.0091
   200        1.4008             nan     0.1000   -0.0191

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.2677             nan     0.2000    0.3760
     2        5.9685             nan     0.2000    0.2790
     3        5.7653             nan     0.2000    0.2346
     4        5.5650             nan     0.2000    0.1451
     5        5.4418             nan     0.2000    0.0497
     6        5.3460             nan     0.2000    0.0898
     7        5.2625             nan     0.2000    0.0425
     8        5.1798             nan     0.2000    0.0480
     9        5.0893             nan     0.2000    0.0155
    10        5.0088             nan     0.2000    0.0589
    20        4.6227             nan     0.2000   -0.0363
    40        4.1299             nan     0.2000   -0.0056
    60        3.9505             nan     0.2000   -0.0205
    80        3.9020             nan     0.2000   -0.0205
   100        3.8499             nan     0.2000   -0.0116
   120        3.8083             nan     0.2000   -0.0328
   140        3.7884             nan     0.2000   -0.0481
   160        3.7439             nan     0.2000   -0.0458
   180        3.7404             nan     0.2000   -0.0141
   200        3.7252             nan     0.2000   -0.0356

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.2055             nan     0.2000    0.3995
     2        5.7807             nan     0.2000    0.2299
     3        5.5259             nan     0.2000    0.1909
     4        5.3197             nan     0.2000    0.1229
     5        5.1182             nan     0.2000    0.1396
     6        4.9409             nan     0.2000    0.1322
     7        4.8375             nan     0.2000    0.0544
     8        4.7459             nan     0.2000   -0.0245
     9        4.6546             nan     0.2000    0.0659
    10        4.5585             nan     0.2000    0.0318
    20        4.0556             nan     0.2000   -0.0152
    40        3.5823             nan     0.2000   -0.0078
    60        3.3246             nan     0.2000   -0.0068
    80        3.1395             nan     0.2000   -0.0750
   100        2.9433             nan     0.2000   -0.0237
   120        2.8020             nan     0.2000   -0.0383
   140        2.6733             nan     0.2000   -0.0422
   160        2.5645             nan     0.2000   -0.0289
   180        2.4522             nan     0.2000   -0.0296
   200        2.3709             nan     0.2000   -0.0231

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.1715             nan     0.2000    0.4205
     2        5.7259             nan     0.2000    0.4410
     3        5.3746             nan     0.2000    0.2045
     4        5.1502             nan     0.2000    0.1350
     5        5.0065             nan     0.2000   -0.0122
     6        4.8237             nan     0.2000    0.0771
     7        4.6698             nan     0.2000    0.1011
     8        4.5379             nan     0.2000    0.0808
     9        4.4337             nan     0.2000    0.0598
    10        4.3332             nan     0.2000    0.0119
    20        3.6906             nan     0.2000   -0.0216
    40        3.1365             nan     0.2000   -0.0558
    60        2.7333             nan     0.2000   -0.0210
    80        2.4912             nan     0.2000   -0.0464
   100        2.2729             nan     0.2000   -0.0102
   120        2.0743             nan     0.2000   -0.0126
   140        1.8829             nan     0.2000   -0.0279
   160        1.7779             nan     0.2000   -0.0319
   180        1.6613             nan     0.2000   -0.0254
   200        1.5601             nan     0.2000   -0.0300

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        5.9900             nan     0.2000    0.7015
     2        5.4825             nan     0.2000    0.3372
     3        5.1700             nan     0.2000    0.2358
     4        4.9042             nan     0.2000    0.1641
     5        4.7097             nan     0.2000    0.0604
     6        4.4809             nan     0.2000    0.1221
     7        4.3700             nan     0.2000   -0.0105
     8        4.2278             nan     0.2000   -0.0172
     9        4.1348             nan     0.2000    0.0423
    10        3.9984             nan     0.2000    0.0481
    20        3.3480             nan     0.2000   -0.0210
    40        2.6277             nan     0.2000   -0.0433
    60        2.1128             nan     0.2000   -0.0527
    80        1.7893             nan     0.2000   -0.0540
   100        1.5170             nan     0.2000   -0.0363
   120        1.2997             nan     0.2000   -0.0175
   140        1.1167             nan     0.2000   -0.0284
   160        0.9507             nan     0.2000   -0.0202
   180        0.8176             nan     0.2000   -0.0149
   200        0.7367             nan     0.2000   -0.0204

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1755             nan     0.0500    0.1090
     2        7.0843             nan     0.0500    0.1105
     3        6.9769             nan     0.0500    0.0940
     4        6.9037             nan     0.0500    0.0799
     5        6.8175             nan     0.0500    0.0708
     6        6.7296             nan     0.0500    0.0791
     7        6.6591             nan     0.0500    0.0735
     8        6.5919             nan     0.0500    0.0700
     9        6.5374             nan     0.0500    0.0568
    10        6.4758             nan     0.0500    0.0483
    20        6.0789             nan     0.0500    0.0368
    40        5.5676             nan     0.0500   -0.0120
    60        5.2559             nan     0.0500    0.0076
    80        5.0441             nan     0.0500   -0.0084
   100        4.8395             nan     0.0500   -0.0027
   120        4.6994             nan     0.0500    0.0036
   140        4.5931             nan     0.0500   -0.0061
   160        4.4844             nan     0.0500   -0.0014
   180        4.4219             nan     0.0500   -0.0161
   200        4.3610             nan     0.0500   -0.0047

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1311             nan     0.0500    0.1142
     2        7.0151             nan     0.0500    0.0888
     3        6.8668             nan     0.0500    0.0826
     4        6.7621             nan     0.0500    0.1023
     5        6.6571             nan     0.0500    0.0734
     6        6.5724             nan     0.0500    0.0767
     7        6.4830             nan     0.0500    0.0682
     8        6.4105             nan     0.0500    0.0706
     9        6.3200             nan     0.0500    0.0581
    10        6.2431             nan     0.0500    0.0316
    20        5.6738             nan     0.0500    0.0253
    40        5.0557             nan     0.0500    0.0061
    60        4.6583             nan     0.0500   -0.0154
    80        4.4152             nan     0.0500   -0.0100
   100        4.2223             nan     0.0500    0.0074
   120        4.0718             nan     0.0500   -0.0138
   140        3.9615             nan     0.0500   -0.0083
   160        3.8723             nan     0.0500   -0.0134
   180        3.7937             nan     0.0500   -0.0070
   200        3.7183             nan     0.0500   -0.0130

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1117             nan     0.0500    0.0907
     2        6.9545             nan     0.0500    0.1158
     3        6.8163             nan     0.0500    0.1264
     4        6.6786             nan     0.0500    0.0748
     5        6.5634             nan     0.0500    0.0831
     6        6.4400             nan     0.0500    0.0656
     7        6.3421             nan     0.0500    0.0819
     8        6.2409             nan     0.0500    0.0538
     9        6.1490             nan     0.0500    0.0803
    10        6.0742             nan     0.0500    0.0565
    20        5.3565             nan     0.0500    0.0369
    40        4.6997             nan     0.0500   -0.0000
    60        4.2359             nan     0.0500   -0.0043
    80        3.9727             nan     0.0500   -0.0007
   100        3.7994             nan     0.0500   -0.0141
   120        3.6576             nan     0.0500   -0.0057
   140        3.5247             nan     0.0500   -0.0047
   160        3.4163             nan     0.0500   -0.0054
   180        3.2940             nan     0.0500   -0.0022
   200        3.1918             nan     0.0500   -0.0043

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0981             nan     0.0500    0.1084
     2        6.9305             nan     0.0500    0.1563
     3        6.7482             nan     0.0500    0.0835
     4        6.6092             nan     0.0500    0.0901
     5        6.4687             nan     0.0500    0.1262
     6        6.3314             nan     0.0500    0.1083
     7        6.2178             nan     0.0500    0.1012
     8        6.1154             nan     0.0500    0.0895
     9        5.9743             nan     0.0500    0.1069
    10        5.8645             nan     0.0500    0.0617
    20        5.1465             nan     0.0500   -0.0203
    40        4.2578             nan     0.0500    0.0172
    60        3.8248             nan     0.0500   -0.0128
    80        3.4641             nan     0.0500   -0.0156
   100        3.2149             nan     0.0500   -0.0163
   120        3.0074             nan     0.0500   -0.0178
   140        2.8098             nan     0.0500   -0.0103
   160        2.6438             nan     0.0500   -0.0034
   180        2.5013             nan     0.0500   -0.0086
   200        2.3610             nan     0.0500   -0.0108

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0171             nan     0.1000    0.1810
     2        6.8380             nan     0.1000    0.1655
     3        6.6980             nan     0.1000    0.1189
     4        6.5295             nan     0.1000    0.1552
     5        6.3853             nan     0.1000    0.1146
     6        6.2981             nan     0.1000    0.0671
     7        6.2334             nan     0.1000    0.0139
     8        6.1398             nan     0.1000    0.0235
     9        6.0612             nan     0.1000    0.0476
    10        5.9839             nan     0.1000    0.0403
    20        5.5275             nan     0.1000    0.0008
    40        4.9538             nan     0.1000   -0.0122
    60        4.6666             nan     0.1000   -0.0082
    80        4.4727             nan     0.1000   -0.0159
   100        4.3569             nan     0.1000   -0.0005
   120        4.2906             nan     0.1000   -0.0095
   140        4.2428             nan     0.1000   -0.0073
   160        4.1968             nan     0.1000   -0.0310
   180        4.1587             nan     0.1000   -0.0188
   200        4.1396             nan     0.1000   -0.0112

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0253             nan     0.1000    0.2230
     2        6.8394             nan     0.1000    0.2062
     3        6.6183             nan     0.1000    0.2218
     4        6.4388             nan     0.1000    0.2004
     5        6.2613             nan     0.1000    0.1438
     6        6.1376             nan     0.1000    0.0978
     7        6.0124             nan     0.1000    0.1132
     8        5.9055             nan     0.1000    0.0623
     9        5.8100             nan     0.1000    0.0480
    10        5.7665             nan     0.1000    0.0104
    20        5.0822             nan     0.1000    0.0291
    40        4.4630             nan     0.1000    0.0081
    60        4.1162             nan     0.1000   -0.0364
    80        3.9426             nan     0.1000   -0.0197
   100        3.7571             nan     0.1000   -0.0171
   120        3.6301             nan     0.1000   -0.0135
   140        3.5224             nan     0.1000   -0.0182
   160        3.4337             nan     0.1000   -0.0217
   180        3.3412             nan     0.1000   -0.0164
   200        3.2767             nan     0.1000   -0.0183

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9658             nan     0.1000    0.2182
     2        6.6918             nan     0.1000    0.2767
     3        6.4676             nan     0.1000    0.1954
     4        6.2328             nan     0.1000    0.1948
     5        6.0431             nan     0.1000    0.0772
     6        5.8933             nan     0.1000    0.0521
     7        5.7424             nan     0.1000    0.1180
     8        5.6311             nan     0.1000    0.0662
     9        5.5130             nan     0.1000    0.1064
    10        5.4323             nan     0.1000    0.0117
    20        4.7173             nan     0.1000    0.0089
    40        4.0605             nan     0.1000   -0.0239
    60        3.7141             nan     0.1000   -0.0399
    80        3.4710             nan     0.1000   -0.0300
   100        3.2525             nan     0.1000   -0.0188
   120        3.0964             nan     0.1000   -0.0157
   140        2.9173             nan     0.1000   -0.0097
   160        2.7808             nan     0.1000   -0.0114
   180        2.6495             nan     0.1000   -0.0161
   200        2.5494             nan     0.1000   -0.0264

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9184             nan     0.1000    0.3574
     2        6.6113             nan     0.1000    0.2534
     3        6.3643             nan     0.1000    0.2004
     4        6.0767             nan     0.1000    0.1800
     5        5.8010             nan     0.1000    0.2067
     6        5.5861             nan     0.1000    0.1194
     7        5.4130             nan     0.1000    0.0183
     8        5.2879             nan     0.1000    0.0755
     9        5.1343             nan     0.1000    0.0599
    10        5.0299             nan     0.1000    0.0166
    20        4.3085             nan     0.1000   -0.0016
    40        3.5125             nan     0.1000   -0.0131
    60        3.0732             nan     0.1000   -0.0288
    80        2.7507             nan     0.1000   -0.0407
   100        2.4578             nan     0.1000   -0.0235
   120        2.2361             nan     0.1000   -0.0080
   140        2.0362             nan     0.1000   -0.0214
   160        1.8770             nan     0.1000   -0.0253
   180        1.7255             nan     0.1000   -0.0124
   200        1.5773             nan     0.1000   -0.0282

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8906             nan     0.2000    0.2959
     2        6.5049             nan     0.2000    0.3680
     3        6.3616             nan     0.2000    0.0999
     4        6.2019             nan     0.2000    0.0588
     5        6.0121             nan     0.2000    0.1877
     6        5.8497             nan     0.2000    0.1606
     7        5.7680             nan     0.2000    0.0016
     8        5.6920             nan     0.2000    0.0513
     9        5.5780             nan     0.2000    0.0395
    10        5.5178             nan     0.2000    0.0404
    20        4.9846             nan     0.2000   -0.0027
    40        4.4667             nan     0.2000   -0.0048
    60        4.3013             nan     0.2000   -0.0151
    80        4.2080             nan     0.2000   -0.0030
   100        4.1721             nan     0.2000   -0.0390
   120        4.1298             nan     0.2000   -0.0231
   140        4.0916             nan     0.2000   -0.0263
   160        4.0916             nan     0.2000   -0.0405
   180        4.1096             nan     0.2000   -0.0534
   200        4.0830             nan     0.2000   -0.0286

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7440             nan     0.2000    0.5420
     2        6.4062             nan     0.2000    0.2642
     3        6.1059             nan     0.2000    0.2197
     4        5.8287             nan     0.2000    0.2369
     5        5.6466             nan     0.2000    0.0928
     6        5.4951             nan     0.2000   -0.0285
     7        5.3646             nan     0.2000    0.0824
     8        5.2551             nan     0.2000    0.0215
     9        5.1534             nan     0.2000   -0.0090
    10        5.0280             nan     0.2000    0.0961
    20        4.5012             nan     0.2000   -0.0203
    40        3.9343             nan     0.2000   -0.0026
    60        3.7076             nan     0.2000   -0.0790
    80        3.5074             nan     0.2000   -0.0331
   100        3.3901             nan     0.2000   -0.0201
   120        3.1895             nan     0.2000   -0.0408
   140        3.0698             nan     0.2000   -0.0494
   160        2.9448             nan     0.2000   -0.0162
   180        2.8311             nan     0.2000   -0.0393
   200        2.7261             nan     0.2000   -0.0341

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7365             nan     0.2000    0.5188
     2        6.3387             nan     0.2000    0.3387
     3        5.8936             nan     0.2000    0.3705
     4        5.6803             nan     0.2000    0.1107
     5        5.4956             nan     0.2000    0.0267
     6        5.2896             nan     0.2000    0.1151
     7        5.1639             nan     0.2000   -0.0682
     8        5.0437             nan     0.2000   -0.0325
     9        4.8921             nan     0.2000    0.0584
    10        4.7696             nan     0.2000    0.0187
    20        4.0473             nan     0.2000   -0.0059
    40        3.5307             nan     0.2000   -0.0111
    60        3.1870             nan     0.2000   -0.0223
    80        2.9047             nan     0.2000   -0.0611
   100        2.6512             nan     0.2000   -0.0921
   120        2.4348             nan     0.2000   -0.0328
   140        2.2682             nan     0.2000   -0.0432
   160        2.0963             nan     0.2000   -0.0305
   180        1.9910             nan     0.2000   -0.0275
   200        1.8682             nan     0.2000   -0.0198

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5862             nan     0.2000    0.5942
     2        6.1306             nan     0.2000    0.2319
     3        5.7482             nan     0.2000    0.2125
     4        5.3455             nan     0.2000    0.2793
     5        5.0651             nan     0.2000    0.1079
     6        4.8865             nan     0.2000    0.1007
     7        4.6570             nan     0.2000    0.0641
     8        4.5078             nan     0.2000   -0.0339
     9        4.4022             nan     0.2000    0.0346
    10        4.2553             nan     0.2000    0.0269
    20        3.5879             nan     0.2000   -0.0684
    40        2.8773             nan     0.2000   -0.0701
    60        2.3153             nan     0.2000   -0.0519
    80        2.0072             nan     0.2000   -0.0362
   100        1.7383             nan     0.2000   -0.0332
   120        1.4907             nan     0.2000   -0.0277
   140        1.2556             nan     0.2000   -0.0200
   160        1.0896             nan     0.2000   -0.0238
   180        0.9462             nan     0.2000   -0.0246
   200        0.8190             nan     0.2000   -0.0106

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2166             nan     0.0500    0.1114
     2        7.1398             nan     0.0500    0.0707
     3        7.0102             nan     0.0500    0.0862
     4        6.9174             nan     0.0500    0.0853
     5        6.8483             nan     0.0500    0.0389
     6        6.7645             nan     0.0500    0.0818
     7        6.6916             nan     0.0500    0.0739
     8        6.6411             nan     0.0500    0.0383
     9        6.5570             nan     0.0500    0.0700
    10        6.4909             nan     0.0500    0.0534
    20        6.0994             nan     0.0500   -0.0133
    40        5.4986             nan     0.0500    0.0127
    60        5.1903             nan     0.0500    0.0067
    80        4.9363             nan     0.0500    0.0005
   100        4.7681             nan     0.0500    0.0022
   120        4.6251             nan     0.0500   -0.0040
   140        4.5167             nan     0.0500    0.0010
   160        4.4456             nan     0.0500   -0.0095
   180        4.3720             nan     0.0500   -0.0001
   200        4.3236             nan     0.0500   -0.0068

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2188             nan     0.0500    0.1186
     2        7.0951             nan     0.0500    0.0780
     3        6.9343             nan     0.0500    0.1074
     4        6.7895             nan     0.0500    0.1126
     5        6.6807             nan     0.0500    0.1270
     6        6.5762             nan     0.0500    0.0937
     7        6.5004             nan     0.0500    0.0459
     8        6.4051             nan     0.0500    0.0791
     9        6.3342             nan     0.0500    0.0603
    10        6.2651             nan     0.0500    0.0623
    20        5.6528             nan     0.0500    0.0376
    40        5.0031             nan     0.0500    0.0073
    60        4.6337             nan     0.0500   -0.0028
    80        4.3894             nan     0.0500   -0.0111
   100        4.2105             nan     0.0500   -0.0064
   120        4.0853             nan     0.0500   -0.0129
   140        3.9905             nan     0.0500   -0.0117
   160        3.8940             nan     0.0500   -0.0070
   180        3.8223             nan     0.0500   -0.0069
   200        3.7500             nan     0.0500   -0.0043

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1748             nan     0.0500    0.1106
     2        7.0054             nan     0.0500    0.1237
     3        6.8519             nan     0.0500    0.1439
     4        6.7141             nan     0.0500    0.0822
     5        6.5923             nan     0.0500    0.0791
     6        6.4724             nan     0.0500    0.0923
     7        6.3839             nan     0.0500    0.0597
     8        6.2886             nan     0.0500    0.0585
     9        6.1949             nan     0.0500    0.0667
    10        6.0922             nan     0.0500    0.0903
    20        5.3711             nan     0.0500    0.0472
    40        4.6128             nan     0.0500    0.0017
    60        4.2291             nan     0.0500   -0.0021
    80        3.9968             nan     0.0500   -0.0068
   100        3.8353             nan     0.0500   -0.0063
   120        3.6717             nan     0.0500   -0.0209
   140        3.5324             nan     0.0500   -0.0179
   160        3.4251             nan     0.0500   -0.0139
   180        3.3040             nan     0.0500   -0.0112
   200        3.2051             nan     0.0500   -0.0104

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1437             nan     0.0500    0.1815
     2        6.9932             nan     0.0500    0.0920
     3        6.8078             nan     0.0500    0.1469
     4        6.6810             nan     0.0500    0.1162
     5        6.5165             nan     0.0500    0.1637
     6        6.3804             nan     0.0500    0.0970
     7        6.2504             nan     0.0500    0.0900
     8        6.1450             nan     0.0500    0.0568
     9        6.0319             nan     0.0500    0.0607
    10        5.9075             nan     0.0500    0.0598
    20        5.1171             nan     0.0500    0.0304
    40        4.3012             nan     0.0500   -0.0055
    60        3.8203             nan     0.0500   -0.0083
    80        3.5251             nan     0.0500   -0.0034
   100        3.3044             nan     0.0500   -0.0124
   120        3.1035             nan     0.0500   -0.0137
   140        2.9111             nan     0.0500   -0.0057
   160        2.7798             nan     0.0500   -0.0260
   180        2.6148             nan     0.0500   -0.0206
   200        2.4949             nan     0.0500   -0.0069

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1173             nan     0.1000    0.2374
     2        6.9537             nan     0.1000    0.1382
     3        6.7983             nan     0.1000    0.1643
     4        6.6640             nan     0.1000    0.1215
     5        6.5276             nan     0.1000    0.1102
     6        6.4155             nan     0.1000    0.0865
     7        6.3087             nan     0.1000    0.0930
     8        6.2245             nan     0.1000    0.0923
     9        6.1499             nan     0.1000    0.0669
    10        6.0938             nan     0.1000    0.0318
    20        5.5270             nan     0.1000   -0.0235
    40        4.9382             nan     0.1000   -0.0002
    60        4.6304             nan     0.1000   -0.0155
    80        4.4516             nan     0.1000   -0.0130
   100        4.3534             nan     0.1000   -0.0437
   120        4.2831             nan     0.1000   -0.0198
   140        4.2357             nan     0.1000   -0.0173
   160        4.1931             nan     0.1000   -0.0059
   180        4.1454             nan     0.1000   -0.0301
   200        4.1136             nan     0.1000   -0.0089

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0772             nan     0.1000    0.2417
     2        6.8435             nan     0.1000    0.1842
     3        6.6232             nan     0.1000    0.1806
     4        6.3753             nan     0.1000    0.1215
     5        6.2467             nan     0.1000    0.1575
     6        6.0800             nan     0.1000    0.1423
     7        5.9567             nan     0.1000    0.0112
     8        5.8254             nan     0.1000    0.1115
     9        5.6963             nan     0.1000    0.0427
    10        5.6100             nan     0.1000    0.0285
    20        4.9624             nan     0.1000   -0.0040
    40        4.3690             nan     0.1000   -0.0005
    60        4.0605             nan     0.1000   -0.0125
    80        3.8761             nan     0.1000    0.0029
   100        3.7101             nan     0.1000   -0.0128
   120        3.6001             nan     0.1000   -0.0417
   140        3.4793             nan     0.1000   -0.0161
   160        3.3728             nan     0.1000   -0.0139
   180        3.3037             nan     0.1000   -0.0151
   200        3.2573             nan     0.1000   -0.0248

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0359             nan     0.1000    0.2999
     2        6.8046             nan     0.1000    0.2393
     3        6.5190             nan     0.1000    0.2339
     4        6.3010             nan     0.1000    0.1163
     5        6.1033             nan     0.1000    0.1708
     6        5.9294             nan     0.1000    0.1316
     7        5.7926             nan     0.1000    0.0850
     8        5.6392             nan     0.1000    0.0948
     9        5.4943             nan     0.1000    0.0526
    10        5.3901             nan     0.1000    0.0664
    20        4.6941             nan     0.1000    0.0108
    40        4.0798             nan     0.1000   -0.0146
    60        3.7593             nan     0.1000   -0.0040
    80        3.4999             nan     0.1000   -0.0200
   100        3.2825             nan     0.1000   -0.0203
   120        3.0811             nan     0.1000   -0.0334
   140        2.9074             nan     0.1000   -0.0332
   160        2.7458             nan     0.1000   -0.0147
   180        2.6067             nan     0.1000   -0.0125
   200        2.4563             nan     0.1000   -0.0183

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9834             nan     0.1000    0.2939
     2        6.6633             nan     0.1000    0.1959
     3        6.3330             nan     0.1000    0.2528
     4        6.0837             nan     0.1000    0.1255
     5        5.8489             nan     0.1000    0.1811
     6        5.6797             nan     0.1000    0.0888
     7        5.4974             nan     0.1000    0.1334
     8        5.3344             nan     0.1000    0.0979
     9        5.2157             nan     0.1000    0.0475
    10        5.0944             nan     0.1000    0.0203
    20        4.2728             nan     0.1000   -0.0061
    40        3.6030             nan     0.1000   -0.0598
    60        3.1632             nan     0.1000   -0.0471
    80        2.7969             nan     0.1000   -0.0181
   100        2.5435             nan     0.1000   -0.0417
   120        2.3141             nan     0.1000   -0.0277
   140        2.1051             nan     0.1000   -0.0282
   160        1.9341             nan     0.1000   -0.0109
   180        1.7619             nan     0.1000   -0.0173
   200        1.6193             nan     0.1000   -0.0121

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8873             nan     0.2000    0.4412
     2        6.5829             nan     0.2000    0.3327
     3        6.3117             nan     0.2000    0.2397
     4        6.2546             nan     0.2000   -0.0548
     5        6.0969             nan     0.2000    0.1243
     6        5.8988             nan     0.2000    0.1325
     7        5.7950             nan     0.2000    0.0845
     8        5.7115             nan     0.2000    0.0743
     9        5.5854             nan     0.2000    0.1186
    10        5.5117             nan     0.2000   -0.0185
    20        5.0141             nan     0.2000    0.0266
    40        4.5291             nan     0.2000   -0.0144
    60        4.3030             nan     0.2000   -0.0480
    80        4.2055             nan     0.2000   -0.0313
   100        4.1629             nan     0.2000   -0.0271
   120        4.1217             nan     0.2000   -0.0213
   140        4.1195             nan     0.2000   -0.0261
   160        4.0748             nan     0.2000   -0.0233
   180        4.0732             nan     0.2000   -0.0434
   200        4.0574             nan     0.2000   -0.0235

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8304             nan     0.2000    0.4701
     2        6.4111             nan     0.2000    0.2058
     3        6.0298             nan     0.2000    0.3046
     4        5.8048             nan     0.2000    0.1450
     5        5.5952             nan     0.2000    0.0915
     6        5.4424             nan     0.2000    0.0890
     7        5.3147             nan     0.2000    0.0374
     8        5.2029             nan     0.2000    0.0201
     9        5.1256             nan     0.2000    0.0153
    10        5.0739             nan     0.2000    0.0003
    20        4.4637             nan     0.2000   -0.0055
    40        4.0298             nan     0.2000   -0.0760
    60        3.7906             nan     0.2000   -0.0460
    80        3.6089             nan     0.2000   -0.0487
   100        3.4670             nan     0.2000   -0.0398
   120        3.2649             nan     0.2000   -0.0479
   140        3.1276             nan     0.2000   -0.0336
   160        3.0234             nan     0.2000   -0.0277
   180        2.9186             nan     0.2000   -0.0147
   200        2.8271             nan     0.2000   -0.0460

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7625             nan     0.2000    0.6159
     2        6.2592             nan     0.2000    0.4549
     3        5.8971             nan     0.2000    0.3218
     4        5.6531             nan     0.2000    0.2006
     5        5.4199             nan     0.2000    0.0364
     6        5.2611             nan     0.2000    0.0767
     7        5.1007             nan     0.2000    0.0307
     8        5.0052             nan     0.2000   -0.0084
     9        4.9233             nan     0.2000   -0.0404
    10        4.8042             nan     0.2000    0.0272
    20        4.1257             nan     0.2000   -0.0306
    40        3.5840             nan     0.2000   -0.0402
    60        3.2356             nan     0.2000   -0.0347
    80        2.8459             nan     0.2000   -0.0214
   100        2.6270             nan     0.2000   -0.0179
   120        2.4848             nan     0.2000   -0.0502
   140        2.2159             nan     0.2000   -0.0752
   160        2.0699             nan     0.2000   -0.0337
   180        1.8861             nan     0.2000   -0.0234
   200        1.7434             nan     0.2000   -0.0316

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6011             nan     0.2000    0.4878
     2        6.0863             nan     0.2000    0.2003
     3        5.5601             nan     0.2000    0.3379
     4        5.3387             nan     0.2000    0.0483
     5        5.1074             nan     0.2000    0.0989
     6        4.9055             nan     0.2000    0.0418
     7        4.7193             nan     0.2000    0.1292
     8        4.5384             nan     0.2000    0.0946
     9        4.3933             nan     0.2000    0.0498
    10        4.2661             nan     0.2000   -0.0067
    20        3.6179             nan     0.2000   -0.0361
    40        2.9278             nan     0.2000   -0.0216
    60        2.4818             nan     0.2000   -0.0882
    80        2.0648             nan     0.2000   -0.0579
   100        1.7291             nan     0.2000   -0.0417
   120        1.5292             nan     0.2000   -0.0506
   140        1.3052             nan     0.2000   -0.0226
   160        1.1440             nan     0.2000   -0.0347
   180        0.9681             nan     0.2000   -0.0334
   200        0.8489             nan     0.2000   -0.0264

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9867             nan     0.0500    0.1199
     2        6.8990             nan     0.0500    0.0556
     3        6.8226             nan     0.0500    0.0724
     4        6.7293             nan     0.0500    0.0853
     5        6.6372             nan     0.0500    0.0792
     6        6.5738             nan     0.0500    0.0758
     7        6.4969             nan     0.0500    0.0674
     8        6.4427             nan     0.0500    0.0489
     9        6.3825             nan     0.0500    0.0361
    10        6.3463             nan     0.0500    0.0182
    20        5.9344             nan     0.0500    0.0347
    40        5.4670             nan     0.0500   -0.0064
    60        5.1350             nan     0.0500    0.0031
    80        4.8725             nan     0.0500   -0.0027
   100        4.6901             nan     0.0500   -0.0041
   120        4.5343             nan     0.0500    0.0009
   140        4.4196             nan     0.0500   -0.0009
   160        4.3232             nan     0.0500    0.0004
   180        4.2437             nan     0.0500   -0.0068
   200        4.1866             nan     0.0500   -0.0058

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9529             nan     0.0500    0.1459
     2        6.8170             nan     0.0500    0.1141
     3        6.6913             nan     0.0500    0.1193
     4        6.5949             nan     0.0500    0.0878
     5        6.4825             nan     0.0500    0.0928
     6        6.3873             nan     0.0500    0.0814
     7        6.2810             nan     0.0500    0.0763
     8        6.2245             nan     0.0500    0.0091
     9        6.1793             nan     0.0500    0.0280
    10        6.1114             nan     0.0500    0.0451
    20        5.5385             nan     0.0500    0.0375
    40        4.8587             nan     0.0500    0.0098
    60        4.4804             nan     0.0500    0.0018
    80        4.2041             nan     0.0500   -0.0079
   100        4.0146             nan     0.0500   -0.0130
   120        3.8609             nan     0.0500   -0.0035
   140        3.7356             nan     0.0500   -0.0106
   160        3.6395             nan     0.0500   -0.0109
   180        3.5774             nan     0.0500   -0.0144
   200        3.5118             nan     0.0500   -0.0110

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9459             nan     0.0500    0.1358
     2        6.8214             nan     0.0500    0.0775
     3        6.6751             nan     0.0500    0.1563
     4        6.5416             nan     0.0500    0.1297
     5        6.4068             nan     0.0500    0.1332
     6        6.3234             nan     0.0500    0.0510
     7        6.2344             nan     0.0500    0.0671
     8        6.1261             nan     0.0500    0.0796
     9        6.0197             nan     0.0500    0.0755
    10        5.9319             nan     0.0500    0.0519
    20        5.2452             nan     0.0500    0.0431
    40        4.5353             nan     0.0500    0.0143
    60        4.1127             nan     0.0500    0.0082
    80        3.8353             nan     0.0500   -0.0129
   100        3.6358             nan     0.0500   -0.0006
   120        3.4844             nan     0.0500   -0.0171
   140        3.3484             nan     0.0500   -0.0209
   160        3.2286             nan     0.0500   -0.0113
   180        3.1375             nan     0.0500   -0.0075
   200        3.0535             nan     0.0500   -0.0162

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9202             nan     0.0500    0.1711
     2        6.7486             nan     0.0500    0.1373
     3        6.5702             nan     0.0500    0.1354
     4        6.4045             nan     0.0500    0.1136
     5        6.2580             nan     0.0500    0.1210
     6        6.0915             nan     0.0500    0.1299
     7        5.9596             nan     0.0500    0.1002
     8        5.8617             nan     0.0500    0.0532
     9        5.7545             nan     0.0500    0.0917
    10        5.6721             nan     0.0500    0.0134
    20        4.9085             nan     0.0500   -0.0085
    40        4.0917             nan     0.0500   -0.0179
    60        3.6362             nan     0.0500   -0.0140
    80        3.3305             nan     0.0500   -0.0067
   100        3.0967             nan     0.0500   -0.0224
   120        2.8821             nan     0.0500   -0.0168
   140        2.7002             nan     0.0500    0.0012
   160        2.5465             nan     0.0500   -0.0077
   180        2.4100             nan     0.0500   -0.0088
   200        2.2875             nan     0.0500   -0.0045

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9479             nan     0.1000    0.1809
     2        6.7313             nan     0.1000    0.1368
     3        6.5537             nan     0.1000    0.1469
     4        6.4154             nan     0.1000    0.1228
     5        6.3115             nan     0.1000    0.1122
     6        6.2488             nan     0.1000    0.0269
     7        6.1519             nan     0.1000    0.0898
     8        6.0867             nan     0.1000    0.0114
     9        6.0164             nan     0.1000    0.0499
    10        5.9235             nan     0.1000    0.0651
    20        5.4251             nan     0.1000    0.0366
    40        4.8822             nan     0.1000   -0.0046
    60        4.5369             nan     0.1000   -0.0096
    80        4.3082             nan     0.1000   -0.0072
   100        4.1781             nan     0.1000   -0.0197
   120        4.0867             nan     0.1000   -0.0130
   140        4.0369             nan     0.1000   -0.0205
   160        4.0021             nan     0.1000   -0.0307
   180        3.9781             nan     0.1000   -0.0203
   200        3.9609             nan     0.1000   -0.0079

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8287             nan     0.1000    0.2903
     2        6.5933             nan     0.1000    0.2247
     3        6.3751             nan     0.1000    0.1666
     4        6.1828             nan     0.1000    0.1593
     5        6.0297             nan     0.1000    0.1316
     6        5.8919             nan     0.1000    0.0862
     7        5.7814             nan     0.1000    0.0819
     8        5.7158             nan     0.1000    0.0096
     9        5.5988             nan     0.1000    0.0712
    10        5.5073             nan     0.1000    0.0265
    20        4.8474             nan     0.1000    0.0044
    40        4.2053             nan     0.1000   -0.0045
    60        3.8662             nan     0.1000   -0.0095
    80        3.6503             nan     0.1000   -0.0124
   100        3.5014             nan     0.1000   -0.0084
   120        3.4109             nan     0.1000   -0.0424
   140        3.2813             nan     0.1000   -0.0207
   160        3.1744             nan     0.1000   -0.0120
   180        3.0747             nan     0.1000   -0.0237
   200        3.0333             nan     0.1000   -0.0308

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8127             nan     0.1000    0.2355
     2        6.5862             nan     0.1000    0.1509
     3        6.3890             nan     0.1000    0.1775
     4        6.1289             nan     0.1000    0.2234
     5        5.9127             nan     0.1000    0.1296
     6        5.7274             nan     0.1000    0.1458
     7        5.5928             nan     0.1000    0.0753
     8        5.4861             nan     0.1000    0.0489
     9        5.3693             nan     0.1000    0.0978
    10        5.2581             nan     0.1000    0.0268
    20        4.5553             nan     0.1000    0.0197
    40        3.8704             nan     0.1000   -0.0211
    60        3.4909             nan     0.1000   -0.0210
    80        3.2343             nan     0.1000   -0.0350
   100        3.0472             nan     0.1000   -0.0091
   120        2.9015             nan     0.1000   -0.0233
   140        2.7563             nan     0.1000   -0.0259
   160        2.6018             nan     0.1000   -0.0260
   180        2.4481             nan     0.1000   -0.0295
   200        2.3480             nan     0.1000   -0.0129

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7189             nan     0.1000    0.2997
     2        6.3832             nan     0.1000    0.2577
     3        6.1048             nan     0.1000    0.2275
     4        5.8546             nan     0.1000    0.2008
     5        5.6100             nan     0.1000    0.1444
     6        5.3934             nan     0.1000    0.1276
     7        5.2612             nan     0.1000    0.0210
     8        5.1392             nan     0.1000    0.0690
     9        4.9859             nan     0.1000    0.0678
    10        4.8575             nan     0.1000    0.0841
    20        4.0792             nan     0.1000   -0.0122
    40        3.3330             nan     0.1000   -0.0264
    60        2.8677             nan     0.1000   -0.0435
    80        2.5458             nan     0.1000   -0.0263
   100        2.2846             nan     0.1000   -0.0189
   120        2.0903             nan     0.1000   -0.0212
   140        1.8925             nan     0.1000   -0.0172
   160        1.7186             nan     0.1000   -0.0190
   180        1.5676             nan     0.1000   -0.0016
   200        1.4472             nan     0.1000   -0.0155

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8029             nan     0.2000    0.2744
     2        6.4685             nan     0.2000    0.3245
     3        6.2139             nan     0.2000    0.2782
     4        6.0489             nan     0.2000    0.1087
     5        5.9322             nan     0.2000   -0.0342
     6        5.8092             nan     0.2000    0.0654
     7        5.6831             nan     0.2000    0.0927
     8        5.5961             nan     0.2000    0.0525
     9        5.4858             nan     0.2000    0.0359
    10        5.3903             nan     0.2000    0.0069
    20        4.9207             nan     0.2000    0.0002
    40        4.3321             nan     0.2000   -0.0151
    60        4.1488             nan     0.2000   -0.0123
    80        4.0518             nan     0.2000   -0.0500
   100        4.0136             nan     0.2000   -0.0433
   120        3.9578             nan     0.2000   -0.0207
   140        3.9012             nan     0.2000   -0.0156
   160        3.8721             nan     0.2000   -0.0579
   180        3.8474             nan     0.2000   -0.0203
   200        3.8497             nan     0.2000   -0.0195

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6184             nan     0.2000    0.3585
     2        6.2630             nan     0.2000    0.2838
     3        5.8845             nan     0.2000    0.2146
     4        5.6514             nan     0.2000    0.2233
     5        5.4210             nan     0.2000    0.0548
     6        5.2875             nan     0.2000    0.0672
     7        5.1885             nan     0.2000    0.0129
     8        5.0814             nan     0.2000    0.0034
     9        4.9820             nan     0.2000    0.0154
    10        4.8976             nan     0.2000    0.0107
    20        4.2018             nan     0.2000   -0.0147
    40        3.7298             nan     0.2000   -0.0140
    60        3.4063             nan     0.2000   -0.0330
    80        3.2605             nan     0.2000   -0.0320
   100        3.1044             nan     0.2000   -0.0403
   120        2.9705             nan     0.2000   -0.0178
   140        2.8371             nan     0.2000   -0.0292
   160        2.7376             nan     0.2000   -0.0086
   180        2.6134             nan     0.2000   -0.0175
   200        2.5330             nan     0.2000   -0.0259

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5485             nan     0.2000    0.4121
     2        6.0677             nan     0.2000    0.3485
     3        5.7338             nan     0.2000    0.2262
     4        5.3911             nan     0.2000    0.2211
     5        5.2381             nan     0.2000   -0.0495
     6        5.0623             nan     0.2000    0.0833
     7        4.9015             nan     0.2000    0.0682
     8        4.7830             nan     0.2000    0.0431
     9        4.6821             nan     0.2000   -0.0118
    10        4.6035             nan     0.2000   -0.0556
    20        3.9805             nan     0.2000   -0.0061
    40        3.4312             nan     0.2000   -0.0633
    60        3.0930             nan     0.2000   -0.0220
    80        2.8743             nan     0.2000   -0.0336
   100        2.5768             nan     0.2000   -0.0165
   120        2.3572             nan     0.2000   -0.0539
   140        2.1383             nan     0.2000   -0.0045
   160        2.0145             nan     0.2000   -0.0214
   180        1.8790             nan     0.2000   -0.0498
   200        1.7475             nan     0.2000   -0.0217

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3042             nan     0.2000    0.6397
     2        5.8429             nan     0.2000    0.3699
     3        5.5171             nan     0.2000    0.1910
     4        5.2407             nan     0.2000    0.0632
     5        4.9402             nan     0.2000    0.1541
     6        4.7320             nan     0.2000    0.0172
     7        4.4993             nan     0.2000    0.0741
     8        4.3365             nan     0.2000    0.1088
     9        4.2295             nan     0.2000   -0.0184
    10        4.0938             nan     0.2000   -0.0471
    20        3.4047             nan     0.2000   -0.0323
    40        2.7054             nan     0.2000   -0.0447
    60        2.1846             nan     0.2000   -0.0354
    80        1.8154             nan     0.2000   -0.0417
   100        1.5130             nan     0.2000   -0.0249
   120        1.2774             nan     0.2000   -0.0307
   140        1.0861             nan     0.2000   -0.0100
   160        0.9342             nan     0.2000   -0.0140
   180        0.8164             nan     0.2000   -0.0088
   200        0.7136             nan     0.2000   -0.0194

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2746             nan     0.0500    0.0995
     2        7.1489             nan     0.0500    0.0819
     3        7.0770             nan     0.0500    0.0784
     4        7.0124             nan     0.0500    0.0660
     5        6.9417             nan     0.0500    0.0729
     6        6.8762             nan     0.0500    0.0578
     7        6.8474             nan     0.0500    0.0020
     8        6.7782             nan     0.0500    0.0664
     9        6.7224             nan     0.0500    0.0575
    10        6.6577             nan     0.0500    0.0477
    20        6.2231             nan     0.0500    0.0155
    40        5.7322             nan     0.0500    0.0073
    60        5.3767             nan     0.0500   -0.0053
    80        5.0956             nan     0.0500    0.0054
   100        4.8808             nan     0.0500   -0.0045
   120        4.7298             nan     0.0500   -0.0127
   140        4.6120             nan     0.0500   -0.0069
   160        4.5092             nan     0.0500   -0.0076
   180        4.4256             nan     0.0500   -0.0006
   200        4.3544             nan     0.0500   -0.0034

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2653             nan     0.0500    0.1050
     2        7.1348             nan     0.0500    0.0854
     3        7.0049             nan     0.0500    0.1075
     4        6.9026             nan     0.0500    0.0992
     5        6.7942             nan     0.0500    0.0907
     6        6.6993             nan     0.0500    0.0778
     7        6.6388             nan     0.0500    0.0059
     8        6.5661             nan     0.0500    0.0815
     9        6.4818             nan     0.0500    0.0692
    10        6.4384             nan     0.0500    0.0145
    20        5.8919             nan     0.0500    0.0263
    40        5.1566             nan     0.0500   -0.0066
    60        4.7365             nan     0.0500    0.0030
    80        4.4538             nan     0.0500   -0.0042
   100        4.2725             nan     0.0500    0.0063
   120        4.1073             nan     0.0500   -0.0087
   140        3.9841             nan     0.0500   -0.0045
   160        3.8622             nan     0.0500   -0.0063
   180        3.7770             nan     0.0500   -0.0105
   200        3.7192             nan     0.0500   -0.0117

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2024             nan     0.0500    0.1404
     2        7.0464             nan     0.0500    0.1360
     3        6.9138             nan     0.0500    0.1042
     4        6.7882             nan     0.0500    0.1109
     5        6.6898             nan     0.0500    0.0644
     6        6.5741             nan     0.0500    0.0801
     7        6.4785             nan     0.0500    0.0807
     8        6.3919             nan     0.0500    0.0585
     9        6.2993             nan     0.0500    0.0749
    10        6.2007             nan     0.0500    0.0434
    20        5.5451             nan     0.0500    0.0206
    40        4.8168             nan     0.0500    0.0173
    60        4.3536             nan     0.0500    0.0012
    80        4.0439             nan     0.0500   -0.0282
   100        3.8260             nan     0.0500   -0.0088
   120        3.6461             nan     0.0500   -0.0094
   140        3.4820             nan     0.0500   -0.0006
   160        3.3575             nan     0.0500   -0.0017
   180        3.2285             nan     0.0500   -0.0132
   200        3.1286             nan     0.0500   -0.0083

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2171             nan     0.0500    0.1486
     2        7.0566             nan     0.0500    0.1103
     3        6.9136             nan     0.0500    0.1299
     4        6.7559             nan     0.0500    0.1107
     5        6.5876             nan     0.0500    0.1006
     6        6.4514             nan     0.0500    0.1179
     7        6.3319             nan     0.0500    0.0836
     8        6.2279             nan     0.0500    0.0500
     9        6.1072             nan     0.0500    0.0630
    10        6.0044             nan     0.0500    0.0710
    20        5.1830             nan     0.0500    0.0591
    40        4.2767             nan     0.0500    0.0074
    60        3.7993             nan     0.0500   -0.0199
    80        3.5195             nan     0.0500   -0.0146
   100        3.2493             nan     0.0500    0.0020
   120        3.0282             nan     0.0500   -0.0183
   140        2.8335             nan     0.0500   -0.0152
   160        2.6843             nan     0.0500   -0.0147
   180        2.5292             nan     0.0500   -0.0194
   200        2.3799             nan     0.0500   -0.0114

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1623             nan     0.1000    0.2097
     2        7.0276             nan     0.1000    0.1203
     3        6.9222             nan     0.1000    0.0065
     4        6.7931             nan     0.1000    0.1523
     5        6.6727             nan     0.1000    0.1285
     6        6.5466             nan     0.1000    0.1022
     7        6.4413             nan     0.1000    0.0680
     8        6.3741             nan     0.1000    0.0007
     9        6.3027             nan     0.1000    0.0414
    10        6.1992             nan     0.1000    0.0427
    20        5.6661             nan     0.1000    0.0129
    40        5.0744             nan     0.1000    0.0106
    60        4.7189             nan     0.1000   -0.0091
    80        4.5143             nan     0.1000    0.0000
   100        4.3907             nan     0.1000   -0.0103
   120        4.2981             nan     0.1000   -0.0055
   140        4.2212             nan     0.1000   -0.0132
   160        4.1724             nan     0.1000   -0.0186
   180        4.1173             nan     0.1000   -0.0064
   200        4.0906             nan     0.1000   -0.0099

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1264             nan     0.1000    0.2078
     2        6.8877             nan     0.1000    0.1650
     3        6.6677             nan     0.1000    0.1477
     4        6.4889             nan     0.1000    0.1309
     5        6.3774             nan     0.1000    0.0754
     6        6.2818             nan     0.1000    0.0500
     7        6.1719             nan     0.1000    0.0846
     8        6.0659             nan     0.1000    0.0899
     9        5.9389             nan     0.1000    0.1023
    10        5.8227             nan     0.1000    0.0498
    20        5.1369             nan     0.1000    0.0044
    40        4.4562             nan     0.1000   -0.0028
    60        4.1236             nan     0.1000   -0.0328
    80        3.9208             nan     0.1000   -0.0265
   100        3.7587             nan     0.1000   -0.0187
   120        3.6111             nan     0.1000   -0.0160
   140        3.5246             nan     0.1000   -0.0081
   160        3.4281             nan     0.1000   -0.0126
   180        3.3555             nan     0.1000   -0.0358
   200        3.2567             nan     0.1000   -0.0202

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0649             nan     0.1000    0.2781
     2        6.7903             nan     0.1000    0.1899
     3        6.5362             nan     0.1000    0.1101
     4        6.3304             nan     0.1000    0.1339
     5        6.1545             nan     0.1000    0.0913
     6        6.0155             nan     0.1000    0.1075
     7        5.8776             nan     0.1000    0.0156
     8        5.7921             nan     0.1000    0.0439
     9        5.7112             nan     0.1000    0.0218
    10        5.5842             nan     0.1000    0.0793
    20        4.8529             nan     0.1000   -0.0129
    40        4.0976             nan     0.1000   -0.0192
    60        3.7085             nan     0.1000   -0.0155
    80        3.4766             nan     0.1000   -0.0282
   100        3.2589             nan     0.1000   -0.0111
   120        3.1036             nan     0.1000   -0.0170
   140        2.9580             nan     0.1000   -0.0076
   160        2.7810             nan     0.1000   -0.0150
   180        2.6570             nan     0.1000   -0.0002
   200        2.5325             nan     0.1000   -0.0264

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0365             nan     0.1000    0.2419
     2        6.7378             nan     0.1000    0.2777
     3        6.4461             nan     0.1000    0.2200
     4        6.2271             nan     0.1000    0.1459
     5        5.9940             nan     0.1000    0.2004
     6        5.8322             nan     0.1000    0.1101
     7        5.6638             nan     0.1000    0.0746
     8        5.4888             nan     0.1000    0.0369
     9        5.3494             nan     0.1000    0.0440
    10        5.2202             nan     0.1000    0.0359
    20        4.4094             nan     0.1000   -0.0288
    40        3.6086             nan     0.1000   -0.0303
    60        3.1472             nan     0.1000   -0.0288
    80        2.7773             nan     0.1000   -0.0289
   100        2.5032             nan     0.1000   -0.0205
   120        2.2628             nan     0.1000   -0.0228
   140        2.0252             nan     0.1000   -0.0247
   160        1.8597             nan     0.1000   -0.0434
   180        1.7269             nan     0.1000   -0.0162
   200        1.5920             nan     0.1000   -0.0155

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2058             nan     0.2000    0.0025
     2        6.8761             nan     0.2000    0.3685
     3        6.6138             nan     0.2000    0.2238
     4        6.4226             nan     0.2000    0.0231
     5        6.2595             nan     0.2000    0.1284
     6        6.1202             nan     0.2000    0.0652
     7        5.9296             nan     0.2000    0.1095
     8        5.8211             nan     0.2000    0.0652
     9        5.7367             nan     0.2000    0.0402
    10        5.6753             nan     0.2000   -0.0005
    20        5.0581             nan     0.2000   -0.0386
    40        4.4959             nan     0.2000   -0.0102
    60        4.3393             nan     0.2000   -0.0574
    80        4.2578             nan     0.2000   -0.0198
   100        4.1875             nan     0.2000   -0.0427
   120        4.1140             nan     0.2000   -0.0215
   140        4.0599             nan     0.2000   -0.0312
   160        4.0345             nan     0.2000   -0.0191
   180        4.0295             nan     0.2000   -0.0255
   200        3.9921             nan     0.2000   -0.0154

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9522             nan     0.2000    0.3580
     2        6.5787             nan     0.2000    0.3337
     3        6.2974             nan     0.2000    0.1974
     4        6.0352             nan     0.2000    0.1841
     5        5.8543             nan     0.2000   -0.0021
     6        5.6283             nan     0.2000    0.0767
     7        5.5100             nan     0.2000    0.0382
     8        5.3786             nan     0.2000    0.0618
     9        5.3430             nan     0.2000   -0.0844
    10        5.2151             nan     0.2000    0.0213
    20        4.5302             nan     0.2000   -0.0186
    40        3.9261             nan     0.2000   -0.0009
    60        3.5990             nan     0.2000   -0.0208
    80        3.4122             nan     0.2000   -0.0963
   100        3.1952             nan     0.2000   -0.0613
   120        3.0823             nan     0.2000   -0.0177
   140        2.9578             nan     0.2000   -0.0453
   160        2.8579             nan     0.2000   -0.0364
   180        2.7481             nan     0.2000   -0.0169
   200        2.5957             nan     0.2000   -0.0507

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8079             nan     0.2000    0.4291
     2        6.4385             nan     0.2000    0.1388
     3        6.1658             nan     0.2000    0.2538
     4        5.8357             nan     0.2000    0.1374
     5        5.5131             nan     0.2000    0.2158
     6        5.2758             nan     0.2000    0.1281
     7        5.1080             nan     0.2000    0.0151
     8        4.9509             nan     0.2000    0.0262
     9        4.8316             nan     0.2000    0.0845
    10        4.7326             nan     0.2000    0.0199
    20        4.0509             nan     0.2000   -0.0632
    40        3.3951             nan     0.2000   -0.0477
    60        3.0494             nan     0.2000   -0.0581
    80        2.7584             nan     0.2000   -0.0490
   100        2.5358             nan     0.2000   -0.0464
   120        2.3466             nan     0.2000   -0.0552
   140        2.1519             nan     0.2000   -0.0494
   160        1.9770             nan     0.2000   -0.0062
   180        1.8457             nan     0.2000   -0.0306
   200        1.7265             nan     0.2000   -0.0260

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7293             nan     0.2000    0.6257
     2        6.2627             nan     0.2000    0.2920
     3        5.8760             nan     0.2000    0.2038
     4        5.5984             nan     0.2000    0.0192
     5        5.3750             nan     0.2000    0.0259
     6        5.0685             nan     0.2000    0.2098
     7        4.8527             nan     0.2000    0.1125
     8        4.7197             nan     0.2000   -0.0335
     9        4.6084             nan     0.2000   -0.0220
    10        4.4850             nan     0.2000   -0.0177
    20        3.6511             nan     0.2000   -0.0303
    40        2.8608             nan     0.2000   -0.0178
    60        2.3318             nan     0.2000   -0.0492
    80        1.9046             nan     0.2000   -0.0715
   100        1.6088             nan     0.2000   -0.0322
   120        1.4060             nan     0.2000   -0.0364
   140        1.1836             nan     0.2000   -0.0304
   160        1.0547             nan     0.2000   -0.0170
   180        0.9258             nan     0.2000   -0.0173
   200        0.7943             nan     0.2000   -0.0116

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3238             nan     0.0500    0.1126
     2        7.1972             nan     0.0500    0.0786
     3        7.1313             nan     0.0500    0.0535
     4        7.0027             nan     0.0500    0.1196
     5        6.9172             nan     0.0500    0.0815
     6        6.8435             nan     0.0500    0.0521
     7        6.7774             nan     0.0500    0.0796
     8        6.7015             nan     0.0500    0.0838
     9        6.6189             nan     0.0500    0.0502
    10        6.5786             nan     0.0500    0.0349
    20        6.1105             nan     0.0500    0.0336
    40        5.5576             nan     0.0500    0.0035
    60        5.1869             nan     0.0500    0.0083
    80        4.9746             nan     0.0500    0.0079
   100        4.8156             nan     0.0500    0.0045
   120        4.6797             nan     0.0500   -0.0117
   140        4.5682             nan     0.0500   -0.0055
   160        4.4857             nan     0.0500   -0.0046
   180        4.4136             nan     0.0500   -0.0183
   200        4.3515             nan     0.0500   -0.0066

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3000             nan     0.0500    0.1160
     2        7.1789             nan     0.0500    0.1344
     3        7.0259             nan     0.0500    0.1113
     4        6.9074             nan     0.0500    0.1093
     5        6.7977             nan     0.0500    0.0714
     6        6.7035             nan     0.0500    0.0634
     7        6.6050             nan     0.0500    0.0762
     8        6.4933             nan     0.0500    0.0745
     9        6.4031             nan     0.0500    0.0671
    10        6.3460             nan     0.0500    0.0400
    20        5.7120             nan     0.0500    0.0260
    40        5.0393             nan     0.0500    0.0031
    60        4.6861             nan     0.0500    0.0048
    80        4.4044             nan     0.0500    0.0007
   100        4.1853             nan     0.0500   -0.0138
   120        4.0658             nan     0.0500   -0.0104
   140        3.9485             nan     0.0500   -0.0072
   160        3.8568             nan     0.0500   -0.0056
   180        3.7681             nan     0.0500   -0.0107
   200        3.6736             nan     0.0500   -0.0175

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2431             nan     0.0500    0.1460
     2        7.0857             nan     0.0500    0.1455
     3        6.9256             nan     0.0500    0.1325
     4        6.7897             nan     0.0500    0.0974
     5        6.6793             nan     0.0500    0.0515
     6        6.6042             nan     0.0500    0.0450
     7        6.4669             nan     0.0500    0.1275
     8        6.3665             nan     0.0500    0.0793
     9        6.2852             nan     0.0500    0.0512
    10        6.1788             nan     0.0500    0.0732
    20        5.5211             nan     0.0500   -0.0131
    40        4.7368             nan     0.0500    0.0260
    60        4.2712             nan     0.0500    0.0002
    80        3.9941             nan     0.0500   -0.0031
   100        3.8019             nan     0.0500   -0.0033
   120        3.6293             nan     0.0500   -0.0084
   140        3.4746             nan     0.0500   -0.0069
   160        3.3436             nan     0.0500   -0.0038
   180        3.2391             nan     0.0500   -0.0102
   200        3.1597             nan     0.0500   -0.0200

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2277             nan     0.0500    0.1981
     2        7.0563             nan     0.0500    0.1475
     3        6.8743             nan     0.0500    0.1233
     4        6.6806             nan     0.0500    0.1275
     5        6.5325             nan     0.0500    0.1208
     6        6.3945             nan     0.0500    0.0855
     7        6.2643             nan     0.0500    0.0938
     8        6.1290             nan     0.0500    0.0821
     9        6.0301             nan     0.0500    0.0760
    10        5.9137             nan     0.0500    0.0593
    20        5.0930             nan     0.0500    0.0062
    40        4.2455             nan     0.0500    0.0210
    60        3.8071             nan     0.0500   -0.0112
    80        3.4470             nan     0.0500   -0.0088
   100        3.2121             nan     0.0500   -0.0091
   120        2.9954             nan     0.0500   -0.0174
   140        2.8210             nan     0.0500   -0.0170
   160        2.6856             nan     0.0500   -0.0068
   180        2.5506             nan     0.0500   -0.0156
   200        2.4330             nan     0.0500   -0.0202

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2336             nan     0.1000    0.1904
     2        7.0419             nan     0.1000    0.1679
     3        6.8500             nan     0.1000    0.1597
     4        6.6933             nan     0.1000    0.0896
     5        6.5918             nan     0.1000    0.0926
     6        6.4530             nan     0.1000    0.0950
     7        6.3407             nan     0.1000    0.0870
     8        6.2404             nan     0.1000    0.0910
     9        6.1612             nan     0.1000    0.0568
    10        6.0924             nan     0.1000    0.0485
    20        5.6038             nan     0.1000   -0.0169
    40        4.9833             nan     0.1000    0.0123
    60        4.6415             nan     0.1000   -0.0189
    80        4.4772             nan     0.1000   -0.0196
   100        4.3675             nan     0.1000   -0.0243
   120        4.2745             nan     0.1000    0.0046
   140        4.2037             nan     0.1000   -0.0357
   160        4.1656             nan     0.1000   -0.0191
   180        4.1194             nan     0.1000   -0.0068
   200        4.0839             nan     0.1000   -0.0190

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1913             nan     0.1000    0.1097
     2        6.9135             nan     0.1000    0.1528
     3        6.6623             nan     0.1000    0.2166
     4        6.5129             nan     0.1000    0.0704
     5        6.3398             nan     0.1000    0.1259
     6        6.1967             nan     0.1000    0.1503
     7        6.0731             nan     0.1000    0.0859
     8        5.9697             nan     0.1000    0.0981
     9        5.8841             nan     0.1000    0.0478
    10        5.8227             nan     0.1000    0.0252
    20        5.1218             nan     0.1000   -0.0260
    40        4.4558             nan     0.1000   -0.0099
    60        4.1274             nan     0.1000   -0.0217
    80        3.8847             nan     0.1000   -0.0170
   100        3.7306             nan     0.1000   -0.0453
   120        3.6221             nan     0.1000   -0.0132
   140        3.5028             nan     0.1000   -0.0095
   160        3.3903             nan     0.1000   -0.0162
   180        3.3252             nan     0.1000   -0.0070
   200        3.2409             nan     0.1000   -0.0191

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1377             nan     0.1000    0.2674
     2        6.8783             nan     0.1000    0.2472
     3        6.6065             nan     0.1000    0.1967
     4        6.4156             nan     0.1000    0.1149
     5        6.2564             nan     0.1000    0.0933
     6        6.0334             nan     0.1000    0.1382
     7        5.8967             nan     0.1000    0.0614
     8        5.7858             nan     0.1000    0.0824
     9        5.6519             nan     0.1000    0.0791
    10        5.5412             nan     0.1000    0.0719
    20        4.7481             nan     0.1000   -0.0166
    40        4.0388             nan     0.1000   -0.0030
    60        3.6281             nan     0.1000   -0.0465
    80        3.3730             nan     0.1000   -0.0036
   100        3.1879             nan     0.1000   -0.0122
   120        2.9880             nan     0.1000   -0.0067
   140        2.8304             nan     0.1000   -0.0318
   160        2.7073             nan     0.1000   -0.0303
   180        2.5973             nan     0.1000   -0.0256
   200        2.4857             nan     0.1000   -0.0168

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9863             nan     0.1000    0.3758
     2        6.6407             nan     0.1000    0.3025
     3        6.3828             nan     0.1000    0.1467
     4        6.1643             nan     0.1000    0.1386
     5        5.9761             nan     0.1000    0.1834
     6        5.7764             nan     0.1000    0.1419
     7        5.5884             nan     0.1000    0.0858
     8        5.4332             nan     0.1000    0.0702
     9        5.2881             nan     0.1000    0.0729
    10        5.1935             nan     0.1000    0.0427
    20        4.3601             nan     0.1000    0.0056
    40        3.6478             nan     0.1000   -0.0275
    60        3.2247             nan     0.1000   -0.0191
    80        2.8083             nan     0.1000   -0.0430
   100        2.5026             nan     0.1000   -0.0017
   120        2.2778             nan     0.1000   -0.0398
   140        2.1046             nan     0.1000   -0.0235
   160        1.9428             nan     0.1000   -0.0125
   180        1.8037             nan     0.1000   -0.0213
   200        1.6648             nan     0.1000   -0.0136

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0401             nan     0.2000    0.4569
     2        6.7363             nan     0.2000    0.2878
     3        6.4874             nan     0.2000    0.2031
     4        6.3187             nan     0.2000    0.1450
     5        6.0812             nan     0.2000    0.0936
     6        5.9693             nan     0.2000    0.0696
     7        5.8176             nan     0.2000    0.1394
     8        5.7325             nan     0.2000    0.0497
     9        5.6326             nan     0.2000    0.0823
    10        5.5601             nan     0.2000    0.0050
    20        5.0346             nan     0.2000   -0.0761
    40        4.5111             nan     0.2000   -0.0337
    60        4.2978             nan     0.2000   -0.0090
    80        4.2001             nan     0.2000   -0.0310
   100        4.1337             nan     0.2000   -0.0106
   120        4.0949             nan     0.2000   -0.0288
   140        4.0630             nan     0.2000   -0.0341
   160        4.0443             nan     0.2000   -0.0405
   180        4.0163             nan     0.2000   -0.0216
   200        4.0189             nan     0.2000   -0.0351

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8992             nan     0.2000    0.4100
     2        6.5201             nan     0.2000    0.4264
     3        6.1559             nan     0.2000    0.3054
     4        5.8942             nan     0.2000    0.0794
     5        5.7507             nan     0.2000    0.0279
     6        5.5730             nan     0.2000   -0.0087
     7        5.4407             nan     0.2000    0.0811
     8        5.3368             nan     0.2000    0.0369
     9        5.2085             nan     0.2000   -0.0127
    10        5.0815             nan     0.2000    0.0393
    20        4.4474             nan     0.2000    0.0059
    40        3.8334             nan     0.2000   -0.0821
    60        3.5556             nan     0.2000   -0.0366
    80        3.3577             nan     0.2000   -0.0230
   100        3.2478             nan     0.2000   -0.0397
   120        3.1264             nan     0.2000   -0.0372
   140        2.9959             nan     0.2000   -0.0427
   160        2.9066             nan     0.2000   -0.0189
   180        2.8335             nan     0.2000   -0.0652
   200        2.7158             nan     0.2000   -0.0199

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6366             nan     0.2000    0.5925
     2        6.2144             nan     0.2000    0.3263
     3        5.8566             nan     0.2000    0.1668
     4        5.5976             nan     0.2000    0.2143
     5        5.4731             nan     0.2000    0.0217
     6        5.3512             nan     0.2000    0.0125
     7        5.1822             nan     0.2000    0.0644
     8        5.0606             nan     0.2000    0.0206
     9        4.9765             nan     0.2000    0.0440
    10        4.8562             nan     0.2000    0.0030
    20        4.1490             nan     0.2000   -0.0325
    40        3.5279             nan     0.2000   -0.0305
    60        3.1877             nan     0.2000   -0.0362
    80        2.9440             nan     0.2000   -0.0564
   100        2.6472             nan     0.2000   -0.0107
   120        2.4033             nan     0.2000   -0.0497
   140        2.1970             nan     0.2000   -0.0322
   160        2.0092             nan     0.2000   -0.0134
   180        1.8633             nan     0.2000   -0.0372
   200        1.7254             nan     0.2000   -0.0333

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6712             nan     0.2000    0.6076
     2        6.1202             nan     0.2000    0.4609
     3        5.6715             nan     0.2000    0.1855
     4        5.3417             nan     0.2000    0.2437
     5        5.0847             nan     0.2000   -0.0017
     6        4.8597             nan     0.2000   -0.0894
     7        4.6894             nan     0.2000    0.0978
     8        4.5207             nan     0.2000    0.0239
     9        4.4431             nan     0.2000   -0.0594
    10        4.2919             nan     0.2000    0.0416
    20        3.5341             nan     0.2000   -0.0250
    40        2.7779             nan     0.2000   -0.0596
    60        2.3104             nan     0.2000   -0.0675
    80        1.9485             nan     0.2000   -0.0346
   100        1.6784             nan     0.2000   -0.0642
   120        1.4567             nan     0.2000   -0.0183
   140        1.2939             nan     0.2000   -0.0198
   160        1.1127             nan     0.2000   -0.0125
   180        1.0018             nan     0.2000   -0.0308
   200        0.8570             nan     0.2000   -0.0101

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6027             nan     0.0500    0.1138
     2        6.5185             nan     0.0500    0.0873
     3        6.4271             nan     0.0500    0.0807
     4        6.3168             nan     0.0500    0.0994
     5        6.2298             nan     0.0500    0.0518
     6        6.1435             nan     0.0500    0.0531
     7        6.0619             nan     0.0500    0.0866
     8        5.9974             nan     0.0500    0.0430
     9        5.9366             nan     0.0500    0.0565
    10        5.8771             nan     0.0500    0.0507
    20        5.4922             nan     0.0500    0.0333
    40        5.0201             nan     0.0500    0.0109
    60        4.7020             nan     0.0500    0.0055
    80        4.4790             nan     0.0500   -0.0038
   100        4.3060             nan     0.0500    0.0032
   120        4.1759             nan     0.0500   -0.0053
   140        4.0766             nan     0.0500   -0.0036
   160        4.0013             nan     0.0500   -0.0002
   180        3.9549             nan     0.0500    0.0003
   200        3.8939             nan     0.0500   -0.0042

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5877             nan     0.0500    0.1331
     2        6.4648             nan     0.0500    0.1265
     3        6.3494             nan     0.0500    0.1094
     4        6.2924             nan     0.0500    0.0291
     5        6.1764             nan     0.0500    0.0979
     6        6.0740             nan     0.0500    0.0811
     7        5.9696             nan     0.0500    0.0630
     8        5.8762             nan     0.0500    0.1040
     9        5.8144             nan     0.0500    0.0533
    10        5.7354             nan     0.0500    0.0402
    20        5.1912             nan     0.0500    0.0118
    40        4.5258             nan     0.0500    0.0022
    60        4.1602             nan     0.0500   -0.0089
    80        3.9197             nan     0.0500   -0.0014
   100        3.7537             nan     0.0500   -0.0063
   120        3.6129             nan     0.0500   -0.0015
   140        3.5140             nan     0.0500   -0.0095
   160        3.4142             nan     0.0500   -0.0090
   180        3.3386             nan     0.0500   -0.0060
   200        3.2762             nan     0.0500   -0.0135

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5464             nan     0.0500    0.1476
     2        6.4015             nan     0.0500    0.1399
     3        6.2200             nan     0.0500    0.1671
     4        6.1013             nan     0.0500    0.1253
     5        6.0056             nan     0.0500    0.1077
     6        5.9104             nan     0.0500    0.0825
     7        5.8362             nan     0.0500    0.0534
     8        5.7515             nan     0.0500    0.0756
     9        5.6542             nan     0.0500    0.0762
    10        5.5458             nan     0.0500    0.0894
    20        4.8720             nan     0.0500    0.0435
    40        4.1965             nan     0.0500   -0.0005
    60        3.8245             nan     0.0500   -0.0007
    80        3.6000             nan     0.0500   -0.0048
   100        3.3970             nan     0.0500   -0.0184
   120        3.2505             nan     0.0500   -0.0077
   140        3.1279             nan     0.0500   -0.0066
   160        3.0195             nan     0.0500   -0.0071
   180        2.9346             nan     0.0500   -0.0111
   200        2.8353             nan     0.0500   -0.0064

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5134             nan     0.0500    0.1834
     2        6.3852             nan     0.0500    0.0754
     3        6.2166             nan     0.0500    0.1472
     4        6.0716             nan     0.0500    0.1054
     5        5.9011             nan     0.0500    0.1529
     6        5.7947             nan     0.0500    0.0687
     7        5.6802             nan     0.0500    0.0470
     8        5.5720             nan     0.0500    0.0663
     9        5.4567             nan     0.0500    0.0839
    10        5.3393             nan     0.0500    0.0893
    20        4.5332             nan     0.0500    0.0524
    40        3.7985             nan     0.0500   -0.0002
    60        3.3672             nan     0.0500   -0.0216
    80        3.0998             nan     0.0500   -0.0202
   100        2.8807             nan     0.0500   -0.0117
   120        2.6866             nan     0.0500   -0.0242
   140        2.5243             nan     0.0500   -0.0071
   160        2.3797             nan     0.0500   -0.0159
   180        2.2324             nan     0.0500   -0.0075
   200        2.0967             nan     0.0500   -0.0083

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5198             nan     0.1000    0.2531
     2        6.2872             nan     0.1000    0.2076
     3        6.1470             nan     0.1000    0.1246
     4        5.9912             nan     0.1000    0.1491
     5        5.8887             nan     0.1000    0.1084
     6        5.7901             nan     0.1000    0.1065
     7        5.6794             nan     0.1000    0.1103
     8        5.5954             nan     0.1000    0.0692
     9        5.5176             nan     0.1000    0.0506
    10        5.4401             nan     0.1000    0.0375
    20        5.0120             nan     0.1000   -0.0251
    40        4.4737             nan     0.1000   -0.0016
    60        4.1871             nan     0.1000   -0.0067
    80        4.0082             nan     0.1000   -0.0164
   100        3.8830             nan     0.1000   -0.0067
   120        3.7870             nan     0.1000   -0.0070
   140        3.7253             nan     0.1000   -0.0143
   160        3.6770             nan     0.1000   -0.0108
   180        3.6445             nan     0.1000   -0.0039
   200        3.6334             nan     0.1000   -0.0099

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4919             nan     0.1000    0.2215
     2        6.2500             nan     0.1000    0.2652
     3        6.0797             nan     0.1000    0.1277
     4        5.8670             nan     0.1000    0.2115
     5        5.7109             nan     0.1000    0.1094
     6        5.5632             nan     0.1000    0.0690
     7        5.4466             nan     0.1000    0.0997
     8        5.3224             nan     0.1000    0.1015
     9        5.2124             nan     0.1000    0.0987
    10        5.1188             nan     0.1000    0.0824
    20        4.5471             nan     0.1000    0.0224
    40        3.9342             nan     0.1000    0.0060
    60        3.6555             nan     0.1000   -0.0213
    80        3.4898             nan     0.1000   -0.0160
   100        3.3508             nan     0.1000   -0.0254
   120        3.2281             nan     0.1000   -0.0144
   140        3.1242             nan     0.1000   -0.0189
   160        3.0307             nan     0.1000   -0.0123
   180        2.9598             nan     0.1000   -0.0064
   200        2.9017             nan     0.1000   -0.0006

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3635             nan     0.1000    0.3763
     2        6.1232             nan     0.1000    0.2365
     3        5.8864             nan     0.1000    0.1986
     4        5.6480             nan     0.1000    0.1905
     5        5.4543             nan     0.1000    0.1520
     6        5.3281             nan     0.1000    0.0535
     7        5.1766             nan     0.1000    0.1127
     8        5.0616             nan     0.1000    0.1061
     9        4.9647             nan     0.1000    0.0512
    10        4.8778             nan     0.1000    0.0499
    20        4.1738             nan     0.1000   -0.0301
    40        3.5743             nan     0.1000   -0.0169
    60        3.2358             nan     0.1000   -0.0191
    80        2.9961             nan     0.1000   -0.0094
   100        2.8232             nan     0.1000   -0.0116
   120        2.6468             nan     0.1000   -0.0079
   140        2.4912             nan     0.1000   -0.0105
   160        2.3789             nan     0.1000   -0.0151
   180        2.2579             nan     0.1000   -0.0204
   200        2.1014             nan     0.1000   -0.0201

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3157             nan     0.1000    0.3547
     2        6.0156             nan     0.1000    0.2529
     3        5.7812             nan     0.1000    0.1899
     4        5.5171             nan     0.1000    0.1667
     5        5.2672             nan     0.1000    0.2332
     6        5.0684             nan     0.1000    0.1681
     7        4.8477             nan     0.1000    0.1361
     8        4.7499             nan     0.1000    0.0252
     9        4.6140             nan     0.1000    0.0606
    10        4.5064             nan     0.1000    0.0471
    20        3.8176             nan     0.1000   -0.0016
    40        3.1095             nan     0.1000   -0.0358
    60        2.6809             nan     0.1000   -0.0225
    80        2.3720             nan     0.1000   -0.0090
   100        2.1205             nan     0.1000   -0.0188
   120        1.8991             nan     0.1000   -0.0198
   140        1.7075             nan     0.1000   -0.0146
   160        1.5849             nan     0.1000   -0.0151
   180        1.4570             nan     0.1000   -0.0147
   200        1.3429             nan     0.1000   -0.0093

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.2869             nan     0.2000    0.3388
     2        5.9089             nan     0.2000    0.3234
     3        5.6634             nan     0.2000    0.1805
     4        5.4853             nan     0.2000    0.1603
     5        5.3719             nan     0.2000    0.0625
     6        5.2874             nan     0.2000    0.0590
     7        5.1904             nan     0.2000    0.0834
     8        5.1022             nan     0.2000    0.0225
     9        5.0039             nan     0.2000    0.0580
    10        4.9455             nan     0.2000   -0.0149
    20        4.4423             nan     0.2000   -0.0321
    40        4.0030             nan     0.2000   -0.0172
    60        3.8566             nan     0.2000   -0.0410
    80        3.7506             nan     0.2000   -0.0259
   100        3.6849             nan     0.2000   -0.0250
   120        3.6420             nan     0.2000   -0.0297
   140        3.6311             nan     0.2000   -0.0221
   160        3.5881             nan     0.2000   -0.0220
   180        3.5564             nan     0.2000   -0.0257
   200        3.5435             nan     0.2000   -0.0256

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.2309             nan     0.2000    0.4312
     2        5.8252             nan     0.2000    0.2627
     3        5.4585             nan     0.2000    0.2607
     4        5.2496             nan     0.2000    0.1227
     5        5.0899             nan     0.2000    0.0604
     6        4.9210             nan     0.2000    0.0827
     7        4.7201             nan     0.2000    0.1334
     8        4.6628             nan     0.2000    0.0207
     9        4.5905             nan     0.2000   -0.0531
    10        4.5130             nan     0.2000    0.0476
    20        3.9231             nan     0.2000   -0.0151
    40        3.4598             nan     0.2000   -0.0322
    60        3.1623             nan     0.2000   -0.0225
    80        2.9965             nan     0.2000   -0.0326
   100        2.8784             nan     0.2000   -0.0353
   120        2.7419             nan     0.2000   -0.0428
   140        2.6170             nan     0.2000   -0.0557
   160        2.4855             nan     0.2000   -0.0191
   180        2.3998             nan     0.2000   -0.0400
   200        2.3092             nan     0.2000   -0.0328

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.0749             nan     0.2000    0.6449
     2        5.6499             nan     0.2000    0.3785
     3        5.3380             nan     0.2000    0.2113
     4        5.0817             nan     0.2000    0.1604
     5        4.8621             nan     0.2000    0.1757
     6        4.6634             nan     0.2000    0.0610
     7        4.5377             nan     0.2000    0.0049
     8        4.4392             nan     0.2000    0.0330
     9        4.3607             nan     0.2000   -0.0427
    10        4.2514             nan     0.2000    0.0235
    20        3.7247             nan     0.2000   -0.0318
    40        3.1982             nan     0.2000   -0.0245
    60        2.8588             nan     0.2000   -0.0423
    80        2.5027             nan     0.2000    0.0230
   100        2.2731             nan     0.2000   -0.0179
   120        2.0869             nan     0.2000   -0.0159
   140        1.8748             nan     0.2000   -0.0329
   160        1.7462             nan     0.2000   -0.0248
   180        1.6123             nan     0.2000   -0.0345
   200        1.5008             nan     0.2000   -0.0154

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.0247             nan     0.2000    0.4652
     2        5.4201             nan     0.2000    0.6325
     3        5.0044             nan     0.2000    0.1398
     4        4.7314             nan     0.2000    0.1958
     5        4.5834             nan     0.2000    0.0087
     6        4.4205             nan     0.2000    0.0720
     7        4.2658             nan     0.2000    0.0517
     8        4.1113             nan     0.2000    0.0578
     9        3.9695             nan     0.2000    0.0843
    10        3.9061             nan     0.2000   -0.0264
    20        3.3016             nan     0.2000   -0.0323
    40        2.5296             nan     0.2000   -0.0252
    60        2.0632             nan     0.2000   -0.0461
    80        1.6880             nan     0.2000   -0.0239
   100        1.4330             nan     0.2000   -0.0251
   120        1.2187             nan     0.2000   -0.0071
   140        1.0530             nan     0.2000   -0.0257
   160        0.8945             nan     0.2000   -0.0140
   180        0.7776             nan     0.2000   -0.0190
   200        0.6675             nan     0.2000   -0.0150

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0813             nan     0.0500    0.0911
     2        6.9712             nan     0.0500    0.0688
     3        6.8672             nan     0.0500    0.0809
     4        6.7921             nan     0.0500    0.0968
     5        6.7005             nan     0.0500    0.0649
     6        6.6004             nan     0.0500    0.0756
     7        6.5340             nan     0.0500    0.0687
     8        6.4689             nan     0.0500    0.0778
     9        6.4035             nan     0.0500    0.0698
    10        6.3363             nan     0.0500    0.0651
    20        5.9652             nan     0.0500    0.0123
    40        5.4135             nan     0.0500    0.0108
    60        5.0936             nan     0.0500    0.0056
    80        4.8684             nan     0.0500   -0.0001
   100        4.6866             nan     0.0500    0.0008
   120        4.5327             nan     0.0500    0.0030
   140        4.4309             nan     0.0500   -0.0089
   160        4.3447             nan     0.0500   -0.0144
   180        4.2849             nan     0.0500   -0.0069
   200        4.2255             nan     0.0500    0.0005

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0447             nan     0.0500    0.1644
     2        6.9111             nan     0.0500    0.1551
     3        6.7796             nan     0.0500    0.1001
     4        6.6757             nan     0.0500    0.1045
     5        6.5649             nan     0.0500    0.0882
     6        6.4745             nan     0.0500    0.0907
     7        6.3851             nan     0.0500    0.0745
     8        6.3084             nan     0.0500    0.0715
     9        6.2343             nan     0.0500    0.0623
    10        6.1522             nan     0.0500    0.0671
    20        5.5730             nan     0.0500    0.0372
    40        4.8644             nan     0.0500    0.0115
    60        4.4786             nan     0.0500    0.0037
    80        4.2360             nan     0.0500   -0.0041
   100        4.0519             nan     0.0500   -0.0055
   120        3.8904             nan     0.0500   -0.0011
   140        3.7740             nan     0.0500   -0.0082
   160        3.6869             nan     0.0500   -0.0056
   180        3.6317             nan     0.0500   -0.0100
   200        3.5281             nan     0.0500   -0.0046

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0429             nan     0.0500    0.1098
     2        6.8791             nan     0.0500    0.1228
     3        6.7444             nan     0.0500    0.1174
     4        6.5860             nan     0.0500    0.1198
     5        6.4561             nan     0.0500    0.0733
     6        6.3504             nan     0.0500    0.0974
     7        6.2632             nan     0.0500    0.0863
     8        6.1658             nan     0.0500    0.0838
     9        6.0833             nan     0.0500    0.0638
    10        5.9898             nan     0.0500    0.0828
    20        5.2875             nan     0.0500    0.0313
    40        4.5581             nan     0.0500   -0.0136
    60        4.1405             nan     0.0500    0.0032
    80        3.8760             nan     0.0500    0.0026
   100        3.6734             nan     0.0500    0.0026
   120        3.4962             nan     0.0500   -0.0166
   140        3.3534             nan     0.0500   -0.0191
   160        3.2354             nan     0.0500   -0.0140
   180        3.1317             nan     0.0500   -0.0084
   200        3.0109             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0276             nan     0.0500    0.1600
     2        6.8573             nan     0.0500    0.1612
     3        6.6758             nan     0.0500    0.1436
     4        6.5100             nan     0.0500    0.1656
     5        6.3683             nan     0.0500    0.0920
     6        6.2095             nan     0.0500    0.1309
     7        6.0754             nan     0.0500    0.0371
     8        5.9431             nan     0.0500    0.1032
     9        5.8346             nan     0.0500    0.0977
    10        5.7228             nan     0.0500    0.0775
    20        4.9013             nan     0.0500    0.0241
    40        4.1106             nan     0.0500    0.0258
    60        3.7008             nan     0.0500   -0.0144
    80        3.4226             nan     0.0500   -0.0279
   100        3.1569             nan     0.0500    0.0068
   120        2.9499             nan     0.0500   -0.0129
   140        2.7731             nan     0.0500   -0.0147
   160        2.5950             nan     0.0500   -0.0058
   180        2.4462             nan     0.0500   -0.0132
   200        2.3090             nan     0.0500   -0.0098

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9013             nan     0.1000    0.2589
     2        6.7282             nan     0.1000    0.1478
     3        6.5551             nan     0.1000    0.1469
     4        6.4302             nan     0.1000    0.1345
     5        6.3094             nan     0.1000    0.1152
     6        6.2016             nan     0.1000    0.1047
     7        6.0889             nan     0.1000    0.0616
     8        6.0158             nan     0.1000    0.0726
     9        5.9504             nan     0.1000    0.0368
    10        5.8675             nan     0.1000    0.0659
    20        5.4132             nan     0.1000   -0.0157
    40        4.8850             nan     0.1000   -0.0016
    60        4.5600             nan     0.1000   -0.0005
    80        4.3787             nan     0.1000   -0.0082
   100        4.2569             nan     0.1000   -0.0083
   120        4.1487             nan     0.1000   -0.0080
   140        4.0982             nan     0.1000   -0.0043
   160        4.0475             nan     0.1000   -0.0193
   180        4.0120             nan     0.1000   -0.0180
   200        3.9828             nan     0.1000   -0.0045

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9020             nan     0.1000    0.2836
     2        6.6485             nan     0.1000    0.2519
     3        6.4145             nan     0.1000    0.1963
     4        6.3224             nan     0.1000    0.0273
     5        6.1459             nan     0.1000    0.1250
     6        5.9775             nan     0.1000    0.1901
     7        5.8413             nan     0.1000    0.0977
     8        5.7581             nan     0.1000    0.0351
     9        5.6519             nan     0.1000    0.0819
    10        5.5605             nan     0.1000    0.0289
    20        4.9050             nan     0.1000    0.0072
    40        4.2733             nan     0.1000   -0.0124
    60        3.9013             nan     0.1000    0.0024
    80        3.6663             nan     0.1000   -0.0114
   100        3.5174             nan     0.1000   -0.0147
   120        3.3446             nan     0.1000   -0.0072
   140        3.1938             nan     0.1000   -0.0042
   160        3.1052             nan     0.1000   -0.0076
   180        3.0389             nan     0.1000   -0.0333
   200        2.9456             nan     0.1000   -0.0165

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8862             nan     0.1000    0.2858
     2        6.6031             nan     0.1000    0.2993
     3        6.4006             nan     0.1000    0.1480
     4        6.2192             nan     0.1000    0.1472
     5        5.9906             nan     0.1000    0.2079
     6        5.8284             nan     0.1000    0.0972
     7        5.6739             nan     0.1000    0.1247
     8        5.5557             nan     0.1000    0.0695
     9        5.4442             nan     0.1000    0.0816
    10        5.3252             nan     0.1000    0.0522
    20        4.6887             nan     0.1000    0.0425
    40        3.9799             nan     0.1000   -0.0320
    60        3.6083             nan     0.1000    0.0004
    80        3.3295             nan     0.1000   -0.0318
   100        3.0707             nan     0.1000   -0.0186
   120        2.8972             nan     0.1000   -0.0313
   140        2.7128             nan     0.1000   -0.0095
   160        2.5713             nan     0.1000   -0.0145
   180        2.5048             nan     0.1000   -0.0212
   200        2.3876             nan     0.1000   -0.0333

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8282             nan     0.1000    0.2847
     2        6.4621             nan     0.1000    0.2339
     3        6.2349             nan     0.1000    0.1361
     4        5.9326             nan     0.1000    0.2753
     5        5.7359             nan     0.1000    0.1639
     6        5.5361             nan     0.1000    0.0960
     7        5.3326             nan     0.1000    0.1318
     8        5.2180             nan     0.1000    0.0065
     9        5.0643             nan     0.1000    0.1001
    10        4.9368             nan     0.1000    0.0756
    20        4.1115             nan     0.1000    0.0103
    40        3.2796             nan     0.1000   -0.0284
    60        2.8575             nan     0.1000   -0.0265
    80        2.5122             nan     0.1000   -0.0475
   100        2.2667             nan     0.1000   -0.0167
   120        2.0608             nan     0.1000   -0.0248
   140        1.8636             nan     0.1000   -0.0134
   160        1.6938             nan     0.1000   -0.0067
   180        1.5586             nan     0.1000   -0.0149
   200        1.4339             nan     0.1000   -0.0069

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7945             nan     0.2000    0.4082
     2        6.4289             nan     0.2000    0.2674
     3        6.1479             nan     0.2000    0.2230
     4        5.9470             nan     0.2000    0.1511
     5        5.8243             nan     0.2000    0.0991
     6        5.7546             nan     0.2000    0.0086
     7        5.6200             nan     0.2000    0.0993
     8        5.5284             nan     0.2000    0.0351
     9        5.4610             nan     0.2000    0.0410
    10        5.3698             nan     0.2000    0.0518
    20        4.8212             nan     0.2000    0.0142
    40        4.3149             nan     0.2000   -0.0182
    60        4.1212             nan     0.2000   -0.0168
    80        4.0508             nan     0.2000   -0.0370
   100        3.9633             nan     0.2000   -0.0184
   120        3.9223             nan     0.2000   -0.0129
   140        3.8873             nan     0.2000   -0.0151
   160        3.8614             nan     0.2000   -0.0248
   180        3.8463             nan     0.2000   -0.0372
   200        3.8488             nan     0.2000   -0.0254

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6435             nan     0.2000    0.4685
     2        6.1834             nan     0.2000    0.3673
     3        5.9036             nan     0.2000    0.1921
     4        5.7040             nan     0.2000    0.1018
     5        5.5797             nan     0.2000    0.0374
     6        5.4255             nan     0.2000    0.1093
     7        5.3205             nan     0.2000    0.0085
     8        5.2026             nan     0.2000    0.1033
     9        5.0563             nan     0.2000   -0.0579
    10        4.9481             nan     0.2000    0.0342
    20        4.2914             nan     0.2000   -0.0302
    40        3.7637             nan     0.2000   -0.0651
    60        3.4263             nan     0.2000   -0.0242
    80        3.1739             nan     0.2000   -0.0195
   100        2.9332             nan     0.2000   -0.0378
   120        2.8035             nan     0.2000   -0.0662
   140        2.6514             nan     0.2000   -0.0491
   160        2.5209             nan     0.2000   -0.0371
   180        2.4241             nan     0.2000   -0.0372
   200        2.3395             nan     0.2000   -0.0301

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6040             nan     0.2000    0.5572
     2        6.0810             nan     0.2000    0.3367
     3        5.7581             nan     0.2000    0.3176
     4        5.5625             nan     0.2000    0.1127
     5        5.2911             nan     0.2000    0.1423
     6        5.0863             nan     0.2000    0.1608
     7        4.9378             nan     0.2000    0.0884
     8        4.7599             nan     0.2000    0.0517
     9        4.6648             nan     0.2000   -0.0672
    10        4.4617             nan     0.2000    0.0460
    20        3.7637             nan     0.2000   -0.0416
    40        3.2035             nan     0.2000   -0.0419
    60        2.8180             nan     0.2000   -0.0614
    80        2.5993             nan     0.2000   -0.0329
   100        2.3939             nan     0.2000   -0.0299
   120        2.1985             nan     0.2000   -0.0408
   140        2.0056             nan     0.2000   -0.0376
   160        1.8998             nan     0.2000   -0.0268
   180        1.7953             nan     0.2000   -0.0294
   200        1.6489             nan     0.2000   -0.0041

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5014             nan     0.2000    0.6588
     2        5.9484             nan     0.2000    0.2294
     3        5.4333             nan     0.2000    0.3380
     4        5.1848             nan     0.2000    0.1253
     5        4.9204             nan     0.2000    0.1437
     6        4.6569             nan     0.2000    0.0839
     7        4.5353             nan     0.2000   -0.0175
     8        4.3421             nan     0.2000   -0.0308
     9        4.1922             nan     0.2000    0.0412
    10        4.0770             nan     0.2000    0.0212
    20        3.4790             nan     0.2000   -0.0178
    40        2.5844             nan     0.2000   -0.0719
    60        2.1206             nan     0.2000   -0.0434
    80        1.7971             nan     0.2000   -0.0481
   100        1.5262             nan     0.2000   -0.0514
   120        1.3204             nan     0.2000   -0.0312
   140        1.1237             nan     0.2000   -0.0148
   160        0.9776             nan     0.2000   -0.0236
   180        0.8554             nan     0.2000   -0.0304
   200        0.7517             nan     0.2000   -0.0163

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2535             nan     0.0500    0.1091
     2        7.1458             nan     0.0500    0.1002
     3        7.0245             nan     0.0500    0.1157
     4        6.9483             nan     0.0500    0.0983
     5        6.8448             nan     0.0500    0.0740
     6        6.7505             nan     0.0500    0.0804
     7        6.6994             nan     0.0500    0.0373
     8        6.6468             nan     0.0500    0.0660
     9        6.5809             nan     0.0500    0.0664
    10        6.4976             nan     0.0500    0.0451
    20        6.0042             nan     0.0500    0.0342
    40        5.4649             nan     0.0500    0.0132
    60        5.1273             nan     0.0500   -0.0070
    80        4.8727             nan     0.0500   -0.0030
   100        4.6841             nan     0.0500    0.0036
   120        4.5549             nan     0.0500   -0.0049
   140        4.4425             nan     0.0500    0.0017
   160        4.3491             nan     0.0500   -0.0075
   180        4.2817             nan     0.0500   -0.0008
   200        4.2398             nan     0.0500   -0.0045

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2216             nan     0.0500    0.1625
     2        7.0809             nan     0.0500    0.1386
     3        6.9250             nan     0.0500    0.1424
     4        6.7858             nan     0.0500    0.1040
     5        6.6766             nan     0.0500    0.0865
     6        6.5931             nan     0.0500    0.0810
     7        6.4971             nan     0.0500    0.1007
     8        6.4016             nan     0.0500    0.0970
     9        6.3247             nan     0.0500    0.0735
    10        6.2359             nan     0.0500    0.0730
    20        5.6497             nan     0.0500    0.0252
    40        4.9453             nan     0.0500   -0.0014
    60        4.5390             nan     0.0500   -0.0028
    80        4.2308             nan     0.0500   -0.0070
   100        4.0609             nan     0.0500   -0.0060
   120        3.9149             nan     0.0500   -0.0119
   140        3.8137             nan     0.0500   -0.0047
   160        3.7135             nan     0.0500   -0.0145
   180        3.6432             nan     0.0500   -0.0059
   200        3.5760             nan     0.0500    0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1604             nan     0.0500    0.1517
     2        7.0188             nan     0.0500    0.1440
     3        6.9007             nan     0.0500    0.1096
     4        6.7472             nan     0.0500    0.0949
     5        6.6115             nan     0.0500    0.1021
     6        6.4640             nan     0.0500    0.1156
     7        6.3748             nan     0.0500    0.0644
     8        6.2647             nan     0.0500    0.0999
     9        6.1508             nan     0.0500    0.0844
    10        6.0604             nan     0.0500    0.0497
    20        5.3230             nan     0.0500    0.0056
    40        4.5198             nan     0.0500   -0.0014
    60        4.1564             nan     0.0500   -0.0027
    80        3.8648             nan     0.0500    0.0112
   100        3.6629             nan     0.0500   -0.0009
   120        3.5228             nan     0.0500   -0.0085
   140        3.3947             nan     0.0500   -0.0267
   160        3.2895             nan     0.0500   -0.0219
   180        3.1853             nan     0.0500   -0.0123
   200        3.0897             nan     0.0500   -0.0158

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1717             nan     0.0500    0.2055
     2        6.9970             nan     0.0500    0.1530
     3        6.7937             nan     0.0500    0.1424
     4        6.6298             nan     0.0500    0.1376
     5        6.4627             nan     0.0500    0.1316
     6        6.2858             nan     0.0500    0.1074
     7        6.1434             nan     0.0500    0.0705
     8        6.0067             nan     0.0500    0.1267
     9        5.8843             nan     0.0500    0.0781
    10        5.7853             nan     0.0500    0.0532
    20        4.9694             nan     0.0500    0.0275
    40        4.1617             nan     0.0500   -0.0050
    60        3.7331             nan     0.0500   -0.0079
    80        3.4590             nan     0.0500   -0.0192
   100        3.2188             nan     0.0500   -0.0176
   120        2.9960             nan     0.0500   -0.0092
   140        2.8218             nan     0.0500   -0.0094
   160        2.6424             nan     0.0500   -0.0089
   180        2.5167             nan     0.0500   -0.0129
   200        2.3690             nan     0.0500   -0.0115

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1062             nan     0.1000    0.2488
     2        6.9291             nan     0.1000    0.2063
     3        6.7429             nan     0.1000    0.1426
     4        6.5930             nan     0.1000    0.0995
     5        6.4573             nan     0.1000    0.1273
     6        6.3323             nan     0.1000    0.0682
     7        6.2360             nan     0.1000    0.0779
     8        6.1493             nan     0.1000    0.0722
     9        6.0772             nan     0.1000    0.0823
    10        6.0157             nan     0.1000    0.0288
    20        5.5422             nan     0.1000    0.0101
    40        4.9391             nan     0.1000    0.0141
    60        4.6178             nan     0.1000   -0.0082
    80        4.4197             nan     0.1000    0.0103
   100        4.2801             nan     0.1000   -0.0245
   120        4.2008             nan     0.1000   -0.0173
   140        4.1281             nan     0.1000   -0.0109
   160        4.1064             nan     0.1000   -0.0147
   180        4.0673             nan     0.1000   -0.0105
   200        4.0446             nan     0.1000   -0.0227

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0368             nan     0.1000    0.2799
     2        6.8198             nan     0.1000    0.1525
     3        6.5882             nan     0.1000    0.1396
     4        6.3868             nan     0.1000    0.1299
     5        6.2697             nan     0.1000    0.1213
     6        6.1003             nan     0.1000    0.1252
     7        5.9861             nan     0.1000    0.1082
     8        5.8449             nan     0.1000    0.1304
     9        5.7389             nan     0.1000    0.0474
    10        5.6348             nan     0.1000    0.1013
    20        4.9647             nan     0.1000    0.0435
    40        4.2993             nan     0.1000   -0.0173
    60        3.9605             nan     0.1000   -0.0221
    80        3.7305             nan     0.1000   -0.0210
   100        3.5881             nan     0.1000   -0.0028
   120        3.4231             nan     0.1000   -0.0186
   140        3.3019             nan     0.1000   -0.0200
   160        3.2346             nan     0.1000   -0.0146
   180        3.1367             nan     0.1000    0.0043
   200        3.0685             nan     0.1000   -0.0149

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0311             nan     0.1000    0.2805
     2        6.7832             nan     0.1000    0.2030
     3        6.5379             nan     0.1000    0.2289
     4        6.2790             nan     0.1000    0.2075
     5        6.1094             nan     0.1000    0.1135
     6        5.9517             nan     0.1000    0.1350
     7        5.7532             nan     0.1000    0.1612
     8        5.6264             nan     0.1000    0.0937
     9        5.4765             nan     0.1000    0.1057
    10        5.3957             nan     0.1000    0.0469
    20        4.6668             nan     0.1000    0.0014
    40        3.9603             nan     0.1000   -0.0155
    60        3.6618             nan     0.1000   -0.0206
    80        3.4183             nan     0.1000   -0.0322
   100        3.2016             nan     0.1000   -0.0180
   120        3.0191             nan     0.1000   -0.0141
   140        2.8340             nan     0.1000   -0.0299
   160        2.6878             nan     0.1000   -0.0150
   180        2.5630             nan     0.1000   -0.0205
   200        2.4430             nan     0.1000   -0.0202

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9628             nan     0.1000    0.3407
     2        6.5787             nan     0.1000    0.2899
     3        6.3115             nan     0.1000    0.2281
     4        6.0823             nan     0.1000    0.1033
     5        5.8665             nan     0.1000    0.0727
     6        5.6552             nan     0.1000    0.1487
     7        5.5192             nan     0.1000    0.0912
     8        5.3700             nan     0.1000    0.0933
     9        5.1969             nan     0.1000    0.1372
    10        5.0477             nan     0.1000    0.0773
    20        4.2185             nan     0.1000   -0.0280
    40        3.4010             nan     0.1000   -0.0202
    60        2.9579             nan     0.1000   -0.0524
    80        2.6380             nan     0.1000   -0.0280
   100        2.3847             nan     0.1000   -0.0172
   120        2.1764             nan     0.1000   -0.0234
   140        1.9914             nan     0.1000   -0.0263
   160        1.8091             nan     0.1000   -0.0183
   180        1.6389             nan     0.1000   -0.0092
   200        1.5023             nan     0.1000   -0.0154

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8602             nan     0.2000    0.4608
     2        6.5703             nan     0.2000    0.2626
     3        6.3037             nan     0.2000    0.2394
     4        6.1939             nan     0.2000    0.0360
     5        6.0594             nan     0.2000    0.1582
     6        5.9133             nan     0.2000    0.0884
     7        5.7748             nan     0.2000    0.0781
     8        5.6885             nan     0.2000    0.0552
     9        5.5779             nan     0.2000    0.1092
    10        5.4856             nan     0.2000    0.0589
    20        4.9756             nan     0.2000    0.0045
    40        4.4652             nan     0.2000   -0.0058
    60        4.2802             nan     0.2000   -0.0922
    80        4.2024             nan     0.2000   -0.0168
   100        4.1531             nan     0.2000   -0.0518
   120        4.0664             nan     0.2000   -0.0247
   140        4.0310             nan     0.2000   -0.0376
   160        3.9927             nan     0.2000   -0.0424
   180        3.9752             nan     0.2000   -0.0261
   200        3.9606             nan     0.2000   -0.0462

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8966             nan     0.2000    0.4136
     2        6.3118             nan     0.2000    0.3776
     3        5.9963             nan     0.2000    0.2887
     4        5.7380             nan     0.2000    0.1504
     5        5.5761             nan     0.2000    0.0971
     6        5.4225             nan     0.2000    0.0416
     7        5.3124             nan     0.2000    0.0043
     8        5.2199             nan     0.2000    0.0352
     9        5.1615             nan     0.2000   -0.0194
    10        5.0040             nan     0.2000    0.0973
    20        4.4708             nan     0.2000   -0.0322
    40        3.8847             nan     0.2000   -0.0286
    60        3.5586             nan     0.2000   -0.0458
    80        3.4501             nan     0.2000   -0.0382
   100        3.3082             nan     0.2000   -0.0220
   120        3.1370             nan     0.2000   -0.0175
   140        2.9889             nan     0.2000   -0.0163
   160        2.8783             nan     0.2000   -0.0386
   180        2.7606             nan     0.2000   -0.0326
   200        2.6770             nan     0.2000   -0.0381

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7653             nan     0.2000    0.5204
     2        6.3205             nan     0.2000    0.3515
     3        5.9552             nan     0.2000    0.2834
     4        5.5652             nan     0.2000    0.3264
     5        5.3510             nan     0.2000    0.0835
     6        5.1224             nan     0.2000    0.1412
     7        4.9757             nan     0.2000    0.0447
     8        4.8585             nan     0.2000   -0.0255
     9        4.7656             nan     0.2000   -0.0092
    10        4.6730             nan     0.2000   -0.0190
    20        3.9548             nan     0.2000   -0.0427
    40        3.4743             nan     0.2000   -0.0453
    60        3.1296             nan     0.2000   -0.0129
    80        2.9406             nan     0.2000   -0.0547
   100        2.6610             nan     0.2000   -0.0371
   120        2.4291             nan     0.2000   -0.0271
   140        2.2592             nan     0.2000   -0.0213
   160        2.1280             nan     0.2000   -0.0126
   180        2.0052             nan     0.2000   -0.0194
   200        1.8735             nan     0.2000   -0.0261

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6622             nan     0.2000    0.6958
     2        6.1247             nan     0.2000    0.4314
     3        5.7237             nan     0.2000    0.2439
     4        5.4263             nan     0.2000    0.1320
     5        5.0931             nan     0.2000    0.1760
     6        4.8978             nan     0.2000    0.0598
     7        4.6708             nan     0.2000    0.0223
     8        4.4568             nan     0.2000    0.0437
     9        4.4070             nan     0.2000   -0.0585
    10        4.2991             nan     0.2000    0.0314
    20        3.5002             nan     0.2000   -0.0597
    40        2.7763             nan     0.2000   -0.0501
    60        2.3548             nan     0.2000   -0.0291
    80        1.8761             nan     0.2000   -0.0410
   100        1.5548             nan     0.2000   -0.0020
   120        1.3611             nan     0.2000   -0.0342
   140        1.1891             nan     0.2000   -0.0323
   160        1.0331             nan     0.2000   -0.0166
   180        0.9222             nan     0.2000   -0.0235
   200        0.7902             nan     0.2000   -0.0207

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3740             nan     0.0500    0.0931
     2        7.2522             nan     0.0500    0.1080
     3        7.1577             nan     0.0500    0.1083
     4        7.0545             nan     0.0500    0.0680
     5        6.9822             nan     0.0500    0.0595
     6        6.9081             nan     0.0500    0.0456
     7        6.8414             nan     0.0500    0.0671
     8        6.7708             nan     0.0500    0.0790
     9        6.6970             nan     0.0500    0.0579
    10        6.6430             nan     0.0500    0.0623
    20        6.2161             nan     0.0500    0.0062
    40        5.6541             nan     0.0500   -0.0032
    60        5.3011             nan     0.0500    0.0036
    80        5.0320             nan     0.0500    0.0129
   100        4.8466             nan     0.0500   -0.0054
   120        4.7115             nan     0.0500   -0.0112
   140        4.5941             nan     0.0500   -0.0001
   160        4.5040             nan     0.0500   -0.0088
   180        4.4234             nan     0.0500   -0.0117
   200        4.3687             nan     0.0500   -0.0040

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3010             nan     0.0500    0.1345
     2        7.1361             nan     0.0500    0.1595
     3        7.0182             nan     0.0500    0.0985
     4        6.9126             nan     0.0500    0.1241
     5        6.8139             nan     0.0500    0.0754
     6        6.6997             nan     0.0500    0.0997
     7        6.6213             nan     0.0500    0.0737
     8        6.5442             nan     0.0500    0.0829
     9        6.4563             nan     0.0500    0.0481
    10        6.3459             nan     0.0500    0.0781
    20        5.8010             nan     0.0500    0.0070
    40        5.1523             nan     0.0500    0.0058
    60        4.7314             nan     0.0500   -0.0039
    80        4.4017             nan     0.0500   -0.0052
   100        4.1956             nan     0.0500   -0.0080
   120        4.0332             nan     0.0500   -0.0111
   140        3.9033             nan     0.0500   -0.0042
   160        3.7913             nan     0.0500   -0.0026
   180        3.7361             nan     0.0500   -0.0088
   200        3.6680             nan     0.0500   -0.0087

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3140             nan     0.0500    0.0839
     2        7.1520             nan     0.0500    0.1419
     3        7.0040             nan     0.0500    0.1593
     4        6.8560             nan     0.0500    0.1254
     5        6.7170             nan     0.0500    0.1077
     6        6.5999             nan     0.0500    0.0762
     7        6.4782             nan     0.0500    0.0962
     8        6.3957             nan     0.0500    0.0580
     9        6.2816             nan     0.0500    0.1102
    10        6.1940             nan     0.0500    0.0679
    20        5.5465             nan     0.0500   -0.0099
    40        4.6839             nan     0.0500    0.0043
    60        4.2547             nan     0.0500    0.0009
    80        3.9875             nan     0.0500    0.0031
   100        3.7644             nan     0.0500   -0.0196
   120        3.6085             nan     0.0500   -0.0186
   140        3.4547             nan     0.0500   -0.0081
   160        3.3356             nan     0.0500    0.0004
   180        3.2406             nan     0.0500   -0.0198
   200        3.1346             nan     0.0500   -0.0165

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2613             nan     0.0500    0.1834
     2        7.0509             nan     0.0500    0.1018
     3        6.8968             nan     0.0500    0.1540
     4        6.7566             nan     0.0500    0.1265
     5        6.6067             nan     0.0500    0.1378
     6        6.4657             nan     0.0500    0.1161
     7        6.3219             nan     0.0500    0.1098
     8        6.1964             nan     0.0500    0.0754
     9        6.1103             nan     0.0500    0.0742
    10        6.0108             nan     0.0500    0.0543
    20        5.1565             nan     0.0500    0.0285
    40        4.3183             nan     0.0500    0.0116
    60        3.8440             nan     0.0500   -0.0004
    80        3.5184             nan     0.0500   -0.0247
   100        3.2390             nan     0.0500   -0.0151
   120        3.0345             nan     0.0500   -0.0078
   140        2.8737             nan     0.0500   -0.0209
   160        2.6973             nan     0.0500   -0.0109
   180        2.5564             nan     0.0500   -0.0059
   200        2.4271             nan     0.0500   -0.0061

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2395             nan     0.1000    0.2281
     2        7.0356             nan     0.1000    0.1909
     3        6.8623             nan     0.1000    0.1564
     4        6.7166             nan     0.1000    0.1449
     5        6.6040             nan     0.1000    0.1068
     6        6.4554             nan     0.1000    0.1298
     7        6.3549             nan     0.1000    0.0678
     8        6.2483             nan     0.1000    0.0981
     9        6.1439             nan     0.1000    0.0578
    10        6.0674             nan     0.1000    0.0380
    20        5.5888             nan     0.1000    0.0250
    40        4.9963             nan     0.1000   -0.0035
    60        4.6816             nan     0.1000    0.0069
    80        4.4922             nan     0.1000    0.0052
   100        4.3566             nan     0.1000   -0.0099
   120        4.2672             nan     0.1000   -0.0042
   140        4.2127             nan     0.1000   -0.0183
   160        4.1776             nan     0.1000   -0.0092
   180        4.1372             nan     0.1000   -0.0137
   200        4.0946             nan     0.1000   -0.0205

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1600             nan     0.1000    0.3162
     2        6.9347             nan     0.1000    0.1990
     3        6.7280             nan     0.1000    0.1488
     4        6.5166             nan     0.1000    0.1383
     5        6.3575             nan     0.1000    0.1426
     6        6.2150             nan     0.1000    0.0883
     7        6.0821             nan     0.1000    0.1134
     8        5.9469             nan     0.1000    0.0917
     9        5.8550             nan     0.1000    0.0658
    10        5.7187             nan     0.1000    0.0693
    20        5.0450             nan     0.1000    0.0367
    40        4.4143             nan     0.1000   -0.0290
    60        4.0900             nan     0.1000   -0.0364
    80        3.8659             nan     0.1000   -0.0172
   100        3.7047             nan     0.1000   -0.0188
   120        3.5603             nan     0.1000   -0.0186
   140        3.4497             nan     0.1000   -0.0085
   160        3.3254             nan     0.1000   -0.0128
   180        3.2374             nan     0.1000   -0.0115
   200        3.1487             nan     0.1000   -0.0249

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2017             nan     0.1000    0.2153
     2        6.9280             nan     0.1000    0.2320
     3        6.6624             nan     0.1000    0.1341
     4        6.3940             nan     0.1000    0.1500
     5        6.2011             nan     0.1000    0.0910
     6        6.0484             nan     0.1000    0.1345
     7        5.9265             nan     0.1000    0.0812
     8        5.7466             nan     0.1000    0.1041
     9        5.6070             nan     0.1000    0.0636
    10        5.4873             nan     0.1000    0.0866
    20        4.7198             nan     0.1000   -0.0156
    40        4.0842             nan     0.1000    0.0039
    60        3.7359             nan     0.1000   -0.0151
    80        3.5017             nan     0.1000   -0.0451
   100        3.3086             nan     0.1000   -0.0284
   120        3.0932             nan     0.1000   -0.0099
   140        2.9201             nan     0.1000   -0.0277
   160        2.7870             nan     0.1000   -0.0230
   180        2.6489             nan     0.1000   -0.0149
   200        2.5007             nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0983             nan     0.1000    0.2238
     2        6.8306             nan     0.1000    0.2107
     3        6.5316             nan     0.1000    0.1383
     4        6.2159             nan     0.1000    0.2007
     5        6.0073             nan     0.1000    0.1670
     6        5.7775             nan     0.1000    0.1436
     7        5.5603             nan     0.1000    0.1296
     8        5.4206             nan     0.1000    0.1283
     9        5.2689             nan     0.1000    0.0643
    10        5.1501             nan     0.1000    0.0432
    20        4.3885             nan     0.1000   -0.0018
    40        3.5272             nan     0.1000    0.0054
    60        3.0656             nan     0.1000   -0.0327
    80        2.7230             nan     0.1000   -0.0088
   100        2.4247             nan     0.1000   -0.0200
   120        2.1635             nan     0.1000   -0.0280
   140        1.9947             nan     0.1000   -0.0309
   160        1.8379             nan     0.1000   -0.0251
   180        1.6729             nan     0.1000   -0.0221
   200        1.5311             nan     0.1000   -0.0059

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9777             nan     0.2000    0.4037
     2        6.6643             nan     0.2000    0.3054
     3        6.3752             nan     0.2000    0.2721
     4        6.1901             nan     0.2000    0.1184
     5        6.1039             nan     0.2000   -0.0050
     6        6.0084             nan     0.2000    0.0328
     7        5.9348             nan     0.2000   -0.0407
     8        5.7942             nan     0.2000    0.1064
     9        5.7179             nan     0.2000    0.0717
    10        5.6156             nan     0.2000    0.0197
    20        4.9912             nan     0.2000   -0.0007
    40        4.4982             nan     0.2000   -0.0256
    60        4.2876             nan     0.2000   -0.0142
    80        4.1906             nan     0.2000   -0.0553
   100        4.1306             nan     0.2000   -0.0244
   120        4.0634             nan     0.2000   -0.0186
   140        4.0558             nan     0.2000   -0.0221
   160        3.9909             nan     0.2000   -0.0345
   180        3.9990             nan     0.2000   -0.0191
   200        3.9886             nan     0.2000   -0.0241

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9377             nan     0.2000    0.4127
     2        6.5525             nan     0.2000    0.2456
     3        6.2352             nan     0.2000    0.3232
     4        5.9521             nan     0.2000    0.1348
     5        5.7254             nan     0.2000    0.0936
     6        5.5504             nan     0.2000    0.0595
     7        5.3903             nan     0.2000    0.0927
     8        5.2527             nan     0.2000    0.0132
     9        5.1359             nan     0.2000    0.0725
    10        5.0465             nan     0.2000    0.0170
    20        4.4028             nan     0.2000    0.0423
    40        3.8517             nan     0.2000   -0.0080
    60        3.5641             nan     0.2000   -0.0161
    80        3.3653             nan     0.2000   -0.0445
   100        3.2686             nan     0.2000   -0.0414
   120        3.1144             nan     0.2000   -0.0093
   140        2.9911             nan     0.2000   -0.0347
   160        2.9145             nan     0.2000   -0.0321
   180        2.7627             nan     0.2000   -0.0236
   200        2.6551             nan     0.2000   -0.0424

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7015             nan     0.2000    0.7052
     2        6.2984             nan     0.2000    0.2675
     3        5.9357             nan     0.2000    0.2266
     4        5.6793             nan     0.2000    0.1859
     5        5.4557             nan     0.2000    0.1561
     6        5.2636             nan     0.2000    0.1070
     7        5.1218             nan     0.2000    0.0102
     8        4.9825             nan     0.2000   -0.0257
     9        4.8468             nan     0.2000    0.0379
    10        4.7972             nan     0.2000   -0.0226
    20        4.1639             nan     0.2000    0.0066
    40        3.4667             nan     0.2000   -0.0418
    60        3.1140             nan     0.2000   -0.0491
    80        2.7787             nan     0.2000   -0.0538
   100        2.4994             nan     0.2000   -0.0736
   120        2.2737             nan     0.2000   -0.0431
   140        2.1109             nan     0.2000   -0.0659
   160        1.9762             nan     0.2000   -0.0212
   180        1.8429             nan     0.2000   -0.0624
   200        1.7269             nan     0.2000   -0.0321

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7461             nan     0.2000    0.6084
     2        6.1503             nan     0.2000    0.4044
     3        5.7604             nan     0.2000    0.1375
     4        5.3576             nan     0.2000    0.2107
     5        5.1198             nan     0.2000    0.1694
     6        4.9375             nan     0.2000    0.0312
     7        4.7437             nan     0.2000    0.0511
     8        4.5965             nan     0.2000   -0.0473
     9        4.5447             nan     0.2000   -0.0889
    10        4.4162             nan     0.2000    0.0627
    20        3.5903             nan     0.2000   -0.0274
    40        2.9058             nan     0.2000   -0.0142
    60        2.3932             nan     0.2000   -0.0637
    80        1.9932             nan     0.2000   -0.0578
   100        1.6876             nan     0.2000   -0.0427
   120        1.4345             nan     0.2000   -0.0272
   140        1.2496             nan     0.2000   -0.0239
   160        1.1269             nan     0.2000   -0.0276
   180        0.9604             nan     0.2000   -0.0293
   200        0.8582             nan     0.2000   -0.0187

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3296             nan     0.0500    0.1195
     2        7.2450             nan     0.0500    0.1060
     3        7.1380             nan     0.0500    0.0699
     4        7.0322             nan     0.0500    0.1088
     5        6.9551             nan     0.0500    0.0536
     6        6.9046             nan     0.0500    0.0186
     7        6.8377             nan     0.0500    0.0809
     8        6.7581             nan     0.0500    0.0628
     9        6.6766             nan     0.0500    0.0636
    10        6.6097             nan     0.0500    0.0518
    20        6.1639             nan     0.0500    0.0054
    40        5.6314             nan     0.0500    0.0079
    60        5.2729             nan     0.0500    0.0104
    80        5.0337             nan     0.0500   -0.0026
   100        4.8217             nan     0.0500    0.0044
   120        4.6484             nan     0.0500   -0.0101
   140        4.5196             nan     0.0500   -0.0049
   160        4.4316             nan     0.0500   -0.0115
   180        4.3690             nan     0.0500   -0.0026
   200        4.3155             nan     0.0500   -0.0038

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2859             nan     0.0500    0.1640
     2        7.1338             nan     0.0500    0.1115
     3        7.0106             nan     0.0500    0.1558
     4        6.8784             nan     0.0500    0.1137
     5        6.7593             nan     0.0500    0.0600
     6        6.6325             nan     0.0500    0.0788
     7        6.5433             nan     0.0500    0.0949
     8        6.4582             nan     0.0500    0.0605
     9        6.3801             nan     0.0500    0.0589
    10        6.3074             nan     0.0500    0.0408
    20        5.7183             nan     0.0500    0.0227
    40        5.0207             nan     0.0500    0.0009
    60        4.6028             nan     0.0500   -0.0076
    80        4.2966             nan     0.0500    0.0107
   100        4.1166             nan     0.0500   -0.0019
   120        3.9740             nan     0.0500   -0.0132
   140        3.8613             nan     0.0500   -0.0111
   160        3.7519             nan     0.0500   -0.0132
   180        3.6844             nan     0.0500   -0.0136
   200        3.6084             nan     0.0500   -0.0053

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2860             nan     0.0500    0.1497
     2        7.1272             nan     0.0500    0.1395
     3        6.9793             nan     0.0500    0.1048
     4        6.8503             nan     0.0500    0.1136
     5        6.7342             nan     0.0500    0.0538
     6        6.5899             nan     0.0500    0.0903
     7        6.4746             nan     0.0500    0.1046
     8        6.3728             nan     0.0500    0.0878
     9        6.2982             nan     0.0500    0.0535
    10        6.2036             nan     0.0500    0.0642
    20        5.5237             nan     0.0500    0.0321
    40        4.7146             nan     0.0500    0.0012
    60        4.2560             nan     0.0500    0.0030
    80        3.9575             nan     0.0500   -0.0060
   100        3.7163             nan     0.0500   -0.0055
   120        3.5364             nan     0.0500   -0.0051
   140        3.4110             nan     0.0500   -0.0144
   160        3.2976             nan     0.0500   -0.0170
   180        3.1940             nan     0.0500   -0.0113
   200        3.1083             nan     0.0500   -0.0121

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2398             nan     0.0500    0.1795
     2        7.0362             nan     0.0500    0.1476
     3        6.8558             nan     0.0500    0.1464
     4        6.6729             nan     0.0500    0.1327
     5        6.5266             nan     0.0500    0.1006
     6        6.3818             nan     0.0500    0.1055
     7        6.2487             nan     0.0500    0.0677
     8        6.0999             nan     0.0500    0.1028
     9        5.9965             nan     0.0500    0.1059
    10        5.8755             nan     0.0500    0.1096
    20        5.0579             nan     0.0500    0.0078
    40        4.2088             nan     0.0500    0.0059
    60        3.7499             nan     0.0500   -0.0057
    80        3.4308             nan     0.0500   -0.0020
   100        3.1634             nan     0.0500   -0.0119
   120        2.9533             nan     0.0500   -0.0129
   140        2.7960             nan     0.0500   -0.0200
   160        2.6346             nan     0.0500   -0.0044
   180        2.4961             nan     0.0500   -0.0053
   200        2.3694             nan     0.0500   -0.0072

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1877             nan     0.1000    0.2482
     2        7.0084             nan     0.1000    0.1678
     3        6.8201             nan     0.1000    0.1650
     4        6.6568             nan     0.1000    0.1286
     5        6.5560             nan     0.1000    0.0988
     6        6.4683             nan     0.1000    0.0670
     7        6.3407             nan     0.1000    0.0947
     8        6.2399             nan     0.1000    0.0901
     9        6.1955             nan     0.1000    0.0185
    10        6.1081             nan     0.1000    0.0703
    20        5.6240             nan     0.1000   -0.0089
    40        5.0244             nan     0.1000    0.0202
    60        4.6640             nan     0.1000   -0.0039
    80        4.4675             nan     0.1000   -0.0114
   100        4.3692             nan     0.1000   -0.0235
   120        4.2737             nan     0.1000   -0.0091
   140        4.1937             nan     0.1000   -0.0050
   160        4.1638             nan     0.1000   -0.0140
   180        4.1338             nan     0.1000   -0.0194
   200        4.0916             nan     0.1000   -0.0152

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2290             nan     0.1000    0.2447
     2        6.9574             nan     0.1000    0.2359
     3        6.7693             nan     0.1000    0.1975
     4        6.5405             nan     0.1000    0.1274
     5        6.4086             nan     0.1000    0.0872
     6        6.2397             nan     0.1000    0.1496
     7        6.1207             nan     0.1000    0.0672
     8        5.9996             nan     0.1000    0.1105
     9        5.8668             nan     0.1000    0.1039
    10        5.7624             nan     0.1000    0.0545
    20        5.0556             nan     0.1000    0.0255
    40        4.4400             nan     0.1000   -0.0155
    60        4.1141             nan     0.1000   -0.0385
    80        3.9132             nan     0.1000   -0.0385
   100        3.7186             nan     0.1000   -0.0055
   120        3.5929             nan     0.1000   -0.0199
   140        3.4324             nan     0.1000   -0.0217
   160        3.3337             nan     0.1000   -0.0361
   180        3.2742             nan     0.1000   -0.0210
   200        3.1954             nan     0.1000   -0.0138

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1244             nan     0.1000    0.2536
     2        6.7664             nan     0.1000    0.2706
     3        6.5145             nan     0.1000    0.1559
     4        6.2833             nan     0.1000    0.1755
     5        6.1226             nan     0.1000    0.1074
     6        5.9986             nan     0.1000    0.0543
     7        5.8399             nan     0.1000    0.0625
     8        5.7002             nan     0.1000    0.0878
     9        5.5657             nan     0.1000    0.0749
    10        5.4348             nan     0.1000    0.0643
    20        4.6946             nan     0.1000    0.0269
    40        4.0293             nan     0.1000   -0.0225
    60        3.6432             nan     0.1000   -0.0215
    80        3.3868             nan     0.1000   -0.0193
   100        3.1387             nan     0.1000   -0.0223
   120        2.9540             nan     0.1000   -0.0166
   140        2.8237             nan     0.1000   -0.0275
   160        2.7340             nan     0.1000   -0.0168
   180        2.6210             nan     0.1000   -0.0323
   200        2.5273             nan     0.1000   -0.0257

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0754             nan     0.1000    0.2979
     2        6.7173             nan     0.1000    0.1987
     3        6.4521             nan     0.1000    0.1755
     4        6.1908             nan     0.1000    0.1986
     5        5.9252             nan     0.1000    0.1932
     6        5.7686             nan     0.1000    0.0974
     7        5.5688             nan     0.1000    0.1146
     8        5.3938             nan     0.1000    0.0640
     9        5.2586             nan     0.1000    0.0393
    10        5.1044             nan     0.1000    0.1033
    20        4.3076             nan     0.1000    0.0104
    40        3.5554             nan     0.1000    0.0012
    60        3.0821             nan     0.1000   -0.0338
    80        2.7480             nan     0.1000   -0.0484
   100        2.4750             nan     0.1000   -0.0071
   120        2.2383             nan     0.1000   -0.0073
   140        2.0201             nan     0.1000   -0.0053
   160        1.8357             nan     0.1000   -0.0116
   180        1.6744             nan     0.1000   -0.0134
   200        1.5509             nan     0.1000   -0.0104

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0213             nan     0.2000    0.3804
     2        6.8926             nan     0.2000   -0.0692
     3        6.5782             nan     0.2000    0.2540
     4        6.2760             nan     0.2000    0.2684
     5        6.1364             nan     0.2000    0.0506
     6        6.0106             nan     0.2000    0.1394
     7        5.8902             nan     0.2000    0.0983
     8        5.7178             nan     0.2000    0.1261
     9        5.6336             nan     0.2000    0.0441
    10        5.5382             nan     0.2000    0.0074
    20        4.9195             nan     0.2000    0.0262
    40        4.4748             nan     0.2000    0.0003
    60        4.2738             nan     0.2000   -0.0281
    80        4.1981             nan     0.2000   -0.0253
   100        4.0894             nan     0.2000   -0.0431
   120        4.0906             nan     0.2000   -0.0132
   140        4.0533             nan     0.2000   -0.0316
   160        4.0317             nan     0.2000   -0.0307
   180        4.0413             nan     0.2000   -0.0513
   200        4.0137             nan     0.2000   -0.0615

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8427             nan     0.2000    0.6141
     2        6.4440             nan     0.2000    0.3694
     3        6.1627             nan     0.2000    0.1495
     4        5.9098             nan     0.2000    0.0472
     5        5.7231             nan     0.2000    0.0984
     6        5.5198             nan     0.2000    0.2050
     7        5.4065             nan     0.2000    0.0975
     8        5.2827             nan     0.2000    0.0320
     9        5.1690             nan     0.2000    0.0359
    10        5.0582             nan     0.2000    0.0452
    20        4.4800             nan     0.2000   -0.0671
    40        3.9195             nan     0.2000   -0.0610
    60        3.6621             nan     0.2000   -0.0838
    80        3.4327             nan     0.2000   -0.0388
   100        3.2748             nan     0.2000   -0.0583
   120        3.0812             nan     0.2000   -0.0421
   140        2.9502             nan     0.2000   -0.0270
   160        2.8042             nan     0.2000   -0.0315
   180        2.6477             nan     0.2000   -0.0510
   200        2.5351             nan     0.2000   -0.0291

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7993             nan     0.2000    0.5562
     2        6.3623             nan     0.2000    0.3813
     3        6.0482             nan     0.2000    0.2386
     4        5.7184             nan     0.2000    0.2399
     5        5.4763             nan     0.2000    0.1884
     6        5.3005             nan     0.2000    0.2105
     7        5.1132             nan     0.2000    0.0829
     8        5.0052             nan     0.2000    0.0076
     9        4.8618             nan     0.2000    0.0692
    10        4.8121             nan     0.2000   -0.0377
    20        4.0809             nan     0.2000   -0.0492
    40        3.4212             nan     0.2000   -0.0631
    60        3.0681             nan     0.2000   -0.0377
    80        2.7457             nan     0.2000   -0.0911
   100        2.4792             nan     0.2000   -0.0489
   120        2.3200             nan     0.2000   -0.0044
   140        2.0572             nan     0.2000   -0.0389
   160        1.9022             nan     0.2000   -0.0285
   180        1.7562             nan     0.2000   -0.0142
   200        1.6405             nan     0.2000   -0.0091

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6895             nan     0.2000    0.5522
     2        6.2110             nan     0.2000    0.2861
     3        5.8858             nan     0.2000    0.2032
     4        5.5415             nan     0.2000    0.2552
     5        5.2180             nan     0.2000    0.0734
     6        5.0043             nan     0.2000    0.1465
     7        4.7482             nan     0.2000    0.1153
     8        4.6389             nan     0.2000   -0.0594
     9        4.4833             nan     0.2000    0.0087
    10        4.3313             nan     0.2000    0.0375
    20        3.5796             nan     0.2000   -0.0624
    40        2.8787             nan     0.2000   -0.0806
    60        2.3038             nan     0.2000   -0.0569
    80        1.9451             nan     0.2000   -0.0492
   100        1.6416             nan     0.2000   -0.0527
   120        1.3761             nan     0.2000   -0.0273
   140        1.1274             nan     0.2000   -0.0111
   160        0.9851             nan     0.2000   -0.0196
   180        0.8463             nan     0.2000   -0.0248
   200        0.7554             nan     0.2000   -0.0193

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2165             nan     0.0500    0.0994
     2        7.0889             nan     0.0500    0.0970
     3        7.0008             nan     0.0500    0.0918
     4        6.9217             nan     0.0500    0.0728
     5        6.8639             nan     0.0500    0.0531
     6        6.8035             nan     0.0500    0.0393
     7        6.7175             nan     0.0500    0.0709
     8        6.6659             nan     0.0500    0.0408
     9        6.6263             nan     0.0500    0.0140
    10        6.5619             nan     0.0500    0.0517
    20        6.1292             nan     0.0500    0.0334
    40        5.5802             nan     0.0500    0.0072
    60        5.2612             nan     0.0500   -0.0075
    80        5.0155             nan     0.0500    0.0103
   100        4.8391             nan     0.0500   -0.0004
   120        4.6909             nan     0.0500   -0.0005
   140        4.5747             nan     0.0500   -0.0038
   160        4.4940             nan     0.0500   -0.0072
   180        4.4304             nan     0.0500   -0.0058
   200        4.3798             nan     0.0500   -0.0058

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2060             nan     0.0500    0.0926
     2        7.0982             nan     0.0500    0.0706
     3        6.9903             nan     0.0500    0.1055
     4        6.8910             nan     0.0500    0.1007
     5        6.7732             nan     0.0500    0.0683
     6        6.6675             nan     0.0500    0.0870
     7        6.5885             nan     0.0500    0.0848
     8        6.4956             nan     0.0500    0.0811
     9        6.4383             nan     0.0500    0.0232
    10        6.3527             nan     0.0500    0.0671
    20        5.7848             nan     0.0500    0.0005
    40        5.0635             nan     0.0500    0.0112
    60        4.6680             nan     0.0500   -0.0006
    80        4.4081             nan     0.0500    0.0052
   100        4.1918             nan     0.0500   -0.0066
   120        4.0545             nan     0.0500   -0.0075
   140        3.9227             nan     0.0500   -0.0057
   160        3.8286             nan     0.0500   -0.0093
   180        3.7494             nan     0.0500   -0.0016
   200        3.6971             nan     0.0500   -0.0049

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1511             nan     0.0500    0.1339
     2        7.0180             nan     0.0500    0.1176
     3        6.8959             nan     0.0500    0.1141
     4        6.7717             nan     0.0500    0.0905
     5        6.6627             nan     0.0500    0.0840
     6        6.5404             nan     0.0500    0.1044
     7        6.4288             nan     0.0500    0.0960
     8        6.3287             nan     0.0500    0.0797
     9        6.2398             nan     0.0500    0.0627
    10        6.1446             nan     0.0500    0.0558
    20        5.4939             nan     0.0500    0.0350
    40        4.7377             nan     0.0500    0.0150
    60        4.3080             nan     0.0500    0.0011
    80        4.0444             nan     0.0500   -0.0056
   100        3.8214             nan     0.0500   -0.0051
   120        3.6457             nan     0.0500   -0.0007
   140        3.5239             nan     0.0500   -0.0026
   160        3.3997             nan     0.0500   -0.0072
   180        3.3128             nan     0.0500   -0.0102
   200        3.2354             nan     0.0500   -0.0160

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1406             nan     0.0500    0.1316
     2        6.9643             nan     0.0500    0.1198
     3        6.8115             nan     0.0500    0.1279
     4        6.6777             nan     0.0500    0.0987
     5        6.5311             nan     0.0500    0.1143
     6        6.3791             nan     0.0500    0.0649
     7        6.2429             nan     0.0500    0.0853
     8        6.1364             nan     0.0500    0.0343
     9        6.0283             nan     0.0500    0.0662
    10        5.9307             nan     0.0500    0.0703
    20        5.0653             nan     0.0500    0.0250
    40        4.1439             nan     0.0500   -0.0169
    60        3.6781             nan     0.0500   -0.0000
    80        3.4127             nan     0.0500   -0.0210
   100        3.1877             nan     0.0500   -0.0246
   120        2.9564             nan     0.0500   -0.0159
   140        2.7597             nan     0.0500   -0.0094
   160        2.5957             nan     0.0500   -0.0169
   180        2.4657             nan     0.0500   -0.0107
   200        2.3461             nan     0.0500   -0.0131

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0868             nan     0.1000    0.1568
     2        6.9468             nan     0.1000    0.1521
     3        6.7968             nan     0.1000    0.1482
     4        6.6407             nan     0.1000    0.1182
     5        6.5180             nan     0.1000    0.1029
     6        6.3943             nan     0.1000    0.0984
     7        6.3074             nan     0.1000    0.0760
     8        6.2533             nan     0.1000    0.0322
     9        6.1682             nan     0.1000    0.0371
    10        6.0974             nan     0.1000    0.0258
    20        5.5921             nan     0.1000    0.0272
    40        5.0538             nan     0.1000   -0.0160
    60        4.7371             nan     0.1000   -0.0026
    80        4.5278             nan     0.1000    0.0074
   100        4.3846             nan     0.1000   -0.0085
   120        4.3340             nan     0.1000   -0.0213
   140        4.2707             nan     0.1000   -0.0223
   160        4.2143             nan     0.1000   -0.0175
   180        4.1750             nan     0.1000   -0.0286
   200        4.1344             nan     0.1000   -0.0087

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0393             nan     0.1000    0.2885
     2        6.8341             nan     0.1000    0.1677
     3        6.6297             nan     0.1000    0.2089
     4        6.5109             nan     0.1000    0.0917
     5        6.3139             nan     0.1000    0.0950
     6        6.2030             nan     0.1000    0.0571
     7        6.0709             nan     0.1000    0.0696
     8        5.9866             nan     0.1000    0.0687
     9        5.8698             nan     0.1000    0.0962
    10        5.8113             nan     0.1000    0.0149
    20        5.1295             nan     0.1000   -0.0121
    40        4.4331             nan     0.1000    0.0079
    60        4.1148             nan     0.1000   -0.0095
    80        3.8959             nan     0.1000   -0.0319
   100        3.7799             nan     0.1000   -0.0473
   120        3.6593             nan     0.1000   -0.0328
   140        3.5294             nan     0.1000   -0.0378
   160        3.4202             nan     0.1000   -0.0263
   180        3.3043             nan     0.1000   -0.0182
   200        3.2314             nan     0.1000   -0.0208

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9927             nan     0.1000    0.2697
     2        6.7523             nan     0.1000    0.2325
     3        6.5040             nan     0.1000    0.1957
     4        6.2527             nan     0.1000    0.1668
     5        6.1034             nan     0.1000    0.1138
     6        5.9258             nan     0.1000    0.0963
     7        5.7737             nan     0.1000    0.1444
     8        5.6441             nan     0.1000    0.0749
     9        5.5345             nan     0.1000   -0.0170
    10        5.4276             nan     0.1000    0.0176
    20        4.8019             nan     0.1000    0.0459
    40        4.0887             nan     0.1000   -0.0196
    60        3.7435             nan     0.1000   -0.0381
    80        3.4506             nan     0.1000   -0.0151
   100        3.2700             nan     0.1000   -0.0321
   120        3.0452             nan     0.1000   -0.0011
   140        2.8642             nan     0.1000   -0.0183
   160        2.7297             nan     0.1000   -0.0153
   180        2.6283             nan     0.1000   -0.0329
   200        2.5014             nan     0.1000   -0.0189

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9880             nan     0.1000    0.2785
     2        6.6460             nan     0.1000    0.2349
     3        6.3349             nan     0.1000    0.2180
     4        6.1116             nan     0.1000    0.1616
     5        5.8450             nan     0.1000    0.1593
     6        5.6365             nan     0.1000    0.1569
     7        5.4342             nan     0.1000    0.1093
     8        5.3282             nan     0.1000    0.0340
     9        5.1809             nan     0.1000    0.0887
    10        5.0434             nan     0.1000    0.0554
    20        4.2139             nan     0.1000   -0.0057
    40        3.5363             nan     0.1000   -0.0250
    60        3.0559             nan     0.1000   -0.0268
    80        2.6835             nan     0.1000   -0.0265
   100        2.4258             nan     0.1000   -0.0331
   120        2.1830             nan     0.1000   -0.0344
   140        1.9654             nan     0.1000   -0.0022
   160        1.8251             nan     0.1000   -0.0203
   180        1.6654             nan     0.1000   -0.0274
   200        1.5516             nan     0.1000   -0.0125

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9248             nan     0.2000    0.2771
     2        6.6383             nan     0.2000    0.2860
     3        6.3944             nan     0.2000    0.1971
     4        6.2860             nan     0.2000    0.0562
     5        6.0844             nan     0.2000    0.1713
     6        5.9611             nan     0.2000    0.0590
     7        5.8763             nan     0.2000    0.0803
     8        5.7943             nan     0.2000    0.0710
     9        5.7222             nan     0.2000    0.0370
    10        5.6355             nan     0.2000    0.0383
    20        5.0558             nan     0.2000   -0.0532
    40        4.6051             nan     0.2000   -0.0047
    60        4.4091             nan     0.2000   -0.0638
    80        4.2545             nan     0.2000   -0.0116
   100        4.2032             nan     0.2000   -0.0626
   120        4.1353             nan     0.2000   -0.0183
   140        4.1119             nan     0.2000   -0.0211
   160        4.1054             nan     0.2000   -0.0404
   180        4.0623             nan     0.2000   -0.0211
   200        4.0563             nan     0.2000   -0.0426

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8029             nan     0.2000    0.4514
     2        6.4103             nan     0.2000    0.3251
     3        6.1318             nan     0.2000    0.1748
     4        5.9374             nan     0.2000    0.1441
     5        5.7392             nan     0.2000    0.2081
     6        5.5835             nan     0.2000    0.0019
     7        5.4464             nan     0.2000    0.0320
     8        5.2946             nan     0.2000    0.0735
     9        5.1416             nan     0.2000    0.0774
    10        5.0952             nan     0.2000   -0.0400
    20        4.4261             nan     0.2000   -0.0533
    40        3.9302             nan     0.2000   -0.0318
    60        3.5946             nan     0.2000   -0.0151
    80        3.4752             nan     0.2000   -0.0323
   100        3.3568             nan     0.2000   -0.0541
   120        3.1938             nan     0.2000   -0.0380
   140        3.0484             nan     0.2000   -0.0414
   160        2.9682             nan     0.2000   -0.0652
   180        2.8273             nan     0.2000   -0.0067
   200        2.7228             nan     0.2000   -0.0341

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6823             nan     0.2000    0.4686
     2        6.2844             nan     0.2000    0.2195
     3        5.9907             nan     0.2000    0.2058
     4        5.6993             nan     0.2000    0.1758
     5        5.4936             nan     0.2000    0.1264
     6        5.3124             nan     0.2000    0.0892
     7        5.1991             nan     0.2000    0.0075
     8        5.0837             nan     0.2000   -0.0130
     9        4.9307             nan     0.2000    0.0877
    10        4.7982             nan     0.2000    0.0224
    20        4.2139             nan     0.2000   -0.0498
    40        3.6702             nan     0.2000   -0.0435
    60        3.2528             nan     0.2000   -0.0509
    80        2.9840             nan     0.2000   -0.0530
   100        2.6501             nan     0.2000   -0.0401
   120        2.4453             nan     0.2000   -0.0279
   140        2.2181             nan     0.2000   -0.0301
   160        2.0709             nan     0.2000   -0.0378
   180        1.8999             nan     0.2000   -0.0257
   200        1.7826             nan     0.2000   -0.0283

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6185             nan     0.2000    0.5537
     2        6.0825             nan     0.2000    0.3738
     3        5.7259             nan     0.2000    0.3207
     4        5.4314             nan     0.2000    0.1850
     5        5.1339             nan     0.2000    0.1866
     6        4.8962             nan     0.2000    0.0156
     7        4.7440             nan     0.2000    0.0427
     8        4.6194             nan     0.2000    0.0360
     9        4.5180             nan     0.2000   -0.0504
    10        4.3656             nan     0.2000   -0.0003
    20        3.4719             nan     0.2000   -0.1042
    40        2.7868             nan     0.2000   -0.0719
    60        2.2914             nan     0.2000   -0.0407
    80        1.8421             nan     0.2000   -0.0415
   100        1.5554             nan     0.2000   -0.0382
   120        1.3380             nan     0.2000   -0.0348
   140        1.1323             nan     0.2000   -0.0231
   160        0.9680             nan     0.2000   -0.0383
   180        0.8275             nan     0.2000   -0.0264
   200        0.7264             nan     0.2000   -0.0238

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1159             nan     0.0500    0.0747
     2        7.0054             nan     0.0500    0.0888
     3        6.8979             nan     0.0500    0.0957
     4        6.7985             nan     0.0500    0.0777
     5        6.7186             nan     0.0500    0.0502
     6        6.6480             nan     0.0500    0.0585
     7        6.5820             nan     0.0500    0.0636
     8        6.5236             nan     0.0500    0.0273
     9        6.4692             nan     0.0500    0.0463
    10        6.4189             nan     0.0500    0.0449
    20        6.0105             nan     0.0500    0.0078
    40        5.5610             nan     0.0500    0.0105
    60        5.2651             nan     0.0500    0.0042
    80        5.0227             nan     0.0500    0.0031
   100        4.8322             nan     0.0500    0.0005
   120        4.6883             nan     0.0500   -0.0042
   140        4.5806             nan     0.0500   -0.0047
   160        4.4943             nan     0.0500   -0.0043
   180        4.4291             nan     0.0500   -0.0029
   200        4.3745             nan     0.0500   -0.0112

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0648             nan     0.0500    0.1479
     2        6.9477             nan     0.0500    0.0996
     3        6.8338             nan     0.0500    0.1186
     4        6.7381             nan     0.0500    0.0952
     5        6.6329             nan     0.0500    0.0964
     6        6.5387             nan     0.0500    0.0504
     7        6.4295             nan     0.0500    0.0729
     8        6.3434             nan     0.0500    0.0602
     9        6.2962             nan     0.0500    0.0170
    10        6.2140             nan     0.0500    0.0632
    20        5.6888             nan     0.0500    0.0254
    40        5.0494             nan     0.0500    0.0122
    60        4.7083             nan     0.0500   -0.0127
    80        4.4529             nan     0.0500   -0.0084
   100        4.2505             nan     0.0500   -0.0185
   120        4.1189             nan     0.0500   -0.0101
   140        3.9955             nan     0.0500   -0.0167
   160        3.8852             nan     0.0500   -0.0175
   180        3.7981             nan     0.0500   -0.0023
   200        3.7249             nan     0.0500   -0.0039

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0182             nan     0.0500    0.1655
     2        6.8506             nan     0.0500    0.1216
     3        6.7848             nan     0.0500    0.0240
     4        6.6572             nan     0.0500    0.0984
     5        6.5146             nan     0.0500    0.0793
     6        6.3898             nan     0.0500    0.0883
     7        6.2892             nan     0.0500    0.1079
     8        6.1936             nan     0.0500    0.0652
     9        6.1092             nan     0.0500    0.0477
    10        6.0134             nan     0.0500    0.0573
    20        5.4214             nan     0.0500    0.0443
    40        4.7139             nan     0.0500    0.0052
    60        4.2857             nan     0.0500    0.0004
    80        3.9991             nan     0.0500   -0.0033
   100        3.7962             nan     0.0500    0.0005
   120        3.6094             nan     0.0500   -0.0119
   140        3.4827             nan     0.0500   -0.0198
   160        3.3441             nan     0.0500   -0.0153
   180        3.2391             nan     0.0500   -0.0095
   200        3.1461             nan     0.0500   -0.0031

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0203             nan     0.0500    0.1508
     2        6.8289             nan     0.0500    0.1853
     3        6.6737             nan     0.0500    0.1244
     4        6.5155             nan     0.0500    0.1158
     5        6.3721             nan     0.0500    0.0946
     6        6.2363             nan     0.0500    0.0675
     7        6.1193             nan     0.0500    0.0873
     8        6.0219             nan     0.0500    0.0657
     9        5.8892             nan     0.0500    0.0858
    10        5.7916             nan     0.0500    0.0629
    20        5.1219             nan     0.0500   -0.0267
    40        4.2443             nan     0.0500    0.0038
    60        3.8140             nan     0.0500    0.0041
    80        3.4941             nan     0.0500   -0.0113
   100        3.2189             nan     0.0500   -0.0147
   120        3.0235             nan     0.0500   -0.0236
   140        2.8605             nan     0.0500   -0.0151
   160        2.7252             nan     0.0500   -0.0215
   180        2.5693             nan     0.0500   -0.0171
   200        2.4298             nan     0.0500   -0.0114

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0010             nan     0.1000    0.1680
     2        6.8422             nan     0.1000    0.1470
     3        6.6606             nan     0.1000    0.1180
     4        6.5363             nan     0.1000    0.1043
     5        6.4167             nan     0.1000    0.1084
     6        6.3487             nan     0.1000    0.0383
     7        6.2954             nan     0.1000    0.0187
     8        6.1890             nan     0.1000    0.0524
     9        6.1194             nan     0.1000    0.0458
    10        6.0767             nan     0.1000   -0.0086
    20        5.5850             nan     0.1000    0.0252
    40        4.9714             nan     0.1000   -0.0133
    60        4.6684             nan     0.1000    0.0036
    80        4.4750             nan     0.1000   -0.0158
   100        4.3357             nan     0.1000   -0.0088
   120        4.2606             nan     0.1000   -0.0182
   140        4.2128             nan     0.1000   -0.0221
   160        4.1624             nan     0.1000   -0.0356
   180        4.1443             nan     0.1000   -0.0125
   200        4.1112             nan     0.1000   -0.0103

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9213             nan     0.1000    0.2383
     2        6.6961             nan     0.1000    0.1356
     3        6.5026             nan     0.1000    0.1825
     4        6.3256             nan     0.1000    0.1585
     5        6.2086             nan     0.1000    0.0957
     6        6.0854             nan     0.1000    0.1033
     7        5.9700             nan     0.1000    0.0127
     8        5.8802             nan     0.1000    0.0599
     9        5.7607             nan     0.1000    0.0550
    10        5.6599             nan     0.1000    0.0653
    20        5.0481             nan     0.1000    0.0344
    40        4.4835             nan     0.1000    0.0215
    60        4.1638             nan     0.1000    0.0035
    80        3.9232             nan     0.1000   -0.0135
   100        3.7744             nan     0.1000   -0.0206
   120        3.6518             nan     0.1000   -0.0124
   140        3.5421             nan     0.1000   -0.0260
   160        3.4504             nan     0.1000   -0.0140
   180        3.3590             nan     0.1000   -0.0183
   200        3.2775             nan     0.1000   -0.0226

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9143             nan     0.1000    0.2448
     2        6.6967             nan     0.1000    0.1658
     3        6.4563             nan     0.1000    0.1450
     4        6.2128             nan     0.1000    0.1527
     5        6.0499             nan     0.1000    0.0777
     6        5.8894             nan     0.1000    0.1372
     7        5.7576             nan     0.1000    0.0911
     8        5.6167             nan     0.1000    0.0926
     9        5.5144             nan     0.1000    0.0692
    10        5.4351             nan     0.1000    0.0551
    20        4.7316             nan     0.1000   -0.0074
    40        4.0072             nan     0.1000   -0.0102
    60        3.6374             nan     0.1000   -0.0206
    80        3.3885             nan     0.1000   -0.0240
   100        3.2397             nan     0.1000   -0.0193
   120        3.0597             nan     0.1000   -0.0149
   140        2.8990             nan     0.1000   -0.0269
   160        2.7743             nan     0.1000   -0.0142
   180        2.6374             nan     0.1000   -0.0129
   200        2.5323             nan     0.1000   -0.0443

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8597             nan     0.1000    0.2528
     2        6.5397             nan     0.1000    0.2535
     3        6.2511             nan     0.1000    0.2386
     4        5.9937             nan     0.1000    0.1818
     5        5.8054             nan     0.1000    0.1320
     6        5.6529             nan     0.1000    0.0540
     7        5.4924             nan     0.1000    0.1231
     8        5.3338             nan     0.1000    0.1276
     9        5.2062             nan     0.1000    0.0622
    10        5.0882             nan     0.1000    0.0612
    20        4.2883             nan     0.1000    0.0007
    40        3.5539             nan     0.1000   -0.0328
    60        3.0982             nan     0.1000   -0.0180
    80        2.7353             nan     0.1000   -0.0108
   100        2.4985             nan     0.1000   -0.0290
   120        2.2677             nan     0.1000   -0.0142
   140        2.0356             nan     0.1000   -0.0185
   160        1.8671             nan     0.1000   -0.0249
   180        1.7277             nan     0.1000   -0.0114
   200        1.5751             nan     0.1000   -0.0090

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8552             nan     0.2000    0.2848
     2        6.5029             nan     0.2000    0.3026
     3        6.3395             nan     0.2000    0.1372
     4        6.1590             nan     0.2000    0.1798
     5        6.0091             nan     0.2000    0.1340
     6        5.9119             nan     0.2000    0.0231
     7        5.8315             nan     0.2000    0.0463
     8        5.7828             nan     0.2000   -0.0053
     9        5.7294             nan     0.2000    0.0115
    10        5.6523             nan     0.2000    0.0421
    20        5.0692             nan     0.2000   -0.0186
    40        4.4921             nan     0.2000   -0.0310
    60        4.3078             nan     0.2000   -0.0308
    80        4.2462             nan     0.2000   -0.0354
   100        4.1521             nan     0.2000   -0.0601
   120        4.1237             nan     0.2000   -0.0486
   140        4.1053             nan     0.2000   -0.0454
   160        4.0866             nan     0.2000   -0.0248
   180        4.0713             nan     0.2000   -0.0226
   200        4.0426             nan     0.2000   -0.0204

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7754             nan     0.2000    0.2415
     2        6.4717             nan     0.2000    0.2987
     3        6.1716             nan     0.2000    0.1525
     4        5.9402             nan     0.2000    0.1132
     5        5.7492             nan     0.2000    0.1285
     6        5.6053             nan     0.2000    0.0739
     7        5.4959             nan     0.2000    0.0556
     8        5.3843             nan     0.2000    0.0361
     9        5.2601             nan     0.2000    0.0673
    10        5.1339             nan     0.2000    0.0674
    20        4.4964             nan     0.2000   -0.0376
    40        4.0201             nan     0.2000   -0.0410
    60        3.7514             nan     0.2000   -0.0518
    80        3.5708             nan     0.2000   -0.0372
   100        3.3901             nan     0.2000   -0.0259
   120        3.2195             nan     0.2000   -0.0453
   140        3.0400             nan     0.2000   -0.0320
   160        2.9088             nan     0.2000   -0.0224
   180        2.7930             nan     0.2000   -0.0242
   200        2.6307             nan     0.2000   -0.0489

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7195             nan     0.2000    0.3657
     2        6.2138             nan     0.2000    0.4080
     3        5.9397             nan     0.2000    0.2785
     4        5.6745             nan     0.2000    0.1583
     5        5.4864             nan     0.2000    0.0432
     6        5.3272             nan     0.2000    0.0514
     7        5.1654             nan     0.2000    0.0685
     8        5.0291             nan     0.2000   -0.0995
     9        4.8786             nan     0.2000    0.0802
    10        4.7263             nan     0.2000    0.0681
    20        4.0987             nan     0.2000   -0.0119
    40        3.5707             nan     0.2000   -0.0751
    60        3.1917             nan     0.2000   -0.0327
    80        2.9314             nan     0.2000   -0.0430
   100        2.7639             nan     0.2000   -0.0211
   120        2.4514             nan     0.2000   -0.0180
   140        2.3038             nan     0.2000   -0.0291
   160        2.0887             nan     0.2000   -0.0143
   180        1.9389             nan     0.2000   -0.0131
   200        1.7942             nan     0.2000   -0.0282

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5608             nan     0.2000    0.3953
     2        6.3061             nan     0.2000    0.0415
     3        5.7390             nan     0.2000    0.2111
     4        5.4445             nan     0.2000    0.1974
     5        5.1297             nan     0.2000    0.1378
     6        4.9162             nan     0.2000   -0.1025
     7        4.7370             nan     0.2000    0.0891
     8        4.6232             nan     0.2000   -0.0672
     9        4.4916             nan     0.2000   -0.0160
    10        4.3982             nan     0.2000    0.0353
    20        3.6949             nan     0.2000   -0.0378
    40        3.0106             nan     0.2000   -0.0876
    60        2.5090             nan     0.2000   -0.0780
    80        2.1031             nan     0.2000   -0.0439
   100        1.7701             nan     0.2000   -0.0489
   120        1.4804             nan     0.2000   -0.0283
   140        1.2841             nan     0.2000   -0.0462
   160        1.1174             nan     0.2000   -0.0244
   180        0.9817             nan     0.2000   -0.0247
   200        0.8511             nan     0.2000   -0.0190

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2336             nan     0.0500    0.0861
     2        7.1171             nan     0.0500    0.1025
     3        7.0197             nan     0.0500    0.1066
     4        6.9186             nan     0.0500    0.0976
     5        6.8285             nan     0.0500    0.0620
     6        6.7571             nan     0.0500    0.0625
     7        6.6789             nan     0.0500    0.0586
     8        6.6251             nan     0.0500    0.0632
     9        6.5905             nan     0.0500    0.0049
    10        6.5277             nan     0.0500    0.0297
    20        6.0689             nan     0.0500    0.0120
    40        5.5178             nan     0.0500    0.0052
    60        5.2114             nan     0.0500    0.0050
    80        4.9887             nan     0.0500   -0.0038
   100        4.8405             nan     0.0500    0.0082
   120        4.7003             nan     0.0500   -0.0033
   140        4.5774             nan     0.0500   -0.0099
   160        4.4812             nan     0.0500   -0.0016
   180        4.4027             nan     0.0500   -0.0062
   200        4.3495             nan     0.0500   -0.0073

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1865             nan     0.0500    0.1280
     2        7.0538             nan     0.0500    0.1091
     3        6.9464             nan     0.0500    0.0591
     4        6.8602             nan     0.0500    0.0619
     5        6.7552             nan     0.0500    0.0854
     6        6.6571             nan     0.0500    0.0702
     7        6.5618             nan     0.0500    0.0792
     8        6.4402             nan     0.0500    0.0948
     9        6.3554             nan     0.0500    0.0624
    10        6.2603             nan     0.0500    0.0591
    20        5.6751             nan     0.0500    0.0421
    40        5.0167             nan     0.0500    0.0004
    60        4.6614             nan     0.0500   -0.0118
    80        4.4172             nan     0.0500   -0.0195
   100        4.1874             nan     0.0500   -0.0062
   120        4.0591             nan     0.0500   -0.0084
   140        3.9309             nan     0.0500   -0.0047
   160        3.8303             nan     0.0500   -0.0056
   180        3.7568             nan     0.0500   -0.0165
   200        3.6645             nan     0.0500   -0.0134

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1798             nan     0.0500    0.1549
     2        7.0283             nan     0.0500    0.1201
     3        6.8813             nan     0.0500    0.1455
     4        6.7362             nan     0.0500    0.1123
     5        6.6663             nan     0.0500    0.0084
     6        6.5549             nan     0.0500    0.0635
     7        6.4283             nan     0.0500    0.0756
     8        6.3228             nan     0.0500    0.0838
     9        6.2297             nan     0.0500    0.0537
    10        6.1150             nan     0.0500    0.0885
    20        5.5003             nan     0.0500    0.0433
    40        4.6917             nan     0.0500    0.0198
    60        4.2920             nan     0.0500   -0.0036
    80        3.9928             nan     0.0500   -0.0005
   100        3.7774             nan     0.0500   -0.0039
   120        3.6242             nan     0.0500   -0.0059
   140        3.5220             nan     0.0500   -0.0148
   160        3.3786             nan     0.0500   -0.0119
   180        3.2828             nan     0.0500   -0.0041
   200        3.1956             nan     0.0500   -0.0150

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1502             nan     0.0500    0.1542
     2        7.0080             nan     0.0500    0.0753
     3        6.8583             nan     0.0500    0.1326
     4        6.6983             nan     0.0500    0.1415
     5        6.5319             nan     0.0500    0.0934
     6        6.3874             nan     0.0500    0.1049
     7        6.2746             nan     0.0500    0.0769
     8        6.1633             nan     0.0500    0.0869
     9        6.0319             nan     0.0500    0.0850
    10        5.9320             nan     0.0500    0.0880
    20        5.1473             nan     0.0500    0.0408
    40        4.3192             nan     0.0500   -0.0164
    60        3.8416             nan     0.0500   -0.0006
    80        3.5015             nan     0.0500   -0.0157
   100        3.2741             nan     0.0500   -0.0177
   120        3.0434             nan     0.0500   -0.0236
   140        2.8712             nan     0.0500   -0.0068
   160        2.7123             nan     0.0500   -0.0167
   180        2.5595             nan     0.0500   -0.0117
   200        2.4117             nan     0.0500   -0.0098

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0829             nan     0.1000    0.2149
     2        6.9284             nan     0.1000    0.1755
     3        6.7866             nan     0.1000    0.1074
     4        6.6474             nan     0.1000    0.1297
     5        6.5872             nan     0.1000    0.0114
     6        6.4658             nan     0.1000    0.1202
     7        6.3856             nan     0.1000    0.0123
     8        6.2941             nan     0.1000    0.1025
     9        6.1994             nan     0.1000    0.0950
    10        6.1022             nan     0.1000    0.0721
    20        5.5628             nan     0.1000    0.0193
    40        5.0000             nan     0.1000   -0.0121
    60        4.7182             nan     0.1000   -0.0162
    80        4.5164             nan     0.1000   -0.0083
   100        4.3928             nan     0.1000   -0.0054
   120        4.3243             nan     0.1000   -0.0329
   140        4.2691             nan     0.1000   -0.0305
   160        4.2101             nan     0.1000   -0.0212
   180        4.1902             nan     0.1000   -0.0202
   200        4.1402             nan     0.1000   -0.0185

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0952             nan     0.1000    0.2766
     2        6.8288             nan     0.1000    0.2184
     3        6.5685             nan     0.1000    0.1307
     4        6.4020             nan     0.1000    0.1335
     5        6.2495             nan     0.1000    0.0978
     6        6.0937             nan     0.1000    0.1536
     7        5.9625             nan     0.1000    0.1219
     8        5.8476             nan     0.1000    0.0722
     9        5.7821             nan     0.1000   -0.0161
    10        5.7353             nan     0.1000    0.0133
    20        5.0670             nan     0.1000    0.0074
    40        4.3973             nan     0.1000   -0.0003
    60        4.0740             nan     0.1000   -0.0111
    80        3.8497             nan     0.1000   -0.0141
   100        3.6979             nan     0.1000   -0.0272
   120        3.5595             nan     0.1000   -0.0120
   140        3.4228             nan     0.1000   -0.0233
   160        3.3476             nan     0.1000   -0.0534
   180        3.2514             nan     0.1000   -0.0225
   200        3.1597             nan     0.1000   -0.0170

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0481             nan     0.1000    0.3104
     2        6.7567             nan     0.1000    0.2272
     3        6.5238             nan     0.1000    0.1983
     4        6.2734             nan     0.1000    0.2105
     5        6.0720             nan     0.1000    0.1177
     6        5.9418             nan     0.1000    0.0185
     7        5.8283             nan     0.1000    0.0156
     8        5.6909             nan     0.1000    0.0999
     9        5.5695             nan     0.1000    0.0273
    10        5.4699             nan     0.1000    0.0512
    20        4.7422             nan     0.1000    0.0093
    40        4.0921             nan     0.1000   -0.0306
    60        3.7566             nan     0.1000   -0.0231
    80        3.5268             nan     0.1000   -0.0134
   100        3.3552             nan     0.1000   -0.0135
   120        3.1606             nan     0.1000   -0.0317
   140        3.0073             nan     0.1000   -0.0260
   160        2.8437             nan     0.1000   -0.0152
   180        2.7198             nan     0.1000   -0.0292
   200        2.5868             nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9439             nan     0.1000    0.3624
     2        6.6512             nan     0.1000    0.2054
     3        6.3527             nan     0.1000    0.1866
     4        6.1653             nan     0.1000    0.1394
     5        5.8863             nan     0.1000    0.1940
     6        5.7286             nan     0.1000    0.1136
     7        5.5662             nan     0.1000    0.0888
     8        5.4033             nan     0.1000    0.0249
     9        5.2264             nan     0.1000    0.1052
    10        5.0774             nan     0.1000    0.0662
    20        4.2728             nan     0.1000   -0.0124
    40        3.5137             nan     0.1000   -0.0355
    60        3.0200             nan     0.1000   -0.0201
    80        2.7416             nan     0.1000   -0.0100
   100        2.4887             nan     0.1000   -0.0360
   120        2.2445             nan     0.1000   -0.0134
   140        2.0331             nan     0.1000   -0.0104
   160        1.8716             nan     0.1000   -0.0267
   180        1.7332             nan     0.1000   -0.0230
   200        1.6320             nan     0.1000   -0.0110

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8760             nan     0.2000    0.4677
     2        6.6120             nan     0.2000    0.2652
     3        6.3948             nan     0.2000    0.2612
     4        6.2009             nan     0.2000    0.1753
     5        6.0806             nan     0.2000    0.0931
     6        6.0145             nan     0.2000   -0.0726
     7        5.8884             nan     0.2000    0.1311
     8        5.7553             nan     0.2000    0.0834
     9        5.6765             nan     0.2000   -0.1078
    10        5.6264             nan     0.2000   -0.0122
    20        5.0321             nan     0.2000    0.0454
    40        4.5435             nan     0.2000    0.0035
    60        4.3553             nan     0.2000    0.0051
    80        4.2715             nan     0.2000   -0.0293
   100        4.1804             nan     0.2000   -0.0329
   120        4.1422             nan     0.2000   -0.0073
   140        4.1302             nan     0.2000   -0.0197
   160        4.0964             nan     0.2000   -0.0170
   180        4.0748             nan     0.2000   -0.0636
   200        4.0479             nan     0.2000   -0.0308

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8292             nan     0.2000    0.4443
     2        6.3996             nan     0.2000    0.3723
     3        6.1037             nan     0.2000    0.2208
     4        5.7999             nan     0.2000    0.2328
     5        5.6073             nan     0.2000    0.0283
     6        5.3863             nan     0.2000    0.0475
     7        5.2487             nan     0.2000    0.0615
     8        5.1376             nan     0.2000   -0.0130
     9        5.0532             nan     0.2000    0.0552
    10        4.9613             nan     0.2000   -0.0005
    20        4.3963             nan     0.2000   -0.0289
    40        3.9025             nan     0.2000   -0.0400
    60        3.6532             nan     0.2000   -0.0430
    80        3.5227             nan     0.2000   -0.0696
   100        3.3990             nan     0.2000   -0.0532
   120        3.2350             nan     0.2000   -0.0303
   140        3.0886             nan     0.2000   -0.0192
   160        2.9548             nan     0.2000   -0.0353
   180        2.8263             nan     0.2000   -0.0276
   200        2.7424             nan     0.2000   -0.0233

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5968             nan     0.2000    0.6248
     2        6.2055             nan     0.2000    0.3185
     3        5.8557             nan     0.2000    0.2423
     4        5.5693             nan     0.2000    0.1260
     5        5.4139             nan     0.2000    0.0003
     6        5.2909             nan     0.2000    0.0236
     7        5.0984             nan     0.2000    0.1016
     8        4.9680             nan     0.2000    0.0331
     9        4.8473             nan     0.2000   -0.0616
    10        4.7266             nan     0.2000    0.0808
    20        3.9736             nan     0.2000    0.0121
    40        3.4733             nan     0.2000   -0.0681
    60        3.0916             nan     0.2000   -0.0488
    80        2.8284             nan     0.2000   -0.0581
   100        2.6213             nan     0.2000   -0.0682
   120        2.4133             nan     0.2000   -0.0423
   140        2.1726             nan     0.2000   -0.0217
   160        2.0274             nan     0.2000   -0.0576
   180        1.8926             nan     0.2000   -0.0363
   200        1.7578             nan     0.2000   -0.0269

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7052             nan     0.2000    0.5473
     2        6.2514             nan     0.2000    0.2325
     3        5.8884             nan     0.2000    0.1406
     4        5.4671             nan     0.2000    0.2000
     5        5.1404             nan     0.2000    0.1792
     6        4.9481             nan     0.2000    0.0728
     7        4.7677             nan     0.2000    0.1011
     8        4.6341             nan     0.2000    0.0107
     9        4.5420             nan     0.2000   -0.0314
    10        4.3899             nan     0.2000    0.0430
    20        3.5988             nan     0.2000    0.0294
    40        2.9227             nan     0.2000   -0.0630
    60        2.3950             nan     0.2000   -0.0398
    80        2.1062             nan     0.2000   -0.0478
   100        1.7999             nan     0.2000   -0.0488
   120        1.5376             nan     0.2000   -0.0335
   140        1.3127             nan     0.2000   -0.0288
   160        1.1459             nan     0.2000   -0.0174
   180        0.9822             nan     0.2000   -0.0296
   200        0.8454             nan     0.2000   -0.0107

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3310             nan     0.0500    0.1187
     2        7.2186             nan     0.0500    0.1102
     3        7.1178             nan     0.0500    0.1043
     4        7.0047             nan     0.0500    0.0969
     5        6.9243             nan     0.0500    0.0710
     6        6.8508             nan     0.0500    0.0742
     7        6.7577             nan     0.0500    0.0687
     8        6.6854             nan     0.0500    0.0633
     9        6.6147             nan     0.0500    0.0475
    10        6.5502             nan     0.0500    0.0628
    20        6.0794             nan     0.0500    0.0376
    40        5.5748             nan     0.0500    0.0074
    60        5.2272             nan     0.0500    0.0079
    80        4.9824             nan     0.0500   -0.0063
   100        4.7942             nan     0.0500    0.0044
   120        4.6401             nan     0.0500   -0.0089
   140        4.5282             nan     0.0500    0.0044
   160        4.4359             nan     0.0500   -0.0020
   180        4.3564             nan     0.0500   -0.0038
   200        4.3020             nan     0.0500   -0.0056

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2755             nan     0.0500    0.1457
     2        7.1271             nan     0.0500    0.1363
     3        7.0186             nan     0.0500    0.1039
     4        6.9238             nan     0.0500    0.0892
     5        6.8185             nan     0.0500    0.0947
     6        6.7049             nan     0.0500    0.0652
     7        6.6103             nan     0.0500    0.0942
     8        6.5083             nan     0.0500    0.0949
     9        6.4168             nan     0.0500    0.0796
    10        6.3275             nan     0.0500    0.0678
    20        5.7599             nan     0.0500    0.0373
    40        5.0508             nan     0.0500    0.0090
    60        4.6836             nan     0.0500    0.0059
    80        4.4258             nan     0.0500   -0.0015
   100        4.2301             nan     0.0500   -0.0133
   120        4.0704             nan     0.0500   -0.0106
   140        3.9523             nan     0.0500   -0.0081
   160        3.8372             nan     0.0500   -0.0047
   180        3.7313             nan     0.0500   -0.0093
   200        3.6341             nan     0.0500   -0.0061

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2864             nan     0.0500    0.0975
     2        7.1256             nan     0.0500    0.1376
     3        6.9444             nan     0.0500    0.1612
     4        6.8153             nan     0.0500    0.0810
     5        6.7068             nan     0.0500    0.1100
     6        6.5973             nan     0.0500    0.0466
     7        6.4813             nan     0.0500    0.1032
     8        6.3572             nan     0.0500    0.0724
     9        6.2418             nan     0.0500    0.0828
    10        6.1271             nan     0.0500    0.0898
    20        5.4212             nan     0.0500    0.0333
    40        4.6840             nan     0.0500    0.0096
    60        4.2418             nan     0.0500   -0.0073
    80        3.9865             nan     0.0500   -0.0065
   100        3.8022             nan     0.0500   -0.0172
   120        3.6402             nan     0.0500   -0.0018
   140        3.4847             nan     0.0500   -0.0077
   160        3.3780             nan     0.0500   -0.0152
   180        3.2751             nan     0.0500   -0.0110
   200        3.1503             nan     0.0500   -0.0074

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2301             nan     0.0500    0.1683
     2        7.0709             nan     0.0500    0.1622
     3        6.8858             nan     0.0500    0.0920
     4        6.7306             nan     0.0500    0.1388
     5        6.5549             nan     0.0500    0.0989
     6        6.4163             nan     0.0500    0.1160
     7        6.2853             nan     0.0500    0.0688
     8        6.1803             nan     0.0500    0.0852
     9        6.0509             nan     0.0500    0.1039
    10        5.9478             nan     0.0500    0.0458
    20        5.0923             nan     0.0500    0.0406
    40        4.2923             nan     0.0500   -0.0107
    60        3.7732             nan     0.0500   -0.0233
    80        3.4300             nan     0.0500   -0.0117
   100        3.1785             nan     0.0500   -0.0057
   120        2.9819             nan     0.0500   -0.0160
   140        2.8083             nan     0.0500   -0.0038
   160        2.6362             nan     0.0500   -0.0057
   180        2.4734             nan     0.0500   -0.0079
   200        2.3502             nan     0.0500   -0.0061

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1793             nan     0.1000    0.2219
     2        6.9580             nan     0.1000    0.2143
     3        6.7986             nan     0.1000    0.1470
     4        6.6573             nan     0.1000    0.1488
     5        6.5573             nan     0.1000    0.0206
     6        6.4172             nan     0.1000    0.1027
     7        6.3112             nan     0.1000    0.0774
     8        6.2551             nan     0.1000    0.0177
     9        6.1616             nan     0.1000    0.0476
    10        6.1074             nan     0.1000    0.0004
    20        5.5438             nan     0.1000    0.0244
    40        4.9406             nan     0.1000   -0.0029
    60        4.6285             nan     0.1000   -0.0217
    80        4.4256             nan     0.1000   -0.0133
   100        4.3133             nan     0.1000   -0.0182
   120        4.2508             nan     0.1000   -0.0199
   140        4.1669             nan     0.1000   -0.0119
   160        4.1202             nan     0.1000   -0.0245
   180        4.0973             nan     0.1000   -0.0065
   200        4.0798             nan     0.1000   -0.0129

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1747             nan     0.1000    0.2633
     2        6.9024             nan     0.1000    0.1762
     3        6.6506             nan     0.1000    0.2257
     4        6.4864             nan     0.1000    0.1987
     5        6.3029             nan     0.1000    0.1381
     6        6.1968             nan     0.1000    0.1174
     7        6.0961             nan     0.1000    0.0972
     8        6.0111             nan     0.1000    0.0315
     9        5.8810             nan     0.1000    0.0388
    10        5.8103             nan     0.1000    0.0155
    20        5.0975             nan     0.1000   -0.0028
    40        4.4153             nan     0.1000   -0.0140
    60        4.0848             nan     0.1000   -0.0400
    80        3.8754             nan     0.1000    0.0059
   100        3.7038             nan     0.1000   -0.0089
   120        3.5828             nan     0.1000   -0.0161
   140        3.4493             nan     0.1000   -0.0100
   160        3.3358             nan     0.1000   -0.0144
   180        3.2489             nan     0.1000   -0.0200
   200        3.1625             nan     0.1000   -0.0086

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0971             nan     0.1000    0.1562
     2        6.7734             nan     0.1000    0.3131
     3        6.5131             nan     0.1000    0.2138
     4        6.3014             nan     0.1000    0.0878
     5        6.1002             nan     0.1000    0.1349
     6        5.9453             nan     0.1000    0.0948
     7        5.7826             nan     0.1000    0.1068
     8        5.6587             nan     0.1000    0.0681
     9        5.5398             nan     0.1000    0.0878
    10        5.4563             nan     0.1000    0.0080
    20        4.7066             nan     0.1000   -0.0218
    40        4.0521             nan     0.1000   -0.0193
    60        3.6778             nan     0.1000   -0.0236
    80        3.4158             nan     0.1000   -0.0226
   100        3.2236             nan     0.1000   -0.0206
   120        3.0183             nan     0.1000   -0.0309
   140        2.8634             nan     0.1000   -0.0034
   160        2.7338             nan     0.1000   -0.0311
   180        2.6076             nan     0.1000   -0.0237
   200        2.4879             nan     0.1000   -0.0077

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9574             nan     0.1000    0.3617
     2        6.6919             nan     0.1000    0.2366
     3        6.4240             nan     0.1000    0.1453
     4        6.1739             nan     0.1000    0.2321
     5        5.9017             nan     0.1000    0.2535
     6        5.7196             nan     0.1000    0.1159
     7        5.5495             nan     0.1000    0.0909
     8        5.4155             nan     0.1000    0.0715
     9        5.3004             nan     0.1000    0.0855
    10        5.1431             nan     0.1000    0.0995
    20        4.2676             nan     0.1000    0.0055
    40        3.5046             nan     0.1000   -0.0380
    60        3.0101             nan     0.1000   -0.0261
    80        2.6350             nan     0.1000   -0.0233
   100        2.3741             nan     0.1000   -0.0315
   120        2.1300             nan     0.1000   -0.0355
   140        1.9592             nan     0.1000   -0.0183
   160        1.8087             nan     0.1000   -0.0128
   180        1.6355             nan     0.1000   -0.0230
   200        1.5042             nan     0.1000   -0.0136

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0000             nan     0.2000    0.3528
     2        6.8255             nan     0.2000    0.0880
     3        6.4866             nan     0.2000    0.2656
     4        6.2923             nan     0.2000    0.1961
     5        6.1033             nan     0.2000    0.1130
     6        5.9408             nan     0.2000    0.1064
     7        5.8476             nan     0.2000    0.0699
     8        5.7633             nan     0.2000    0.0278
     9        5.6915             nan     0.2000    0.0180
    10        5.6139             nan     0.2000    0.0636
    20        5.0659             nan     0.2000   -0.0405
    40        4.5246             nan     0.2000   -0.0166
    60        4.2927             nan     0.2000   -0.0285
    80        4.1998             nan     0.2000   -0.0424
   100        4.1345             nan     0.2000   -0.0375
   120        4.1017             nan     0.2000   -0.0152
   140        4.0552             nan     0.2000   -0.0624
   160        4.0609             nan     0.2000   -0.0538
   180        4.0396             nan     0.2000   -0.0492
   200        4.0438             nan     0.2000   -0.0349

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9343             nan     0.2000    0.3980
     2        6.4657             nan     0.2000    0.3256
     3        6.2225             nan     0.2000    0.1045
     4        5.9103             nan     0.2000    0.2953
     5        5.7317             nan     0.2000    0.0494
     6        5.5100             nan     0.2000    0.0781
     7        5.3832             nan     0.2000    0.1266
     8        5.3138             nan     0.2000    0.0237
     9        5.1687             nan     0.2000    0.0549
    10        5.0450             nan     0.2000    0.0247
    20        4.4166             nan     0.2000    0.0018
    40        3.9053             nan     0.2000   -0.0195
    60        3.6621             nan     0.2000   -0.0803
    80        3.4071             nan     0.2000   -0.0529
   100        3.2252             nan     0.2000   -0.0495
   120        3.0926             nan     0.2000   -0.0536
   140        2.9385             nan     0.2000   -0.0413
   160        2.8629             nan     0.2000   -0.0539
   180        2.6947             nan     0.2000   -0.0460
   200        2.5883             nan     0.2000   -0.0296

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7758             nan     0.2000    0.5088
     2        6.2036             nan     0.2000    0.5895
     3        5.8492             nan     0.2000    0.1001
     4        5.5349             nan     0.2000    0.2522
     5        5.3133             nan     0.2000    0.0692
     6        5.1197             nan     0.2000    0.1564
     7        4.9866             nan     0.2000    0.0878
     8        4.8685             nan     0.2000    0.0726
     9        4.7474             nan     0.2000    0.0280
    10        4.6685             nan     0.2000   -0.0267
    20        4.0583             nan     0.2000    0.0268
    40        3.4780             nan     0.2000   -0.0174
    60        3.1344             nan     0.2000   -0.0684
    80        2.7885             nan     0.2000   -0.0383
   100        2.5918             nan     0.2000   -0.0527
   120        2.4092             nan     0.2000   -0.0272
   140        2.2439             nan     0.2000   -0.0261
   160        2.1154             nan     0.2000   -0.0662
   180        1.9277             nan     0.2000   -0.0186
   200        1.7653             nan     0.2000   -0.0095

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6280             nan     0.2000    0.7340
     2        6.3675             nan     0.2000    0.1041
     3        5.8454             nan     0.2000    0.3354
     4        5.5826             nan     0.2000    0.0117
     5        5.3198             nan     0.2000    0.0159
     6        5.0552             nan     0.2000    0.2087
     7        4.8689             nan     0.2000    0.0944
     8        4.6915             nan     0.2000    0.0792
     9        4.5217             nan     0.2000    0.0123
    10        4.4578             nan     0.2000   -0.0660
    20        3.7399             nan     0.2000   -0.0518
    40        3.0064             nan     0.2000   -0.0544
    60        2.4456             nan     0.2000   -0.0404
    80        1.9683             nan     0.2000   -0.0577
   100        1.6778             nan     0.2000   -0.0415
   120        1.4612             nan     0.2000   -0.0319
   140        1.2603             nan     0.2000   -0.0370
   160        1.0845             nan     0.2000   -0.0228
   180        0.9671             nan     0.2000   -0.0410
   200        0.8372             nan     0.2000   -0.0214

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2833             nan     0.0500    0.1198
     2        7.1693             nan     0.0500    0.1067
     3        7.0672             nan     0.0500    0.0921
     4        6.9577             nan     0.0500    0.0827
     5        6.8747             nan     0.0500    0.0590
     6        6.7947             nan     0.0500    0.0705
     7        6.7270             nan     0.0500    0.0397
     8        6.6681             nan     0.0500    0.0538
     9        6.6039             nan     0.0500    0.0525
    10        6.5564             nan     0.0500    0.0376
    20        6.1602             nan     0.0500    0.0163
    40        5.6713             nan     0.0500    0.0153
    60        5.2739             nan     0.0500    0.0039
    80        5.0033             nan     0.0500    0.0134
   100        4.8254             nan     0.0500   -0.0025
   120        4.6965             nan     0.0500    0.0002
   140        4.5700             nan     0.0500    0.0008
   160        4.4839             nan     0.0500   -0.0041
   180        4.3875             nan     0.0500   -0.0111
   200        4.3194             nan     0.0500   -0.0028

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2933             nan     0.0500    0.1177
     2        7.1748             nan     0.0500    0.1274
     3        7.0714             nan     0.0500    0.0761
     4        6.9521             nan     0.0500    0.1209
     5        6.8599             nan     0.0500    0.0647
     6        6.7462             nan     0.0500    0.0868
     7        6.6480             nan     0.0500    0.0846
     8        6.5220             nan     0.0500    0.0787
     9        6.4400             nan     0.0500    0.0450
    10        6.3718             nan     0.0500    0.0705
    20        5.8151             nan     0.0500    0.0371
    40        5.1229             nan     0.0500   -0.0029
    60        4.6959             nan     0.0500   -0.0173
    80        4.4018             nan     0.0500   -0.0018
   100        4.1961             nan     0.0500   -0.0041
   120        4.0548             nan     0.0500   -0.0064
   140        3.9397             nan     0.0500   -0.0154
   160        3.8383             nan     0.0500   -0.0177
   180        3.7550             nan     0.0500   -0.0025
   200        3.6910             nan     0.0500   -0.0156

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2546             nan     0.0500    0.1439
     2        7.1183             nan     0.0500    0.1248
     3        6.9444             nan     0.0500    0.1160
     4        6.8335             nan     0.0500    0.0855
     5        6.6937             nan     0.0500    0.0925
     6        6.6067             nan     0.0500    0.0298
     7        6.4816             nan     0.0500    0.0721
     8        6.3730             nan     0.0500    0.1016
     9        6.2708             nan     0.0500    0.0861
    10        6.1666             nan     0.0500    0.0734
    20        5.5243             nan     0.0500    0.0299
    40        4.7084             nan     0.0500   -0.0016
    60        4.2853             nan     0.0500   -0.0057
    80        3.9595             nan     0.0500   -0.0229
   100        3.7694             nan     0.0500   -0.0111
   120        3.6131             nan     0.0500   -0.0109
   140        3.4732             nan     0.0500   -0.0056
   160        3.3379             nan     0.0500   -0.0078
   180        3.2161             nan     0.0500   -0.0187
   200        3.1080             nan     0.0500   -0.0094

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1979             nan     0.0500    0.1478
     2        7.0038             nan     0.0500    0.1173
     3        6.8655             nan     0.0500    0.0519
     4        6.7066             nan     0.0500    0.1403
     5        6.5457             nan     0.0500    0.1300
     6        6.3946             nan     0.0500    0.0753
     7        6.2553             nan     0.0500    0.0833
     8        6.1358             nan     0.0500    0.0465
     9        6.0404             nan     0.0500    0.0802
    10        5.9732             nan     0.0500    0.0226
    20        5.1251             nan     0.0500    0.0530
    40        4.2985             nan     0.0500   -0.0141
    60        3.8276             nan     0.0500   -0.0195
    80        3.5110             nan     0.0500    0.0013
   100        3.2351             nan     0.0500   -0.0170
   120        3.0059             nan     0.0500   -0.0150
   140        2.8236             nan     0.0500   -0.0110
   160        2.6397             nan     0.0500   -0.0051
   180        2.5052             nan     0.0500   -0.0236
   200        2.3841             nan     0.0500   -0.0114

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2157             nan     0.1000    0.2329
     2        7.0673             nan     0.1000    0.1349
     3        6.8765             nan     0.1000    0.1814
     4        6.7343             nan     0.1000    0.1571
     5        6.6333             nan     0.1000    0.0879
     6        6.5570             nan     0.1000    0.0728
     7        6.4436             nan     0.1000    0.0788
     8        6.3470             nan     0.1000    0.0747
     9        6.2841             nan     0.1000    0.0220
    10        6.2111             nan     0.1000    0.0640
    20        5.6710             nan     0.1000    0.0049
    40        5.0703             nan     0.1000   -0.0036
    60        4.7035             nan     0.1000   -0.0001
    80        4.4717             nan     0.1000   -0.0106
   100        4.3246             nan     0.1000    0.0084
   120        4.2108             nan     0.1000   -0.0019
   140        4.1431             nan     0.1000   -0.0262
   160        4.0917             nan     0.1000   -0.0114
   180        4.0654             nan     0.1000   -0.0245
   200        4.0265             nan     0.1000   -0.0114

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1383             nan     0.1000    0.2132
     2        6.9227             nan     0.1000    0.2413
     3        6.7257             nan     0.1000    0.1108
     4        6.5365             nan     0.1000    0.1434
     5        6.3529             nan     0.1000    0.1300
     6        6.2506             nan     0.1000    0.0086
     7        6.0924             nan     0.1000    0.1371
     8        6.0004             nan     0.1000    0.0281
     9        5.9209             nan     0.1000    0.0530
    10        5.8158             nan     0.1000    0.0205
    20        5.1206             nan     0.1000    0.0361
    40        4.4341             nan     0.1000   -0.0056
    60        4.0778             nan     0.1000   -0.0410
    80        3.8564             nan     0.1000   -0.0066
   100        3.6999             nan     0.1000   -0.0319
   120        3.5776             nan     0.1000   -0.0092
   140        3.4484             nan     0.1000   -0.0016
   160        3.3681             nan     0.1000   -0.0252
   180        3.2798             nan     0.1000   -0.0172
   200        3.2052             nan     0.1000   -0.0149

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0774             nan     0.1000    0.2541
     2        6.7827             nan     0.1000    0.2294
     3        6.5186             nan     0.1000    0.1873
     4        6.3078             nan     0.1000    0.1845
     5        6.1417             nan     0.1000    0.1083
     6        5.9410             nan     0.1000    0.1022
     7        5.7798             nan     0.1000    0.0947
     8        5.6407             nan     0.1000    0.0541
     9        5.4986             nan     0.1000    0.0595
    10        5.3882             nan     0.1000    0.0839
    20        4.7108             nan     0.1000    0.0091
    40        4.0009             nan     0.1000   -0.0130
    60        3.6081             nan     0.1000   -0.0184
    80        3.3620             nan     0.1000   -0.0209
   100        3.1365             nan     0.1000   -0.0106
   120        2.9229             nan     0.1000   -0.0113
   140        2.7358             nan     0.1000   -0.0336
   160        2.6166             nan     0.1000   -0.0170
   180        2.5021             nan     0.1000   -0.0228
   200        2.3816             nan     0.1000   -0.0157

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9882             nan     0.1000    0.3128
     2        6.6520             nan     0.1000    0.2525
     3        6.3748             nan     0.1000    0.2086
     4        6.1289             nan     0.1000    0.1394
     5        5.9022             nan     0.1000    0.1245
     6        5.7237             nan     0.1000    0.1153
     7        5.5272             nan     0.1000    0.0993
     8        5.3923             nan     0.1000    0.0731
     9        5.2169             nan     0.1000    0.0689
    10        5.0774             nan     0.1000    0.0412
    20        4.2246             nan     0.1000    0.0059
    40        3.4762             nan     0.1000   -0.0257
    60        2.9810             nan     0.1000   -0.0221
    80        2.6720             nan     0.1000   -0.0243
   100        2.3815             nan     0.1000   -0.0295
   120        2.1503             nan     0.1000   -0.0309
   140        1.9643             nan     0.1000   -0.0206
   160        1.8022             nan     0.1000   -0.0246
   180        1.6682             nan     0.1000   -0.0111
   200        1.5279             nan     0.1000   -0.0172

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9611             nan     0.2000    0.4066
     2        6.7063             nan     0.2000    0.2574
     3        6.4901             nan     0.2000    0.2238
     4        6.3125             nan     0.2000    0.1359
     5        6.2198             nan     0.2000    0.0405
     6        6.1192             nan     0.2000    0.0552
     7        5.9624             nan     0.2000    0.1250
     8        5.8828             nan     0.2000    0.0562
     9        5.7968             nan     0.2000   -0.0413
    10        5.6897             nan     0.2000    0.0291
    20        5.0413             nan     0.2000   -0.0445
    40        4.4404             nan     0.2000    0.0015
    60        4.2423             nan     0.2000   -0.0034
    80        4.1653             nan     0.2000   -0.0117
   100        4.1022             nan     0.2000   -0.0173
   120        4.0696             nan     0.2000   -0.0296
   140        4.0396             nan     0.2000   -0.0462
   160        4.0266             nan     0.2000   -0.0250
   180        3.9787             nan     0.2000   -0.0222
   200        3.9799             nan     0.2000   -0.0376

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8970             nan     0.2000    0.4900
     2        6.4681             nan     0.2000    0.2507
     3        6.1569             nan     0.2000    0.3008
     4        5.9882             nan     0.2000    0.0236
     5        5.7950             nan     0.2000    0.1691
     6        5.5837             nan     0.2000    0.1178
     7        5.4222             nan     0.2000    0.0116
     8        5.3140             nan     0.2000    0.0373
     9        5.2355             nan     0.2000    0.0201
    10        5.1386             nan     0.2000    0.0481
    20        4.4357             nan     0.2000    0.0142
    40        3.8291             nan     0.2000   -0.0255
    60        3.5225             nan     0.2000   -0.0352
    80        3.3463             nan     0.2000   -0.0212
   100        3.1686             nan     0.2000   -0.0165
   120        3.0551             nan     0.2000   -0.0367
   140        2.9231             nan     0.2000   -0.0226
   160        2.8232             nan     0.2000   -0.0298
   180        2.7436             nan     0.2000   -0.0391
   200        2.6161             nan     0.2000   -0.0389

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7771             nan     0.2000    0.5266
     2        6.3625             nan     0.2000    0.2495
     3        6.0178             nan     0.2000    0.2525
     4        5.7617             nan     0.2000    0.2580
     5        5.5244             nan     0.2000    0.1242
     6        5.3355             nan     0.2000    0.1111
     7        5.1498             nan     0.2000    0.0986
     8        5.0308             nan     0.2000    0.0452
     9        4.9261             nan     0.2000   -0.0369
    10        4.8295             nan     0.2000   -0.0101
    20        4.1414             nan     0.2000   -0.0663
    40        3.4817             nan     0.2000   -0.0550
    60        3.1908             nan     0.2000   -0.0677
    80        2.8807             nan     0.2000   -0.0287
   100        2.6406             nan     0.2000   -0.0495
   120        2.3768             nan     0.2000   -0.0549
   140        2.2216             nan     0.2000   -0.0657
   160        2.0678             nan     0.2000   -0.0454
   180        1.9094             nan     0.2000   -0.0262
   200        1.7696             nan     0.2000   -0.0206

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6788             nan     0.2000    0.6416
     2        6.1558             nan     0.2000    0.3744
     3        5.6972             nan     0.2000    0.3788
     4        5.3795             nan     0.2000    0.2230
     5        5.1251             nan     0.2000    0.0407
     6        4.8779             nan     0.2000    0.1461
     7        4.7299             nan     0.2000    0.0683
     8        4.5995             nan     0.2000    0.0120
     9        4.4995             nan     0.2000   -0.1036
    10        4.3831             nan     0.2000   -0.0504
    20        3.5815             nan     0.2000   -0.0214
    40        2.7593             nan     0.2000   -0.0475
    60        2.2252             nan     0.2000   -0.0720
    80        1.8892             nan     0.2000   -0.0292
   100        1.5605             nan     0.2000   -0.0472
   120        1.3441             nan     0.2000   -0.0296
   140        1.1538             nan     0.2000   -0.0404
   160        1.0072             nan     0.2000   -0.0258
   180        0.8664             nan     0.2000   -0.0237
   200        0.7665             nan     0.2000   -0.0136

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9735             nan     0.0500    0.0817
     2        6.8785             nan     0.0500    0.0961
     3        6.7675             nan     0.0500    0.0962
     4        6.6687             nan     0.0500    0.0691
     5        6.5942             nan     0.0500    0.0674
     6        6.5017             nan     0.0500    0.0523
     7        6.4594             nan     0.0500    0.0330
     8        6.4018             nan     0.0500    0.0783
     9        6.3113             nan     0.0500    0.0794
    10        6.2492             nan     0.0500    0.0483
    20        5.8074             nan     0.0500    0.0015
    40        5.3279             nan     0.0500   -0.0199
    60        5.0192             nan     0.0500    0.0091
    80        4.8045             nan     0.0500   -0.0006
   100        4.6293             nan     0.0500    0.0012
   120        4.5072             nan     0.0500   -0.0106
   140        4.4077             nan     0.0500   -0.0037
   160        4.3263             nan     0.0500    0.0001
   180        4.2721             nan     0.0500   -0.0137
   200        4.2175             nan     0.0500   -0.0083

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9728             nan     0.0500    0.1285
     2        6.8401             nan     0.0500    0.1283
     3        6.7543             nan     0.0500    0.0779
     4        6.6306             nan     0.0500    0.0905
     5        6.5352             nan     0.0500    0.0921
     6        6.4446             nan     0.0500    0.0739
     7        6.3328             nan     0.0500    0.0867
     8        6.2182             nan     0.0500    0.0748
     9        6.1411             nan     0.0500    0.0527
    10        6.0631             nan     0.0500    0.0759
    20        5.4837             nan     0.0500    0.0290
    40        4.8489             nan     0.0500    0.0151
    60        4.4605             nan     0.0500   -0.0071
    80        4.2201             nan     0.0500   -0.0031
   100        4.0440             nan     0.0500   -0.0055
   120        3.9017             nan     0.0500   -0.0145
   140        3.8022             nan     0.0500   -0.0128
   160        3.7065             nan     0.0500   -0.0049
   180        3.6185             nan     0.0500   -0.0147
   200        3.5538             nan     0.0500   -0.0101

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9443             nan     0.0500    0.1507
     2        6.7862             nan     0.0500    0.1338
     3        6.6568             nan     0.0500    0.1051
     4        6.5286             nan     0.0500    0.1277
     5        6.4316             nan     0.0500    0.0895
     6        6.3139             nan     0.0500    0.0685
     7        6.2064             nan     0.0500    0.0946
     8        6.0988             nan     0.0500    0.0671
     9        6.0184             nan     0.0500    0.0626
    10        5.9027             nan     0.0500    0.0819
    20        5.2502             nan     0.0500   -0.0201
    40        4.5425             nan     0.0500    0.0185
    60        4.1354             nan     0.0500    0.0042
    80        3.8568             nan     0.0500   -0.0048
   100        3.6614             nan     0.0500   -0.0121
   120        3.5010             nan     0.0500   -0.0262
   140        3.3760             nan     0.0500   -0.0100
   160        3.2593             nan     0.0500   -0.0112
   180        3.1609             nan     0.0500   -0.0167
   200        3.0668             nan     0.0500   -0.0101

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9174             nan     0.0500    0.0925
     2        6.7054             nan     0.0500    0.1481
     3        6.5727             nan     0.0500    0.1153
     4        6.4250             nan     0.0500    0.0882
     5        6.2517             nan     0.0500    0.1475
     6        6.1230             nan     0.0500    0.1033
     7        6.0125             nan     0.0500    0.0705
     8        5.9124             nan     0.0500    0.0858
     9        5.8066             nan     0.0500    0.0827
    10        5.7086             nan     0.0500    0.0541
    20        4.9079             nan     0.0500    0.0236
    40        4.0765             nan     0.0500   -0.0156
    60        3.6476             nan     0.0500   -0.0179
    80        3.3636             nan     0.0500   -0.0180
   100        3.1236             nan     0.0500   -0.0151
   120        2.9230             nan     0.0500   -0.0005
   140        2.7574             nan     0.0500   -0.0092
   160        2.6057             nan     0.0500   -0.0136
   180        2.4693             nan     0.0500   -0.0214
   200        2.3438             nan     0.0500   -0.0133

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8937             nan     0.1000    0.2004
     2        6.6944             nan     0.1000    0.1573
     3        6.5200             nan     0.1000    0.1376
     4        6.3469             nan     0.1000    0.1326
     5        6.2088             nan     0.1000    0.1303
     6        6.1150             nan     0.1000    0.0900
     7        6.0798             nan     0.1000   -0.0103
     8        5.9985             nan     0.1000    0.0448
     9        5.9258             nan     0.1000    0.0738
    10        5.8213             nan     0.1000    0.0526
    20        5.3705             nan     0.1000    0.0296
    40        4.7708             nan     0.1000   -0.0097
    60        4.4876             nan     0.1000   -0.0063
    80        4.3138             nan     0.1000   -0.0127
   100        4.2030             nan     0.1000   -0.0110
   120        4.1261             nan     0.1000   -0.0006
   140        4.0818             nan     0.1000   -0.0092
   160        4.0409             nan     0.1000   -0.0121
   180        4.0077             nan     0.1000   -0.0075
   200        3.9839             nan     0.1000   -0.0082

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8366             nan     0.1000    0.2764
     2        6.6199             nan     0.1000    0.1149
     3        6.4175             nan     0.1000    0.1804
     4        6.2011             nan     0.1000    0.1614
     5        6.0382             nan     0.1000    0.1246
     6        5.8780             nan     0.1000    0.1377
     7        5.7324             nan     0.1000    0.1056
     8        5.6361             nan     0.1000    0.0796
     9        5.5714             nan     0.1000    0.0039
    10        5.4626             nan     0.1000    0.0555
    20        4.7876             nan     0.1000   -0.0109
    40        4.1822             nan     0.1000    0.0067
    60        3.9142             nan     0.1000   -0.0209
    80        3.7354             nan     0.1000   -0.0298
   100        3.6026             nan     0.1000   -0.0265
   120        3.4737             nan     0.1000   -0.0154
   140        3.3471             nan     0.1000   -0.0180
   160        3.2471             nan     0.1000   -0.0112
   180        3.1529             nan     0.1000   -0.0172
   200        3.0629             nan     0.1000   -0.0112

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7630             nan     0.1000    0.3507
     2        6.5324             nan     0.1000    0.1880
     3        6.2442             nan     0.1000    0.2529
     4        5.9938             nan     0.1000    0.1937
     5        5.8356             nan     0.1000    0.0923
     6        5.6770             nan     0.1000    0.1591
     7        5.5888             nan     0.1000    0.0061
     8        5.4583             nan     0.1000    0.0827
     9        5.3182             nan     0.1000    0.0547
    10        5.2038             nan     0.1000    0.0693
    20        4.5088             nan     0.1000    0.0095
    40        3.8526             nan     0.1000   -0.0295
    60        3.4504             nan     0.1000    0.0033
    80        3.1958             nan     0.1000   -0.0085
   100        3.0233             nan     0.1000   -0.0142
   120        2.8692             nan     0.1000   -0.0174
   140        2.7436             nan     0.1000   -0.0153
   160        2.5958             nan     0.1000   -0.0065
   180        2.4971             nan     0.1000   -0.0298
   200        2.4060             nan     0.1000   -0.0304

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6808             nan     0.1000    0.4159
     2        6.3282             nan     0.1000    0.3081
     3        6.0313             nan     0.1000    0.2546
     4        5.8433             nan     0.1000    0.1244
     5        5.6226             nan     0.1000    0.1024
     6        5.4063             nan     0.1000    0.1032
     7        5.2322             nan     0.1000    0.1024
     8        5.0978             nan     0.1000    0.0404
     9        4.9678             nan     0.1000    0.0565
    10        4.8066             nan     0.1000    0.0776
    20        4.0225             nan     0.1000    0.0009
    40        3.3864             nan     0.1000   -0.0453
    60        2.9697             nan     0.1000   -0.0439
    80        2.6419             nan     0.1000   -0.0392
   100        2.3784             nan     0.1000   -0.0153
   120        2.1416             nan     0.1000   -0.0232
   140        1.9549             nan     0.1000   -0.0108
   160        1.7756             nan     0.1000   -0.0117
   180        1.6476             nan     0.1000   -0.0229
   200        1.4871             nan     0.1000   -0.0102

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6652             nan     0.2000    0.3953
     2        6.5531             nan     0.2000    0.0431
     3        6.2489             nan     0.2000    0.2148
     4        5.9887             nan     0.2000    0.1589
     5        5.9021             nan     0.2000    0.0401
     6        5.8239             nan     0.2000   -0.0110
     7        5.6972             nan     0.2000    0.1253
     8        5.5977             nan     0.2000    0.0486
     9        5.5400             nan     0.2000    0.0073
    10        5.4339             nan     0.2000    0.0476
    20        4.9020             nan     0.2000   -0.0339
    40        4.3695             nan     0.2000   -0.0180
    60        4.1783             nan     0.2000   -0.0219
    80        4.0890             nan     0.2000   -0.0303
   100        4.0760             nan     0.2000   -0.0257
   120        4.0766             nan     0.2000   -0.0368
   140        4.0084             nan     0.2000   -0.0026
   160        3.9980             nan     0.2000   -0.0266
   180        3.9672             nan     0.2000   -0.0250
   200        3.9753             nan     0.2000   -0.0253

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6364             nan     0.2000    0.3716
     2        6.2967             nan     0.2000    0.2960
     3        5.9431             nan     0.2000    0.3511
     4        5.6495             nan     0.2000    0.1414
     5        5.4859             nan     0.2000    0.1384
     6        5.3414             nan     0.2000    0.0957
     7        5.1985             nan     0.2000    0.0367
     8        5.1091             nan     0.2000   -0.0086
     9        5.0119             nan     0.2000   -0.0159
    10        4.8790             nan     0.2000    0.1309
    20        4.2258             nan     0.2000   -0.0018
    40        3.8037             nan     0.2000   -0.0708
    60        3.5874             nan     0.2000   -0.0288
    80        3.3804             nan     0.2000   -0.0116
   100        3.2532             nan     0.2000   -0.0168
   120        3.1651             nan     0.2000   -0.0342
   140        2.9952             nan     0.2000   -0.0155
   160        2.8643             nan     0.2000   -0.0309
   180        2.7566             nan     0.2000   -0.0402
   200        2.6614             nan     0.2000   -0.0170

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3950             nan     0.2000    0.5048
     2        6.0002             nan     0.2000    0.1909
     3        5.6753             nan     0.2000    0.3204
     4        5.3842             nan     0.2000    0.2533
     5        5.1678             nan     0.2000    0.1924
     6        4.9958             nan     0.2000    0.0836
     7        4.8773             nan     0.2000    0.0346
     8        4.8184             nan     0.2000   -0.0187
     9        4.7084             nan     0.2000    0.0369
    10        4.6046             nan     0.2000   -0.0171
    20        4.0052             nan     0.2000    0.0007
    40        3.3733             nan     0.2000   -0.0369
    60        3.0219             nan     0.2000   -0.0307
    80        2.6904             nan     0.2000   -0.0333
   100        2.4521             nan     0.2000   -0.0565
   120        2.2764             nan     0.2000   -0.0451
   140        2.1281             nan     0.2000   -0.0451
   160        1.9805             nan     0.2000   -0.0100
   180        1.7972             nan     0.2000   -0.0120
   200        1.7013             nan     0.2000   -0.0346

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3891             nan     0.2000    0.6947
     2        5.9294             nan     0.2000    0.3151
     3        5.4807             nan     0.2000    0.2791
     4        5.2445             nan     0.2000    0.1080
     5        4.9289             nan     0.2000    0.2458
     6        4.7477             nan     0.2000    0.0501
     7        4.6149             nan     0.2000   -0.0071
     8        4.4082             nan     0.2000    0.0708
     9        4.2741             nan     0.2000    0.0112
    10        4.1774             nan     0.2000   -0.0467
    20        3.5541             nan     0.2000   -0.0972
    40        2.8774             nan     0.2000   -0.0513
    60        2.3755             nan     0.2000   -0.0419
    80        2.0849             nan     0.2000   -0.0492
   100        1.7293             nan     0.2000   -0.0427
   120        1.4902             nan     0.2000   -0.0455
   140        1.2875             nan     0.2000   -0.0199
   160        1.1084             nan     0.2000   -0.0142
   180        0.9641             nan     0.2000   -0.0205
   200        0.8309             nan     0.2000   -0.0234

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.4098             nan     0.0500    0.0756
     2        7.2867             nan     0.0500    0.0797
     3        7.1964             nan     0.0500    0.0800
     4        7.1058             nan     0.0500    0.0829
     5        7.0076             nan     0.0500    0.0792
     6        6.9406             nan     0.0500    0.0815
     7        6.8629             nan     0.0500    0.0453
     8        6.7959             nan     0.0500    0.0665
     9        6.7306             nan     0.0500    0.0552
    10        6.6695             nan     0.0500    0.0665
    20        6.1778             nan     0.0500    0.0372
    40        5.6240             nan     0.0500    0.0091
    60        5.2454             nan     0.0500    0.0059
    80        4.9908             nan     0.0500   -0.0035
   100        4.7878             nan     0.0500   -0.0024
   120        4.6454             nan     0.0500   -0.0013
   140        4.5249             nan     0.0500   -0.0067
   160        4.4453             nan     0.0500   -0.0045
   180        4.3612             nan     0.0500   -0.0065
   200        4.2988             nan     0.0500   -0.0028

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3806             nan     0.0500    0.0968
     2        7.2394             nan     0.0500    0.1267
     3        7.1171             nan     0.0500    0.1355
     4        6.9861             nan     0.0500    0.0940
     5        6.8613             nan     0.0500    0.1220
     6        6.7576             nan     0.0500    0.0944
     7        6.6539             nan     0.0500    0.0856
     8        6.5603             nan     0.0500    0.0815
     9        6.4355             nan     0.0500    0.0948
    10        6.3456             nan     0.0500    0.0638
    20        5.7489             nan     0.0500    0.0287
    40        5.0875             nan     0.0500    0.0060
    60        4.6730             nan     0.0500   -0.0002
    80        4.3899             nan     0.0500   -0.0189
   100        4.1796             nan     0.0500   -0.0189
   120        4.0128             nan     0.0500   -0.0191
   140        3.9070             nan     0.0500   -0.0046
   160        3.8180             nan     0.0500   -0.0132
   180        3.7372             nan     0.0500   -0.0106
   200        3.6684             nan     0.0500   -0.0014

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3500             nan     0.0500    0.1384
     2        7.1959             nan     0.0500    0.1226
     3        7.0460             nan     0.0500    0.1118
     4        6.8985             nan     0.0500    0.1183
     5        6.7434             nan     0.0500    0.1390
     6        6.6051             nan     0.0500    0.0993
     7        6.4605             nan     0.0500    0.1095
     8        6.3541             nan     0.0500    0.0243
     9        6.2322             nan     0.0500    0.0747
    10        6.1229             nan     0.0500    0.0724
    20        5.4619             nan     0.0500    0.0360
    40        4.7170             nan     0.0500    0.0008
    60        4.2950             nan     0.0500   -0.0056
    80        4.0192             nan     0.0500    0.0032
   100        3.8096             nan     0.0500   -0.0106
   120        3.6579             nan     0.0500   -0.0104
   140        3.5049             nan     0.0500   -0.0064
   160        3.3820             nan     0.0500   -0.0118
   180        3.2798             nan     0.0500    0.0006
   200        3.1749             nan     0.0500   -0.0094

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3192             nan     0.0500    0.1754
     2        7.1426             nan     0.0500    0.1388
     3        6.9261             nan     0.0500    0.1623
     4        6.7497             nan     0.0500    0.1661
     5        6.5983             nan     0.0500    0.0780
     6        6.4381             nan     0.0500    0.0911
     7        6.2834             nan     0.0500    0.1224
     8        6.1733             nan     0.0500    0.0445
     9        6.0620             nan     0.0500    0.0726
    10        5.9581             nan     0.0500    0.0536
    20        5.1401             nan     0.0500    0.0104
    40        4.2437             nan     0.0500   -0.0060
    60        3.7808             nan     0.0500   -0.0140
    80        3.4440             nan     0.0500   -0.0096
   100        3.2188             nan     0.0500   -0.0174
   120        2.9957             nan     0.0500   -0.0112
   140        2.8220             nan     0.0500   -0.0059
   160        2.6533             nan     0.0500   -0.0112
   180        2.5133             nan     0.0500   -0.0139
   200        2.3712             nan     0.0500   -0.0111

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3121             nan     0.1000    0.2159
     2        7.1223             nan     0.1000    0.1100
     3        6.9953             nan     0.1000    0.1494
     4        6.8583             nan     0.1000    0.1505
     5        6.7053             nan     0.1000    0.0997
     6        6.6240             nan     0.1000    0.0125
     7        6.5360             nan     0.1000    0.0926
     8        6.4377             nan     0.1000    0.0916
     9        6.3031             nan     0.1000    0.1037
    10        6.2009             nan     0.1000    0.0573
    20        5.6065             nan     0.1000    0.0359
    40        4.9831             nan     0.1000    0.0160
    60        4.6631             nan     0.1000    0.0083
    80        4.4651             nan     0.1000   -0.0113
   100        4.3214             nan     0.1000   -0.0149
   120        4.2517             nan     0.1000   -0.0163
   140        4.1920             nan     0.1000   -0.0102
   160        4.1567             nan     0.1000   -0.0086
   180        4.1108             nan     0.1000   -0.0153
   200        4.0883             nan     0.1000   -0.0165

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2734             nan     0.1000    0.2818
     2        6.9681             nan     0.1000    0.3136
     3        6.7612             nan     0.1000    0.1642
     4        6.5636             nan     0.1000    0.1633
     5        6.4016             nan     0.1000    0.1367
     6        6.2715             nan     0.1000    0.0620
     7        6.1271             nan     0.1000    0.1549
     8        6.0607             nan     0.1000    0.0388
     9        5.9414             nan     0.1000    0.1076
    10        5.7854             nan     0.1000    0.1320
    20        5.0820             nan     0.1000    0.0166
    40        4.4133             nan     0.1000   -0.0212
    60        4.0512             nan     0.1000   -0.0028
    80        3.8266             nan     0.1000   -0.0089
   100        3.6761             nan     0.1000   -0.0120
   120        3.5667             nan     0.1000   -0.0169
   140        3.4595             nan     0.1000   -0.0112
   160        3.3687             nan     0.1000   -0.0179
   180        3.2376             nan     0.1000   -0.0099
   200        3.1193             nan     0.1000   -0.0080

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1920             nan     0.1000    0.3097
     2        6.9217             nan     0.1000    0.1770
     3        6.5982             nan     0.1000    0.1475
     4        6.4056             nan     0.1000    0.1767
     5        6.2015             nan     0.1000    0.1689
     6        6.0277             nan     0.1000    0.1140
     7        5.9033             nan     0.1000    0.0297
     8        5.7906             nan     0.1000    0.0563
     9        5.6625             nan     0.1000    0.1107
    10        5.5416             nan     0.1000    0.0520
    20        4.7183             nan     0.1000    0.0142
    40        4.0344             nan     0.1000   -0.0283
    60        3.6419             nan     0.1000    0.0025
    80        3.3914             nan     0.1000   -0.0088
   100        3.1778             nan     0.1000   -0.0136
   120        2.9813             nan     0.1000   -0.0218
   140        2.8530             nan     0.1000   -0.0379
   160        2.7003             nan     0.1000   -0.0267
   180        2.5838             nan     0.1000   -0.0219
   200        2.4678             nan     0.1000   -0.0259

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1086             nan     0.1000    0.3290
     2        6.7910             nan     0.1000    0.2645
     3        6.4556             nan     0.1000    0.2852
     4        6.1826             nan     0.1000    0.1995
     5        5.9836             nan     0.1000    0.0927
     6        5.8112             nan     0.1000    0.1033
     7        5.6382             nan     0.1000    0.0726
     8        5.4532             nan     0.1000    0.1076
     9        5.2887             nan     0.1000    0.0836
    10        5.1554             nan     0.1000    0.0647
    20        4.2943             nan     0.1000   -0.0210
    40        3.5174             nan     0.1000   -0.0386
    60        3.1529             nan     0.1000   -0.0475
    80        2.7975             nan     0.1000   -0.0129
   100        2.5065             nan     0.1000   -0.0160
   120        2.2814             nan     0.1000   -0.0350
   140        2.0487             nan     0.1000   -0.0142
   160        1.8390             nan     0.1000   -0.0071
   180        1.6493             nan     0.1000   -0.0086
   200        1.5166             nan     0.1000   -0.0164

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0659             nan     0.2000    0.4656
     2        6.7603             nan     0.2000    0.2924
     3        6.5028             nan     0.2000    0.0914
     4        6.2874             nan     0.2000    0.1385
     5        6.1306             nan     0.2000    0.1765
     6        6.0334             nan     0.2000    0.0359
     7        5.9324             nan     0.2000    0.0111
     8        5.8045             nan     0.2000    0.0450
     9        5.7252             nan     0.2000    0.0295
    10        5.6274             nan     0.2000    0.0443
    20        5.0682             nan     0.2000   -0.0087
    40        4.4845             nan     0.2000   -0.0036
    60        4.2496             nan     0.2000   -0.0474
    80        4.1608             nan     0.2000   -0.0224
   100        4.1035             nan     0.2000   -0.0218
   120        4.0869             nan     0.2000   -0.0432
   140        4.0575             nan     0.2000   -0.0234
   160        4.0497             nan     0.2000   -0.0037
   180        4.0371             nan     0.2000   -0.0299
   200        4.0104             nan     0.2000   -0.0188

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9378             nan     0.2000    0.4066
     2        6.5084             nan     0.2000    0.4811
     3        6.2142             nan     0.2000    0.2265
     4        5.9675             nan     0.2000    0.1718
     5        5.7769             nan     0.2000    0.0694
     6        5.5855             nan     0.2000    0.1510
     7        5.3893             nan     0.2000    0.0216
     8        5.2899             nan     0.2000    0.0513
     9        5.2121             nan     0.2000   -0.0544
    10        5.1198             nan     0.2000    0.0318
    20        4.4227             nan     0.2000    0.0123
    40        4.0176             nan     0.2000   -0.1029
    60        3.6863             nan     0.2000   -0.0180
    80        3.5042             nan     0.2000   -0.0372
   100        3.2936             nan     0.2000   -0.0215
   120        3.1305             nan     0.2000   -0.0422
   140        2.9756             nan     0.2000   -0.0274
   160        2.8311             nan     0.2000   -0.0504
   180        2.7077             nan     0.2000   -0.0554
   200        2.6392             nan     0.2000   -0.0421

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8953             nan     0.2000    0.5192
     2        6.3529             nan     0.2000    0.4059
     3        6.0233             nan     0.2000    0.2158
     4        5.6428             nan     0.2000    0.2182
     5        5.4369             nan     0.2000    0.0160
     6        5.2531             nan     0.2000    0.0629
     7        5.0996             nan     0.2000   -0.0023
     8        4.9635             nan     0.2000    0.0398
     9        4.8591             nan     0.2000    0.0317
    10        4.7187             nan     0.2000    0.0058
    20        4.1283             nan     0.2000   -0.0689
    40        3.4903             nan     0.2000   -0.0551
    60        3.1938             nan     0.2000   -0.0352
    80        2.8326             nan     0.2000   -0.0127
   100        2.5591             nan     0.2000   -0.0122
   120        2.3385             nan     0.2000   -0.0135
   140        2.2107             nan     0.2000   -0.0256
   160        2.0177             nan     0.2000   -0.0124
   180        1.8556             nan     0.2000   -0.0225
   200        1.6991             nan     0.2000   -0.0281

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8493             nan     0.2000    0.5773
     2        6.3113             nan     0.2000    0.3601
     3        5.7995             nan     0.2000    0.3484
     4        5.5134             nan     0.2000    0.1084
     5        5.1983             nan     0.2000    0.1975
     6        5.0092             nan     0.2000    0.0811
     7        4.7824             nan     0.2000    0.1607
     8        4.5935             nan     0.2000    0.0882
     9        4.4046             nan     0.2000    0.0866
    10        4.2762             nan     0.2000    0.0345
    20        3.6259             nan     0.2000   -0.0454
    40        3.0307             nan     0.2000   -0.0713
    60        2.5104             nan     0.2000   -0.0539
    80        2.0824             nan     0.2000   -0.0489
   100        1.8106             nan     0.2000   -0.0274
   120        1.5408             nan     0.2000   -0.0244
   140        1.3210             nan     0.2000   -0.0320
   160        1.1230             nan     0.2000   -0.0380
   180        0.9676             nan     0.2000   -0.0106
   200        0.8463             nan     0.2000   -0.0223

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9284             nan     0.0500    0.1103
     2        6.8310             nan     0.0500    0.1091
     3        6.7475             nan     0.0500    0.0889
     4        6.6651             nan     0.0500    0.0682
     5        6.5780             nan     0.0500    0.0570
     6        6.5441             nan     0.0500    0.0194
     7        6.4777             nan     0.0500    0.0650
     8        6.4114             nan     0.0500    0.0338
     9        6.3488             nan     0.0500    0.0602
    10        6.2933             nan     0.0500    0.0409
    20        5.9092             nan     0.0500    0.0191
    40        5.4397             nan     0.0500    0.0091
    60        5.1271             nan     0.0500    0.0095
    80        4.8949             nan     0.0500    0.0004
   100        4.7017             nan     0.0500   -0.0061
   120        4.5616             nan     0.0500   -0.0008
   140        4.4519             nan     0.0500   -0.0021
   160        4.3678             nan     0.0500   -0.0139
   180        4.2988             nan     0.0500   -0.0062
   200        4.2462             nan     0.0500   -0.0087

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9034             nan     0.0500    0.1257
     2        6.7482             nan     0.0500    0.1021
     3        6.6543             nan     0.0500    0.0795
     4        6.5325             nan     0.0500    0.0731
     5        6.4338             nan     0.0500    0.0979
     6        6.3776             nan     0.0500    0.0356
     7        6.2855             nan     0.0500    0.0729
     8        6.2164             nan     0.0500    0.0651
     9        6.1389             nan     0.0500    0.0644
    10        6.0759             nan     0.0500    0.0481
    20        5.5725             nan     0.0500    0.0057
    40        4.9238             nan     0.0500    0.0151
    60        4.5299             nan     0.0500    0.0036
    80        4.2762             nan     0.0500    0.0019
   100        4.0704             nan     0.0500   -0.0052
   120        3.9259             nan     0.0500   -0.0028
   140        3.8123             nan     0.0500   -0.0043
   160        3.7141             nan     0.0500   -0.0094
   180        3.6281             nan     0.0500   -0.0108
   200        3.5628             nan     0.0500   -0.0102

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8925             nan     0.0500    0.1415
     2        6.7337             nan     0.0500    0.1287
     3        6.6210             nan     0.0500    0.0620
     4        6.5050             nan     0.0500    0.0826
     5        6.3800             nan     0.0500    0.1045
     6        6.2817             nan     0.0500    0.0820
     7        6.1977             nan     0.0500    0.0774
     8        6.0988             nan     0.0500    0.0427
     9        5.9944             nan     0.0500    0.0725
    10        5.9054             nan     0.0500    0.0538
    20        5.2676             nan     0.0500    0.0179
    40        4.5245             nan     0.0500    0.0012
    60        4.1318             nan     0.0500   -0.0112
    80        3.8588             nan     0.0500   -0.0078
   100        3.6577             nan     0.0500   -0.0038
   120        3.4770             nan     0.0500   -0.0045
   140        3.3545             nan     0.0500   -0.0158
   160        3.2167             nan     0.0500   -0.0104
   180        3.1129             nan     0.0500   -0.0129
   200        3.0364             nan     0.0500   -0.0123

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8514             nan     0.0500    0.1593
     2        6.6976             nan     0.0500    0.1074
     3        6.5671             nan     0.0500    0.1086
     4        6.4097             nan     0.0500    0.0770
     5        6.2653             nan     0.0500    0.1040
     6        6.1320             nan     0.0500    0.1266
     7        5.9802             nan     0.0500    0.0987
     8        5.8587             nan     0.0500    0.1042
     9        5.7582             nan     0.0500    0.0300
    10        5.6442             nan     0.0500    0.0684
    20        4.9252             nan     0.0500    0.0245
    40        4.1265             nan     0.0500   -0.0137
    60        3.6624             nan     0.0500   -0.0138
    80        3.3561             nan     0.0500    0.0027
   100        3.0800             nan     0.0500   -0.0067
   120        2.8823             nan     0.0500   -0.0054
   140        2.7138             nan     0.0500   -0.0103
   160        2.5552             nan     0.0500   -0.0186
   180        2.4295             nan     0.0500   -0.0079
   200        2.2928             nan     0.0500   -0.0097

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8079             nan     0.1000    0.2258
     2        6.6719             nan     0.1000    0.1420
     3        6.4926             nan     0.1000    0.1525
     4        6.4037             nan     0.1000    0.0399
     5        6.2775             nan     0.1000    0.0930
     6        6.1729             nan     0.1000    0.0929
     7        6.0585             nan     0.1000    0.0896
     8        6.0000             nan     0.1000    0.0146
     9        5.9208             nan     0.1000    0.0467
    10        5.8748             nan     0.1000   -0.0004
    20        5.4133             nan     0.1000    0.0272
    40        4.8960             nan     0.1000    0.0007
    60        4.5708             nan     0.1000   -0.0112
    80        4.4089             nan     0.1000   -0.0331
   100        4.2726             nan     0.1000   -0.0052
   120        4.1918             nan     0.1000   -0.0059
   140        4.1342             nan     0.1000   -0.0094
   160        4.0689             nan     0.1000   -0.0103
   180        4.0364             nan     0.1000   -0.0213
   200        4.0173             nan     0.1000   -0.0072

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7806             nan     0.1000    0.2326
     2        6.5811             nan     0.1000    0.1384
     3        6.3864             nan     0.1000    0.1770
     4        6.2439             nan     0.1000    0.1207
     5        6.0632             nan     0.1000    0.1444
     6        5.9371             nan     0.1000    0.1090
     7        5.8353             nan     0.1000    0.0691
     8        5.7126             nan     0.1000    0.0928
     9        5.6234             nan     0.1000   -0.0043
    10        5.5362             nan     0.1000    0.0597
    20        4.8643             nan     0.1000    0.0095
    40        4.2317             nan     0.1000    0.0075
    60        3.9645             nan     0.1000   -0.0329
    80        3.7327             nan     0.1000   -0.0088
   100        3.6124             nan     0.1000   -0.0282
   120        3.5177             nan     0.1000   -0.0083
   140        3.4231             nan     0.1000   -0.0157
   160        3.3146             nan     0.1000   -0.0291
   180        3.2275             nan     0.1000   -0.0263
   200        3.1329             nan     0.1000   -0.0147

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7350             nan     0.1000    0.1710
     2        6.4978             nan     0.1000    0.1799
     3        6.2770             nan     0.1000    0.1978
     4        6.0571             nan     0.1000    0.1677
     5        5.8996             nan     0.1000    0.1017
     6        5.7544             nan     0.1000    0.1012
     7        5.6378             nan     0.1000    0.0885
     8        5.5042             nan     0.1000    0.0481
     9        5.4165             nan     0.1000    0.0541
    10        5.3165             nan     0.1000    0.0620
    20        4.5335             nan     0.1000    0.0110
    40        3.8533             nan     0.1000   -0.0253
    60        3.5286             nan     0.1000   -0.0164
    80        3.2875             nan     0.1000   -0.0410
   100        3.0811             nan     0.1000   -0.0296
   120        2.9180             nan     0.1000   -0.0317
   140        2.7582             nan     0.1000   -0.0165
   160        2.6163             nan     0.1000   -0.0151
   180        2.4699             nan     0.1000   -0.0248
   200        2.3608             nan     0.1000   -0.0187

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7380             nan     0.1000    0.2463
     2        6.4643             nan     0.1000    0.2127
     3        6.1588             nan     0.1000    0.2195
     4        5.9320             nan     0.1000    0.0959
     5        5.7250             nan     0.1000    0.1539
     6        5.5108             nan     0.1000    0.0870
     7        5.3355             nan     0.1000    0.0753
     8        5.1893             nan     0.1000    0.0624
     9        5.0551             nan     0.1000    0.0972
    10        4.9012             nan     0.1000    0.0701
    20        4.1582             nan     0.1000    0.0219
    40        3.4043             nan     0.1000   -0.0241
    60        2.9357             nan     0.1000   -0.0266
    80        2.5475             nan     0.1000   -0.0062
   100        2.2876             nan     0.1000   -0.0024
   120        2.1098             nan     0.1000   -0.0163
   140        1.9610             nan     0.1000   -0.0357
   160        1.8008             nan     0.1000   -0.0165
   180        1.6469             nan     0.1000   -0.0136
   200        1.5332             nan     0.1000   -0.0129

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6532             nan     0.2000    0.3554
     2        6.3771             nan     0.2000    0.1833
     3        6.1636             nan     0.2000    0.1857
     4        6.0003             nan     0.2000    0.1219
     5        5.9452             nan     0.2000   -0.0226
     6        5.8354             nan     0.2000    0.0375
     7        5.7233             nan     0.2000    0.0199
     8        5.6721             nan     0.2000   -0.0264
     9        5.6239             nan     0.2000    0.0020
    10        5.5497             nan     0.2000    0.0183
    20        4.9731             nan     0.2000   -0.0219
    40        4.4398             nan     0.2000   -0.0444
    60        4.2363             nan     0.2000   -0.0246
    80        4.1140             nan     0.2000   -0.0175
   100        4.0387             nan     0.2000   -0.0392
   120        3.9943             nan     0.2000   -0.0317
   140        3.9859             nan     0.2000   -0.0485
   160        3.9319             nan     0.2000   -0.0352
   180        3.9235             nan     0.2000   -0.0692
   200        3.9126             nan     0.2000   -0.0379

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6673             nan     0.2000    0.3722
     2        6.2438             nan     0.2000    0.3726
     3        5.9878             nan     0.2000    0.1515
     4        5.7171             nan     0.2000    0.2263
     5        5.5611             nan     0.2000    0.0795
     6        5.4783             nan     0.2000   -0.0107
     7        5.3469             nan     0.2000    0.0098
     8        5.2758             nan     0.2000   -0.0127
     9        5.1271             nan     0.2000    0.0885
    10        5.0403             nan     0.2000    0.0139
    20        4.3671             nan     0.2000    0.0081
    40        3.8384             nan     0.2000   -0.0211
    60        3.5994             nan     0.2000   -0.0174
    80        3.4205             nan     0.2000   -0.0432
   100        3.2433             nan     0.2000   -0.0525
   120        3.1063             nan     0.2000   -0.0303
   140        2.9536             nan     0.2000   -0.0033
   160        2.8234             nan     0.2000   -0.0349
   180        2.7161             nan     0.2000   -0.0324
   200        2.5757             nan     0.2000   -0.0128

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4611             nan     0.2000    0.5400
     2        6.0682             nan     0.2000    0.2952
     3        5.7192             nan     0.2000    0.2704
     4        5.4168             nan     0.2000    0.1528
     5        5.2365             nan     0.2000    0.0210
     6        5.0252             nan     0.2000    0.1288
     7        4.8978             nan     0.2000    0.0492
     8        4.7574             nan     0.2000    0.0352
     9        4.6487             nan     0.2000   -0.0374
    10        4.5738             nan     0.2000    0.0180
    20        3.9604             nan     0.2000   -0.0602
    40        3.3605             nan     0.2000   -0.0215
    60        3.0044             nan     0.2000   -0.0594
    80        2.7372             nan     0.2000   -0.0437
   100        2.4690             nan     0.2000   -0.0337
   120        2.3086             nan     0.2000   -0.0295
   140        2.0878             nan     0.2000   -0.0111
   160        1.9274             nan     0.2000   -0.0621
   180        1.7996             nan     0.2000   -0.0278
   200        1.6562             nan     0.2000   -0.0132

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.2206             nan     0.2000    0.7019
     2        5.7959             nan     0.2000    0.2427
     3        5.3537             nan     0.2000    0.3170
     4        5.1628             nan     0.2000    0.0615
     5        4.9286             nan     0.2000    0.1100
     6        4.7381             nan     0.2000   -0.0015
     7        4.6043             nan     0.2000    0.0228
     8        4.4582             nan     0.2000   -0.0097
     9        4.3452             nan     0.2000    0.0063
    10        4.1860             nan     0.2000    0.0565
    20        3.5366             nan     0.2000   -0.0080
    40        2.8756             nan     0.2000   -0.0718
    60        2.4183             nan     0.2000   -0.0392
    80        1.9186             nan     0.2000   -0.0047
   100        1.6403             nan     0.2000   -0.0079
   120        1.4532             nan     0.2000   -0.0461
   140        1.2087             nan     0.2000   -0.0193
   160        1.0111             nan     0.2000   -0.0132
   180        0.9153             nan     0.2000   -0.0269
   200        0.7911             nan     0.2000   -0.0223

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2763             nan     0.0500    0.1318
     2        7.1885             nan     0.0500    0.0758
     3        7.0789             nan     0.0500    0.1168
     4        7.0384             nan     0.0500    0.0284
     5        6.9492             nan     0.0500    0.0976
     6        6.8487             nan     0.0500    0.0839
     7        6.7554             nan     0.0500    0.0882
     8        6.6749             nan     0.0500    0.0789
     9        6.6033             nan     0.0500    0.0465
    10        6.5426             nan     0.0500    0.0523
    20        6.0637             nan     0.0500    0.0076
    40        5.4993             nan     0.0500    0.0174
    60        5.1641             nan     0.0500   -0.0009
    80        4.9155             nan     0.0500   -0.0030
   100        4.7255             nan     0.0500    0.0083
   120        4.5518             nan     0.0500   -0.0045
   140        4.4297             nan     0.0500   -0.0079
   160        4.3454             nan     0.0500   -0.0112
   180        4.2762             nan     0.0500   -0.0126
   200        4.2229             nan     0.0500   -0.0033

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2459             nan     0.0500    0.1221
     2        7.0882             nan     0.0500    0.1075
     3        6.9523             nan     0.0500    0.1270
     4        6.8435             nan     0.0500    0.0928
     5        6.7362             nan     0.0500    0.0691
     6        6.6341             nan     0.0500    0.0640
     7        6.5410             nan     0.0500    0.0954
     8        6.4621             nan     0.0500    0.0595
     9        6.3766             nan     0.0500    0.0490
    10        6.2932             nan     0.0500    0.0423
    20        5.6928             nan     0.0500    0.0289
    40        4.9987             nan     0.0500    0.0119
    60        4.5532             nan     0.0500    0.0027
    80        4.2636             nan     0.0500   -0.0024
   100        4.0492             nan     0.0500    0.0007
   120        3.9334             nan     0.0500   -0.0028
   140        3.8407             nan     0.0500   -0.0081
   160        3.7295             nan     0.0500   -0.0127
   180        3.6583             nan     0.0500   -0.0042
   200        3.5712             nan     0.0500   -0.0121

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2066             nan     0.0500    0.1677
     2        7.0491             nan     0.0500    0.1332
     3        6.8977             nan     0.0500    0.1296
     4        6.7665             nan     0.0500    0.1125
     5        6.6173             nan     0.0500    0.1288
     6        6.4971             nan     0.0500    0.1129
     7        6.4001             nan     0.0500    0.0274
     8        6.2755             nan     0.0500    0.0720
     9        6.1927             nan     0.0500    0.0473
    10        6.1016             nan     0.0500    0.0603
    20        5.4412             nan     0.0500    0.0206
    40        4.6206             nan     0.0500   -0.0045
    60        4.1903             nan     0.0500    0.0038
    80        3.9349             nan     0.0500   -0.0093
   100        3.7243             nan     0.0500   -0.0006
   120        3.5597             nan     0.0500   -0.0114
   140        3.4338             nan     0.0500   -0.0076
   160        3.3063             nan     0.0500   -0.0118
   180        3.2044             nan     0.0500   -0.0052
   200        3.0819             nan     0.0500   -0.0125

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2210             nan     0.0500    0.1875
     2        7.0069             nan     0.0500    0.1508
     3        6.8490             nan     0.0500    0.1492
     4        6.6741             nan     0.0500    0.1371
     5        6.5093             nan     0.0500    0.1266
     6        6.3696             nan     0.0500    0.1048
     7        6.2357             nan     0.0500    0.1217
     8        6.1491             nan     0.0500    0.0647
     9        6.0311             nan     0.0500    0.0903
    10        5.9179             nan     0.0500    0.0854
    20        5.0631             nan     0.0500    0.0386
    40        4.1622             nan     0.0500    0.0037
    60        3.6661             nan     0.0500   -0.0028
    80        3.3622             nan     0.0500   -0.0220
   100        3.1474             nan     0.0500   -0.0111
   120        2.9327             nan     0.0500   -0.0141
   140        2.7651             nan     0.0500   -0.0264
   160        2.6104             nan     0.0500   -0.0110
   180        2.4894             nan     0.0500   -0.0077
   200        2.3632             nan     0.0500   -0.0096

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2187             nan     0.1000    0.2300
     2        7.0074             nan     0.1000    0.1802
     3        6.8047             nan     0.1000    0.1810
     4        6.6475             nan     0.1000    0.1737
     5        6.4802             nan     0.1000    0.1294
     6        6.4064             nan     0.1000    0.0500
     7        6.2980             nan     0.1000    0.0832
     8        6.1730             nan     0.1000    0.0872
     9        6.1055             nan     0.1000    0.0321
    10        6.0615             nan     0.1000    0.0218
    20        5.4704             nan     0.1000    0.0069
    40        4.8881             nan     0.1000    0.0097
    60        4.5603             nan     0.1000   -0.0217
    80        4.3858             nan     0.1000   -0.0101
   100        4.2621             nan     0.1000   -0.0189
   120        4.1678             nan     0.1000   -0.0353
   140        4.1113             nan     0.1000   -0.0139
   160        4.0591             nan     0.1000   -0.0056
   180        4.0150             nan     0.1000   -0.0138
   200        3.9955             nan     0.1000   -0.0202

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1610             nan     0.1000    0.2516
     2        6.8582             nan     0.1000    0.1814
     3        6.6243             nan     0.1000    0.2673
     4        6.4036             nan     0.1000    0.2010
     5        6.2868             nan     0.1000    0.0817
     6        6.1579             nan     0.1000    0.0360
     7        6.0116             nan     0.1000    0.1220
     8        5.8787             nan     0.1000    0.0818
     9        5.7787             nan     0.1000    0.0755
    10        5.6547             nan     0.1000    0.0679
    20        4.9983             nan     0.1000    0.0398
    40        4.3105             nan     0.1000   -0.0125
    60        3.9684             nan     0.1000   -0.0226
    80        3.7805             nan     0.1000   -0.0185
   100        3.6219             nan     0.1000   -0.0225
   120        3.5083             nan     0.1000   -0.0514
   140        3.4023             nan     0.1000   -0.0171
   160        3.2864             nan     0.1000   -0.0099
   180        3.2075             nan     0.1000   -0.0115
   200        3.1274             nan     0.1000   -0.0142

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0579             nan     0.1000    0.3061
     2        6.7926             nan     0.1000    0.2752
     3        6.5547             nan     0.1000    0.2135
     4        6.3664             nan     0.1000    0.1713
     5        6.2121             nan     0.1000    0.0485
     6        5.9913             nan     0.1000    0.1426
     7        5.8285             nan     0.1000    0.1641
     8        5.6919             nan     0.1000    0.0742
     9        5.5557             nan     0.1000    0.1050
    10        5.4327             nan     0.1000    0.0773
    20        4.6149             nan     0.1000   -0.0054
    40        3.9595             nan     0.1000   -0.0162
    60        3.6090             nan     0.1000   -0.0229
    80        3.3523             nan     0.1000   -0.0213
   100        3.1352             nan     0.1000   -0.0437
   120        2.9388             nan     0.1000   -0.0189
   140        2.7818             nan     0.1000   -0.0201
   160        2.6311             nan     0.1000   -0.0116
   180        2.5038             nan     0.1000   -0.0222
   200        2.3877             nan     0.1000   -0.0176

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9709             nan     0.1000    0.3543
     2        6.5625             nan     0.1000    0.2334
     3        6.2848             nan     0.1000    0.2279
     4        6.0233             nan     0.1000    0.1524
     5        5.7932             nan     0.1000    0.1900
     6        5.6235             nan     0.1000    0.1551
     7        5.4484             nan     0.1000    0.1002
     8        5.3083             nan     0.1000    0.0768
     9        5.1434             nan     0.1000    0.1228
    10        5.0248             nan     0.1000    0.0519
    20        4.1668             nan     0.1000   -0.0482
    40        3.3551             nan     0.1000   -0.0304
    60        2.9295             nan     0.1000   -0.0248
    80        2.5815             nan     0.1000   -0.0066
   100        2.3226             nan     0.1000   -0.0254
   120        2.1302             nan     0.1000   -0.0366
   140        1.9400             nan     0.1000   -0.0065
   160        1.7704             nan     0.1000   -0.0124
   180        1.6263             nan     0.1000   -0.0113
   200        1.4855             nan     0.1000   -0.0065

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9985             nan     0.2000    0.5026
     2        6.6206             nan     0.2000    0.2255
     3        6.3746             nan     0.2000    0.2653
     4        6.2222             nan     0.2000    0.1244
     5        6.1292             nan     0.2000    0.0377
     6        5.9946             nan     0.2000    0.0160
     7        5.9097             nan     0.2000   -0.0313
     8        5.7716             nan     0.2000    0.1089
     9        5.6538             nan     0.2000    0.0349
    10        5.5921             nan     0.2000   -0.0222
    20        4.9782             nan     0.2000   -0.0306
    40        4.4156             nan     0.2000   -0.0209
    60        4.1635             nan     0.2000   -0.0136
    80        4.0228             nan     0.2000   -0.0223
   100        3.9806             nan     0.2000   -0.0285
   120        3.9312             nan     0.2000   -0.0165
   140        3.9305             nan     0.2000   -0.0307
   160        3.9022             nan     0.2000   -0.0167
   180        3.9066             nan     0.2000   -0.0404
   200        3.8808             nan     0.2000   -0.0154

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8982             nan     0.2000    0.5239
     2        6.4344             nan     0.2000    0.3606
     3        6.1220             nan     0.2000    0.2376
     4        5.8213             nan     0.2000    0.2244
     5        5.6167             nan     0.2000    0.1192
     6        5.4733             nan     0.2000    0.1051
     7        5.3138             nan     0.2000   -0.0028
     8        5.2164             nan     0.2000    0.0573
     9        5.1307             nan     0.2000   -0.0437
    10        5.0156             nan     0.2000    0.0641
    20        4.4165             nan     0.2000   -0.0332
    40        3.8530             nan     0.2000   -0.0284
    60        3.6577             nan     0.2000   -0.0487
    80        3.5014             nan     0.2000   -0.0472
   100        3.3485             nan     0.2000   -0.0264
   120        3.1616             nan     0.2000   -0.0067
   140        2.9859             nan     0.2000   -0.0315
   160        2.8722             nan     0.2000   -0.0081
   180        2.7364             nan     0.2000   -0.0209
   200        2.6310             nan     0.2000   -0.0179

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7960             nan     0.2000    0.5460
     2        6.4091             nan     0.2000    0.2769
     3        5.9498             nan     0.2000    0.3080
     4        5.8058             nan     0.2000   -0.0056
     5        5.6369             nan     0.2000    0.1152
     6        5.3472             nan     0.2000    0.1445
     7        5.1031             nan     0.2000    0.1017
     8        4.9473             nan     0.2000    0.0474
     9        4.8456             nan     0.2000   -0.0384
    10        4.7658             nan     0.2000   -0.0137
    20        4.0459             nan     0.2000   -0.0230
    40        3.5078             nan     0.2000   -0.0264
    60        3.1888             nan     0.2000   -0.0429
    80        2.8654             nan     0.2000   -0.0538
   100        2.5907             nan     0.2000   -0.0355
   120        2.3763             nan     0.2000   -0.0257
   140        2.2042             nan     0.2000   -0.0228
   160        2.0850             nan     0.2000   -0.0381
   180        1.9535             nan     0.2000   -0.0190
   200        1.8263             nan     0.2000   -0.0067

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5278             nan     0.2000    0.7749
     2        6.0958             nan     0.2000    0.2030
     3        5.6677             nan     0.2000    0.3368
     4        5.3675             nan     0.2000    0.1633
     5        5.0773             nan     0.2000    0.2043
     6        4.8402             nan     0.2000    0.0398
     7        4.6383             nan     0.2000    0.1047
     8        4.5354             nan     0.2000   -0.0137
     9        4.3567             nan     0.2000   -0.0395
    10        4.2611             nan     0.2000    0.0219
    20        3.6309             nan     0.2000   -0.0659
    40        2.9449             nan     0.2000   -0.0864
    60        2.4544             nan     0.2000   -0.0671
    80        2.0867             nan     0.2000   -0.0467
   100        1.7605             nan     0.2000   -0.0685
   120        1.5040             nan     0.2000   -0.0293
   140        1.3190             nan     0.2000   -0.0325
   160        1.1577             nan     0.2000   -0.0282
   180        1.0301             nan     0.2000   -0.0260
   200        0.9238             nan     0.2000   -0.0138

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3267             nan     0.0500    0.1005
     2        7.2142             nan     0.0500    0.0896
     3        7.1272             nan     0.0500    0.0892
     4        7.0531             nan     0.0500    0.0395
     5        6.9518             nan     0.0500    0.1064
     6        6.8709             nan     0.0500    0.0819
     7        6.7911             nan     0.0500    0.0632
     8        6.7031             nan     0.0500    0.0707
     9        6.6663             nan     0.0500    0.0128
    10        6.6067             nan     0.0500    0.0444
    20        6.0912             nan     0.0500    0.0190
    40        5.5587             nan     0.0500    0.0089
    60        5.2165             nan     0.0500   -0.0038
    80        4.9806             nan     0.0500   -0.0027
   100        4.7783             nan     0.0500    0.0020
   120        4.6411             nan     0.0500    0.0014
   140        4.5170             nan     0.0500   -0.0066
   160        4.4272             nan     0.0500   -0.0013
   180        4.3625             nan     0.0500   -0.0118
   200        4.3031             nan     0.0500   -0.0060

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3242             nan     0.0500    0.1123
     2        7.1920             nan     0.0500    0.1024
     3        7.0538             nan     0.0500    0.1179
     4        6.9554             nan     0.0500    0.0904
     5        6.8311             nan     0.0500    0.1028
     6        6.7227             nan     0.0500    0.0702
     7        6.6222             nan     0.0500    0.0691
     8        6.5169             nan     0.0500    0.1008
     9        6.4292             nan     0.0500    0.0642
    10        6.3621             nan     0.0500    0.0740
    20        5.7355             nan     0.0500    0.0103
    40        5.0499             nan     0.0500   -0.0049
    60        4.6487             nan     0.0500   -0.0017
    80        4.3930             nan     0.0500    0.0001
   100        4.1942             nan     0.0500   -0.0029
   120        4.0448             nan     0.0500   -0.0126
   140        3.9283             nan     0.0500   -0.0106
   160        3.8337             nan     0.0500   -0.0120
   180        3.7490             nan     0.0500   -0.0127
   200        3.6788             nan     0.0500   -0.0118

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2733             nan     0.0500    0.1714
     2        7.0999             nan     0.0500    0.1411
     3        6.9317             nan     0.0500    0.1429
     4        6.7928             nan     0.0500    0.0841
     5        6.6517             nan     0.0500    0.0783
     6        6.4950             nan     0.0500    0.1266
     7        6.3866             nan     0.0500    0.0756
     8        6.2778             nan     0.0500    0.0860
     9        6.1687             nan     0.0500    0.0793
    10        6.0859             nan     0.0500    0.0788
    20        5.3865             nan     0.0500    0.0318
    40        4.6504             nan     0.0500   -0.0022
    60        4.2459             nan     0.0500    0.0013
    80        3.9510             nan     0.0500   -0.0143
   100        3.7465             nan     0.0500   -0.0171
   120        3.5839             nan     0.0500   -0.0125
   140        3.4240             nan     0.0500   -0.0140
   160        3.3037             nan     0.0500   -0.0130
   180        3.1712             nan     0.0500   -0.0098
   200        3.0902             nan     0.0500   -0.0215

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2436             nan     0.0500    0.1592
     2        7.0584             nan     0.0500    0.1476
     3        6.8580             nan     0.0500    0.1106
     4        6.6754             nan     0.0500    0.1149
     5        6.5414             nan     0.0500    0.1032
     6        6.3833             nan     0.0500    0.1270
     7        6.2651             nan     0.0500    0.0881
     8        6.1450             nan     0.0500    0.1071
     9        6.0312             nan     0.0500    0.0986
    10        5.9150             nan     0.0500    0.0567
    20        5.1027             nan     0.0500    0.0385
    40        4.2864             nan     0.0500   -0.0211
    60        3.8176             nan     0.0500   -0.0185
    80        3.4706             nan     0.0500   -0.0117
   100        3.1949             nan     0.0500   -0.0111
   120        2.9588             nan     0.0500   -0.0121
   140        2.7612             nan     0.0500   -0.0093
   160        2.6119             nan     0.0500   -0.0137
   180        2.4584             nan     0.0500   -0.0068
   200        2.3389             nan     0.0500   -0.0180

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2508             nan     0.1000    0.1430
     2        7.0019             nan     0.1000    0.1809
     3        6.8438             nan     0.1000    0.1461
     4        6.6879             nan     0.1000    0.1507
     5        6.5788             nan     0.1000    0.0749
     6        6.4247             nan     0.1000    0.0987
     7        6.3408             nan     0.1000    0.0457
     8        6.2224             nan     0.1000    0.0832
     9        6.1499             nan     0.1000    0.0815
    10        6.0893             nan     0.1000    0.0519
    20        5.5656             nan     0.1000    0.0126
    40        4.9979             nan     0.1000    0.0157
    60        4.6462             nan     0.1000   -0.0017
    80        4.4632             nan     0.1000   -0.0266
   100        4.3210             nan     0.1000   -0.0023
   120        4.2340             nan     0.1000   -0.0045
   140        4.1737             nan     0.1000   -0.0065
   160        4.1219             nan     0.1000   -0.0061
   180        4.0871             nan     0.1000   -0.0225
   200        4.0490             nan     0.1000   -0.0197

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2026             nan     0.1000    0.2375
     2        6.9610             nan     0.1000    0.2058
     3        6.7251             nan     0.1000    0.2208
     4        6.5356             nan     0.1000    0.1567
     5        6.3798             nan     0.1000    0.1052
     6        6.2175             nan     0.1000    0.1069
     7        6.0773             nan     0.1000    0.0500
     8        5.9726             nan     0.1000    0.0894
     9        5.8696             nan     0.1000    0.0625
    10        5.7652             nan     0.1000    0.0534
    20        5.0153             nan     0.1000    0.0269
    40        4.4153             nan     0.1000   -0.0230
    60        4.0940             nan     0.1000   -0.0205
    80        3.8959             nan     0.1000   -0.0041
   100        3.6638             nan     0.1000   -0.0143
   120        3.5063             nan     0.1000   -0.0183
   140        3.3785             nan     0.1000   -0.0075
   160        3.2785             nan     0.1000   -0.0241
   180        3.1841             nan     0.1000   -0.0192
   200        3.1089             nan     0.1000   -0.0185

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1430             nan     0.1000    0.1870
     2        6.8440             nan     0.1000    0.2517
     3        6.5609             nan     0.1000    0.2633
     4        6.2809             nan     0.1000    0.1563
     5        6.1179             nan     0.1000    0.1118
     6        5.9526             nan     0.1000    0.1375
     7        5.8225             nan     0.1000    0.0447
     8        5.6631             nan     0.1000    0.1361
     9        5.5438             nan     0.1000    0.1025
    10        5.4200             nan     0.1000    0.0939
    20        4.6758             nan     0.1000    0.0049
    40        4.0125             nan     0.1000   -0.0235
    60        3.7112             nan     0.1000   -0.0462
    80        3.4880             nan     0.1000   -0.0193
   100        3.2104             nan     0.1000   -0.0189
   120        3.0310             nan     0.1000   -0.0168
   140        2.8431             nan     0.1000   -0.0138
   160        2.6609             nan     0.1000   -0.0222
   180        2.5366             nan     0.1000   -0.0117
   200        2.4243             nan     0.1000   -0.0212

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0069             nan     0.1000    0.3210
     2        6.6922             nan     0.1000    0.2891
     3        6.4532             nan     0.1000    0.1407
     4        6.2166             nan     0.1000    0.2362
     5        5.9924             nan     0.1000    0.1580
     6        5.7577             nan     0.1000    0.1660
     7        5.6087             nan     0.1000    0.0884
     8        5.4285             nan     0.1000    0.1189
     9        5.2575             nan     0.1000    0.0942
    10        5.1113             nan     0.1000    0.0699
    20        4.3151             nan     0.1000   -0.0473
    40        3.4797             nan     0.1000   -0.0515
    60        3.0669             nan     0.1000   -0.0220
    80        2.7140             nan     0.1000   -0.0292
   100        2.4719             nan     0.1000   -0.0097
   120        2.1969             nan     0.1000   -0.0264
   140        1.9877             nan     0.1000   -0.0241
   160        1.8031             nan     0.1000   -0.0220
   180        1.6524             nan     0.1000   -0.0135
   200        1.4938             nan     0.1000   -0.0101

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9769             nan     0.2000    0.5017
     2        6.6136             nan     0.2000    0.3187
     3        6.4771             nan     0.2000    0.0534
     4        6.2138             nan     0.2000    0.1796
     5        6.0773             nan     0.2000    0.1065
     6        5.8705             nan     0.2000    0.1207
     7        5.7513             nan     0.2000    0.0614
     8        5.7166             nan     0.2000   -0.0403
     9        5.6151             nan     0.2000    0.0557
    10        5.5417             nan     0.2000    0.0390
    20        4.9862             nan     0.2000   -0.0376
    40        4.5173             nan     0.2000   -0.0067
    60        4.3211             nan     0.2000   -0.0182
    80        4.1832             nan     0.2000   -0.0260
   100        4.0722             nan     0.2000   -0.0090
   120        4.0201             nan     0.2000   -0.0221
   140        4.0137             nan     0.2000   -0.0713
   160        3.9655             nan     0.2000   -0.0447
   180        3.9705             nan     0.2000   -0.0146
   200        3.9501             nan     0.2000   -0.0361

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9684             nan     0.2000    0.4523
     2        6.5813             nan     0.2000    0.3071
     3        6.2584             nan     0.2000    0.2831
     4        6.0009             nan     0.2000    0.2895
     5        5.7971             nan     0.2000    0.1780
     6        5.6462             nan     0.2000    0.0143
     7        5.4808             nan     0.2000    0.1484
     8        5.3886             nan     0.2000   -0.0069
     9        5.2742             nan     0.2000    0.0483
    10        5.1615             nan     0.2000    0.0392
    20        4.4918             nan     0.2000   -0.0399
    40        3.9530             nan     0.2000   -0.0047
    60        3.6048             nan     0.2000   -0.0282
    80        3.3758             nan     0.2000   -0.0413
   100        3.2469             nan     0.2000   -0.0560
   120        3.0576             nan     0.2000   -0.0056
   140        2.9293             nan     0.2000   -0.0220
   160        2.8067             nan     0.2000   -0.0209
   180        2.7447             nan     0.2000   -0.0449
   200        2.6006             nan     0.2000   -0.0319

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7350             nan     0.2000    0.6558
     2        6.3017             nan     0.2000    0.3409
     3        5.9325             nan     0.2000    0.2679
     4        5.7114             nan     0.2000    0.1805
     5        5.4521             nan     0.2000    0.0901
     6        5.2362             nan     0.2000    0.1606
     7        5.0957             nan     0.2000    0.0627
     8        4.9160             nan     0.2000    0.0720
     9        4.8238             nan     0.2000    0.0130
    10        4.6945             nan     0.2000    0.0215
    20        4.1130             nan     0.2000   -0.0599
    40        3.4691             nan     0.2000    0.0019
    60        3.0523             nan     0.2000   -0.0389
    80        2.7487             nan     0.2000   -0.0559
   100        2.5105             nan     0.2000   -0.0584
   120        2.3411             nan     0.2000   -0.0363
   140        2.1588             nan     0.2000   -0.0354
   160        1.9768             nan     0.2000   -0.0461
   180        1.8373             nan     0.2000   -0.0303
   200        1.6953             nan     0.2000   -0.0292

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6302             nan     0.2000    0.6104
     2        6.1139             nan     0.2000    0.3776
     3        5.6327             nan     0.2000    0.4213
     4        5.3121             nan     0.2000    0.1257
     5        5.0761             nan     0.2000    0.1330
     6        4.9966             nan     0.2000   -0.1229
     7        4.7280             nan     0.2000   -0.0116
     8        4.5750             nan     0.2000    0.0151
     9        4.4342             nan     0.2000    0.0046
    10        4.3739             nan     0.2000   -0.1263
    20        3.5751             nan     0.2000   -0.0640
    40        2.8248             nan     0.2000    0.0046
    60        2.3721             nan     0.2000   -0.0603
    80        2.0467             nan     0.2000   -0.0232
   100        1.7229             nan     0.2000   -0.0277
   120        1.4625             nan     0.2000   -0.0346
   140        1.2584             nan     0.2000   -0.0273
   160        1.0814             nan     0.2000   -0.0342
   180        0.9649             nan     0.2000   -0.0342
   200        0.8419             nan     0.2000   -0.0243

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3054             nan     0.0500    0.0995
     2        7.2076             nan     0.0500    0.1187
     3        7.0753             nan     0.0500    0.1023
     4        6.9863             nan     0.0500    0.1048
     5        6.8979             nan     0.0500    0.0772
     6        6.8800             nan     0.0500   -0.0071
     7        6.7847             nan     0.0500    0.0870
     8        6.7116             nan     0.0500    0.0590
     9        6.6615             nan     0.0500    0.0445
    10        6.5925             nan     0.0500    0.0601
    20        6.0860             nan     0.0500    0.0161
    40        5.5539             nan     0.0500    0.0209
    60        5.2268             nan     0.0500   -0.0025
    80        4.9550             nan     0.0500    0.0067
   100        4.7609             nan     0.0500   -0.0116
   120        4.6055             nan     0.0500   -0.0067
   140        4.4944             nan     0.0500   -0.0014
   160        4.4131             nan     0.0500    0.0019
   180        4.3442             nan     0.0500   -0.0040
   200        4.2987             nan     0.0500   -0.0039

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3276             nan     0.0500    0.1221
     2        7.1375             nan     0.0500    0.1792
     3        6.9923             nan     0.0500    0.1222
     4        6.8591             nan     0.0500    0.1098
     5        6.7611             nan     0.0500    0.0999
     6        6.6581             nan     0.0500    0.1139
     7        6.5548             nan     0.0500    0.0750
     8        6.4707             nan     0.0500    0.0695
     9        6.3837             nan     0.0500    0.0693
    10        6.3035             nan     0.0500    0.0743
    20        5.6901             nan     0.0500    0.0336
    40        5.0135             nan     0.0500    0.0059
    60        4.6053             nan     0.0500    0.0037
    80        4.3276             nan     0.0500   -0.0059
   100        4.1514             nan     0.0500   -0.0054
   120        4.0178             nan     0.0500   -0.0028
   140        3.9158             nan     0.0500   -0.0092
   160        3.8024             nan     0.0500   -0.0182
   180        3.7258             nan     0.0500   -0.0075
   200        3.6351             nan     0.0500   -0.0055

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2464             nan     0.0500    0.1585
     2        7.0515             nan     0.0500    0.1420
     3        6.9300             nan     0.0500    0.0872
     4        6.8005             nan     0.0500    0.1275
     5        6.6838             nan     0.0500    0.1203
     6        6.6076             nan     0.0500    0.0486
     7        6.4965             nan     0.0500    0.0961
     8        6.3709             nan     0.0500    0.1070
     9        6.2360             nan     0.0500    0.0910
    10        6.1330             nan     0.0500    0.0718
    20        5.4178             nan     0.0500    0.0240
    40        4.6798             nan     0.0500   -0.0047
    60        4.2573             nan     0.0500    0.0017
    80        3.9313             nan     0.0500   -0.0069
   100        3.7485             nan     0.0500   -0.0150
   120        3.5804             nan     0.0500   -0.0249
   140        3.4540             nan     0.0500   -0.0107
   160        3.3262             nan     0.0500   -0.0116
   180        3.2051             nan     0.0500   -0.0050
   200        3.0980             nan     0.0500   -0.0181

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2400             nan     0.0500    0.1786
     2        7.0483             nan     0.0500    0.1591
     3        6.8843             nan     0.0500    0.1396
     4        6.6972             nan     0.0500    0.1393
     5        6.5176             nan     0.0500    0.1555
     6        6.3717             nan     0.0500    0.1197
     7        6.2251             nan     0.0500    0.0845
     8        6.0940             nan     0.0500    0.0567
     9        5.9610             nan     0.0500    0.0652
    10        5.8471             nan     0.0500    0.1061
    20        5.0507             nan     0.0500    0.0287
    40        4.2154             nan     0.0500    0.0071
    60        3.7885             nan     0.0500   -0.0202
    80        3.4510             nan     0.0500   -0.0208
   100        3.1974             nan     0.0500   -0.0214
   120        2.9784             nan     0.0500   -0.0259
   140        2.7985             nan     0.0500   -0.0071
   160        2.6450             nan     0.0500   -0.0070
   180        2.5083             nan     0.0500   -0.0028
   200        2.3626             nan     0.0500   -0.0098

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2280             nan     0.1000    0.1888
     2        7.0070             nan     0.1000    0.1695
     3        6.8580             nan     0.1000    0.1724
     4        6.6899             nan     0.1000    0.1197
     5        6.5520             nan     0.1000    0.1003
     6        6.4612             nan     0.1000    0.0817
     7        6.3373             nan     0.1000    0.0989
     8        6.2380             nan     0.1000    0.0805
     9        6.1770             nan     0.1000    0.0358
    10        6.1164             nan     0.1000    0.0190
    20        5.5831             nan     0.1000    0.0153
    40        4.9647             nan     0.1000   -0.0034
    60        4.6671             nan     0.1000   -0.0251
    80        4.4524             nan     0.1000   -0.0546
   100        4.3162             nan     0.1000   -0.0130
   120        4.2325             nan     0.1000   -0.0037
   140        4.1748             nan     0.1000   -0.0122
   160        4.1511             nan     0.1000   -0.0060
   180        4.1283             nan     0.1000   -0.0153
   200        4.0998             nan     0.1000   -0.0278

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0873             nan     0.1000    0.3459
     2        6.9444             nan     0.1000    0.0429
     3        6.7406             nan     0.1000    0.2164
     4        6.4881             nan     0.1000    0.2210
     5        6.2909             nan     0.1000    0.1533
     6        6.1469             nan     0.1000    0.1174
     7        6.0294             nan     0.1000    0.1081
     8        5.8925             nan     0.1000    0.1303
     9        5.7908             nan     0.1000    0.0298
    10        5.7094             nan     0.1000    0.0319
    20        4.9459             nan     0.1000   -0.0204
    40        4.3208             nan     0.1000   -0.0111
    60        3.9976             nan     0.1000   -0.0194
    80        3.7607             nan     0.1000   -0.0173
   100        3.6140             nan     0.1000   -0.0158
   120        3.4985             nan     0.1000    0.0001
   140        3.3679             nan     0.1000   -0.0222
   160        3.2857             nan     0.1000   -0.0237
   180        3.2139             nan     0.1000   -0.0070
   200        3.1166             nan     0.1000   -0.0220

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1623             nan     0.1000    0.3431
     2        6.8262             nan     0.1000    0.2191
     3        6.5657             nan     0.1000    0.2413
     4        6.3773             nan     0.1000    0.1802
     5        6.1378             nan     0.1000    0.1890
     6        5.9743             nan     0.1000    0.0616
     7        5.8383             nan     0.1000    0.1209
     8        5.6850             nan     0.1000    0.1376
     9        5.5807             nan     0.1000    0.0645
    10        5.4607             nan     0.1000    0.0388
    20        4.6077             nan     0.1000   -0.0244
    40        3.9676             nan     0.1000   -0.0325
    60        3.6070             nan     0.1000   -0.0453
    80        3.3453             nan     0.1000   -0.0276
   100        3.1542             nan     0.1000   -0.0066
   120        2.9666             nan     0.1000   -0.0202
   140        2.8162             nan     0.1000   -0.0273
   160        2.6812             nan     0.1000    0.0005
   180        2.5769             nan     0.1000   -0.0325
   200        2.4916             nan     0.1000   -0.0212

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9722             nan     0.1000    0.4372
     2        6.6140             nan     0.1000    0.3475
     3        6.2828             nan     0.1000    0.2068
     4        6.0390             nan     0.1000    0.2445
     5        5.8180             nan     0.1000    0.0853
     6        5.5801             nan     0.1000    0.0828
     7        5.3903             nan     0.1000    0.0960
     8        5.2239             nan     0.1000    0.0715
     9        5.1002             nan     0.1000    0.0358
    10        4.9535             nan     0.1000    0.0459
    20        4.1927             nan     0.1000    0.0296
    40        3.4345             nan     0.1000   -0.0694
    60        3.0254             nan     0.1000   -0.0346
    80        2.7023             nan     0.1000   -0.0165
   100        2.4739             nan     0.1000   -0.0277
   120        2.2505             nan     0.1000   -0.0098
   140        2.0734             nan     0.1000   -0.0115
   160        1.8602             nan     0.1000   -0.0140
   180        1.6943             nan     0.1000   -0.0154
   200        1.5328             nan     0.1000   -0.0171

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9039             nan     0.2000    0.3280
     2        6.6250             nan     0.2000    0.3005
     3        6.3127             nan     0.2000    0.2192
     4        6.1047             nan     0.2000    0.1980
     5        5.9867             nan     0.2000    0.0856
     6        5.8992             nan     0.2000    0.0203
     7        5.7232             nan     0.2000    0.1009
     8        5.6465             nan     0.2000    0.0383
     9        5.5758             nan     0.2000   -0.0177
    10        5.4549             nan     0.2000    0.0316
    20        4.8937             nan     0.2000    0.0199
    40        4.4310             nan     0.2000   -0.0386
    60        4.2013             nan     0.2000   -0.0337
    80        4.1042             nan     0.2000   -0.0032
   100        4.0858             nan     0.2000   -0.0694
   120        4.0543             nan     0.2000   -0.0419
   140        4.0370             nan     0.2000   -0.0222
   160        4.0281             nan     0.2000   -0.0547
   180        4.0068             nan     0.2000   -0.0282
   200        4.0154             nan     0.2000   -0.0297

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7391             nan     0.2000    0.5288
     2        6.3733             nan     0.2000    0.2968
     3        6.0801             nan     0.2000    0.1985
     4        5.8670             nan     0.2000    0.1442
     5        5.5998             nan     0.2000    0.1804
     6        5.4577             nan     0.2000    0.0494
     7        5.2730             nan     0.2000    0.1400
     8        5.1828             nan     0.2000    0.0561
     9        5.0930             nan     0.2000    0.0119
    10        5.0047             nan     0.2000   -0.0468
    20        4.4268             nan     0.2000   -0.0151
    40        3.9444             nan     0.2000    0.0119
    60        3.6080             nan     0.2000   -0.0236
    80        3.4617             nan     0.2000   -0.0336
   100        3.3120             nan     0.2000   -0.0322
   120        3.1755             nan     0.2000   -0.0709
   140        3.0772             nan     0.2000   -0.0728
   160        2.9302             nan     0.2000   -0.0241
   180        2.8213             nan     0.2000   -0.0543
   200        2.7154             nan     0.2000   -0.0412

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7570             nan     0.2000    0.5192
     2        6.1858             nan     0.2000    0.3862
     3        5.8349             nan     0.2000    0.2192
     4        5.5757             nan     0.2000    0.1409
     5        5.3460             nan     0.2000    0.1026
     6        5.1797             nan     0.2000    0.0813
     7        5.0321             nan     0.2000    0.0253
     8        4.8893             nan     0.2000    0.0796
     9        4.7565             nan     0.2000    0.0470
    10        4.6358             nan     0.2000   -0.0297
    20        4.0997             nan     0.2000   -0.0677
    40        3.4204             nan     0.2000   -0.0332
    60        3.0568             nan     0.2000   -0.0582
    80        2.7749             nan     0.2000   -0.0613
   100        2.5302             nan     0.2000   -0.0586
   120        2.3164             nan     0.2000   -0.0405
   140        2.1927             nan     0.2000   -0.0415
   160        1.9801             nan     0.2000   -0.0418
   180        1.8789             nan     0.2000   -0.0260
   200        1.7442             nan     0.2000   -0.0020

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6495             nan     0.2000    0.5417
     2        6.2694             nan     0.2000    0.1068
     3        5.7713             nan     0.2000    0.2794
     4        5.4168             nan     0.2000    0.1903
     5        5.0676             nan     0.2000    0.2641
     6        4.8255             nan     0.2000    0.1058
     7        4.7520             nan     0.2000   -0.0732
     8        4.5353             nan     0.2000    0.0731
     9        4.4240             nan     0.2000    0.0395
    10        4.2889             nan     0.2000   -0.0599
    20        3.5648             nan     0.2000   -0.0338
    40        2.7698             nan     0.2000   -0.0133
    60        2.1972             nan     0.2000   -0.0378
    80        1.7941             nan     0.2000   -0.0316
   100        1.4810             nan     0.2000   -0.0319
   120        1.2351             nan     0.2000   -0.0247
   140        1.0210             nan     0.2000   -0.0114
   160        0.8777             nan     0.2000   -0.0300
   180        0.7718             nan     0.2000   -0.0209
   200        0.6808             nan     0.2000   -0.0142

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2736             nan     0.0500    0.1294
     2        7.1822             nan     0.0500    0.0881
     3        7.0924             nan     0.0500    0.0983
     4        6.9817             nan     0.0500    0.1235
     5        6.8861             nan     0.0500    0.0843
     6        6.8066             nan     0.0500    0.0677
     7        6.6976             nan     0.0500    0.0585
     8        6.6257             nan     0.0500    0.0703
     9        6.5567             nan     0.0500    0.0603
    10        6.4820             nan     0.0500    0.0611
    20        5.9983             nan     0.0500    0.0500
    40        5.4797             nan     0.0500   -0.0019
    60        5.1555             nan     0.0500    0.0038
    80        4.9165             nan     0.0500   -0.0034
   100        4.7210             nan     0.0500   -0.0026
   120        4.5667             nan     0.0500   -0.0037
   140        4.4663             nan     0.0500   -0.0043
   160        4.3852             nan     0.0500   -0.0038
   180        4.3027             nan     0.0500   -0.0095
   200        4.2437             nan     0.0500   -0.0049

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2252             nan     0.0500    0.1334
     2        7.1054             nan     0.0500    0.1478
     3        6.9679             nan     0.0500    0.0771
     4        6.8795             nan     0.0500    0.0884
     5        6.7656             nan     0.0500    0.0982
     6        6.6302             nan     0.0500    0.1208
     7        6.5372             nan     0.0500    0.0872
     8        6.4439             nan     0.0500    0.0693
     9        6.3430             nan     0.0500    0.0602
    10        6.2650             nan     0.0500    0.0791
    20        5.6047             nan     0.0500    0.0392
    40        4.9777             nan     0.0500    0.0052
    60        4.5786             nan     0.0500   -0.0082
    80        4.3033             nan     0.0500   -0.0054
   100        4.0767             nan     0.0500   -0.0043
   120        3.9495             nan     0.0500   -0.0144
   140        3.8203             nan     0.0500   -0.0025
   160        3.7174             nan     0.0500   -0.0105
   180        3.6226             nan     0.0500   -0.0091
   200        3.5375             nan     0.0500   -0.0084

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2201             nan     0.0500    0.1598
     2        7.0278             nan     0.0500    0.1447
     3        6.8444             nan     0.0500    0.1461
     4        6.6979             nan     0.0500    0.1134
     5        6.5934             nan     0.0500    0.0959
     6        6.4787             nan     0.0500    0.1069
     7        6.3715             nan     0.0500    0.0842
     8        6.2572             nan     0.0500    0.0793
     9        6.1389             nan     0.0500    0.0648
    10        6.0459             nan     0.0500    0.0662
    20        5.3607             nan     0.0500    0.0400
    40        4.6300             nan     0.0500   -0.0074
    60        4.2020             nan     0.0500   -0.0076
    80        3.9346             nan     0.0500   -0.0155
   100        3.7254             nan     0.0500    0.0009
   120        3.5660             nan     0.0500   -0.0098
   140        3.4368             nan     0.0500   -0.0222
   160        3.3057             nan     0.0500   -0.0144
   180        3.1632             nan     0.0500   -0.0003
   200        3.0450             nan     0.0500   -0.0115

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2128             nan     0.0500    0.1214
     2        7.0075             nan     0.0500    0.1941
     3        6.8454             nan     0.0500    0.1544
     4        6.6754             nan     0.0500    0.1228
     5        6.4926             nan     0.0500    0.1553
     6        6.3545             nan     0.0500    0.1014
     7        6.2340             nan     0.0500    0.0653
     8        6.1467             nan     0.0500    0.0370
     9        6.0125             nan     0.0500    0.1044
    10        5.9181             nan     0.0500    0.0784
    20        5.0895             nan     0.0500    0.0474
    40        4.2127             nan     0.0500    0.0025
    60        3.7472             nan     0.0500   -0.0062
    80        3.4111             nan     0.0500   -0.0122
   100        3.1422             nan     0.0500   -0.0129
   120        2.9272             nan     0.0500   -0.0026
   140        2.7230             nan     0.0500   -0.0021
   160        2.6030             nan     0.0500   -0.0087
   180        2.4635             nan     0.0500   -0.0074
   200        2.3286             nan     0.0500   -0.0079

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1887             nan     0.1000    0.1908
     2        6.9414             nan     0.1000    0.1806
     3        6.7233             nan     0.1000    0.2045
     4        6.5700             nan     0.1000    0.1154
     5        6.4226             nan     0.1000    0.1405
     6        6.3371             nan     0.1000   -0.0165
     7        6.2399             nan     0.1000    0.0449
     8        6.1574             nan     0.1000    0.0994
     9        6.0556             nan     0.1000    0.0917
    10        5.9654             nan     0.1000    0.0446
    20        5.4899             nan     0.1000    0.0433
    40        4.9597             nan     0.1000    0.0116
    60        4.6346             nan     0.1000   -0.0091
    80        4.4378             nan     0.1000    0.0016
   100        4.3078             nan     0.1000   -0.0123
   120        4.2259             nan     0.1000   -0.0176
   140        4.1550             nan     0.1000   -0.0123
   160        4.1185             nan     0.1000   -0.0232
   180        4.0615             nan     0.1000   -0.0121
   200        4.0410             nan     0.1000   -0.0123

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0229             nan     0.1000    0.3422
     2        6.7749             nan     0.1000    0.2458
     3        6.5589             nan     0.1000    0.2054
     4        6.3867             nan     0.1000    0.1263
     5        6.2088             nan     0.1000    0.1034
     6        6.0316             nan     0.1000    0.0569
     7        5.8930             nan     0.1000    0.1123
     8        5.7887             nan     0.1000    0.0178
     9        5.6827             nan     0.1000    0.0712
    10        5.6045             nan     0.1000    0.0268
    20        4.9463             nan     0.1000   -0.0041
    40        4.2457             nan     0.1000   -0.0242
    60        3.9662             nan     0.1000   -0.0296
    80        3.7716             nan     0.1000   -0.0081
   100        3.6265             nan     0.1000   -0.0160
   120        3.4732             nan     0.1000   -0.0139
   140        3.3719             nan     0.1000   -0.0052
   160        3.2829             nan     0.1000   -0.0180
   180        3.2013             nan     0.1000   -0.0333
   200        3.1183             nan     0.1000   -0.0014

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0687             nan     0.1000    0.3014
     2        6.7495             nan     0.1000    0.3528
     3        6.4830             nan     0.1000    0.2745
     4        6.2273             nan     0.1000    0.1671
     5        6.0095             nan     0.1000    0.1548
     6        5.8540             nan     0.1000    0.1016
     7        5.7281             nan     0.1000    0.0473
     8        5.6019             nan     0.1000    0.0998
     9        5.4803             nan     0.1000    0.0703
    10        5.3577             nan     0.1000    0.0878
    20        4.6688             nan     0.1000    0.0134
    40        4.0151             nan     0.1000    0.0045
    60        3.6555             nan     0.1000   -0.0510
    80        3.3971             nan     0.1000   -0.0470
   100        3.1727             nan     0.1000   -0.0257
   120        2.9908             nan     0.1000   -0.0295
   140        2.8395             nan     0.1000   -0.0265
   160        2.6886             nan     0.1000   -0.0211
   180        2.5619             nan     0.1000   -0.0241
   200        2.4449             nan     0.1000   -0.0208

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9963             nan     0.1000    0.3362
     2        6.6381             nan     0.1000    0.2874
     3        6.3081             nan     0.1000    0.2146
     4        6.0670             nan     0.1000    0.1869
     5        5.8159             nan     0.1000    0.1817
     6        5.6224             nan     0.1000    0.1679
     7        5.4527             nan     0.1000    0.0471
     8        5.2877             nan     0.1000    0.1222
     9        5.1672             nan     0.1000    0.0560
    10        5.0510             nan     0.1000    0.0545
    20        4.1541             nan     0.1000    0.0020
    40        3.4260             nan     0.1000   -0.0139
    60        2.9842             nan     0.1000   -0.0402
    80        2.6560             nan     0.1000   -0.0163
   100        2.3757             nan     0.1000   -0.0230
   120        2.1665             nan     0.1000   -0.0243
   140        1.9394             nan     0.1000   -0.0201
   160        1.7668             nan     0.1000   -0.0171
   180        1.6183             nan     0.1000   -0.0163
   200        1.4902             nan     0.1000   -0.0081

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8384             nan     0.2000    0.3919
     2        6.4598             nan     0.2000    0.2914
     3        6.2348             nan     0.2000    0.2358
     4        6.0759             nan     0.2000    0.1239
     5        5.9660             nan     0.2000    0.0128
     6        5.8340             nan     0.2000    0.1113
     7        5.7011             nan     0.2000    0.0597
     8        5.6220             nan     0.2000    0.0515
     9        5.5411             nan     0.2000    0.0616
    10        5.4466             nan     0.2000   -0.0337
    20        4.9282             nan     0.2000    0.0048
    40        4.3829             nan     0.2000   -0.0036
    60        4.1815             nan     0.2000   -0.0119
    80        4.1061             nan     0.2000   -0.0278
   100        4.0874             nan     0.2000   -0.0617
   120        4.0307             nan     0.2000   -0.0112
   140        3.9914             nan     0.2000   -0.0383
   160        3.9713             nan     0.2000   -0.0443
   180        3.9307             nan     0.2000   -0.0138
   200        3.9442             nan     0.2000   -0.0571

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8768             nan     0.2000    0.6036
     2        6.4459             nan     0.2000    0.3827
     3        6.0671             nan     0.2000    0.1832
     4        5.8637             nan     0.2000    0.1611
     5        5.6176             nan     0.2000    0.1835
     6        5.4088             nan     0.2000    0.1667
     7        5.2481             nan     0.2000    0.0400
     8        5.1294             nan     0.2000    0.0042
     9        5.0466             nan     0.2000    0.0086
    10        4.9315             nan     0.2000    0.0327
    20        4.2840             nan     0.2000   -0.0018
    40        3.8020             nan     0.2000   -0.0346
    60        3.4567             nan     0.2000   -0.0356
    80        3.2595             nan     0.2000   -0.0484
   100        3.1298             nan     0.2000   -0.0348
   120        2.9824             nan     0.2000   -0.0162
   140        2.8475             nan     0.2000   -0.0195
   160        2.7979             nan     0.2000   -0.0464
   180        2.6800             nan     0.2000   -0.0339
   200        2.5218             nan     0.2000   -0.0440

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7606             nan     0.2000    0.4931
     2        6.2030             nan     0.2000    0.3721
     3        5.8917             nan     0.2000    0.2785
     4        5.5718             nan     0.2000    0.1656
     5        5.3845             nan     0.2000    0.1254
     6        5.1860             nan     0.2000    0.0958
     7        5.0355             nan     0.2000    0.0504
     8        4.9379             nan     0.2000   -0.0056
     9        4.8213             nan     0.2000    0.0212
    10        4.7353             nan     0.2000    0.0256
    20        4.1476             nan     0.2000    0.0177
    40        3.4774             nan     0.2000   -0.0676
    60        3.0634             nan     0.2000   -0.0557
    80        2.7405             nan     0.2000   -0.0118
   100        2.5328             nan     0.2000   -0.0373
   120        2.2711             nan     0.2000   -0.0318
   140        2.0700             nan     0.2000   -0.0309
   160        1.8494             nan     0.2000   -0.0205
   180        1.7162             nan     0.2000   -0.0165
   200        1.6138             nan     0.2000   -0.0241

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5479             nan     0.2000    0.7900
     2        6.0590             nan     0.2000    0.3572
     3        5.6432             nan     0.2000    0.1524
     4        5.3741             nan     0.2000    0.1298
     5        5.1198             nan     0.2000    0.1196
     6        4.8600             nan     0.2000    0.1532
     7        4.6986             nan     0.2000   -0.0249
     8        4.5275             nan     0.2000    0.0975
     9        4.3575             nan     0.2000    0.0183
    10        4.2459             nan     0.2000    0.0001
    20        3.5419             nan     0.2000   -0.0460
    40        2.9142             nan     0.2000   -0.1180
    60        2.3823             nan     0.2000   -0.0205
    80        2.0014             nan     0.2000   -0.0331
   100        1.6640             nan     0.2000   -0.0170
   120        1.4171             nan     0.2000   -0.0478
   140        1.2307             nan     0.2000   -0.0494
   160        1.0437             nan     0.2000   -0.0343
   180        0.9016             nan     0.2000   -0.0186
   200        0.7874             nan     0.2000   -0.0169

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9627             nan     0.0500    0.1005
     2        6.8947             nan     0.0500    0.0741
     3        6.8040             nan     0.0500    0.0820
     4        6.7153             nan     0.0500    0.0786
     5        6.6347             nan     0.0500    0.0753
     6        6.5663             nan     0.0500    0.0558
     7        6.5280             nan     0.0500    0.0158
     8        6.4672             nan     0.0500    0.0556
     9        6.4121             nan     0.0500    0.0448
    10        6.3616             nan     0.0500    0.0200
    20        5.9514             nan     0.0500    0.0184
    40        5.4318             nan     0.0500    0.0129
    60        5.1363             nan     0.0500   -0.0057
    80        4.8907             nan     0.0500   -0.0124
   100        4.7166             nan     0.0500    0.0010
   120        4.5913             nan     0.0500   -0.0093
   140        4.4752             nan     0.0500   -0.0011
   160        4.3837             nan     0.0500   -0.0103
   180        4.3219             nan     0.0500   -0.0046
   200        4.2704             nan     0.0500   -0.0042

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9184             nan     0.0500    0.1167
     2        6.7870             nan     0.0500    0.0814
     3        6.6564             nan     0.0500    0.1238
     4        6.5788             nan     0.0500    0.0735
     5        6.4916             nan     0.0500    0.0589
     6        6.3976             nan     0.0500    0.0563
     7        6.3078             nan     0.0500    0.0534
     8        6.2113             nan     0.0500    0.0361
     9        6.1377             nan     0.0500    0.0437
    10        6.0636             nan     0.0500    0.0561
    20        5.5213             nan     0.0500    0.0283
    40        4.9086             nan     0.0500    0.0076
    60        4.5589             nan     0.0500   -0.0197
    80        4.3147             nan     0.0500   -0.0040
   100        4.1181             nan     0.0500   -0.0065
   120        3.9719             nan     0.0500   -0.0086
   140        3.8760             nan     0.0500   -0.0096
   160        3.7834             nan     0.0500   -0.0081
   180        3.7065             nan     0.0500   -0.0076
   200        3.6325             nan     0.0500   -0.0070

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9091             nan     0.0500    0.0915
     2        6.7582             nan     0.0500    0.1057
     3        6.6400             nan     0.0500    0.1109
     4        6.4987             nan     0.0500    0.0773
     5        6.3914             nan     0.0500    0.0869
     6        6.2819             nan     0.0500    0.0995
     7        6.1779             nan     0.0500    0.0674
     8        6.0886             nan     0.0500    0.0759
     9        5.9830             nan     0.0500    0.0756
    10        5.8825             nan     0.0500    0.0780
    20        5.2983             nan     0.0500    0.0179
    40        4.6169             nan     0.0500    0.0149
    60        4.2204             nan     0.0500   -0.0064
    80        3.9760             nan     0.0500   -0.0181
   100        3.7809             nan     0.0500   -0.0093
   120        3.6136             nan     0.0500   -0.0008
   140        3.4640             nan     0.0500    0.0017
   160        3.3399             nan     0.0500   -0.0025
   180        3.2237             nan     0.0500   -0.0035
   200        3.1162             nan     0.0500   -0.0094

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8821             nan     0.0500    0.1093
     2        6.7230             nan     0.0500    0.1098
     3        6.5758             nan     0.0500    0.0935
     4        6.4094             nan     0.0500    0.1003
     5        6.2721             nan     0.0500    0.1046
     6        6.1654             nan     0.0500    0.0863
     7        6.0651             nan     0.0500    0.0860
     8        5.9348             nan     0.0500    0.0821
     9        5.8263             nan     0.0500    0.0935
    10        5.7269             nan     0.0500    0.0528
    20        5.0181             nan     0.0500    0.0003
    40        4.2233             nan     0.0500    0.0162
    60        3.7229             nan     0.0500   -0.0067
    80        3.4111             nan     0.0500   -0.0166
   100        3.1419             nan     0.0500   -0.0150
   120        2.9375             nan     0.0500   -0.0106
   140        2.7578             nan     0.0500   -0.0181
   160        2.5847             nan     0.0500   -0.0074
   180        2.4383             nan     0.0500   -0.0193
   200        2.3118             nan     0.0500   -0.0050

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8827             nan     0.1000    0.1590
     2        6.7094             nan     0.1000    0.1679
     3        6.5561             nan     0.1000    0.1566
     4        6.4256             nan     0.1000    0.1158
     5        6.3364             nan     0.1000    0.0653
     6        6.2383             nan     0.1000    0.1029
     7        6.1407             nan     0.1000    0.0913
     8        6.0598             nan     0.1000    0.0696
     9        6.0141             nan     0.1000    0.0281
    10        5.9415             nan     0.1000    0.0676
    20        5.4670             nan     0.1000    0.0097
    40        4.9118             nan     0.1000    0.0094
    60        4.6145             nan     0.1000    0.0083
    80        4.4315             nan     0.1000   -0.0036
   100        4.2878             nan     0.1000   -0.0204
   120        4.2101             nan     0.1000   -0.0279
   140        4.1471             nan     0.1000   -0.0214
   160        4.1073             nan     0.1000   -0.0082
   180        4.0565             nan     0.1000   -0.0123
   200        4.0190             nan     0.1000   -0.0070

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8531             nan     0.1000    0.1883
     2        6.6251             nan     0.1000    0.1703
     3        6.3995             nan     0.1000    0.1496
     4        6.2271             nan     0.1000    0.1263
     5        6.0878             nan     0.1000    0.1346
     6        5.9399             nan     0.1000    0.1370
     7        5.8294             nan     0.1000    0.0670
     8        5.6935             nan     0.1000    0.0791
     9        5.5954             nan     0.1000    0.0776
    10        5.5192             nan     0.1000    0.0332
    20        4.8502             nan     0.1000    0.0015
    40        4.3250             nan     0.1000   -0.0403
    60        4.0831             nan     0.1000   -0.0226
    80        3.8626             nan     0.1000   -0.0173
   100        3.7066             nan     0.1000   -0.0399
   120        3.5691             nan     0.1000   -0.0152
   140        3.4708             nan     0.1000   -0.0212
   160        3.3515             nan     0.1000   -0.0179
   180        3.2749             nan     0.1000   -0.0224
   200        3.1914             nan     0.1000   -0.0074

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8038             nan     0.1000    0.2329
     2        6.5474             nan     0.1000    0.1936
     3        6.2820             nan     0.1000    0.1884
     4        6.0654             nan     0.1000    0.1511
     5        5.9073             nan     0.1000    0.1100
     6        5.8175             nan     0.1000    0.0447
     7        5.7031             nan     0.1000    0.0561
     8        5.5392             nan     0.1000    0.1134
     9        5.4294             nan     0.1000    0.0712
    10        5.3383             nan     0.1000    0.0376
    20        4.6333             nan     0.1000    0.0175
    40        4.0002             nan     0.1000   -0.0328
    60        3.6307             nan     0.1000   -0.0306
    80        3.3886             nan     0.1000   -0.0502
   100        3.1934             nan     0.1000   -0.0245
   120        2.9932             nan     0.1000   -0.0276
   140        2.8436             nan     0.1000   -0.0190
   160        2.7176             nan     0.1000   -0.0147
   180        2.5537             nan     0.1000   -0.0115
   200        2.4314             nan     0.1000   -0.0176

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7256             nan     0.1000    0.2830
     2        6.4538             nan     0.1000    0.1749
     3        6.1798             nan     0.1000    0.2426
     4        5.9418             nan     0.1000    0.2112
     5        5.7295             nan     0.1000    0.1603
     6        5.5415             nan     0.1000    0.1387
     7        5.3953             nan     0.1000    0.1201
     8        5.2432             nan     0.1000    0.0969
     9        5.1348             nan     0.1000    0.0245
    10        5.0301             nan     0.1000    0.0391
    20        4.2357             nan     0.1000   -0.0040
    40        3.4355             nan     0.1000   -0.0170
    60        2.9525             nan     0.1000   -0.0064
    80        2.6142             nan     0.1000   -0.0040
   100        2.3422             nan     0.1000   -0.0096
   120        2.0903             nan     0.1000   -0.0221
   140        1.9135             nan     0.1000   -0.0243
   160        1.7621             nan     0.1000   -0.0185
   180        1.6000             nan     0.1000   -0.0119
   200        1.4697             nan     0.1000   -0.0191

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6913             nan     0.2000    0.3003
     2        6.3835             nan     0.2000    0.3055
     3        6.1852             nan     0.2000    0.1855
     4        6.0300             nan     0.2000    0.1250
     5        5.8504             nan     0.2000    0.1555
     6        5.7200             nan     0.2000    0.0741
     7        5.6424             nan     0.2000    0.0361
     8        5.5596             nan     0.2000    0.0192
     9        5.4701             nan     0.2000    0.0115
    10        5.4034             nan     0.2000    0.0099
    20        4.8619             nan     0.2000    0.0421
    40        4.4006             nan     0.2000    0.0114
    60        4.2167             nan     0.2000   -0.0350
    80        4.0943             nan     0.2000   -0.0280
   100        3.9837             nan     0.2000   -0.0288
   120        3.9493             nan     0.2000   -0.0300
   140        3.9469             nan     0.2000   -0.0198
   160        3.9319             nan     0.2000   -0.0145
   180        3.9540             nan     0.2000   -0.0195
   200        3.9292             nan     0.2000   -0.0107

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5316             nan     0.2000    0.5280
     2        6.2085             nan     0.2000    0.2176
     3        5.9584             nan     0.2000    0.2615
     4        5.6997             nan     0.2000    0.2095
     5        5.5406             nan     0.2000    0.1190
     6        5.4012             nan     0.2000    0.0689
     7        5.3007             nan     0.2000    0.0593
     8        5.1709             nan     0.2000    0.0292
     9        5.0256             nan     0.2000    0.0230
    10        4.9190             nan     0.2000   -0.0137
    20        4.3232             nan     0.2000   -0.0237
    40        3.8345             nan     0.2000   -0.0667
    60        3.5715             nan     0.2000   -0.0022
    80        3.4311             nan     0.2000   -0.0385
   100        3.2249             nan     0.2000   -0.0448
   120        3.1208             nan     0.2000   -0.0331
   140        2.9434             nan     0.2000   -0.0427
   160        2.8140             nan     0.2000   -0.0315
   180        2.6981             nan     0.2000   -0.0406
   200        2.5866             nan     0.2000   -0.0549

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6123             nan     0.2000    0.4164
     2        6.0099             nan     0.2000    0.4486
     3        5.7530             nan     0.2000    0.1871
     4        5.5624             nan     0.2000    0.1211
     5        5.3269             nan     0.2000    0.1807
     6        5.1313             nan     0.2000    0.0777
     7        4.9820             nan     0.2000    0.0911
     8        4.8830             nan     0.2000   -0.0400
     9        4.7660             nan     0.2000    0.0464
    10        4.6454             nan     0.2000    0.0066
    20        4.0145             nan     0.2000   -0.0246
    40        3.4509             nan     0.2000   -0.0489
    60        3.0372             nan     0.2000   -0.0148
    80        2.6900             nan     0.2000   -0.0239
   100        2.4801             nan     0.2000   -0.0507
   120        2.2862             nan     0.2000   -0.0292
   140        2.0912             nan     0.2000   -0.0191
   160        1.9222             nan     0.2000   -0.0340
   180        1.7920             nan     0.2000   -0.0292
   200        1.6572             nan     0.2000   -0.0257

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3873             nan     0.2000    0.5012
     2        5.8204             nan     0.2000    0.4526
     3        5.4650             nan     0.2000    0.2199
     4        5.2268             nan     0.2000    0.0129
     5        4.9575             nan     0.2000    0.1349
     6        4.7816             nan     0.2000    0.0604
     7        4.6128             nan     0.2000   -0.0022
     8        4.5185             nan     0.2000    0.0242
     9        4.3702             nan     0.2000    0.0252
    10        4.2820             nan     0.2000   -0.0251
    20        3.5715             nan     0.2000   -0.0384
    40        2.9072             nan     0.2000   -0.0454
    60        2.3974             nan     0.2000   -0.0541
    80        2.0312             nan     0.2000   -0.0461
   100        1.7428             nan     0.2000   -0.0650
   120        1.4413             nan     0.2000   -0.0488
   140        1.2123             nan     0.2000   -0.0278
   160        1.0360             nan     0.2000   -0.0305
   180        0.8951             nan     0.2000   -0.0210
   200        0.7957             nan     0.2000   -0.0183

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1126             nan     0.0500    0.1105
     2        7.0001             nan     0.0500    0.1114
     3        6.9094             nan     0.0500    0.0926
     4        6.8333             nan     0.0500    0.0815
     5        6.7467             nan     0.0500    0.0889
     6        6.6512             nan     0.0500    0.0611
     7        6.5912             nan     0.0500    0.0508
     8        6.5246             nan     0.0500    0.0508
     9        6.4773             nan     0.0500    0.0409
    10        6.4161             nan     0.0500    0.0513
    20        5.9792             nan     0.0500    0.0345
    40        5.4632             nan     0.0500    0.0065
    60        5.1316             nan     0.0500    0.0039
    80        4.8890             nan     0.0500    0.0012
   100        4.7107             nan     0.0500   -0.0037
   120        4.5702             nan     0.0500   -0.0003
   140        4.4582             nan     0.0500   -0.0073
   160        4.3770             nan     0.0500   -0.0078
   180        4.3154             nan     0.0500   -0.0021
   200        4.2690             nan     0.0500   -0.0136

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1172             nan     0.0500    0.1216
     2        6.9710             nan     0.0500    0.1224
     3        6.8595             nan     0.0500    0.1049
     4        6.7399             nan     0.0500    0.1006
     5        6.6325             nan     0.0500    0.0703
     6        6.5639             nan     0.0500    0.0712
     7        6.4809             nan     0.0500    0.0556
     8        6.4135             nan     0.0500    0.0527
     9        6.3786             nan     0.0500    0.0071
    10        6.2910             nan     0.0500    0.0488
    20        5.6422             nan     0.0500    0.0324
    40        4.9826             nan     0.0500   -0.0076
    60        4.5906             nan     0.0500    0.0039
    80        4.3256             nan     0.0500   -0.0118
   100        4.1431             nan     0.0500   -0.0109
   120        4.0159             nan     0.0500   -0.0150
   140        3.8885             nan     0.0500   -0.0008
   160        3.7730             nan     0.0500   -0.0070
   180        3.6752             nan     0.0500   -0.0031
   200        3.6181             nan     0.0500   -0.0130

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0699             nan     0.0500    0.1304
     2        6.9195             nan     0.0500    0.1202
     3        6.7755             nan     0.0500    0.1248
     4        6.6449             nan     0.0500    0.1150
     5        6.5227             nan     0.0500    0.1058
     6        6.4198             nan     0.0500    0.1051
     7        6.2901             nan     0.0500    0.0778
     8        6.2022             nan     0.0500    0.0766
     9        6.0972             nan     0.0500    0.0863
    10        6.0138             nan     0.0500    0.0621
    20        5.3335             nan     0.0500    0.0317
    40        4.6009             nan     0.0500    0.0034
    60        4.1529             nan     0.0500    0.0079
    80        3.8956             nan     0.0500    0.0019
   100        3.6878             nan     0.0500   -0.0102
   120        3.5372             nan     0.0500   -0.0086
   140        3.4278             nan     0.0500   -0.0039
   160        3.3226             nan     0.0500   -0.0155
   180        3.2233             nan     0.0500   -0.0142
   200        3.1271             nan     0.0500   -0.0159

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0352             nan     0.0500    0.1432
     2        6.8658             nan     0.0500    0.1503
     3        6.6884             nan     0.0500    0.1267
     4        6.5410             nan     0.0500    0.1007
     5        6.3795             nan     0.0500    0.1022
     6        6.2450             nan     0.0500    0.1257
     7        6.0892             nan     0.0500    0.1165
     8        5.9802             nan     0.0500    0.0564
     9        5.8592             nan     0.0500    0.1033
    10        5.7373             nan     0.0500    0.0836
    20        4.9382             nan     0.0500    0.0501
    40        4.1319             nan     0.0500   -0.0145
    60        3.6931             nan     0.0500   -0.0108
    80        3.3962             nan     0.0500   -0.0064
   100        3.1583             nan     0.0500   -0.0058
   120        2.9611             nan     0.0500   -0.0321
   140        2.7658             nan     0.0500   -0.0146
   160        2.6245             nan     0.0500   -0.0059
   180        2.4966             nan     0.0500   -0.0066
   200        2.3810             nan     0.0500   -0.0072

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9656             nan     0.1000    0.2018
     2        6.8822             nan     0.1000    0.0545
     3        6.7444             nan     0.1000    0.1649
     4        6.5829             nan     0.1000    0.1029
     5        6.4473             nan     0.1000    0.0976
     6        6.3103             nan     0.1000    0.0582
     7        6.2225             nan     0.1000    0.0658
     8        6.1197             nan     0.1000    0.0894
     9        6.0882             nan     0.1000    0.0088
    10        6.0079             nan     0.1000    0.0714
    20        5.4946             nan     0.1000    0.0363
    40        4.9039             nan     0.1000   -0.0078
    60        4.6032             nan     0.1000   -0.0100
    80        4.4227             nan     0.1000   -0.0170
   100        4.2811             nan     0.1000   -0.0124
   120        4.2161             nan     0.1000   -0.0106
   140        4.1778             nan     0.1000   -0.0086
   160        4.1463             nan     0.1000   -0.0049
   180        4.1020             nan     0.1000   -0.0235
   200        4.0858             nan     0.1000   -0.0081

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9003             nan     0.1000    0.2842
     2        6.6962             nan     0.1000    0.2072
     3        6.5055             nan     0.1000    0.1582
     4        6.3352             nan     0.1000    0.1137
     5        6.1503             nan     0.1000    0.1040
     6        6.0102             nan     0.1000    0.0690
     7        5.9016             nan     0.1000    0.0715
     8        5.7957             nan     0.1000    0.0680
     9        5.7411             nan     0.1000    0.0099
    10        5.6133             nan     0.1000    0.0843
    20        4.9212             nan     0.1000   -0.0138
    40        4.2264             nan     0.1000   -0.0281
    60        3.9621             nan     0.1000   -0.0092
    80        3.8013             nan     0.1000   -0.0214
   100        3.6370             nan     0.1000   -0.0280
   120        3.5175             nan     0.1000   -0.0110
   140        3.4088             nan     0.1000   -0.0157
   160        3.3278             nan     0.1000   -0.0130
   180        3.2451             nan     0.1000   -0.0211
   200        3.1662             nan     0.1000   -0.0216

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8990             nan     0.1000    0.2684
     2        6.6276             nan     0.1000    0.1756
     3        6.3983             nan     0.1000    0.1514
     4        6.1986             nan     0.1000    0.1384
     5        6.0106             nan     0.1000    0.1566
     6        5.8296             nan     0.1000    0.1079
     7        5.6691             nan     0.1000    0.1138
     8        5.5267             nan     0.1000    0.0835
     9        5.4256             nan     0.1000    0.0286
    10        5.3087             nan     0.1000    0.0587
    20        4.5917             nan     0.1000   -0.0189
    40        4.0289             nan     0.1000   -0.0428
    60        3.7174             nan     0.1000   -0.0294
    80        3.4263             nan     0.1000   -0.0139
   100        3.2282             nan     0.1000   -0.0278
   120        3.0494             nan     0.1000   -0.0225
   140        2.8674             nan     0.1000   -0.0211
   160        2.7185             nan     0.1000   -0.0273
   180        2.5756             nan     0.1000   -0.0119
   200        2.4135             nan     0.1000   -0.0187

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9049             nan     0.1000    0.3241
     2        6.5665             nan     0.1000    0.2144
     3        6.2832             nan     0.1000    0.1750
     4        6.0837             nan     0.1000    0.1416
     5        5.8604             nan     0.1000    0.1596
     6        5.6554             nan     0.1000    0.1343
     7        5.4639             nan     0.1000    0.1574
     8        5.2913             nan     0.1000    0.1127
     9        5.1697             nan     0.1000    0.0618
    10        5.0507             nan     0.1000    0.0374
    20        4.1986             nan     0.1000   -0.0026
    40        3.4679             nan     0.1000   -0.0404
    60        3.0749             nan     0.1000   -0.0196
    80        2.7980             nan     0.1000   -0.0321
   100        2.4766             nan     0.1000   -0.0195
   120        2.2161             nan     0.1000   -0.0207
   140        2.0087             nan     0.1000   -0.0195
   160        1.8426             nan     0.1000   -0.0366
   180        1.6918             nan     0.1000   -0.0184
   200        1.5545             nan     0.1000   -0.0107

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8530             nan     0.2000    0.4401
     2        6.5266             nan     0.2000    0.2058
     3        6.3310             nan     0.2000    0.1214
     4        6.0984             nan     0.2000    0.2070
     5        5.9122             nan     0.2000    0.1433
     6        5.7975             nan     0.2000    0.0630
     7        5.7108             nan     0.2000    0.0565
     8        5.6273             nan     0.2000    0.0299
     9        5.5165             nan     0.2000    0.0625
    10        5.4764             nan     0.2000   -0.0399
    20        4.9001             nan     0.2000   -0.0032
    40        4.3722             nan     0.2000   -0.0973
    60        4.2053             nan     0.2000   -0.0277
    80        4.1283             nan     0.2000   -0.0271
   100        4.0901             nan     0.2000   -0.0147
   120        4.0645             nan     0.2000   -0.0346
   140        4.0500             nan     0.2000   -0.0101
   160        4.0219             nan     0.2000   -0.0305
   180        4.0106             nan     0.2000   -0.0457
   200        3.9868             nan     0.2000   -0.0204

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6449             nan     0.2000    0.4555
     2        6.2283             nan     0.2000    0.2866
     3        6.0120             nan     0.2000    0.0842
     4        5.8032             nan     0.2000    0.1201
     5        5.6222             nan     0.2000    0.1091
     6        5.5092             nan     0.2000    0.0028
     7        5.3721             nan     0.2000    0.0654
     8        5.1995             nan     0.2000    0.0976
     9        5.0578             nan     0.2000    0.0256
    10        4.9970             nan     0.2000   -0.0095
    20        4.3305             nan     0.2000   -0.0301
    40        3.8917             nan     0.2000   -0.0683
    60        3.6256             nan     0.2000   -0.0393
    80        3.3573             nan     0.2000   -0.0414
   100        3.1999             nan     0.2000   -0.0500
   120        3.0708             nan     0.2000   -0.0389
   140        2.9485             nan     0.2000   -0.0589
   160        2.8183             nan     0.2000   -0.0278
   180        2.7177             nan     0.2000   -0.0474
   200        2.5950             nan     0.2000   -0.0366

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6734             nan     0.2000    0.5402
     2        6.2612             nan     0.2000    0.3259
     3        5.8301             nan     0.2000    0.3906
     4        5.6359             nan     0.2000    0.0727
     5        5.3550             nan     0.2000    0.1324
     6        5.1979             nan     0.2000    0.0968
     7        5.0345             nan     0.2000   -0.0702
     8        4.8689             nan     0.2000    0.0574
     9        4.7482             nan     0.2000    0.0061
    10        4.6491             nan     0.2000    0.0501
    20        4.0182             nan     0.2000   -0.0527
    40        3.3397             nan     0.2000   -0.0287
    60        3.0604             nan     0.2000   -0.0260
    80        2.7358             nan     0.2000   -0.0281
   100        2.5440             nan     0.2000   -0.0457
   120        2.3575             nan     0.2000   -0.0476
   140        2.2027             nan     0.2000   -0.0162
   160        2.0218             nan     0.2000   -0.0531
   180        1.8636             nan     0.2000   -0.0450
   200        1.7226             nan     0.2000   -0.0033

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4475             nan     0.2000    0.4415
     2        5.9551             nan     0.2000    0.3851
     3        5.5562             nan     0.2000    0.1701
     4        5.1973             nan     0.2000    0.2713
     5        4.8784             nan     0.2000    0.0673
     6        4.6773             nan     0.2000    0.0617
     7        4.5067             nan     0.2000    0.0664
     8        4.3635             nan     0.2000    0.0585
     9        4.2435             nan     0.2000   -0.0651
    10        4.1508             nan     0.2000   -0.0173
    20        3.4831             nan     0.2000   -0.0366
    40        2.7549             nan     0.2000   -0.0339
    60        2.3029             nan     0.2000   -0.0537
    80        1.8925             nan     0.2000   -0.0326
   100        1.5870             nan     0.2000   -0.0227
   120        1.3571             nan     0.2000   -0.0234
   140        1.1872             nan     0.2000   -0.0161
   160        1.0200             nan     0.2000   -0.0280
   180        0.8742             nan     0.2000   -0.0152
   200        0.7736             nan     0.2000   -0.0129

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1712             nan     0.0500    0.0728
     2        7.1228             nan     0.0500    0.0276
     3        7.0319             nan     0.0500    0.1056
     4        6.9366             nan     0.0500    0.1140
     5        6.8649             nan     0.0500    0.0638
     6        6.8081             nan     0.0500    0.0609
     7        6.7301             nan     0.0500    0.0883
     8        6.6635             nan     0.0500    0.0595
     9        6.5978             nan     0.0500    0.0597
    10        6.5302             nan     0.0500    0.0521
    20        6.1424             nan     0.0500    0.0153
    40        5.6328             nan     0.0500    0.0126
    60        5.2917             nan     0.0500    0.0007
    80        5.0322             nan     0.0500   -0.0101
   100        4.8335             nan     0.0500    0.0041
   120        4.6918             nan     0.0500   -0.0059
   140        4.5877             nan     0.0500   -0.0073
   160        4.4780             nan     0.0500   -0.0029
   180        4.4032             nan     0.0500   -0.0018
   200        4.3335             nan     0.0500   -0.0038

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1304             nan     0.0500    0.0969
     2        7.0135             nan     0.0500    0.0915
     3        6.9164             nan     0.0500    0.0893
     4        6.8094             nan     0.0500    0.1188
     5        6.7046             nan     0.0500    0.0701
     6        6.6025             nan     0.0500    0.1067
     7        6.5329             nan     0.0500    0.0777
     8        6.4433             nan     0.0500    0.0649
     9        6.3534             nan     0.0500    0.0680
    10        6.2913             nan     0.0500    0.0650
    20        5.6948             nan     0.0500    0.0062
    40        5.0352             nan     0.0500   -0.0010
    60        4.6081             nan     0.0500   -0.0030
    80        4.3387             nan     0.0500   -0.0012
   100        4.1190             nan     0.0500   -0.0087
   120        3.9682             nan     0.0500   -0.0090
   140        3.8435             nan     0.0500   -0.0058
   160        3.7541             nan     0.0500   -0.0240
   180        3.6822             nan     0.0500   -0.0105
   200        3.6121             nan     0.0500   -0.0117

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1038             nan     0.0500    0.1105
     2        6.9679             nan     0.0500    0.0855
     3        6.8346             nan     0.0500    0.1239
     4        6.6876             nan     0.0500    0.1037
     5        6.5621             nan     0.0500    0.1217
     6        6.4606             nan     0.0500    0.0694
     7        6.3563             nan     0.0500    0.0861
     8        6.2474             nan     0.0500    0.0776
     9        6.1698             nan     0.0500    0.0654
    10        6.1100             nan     0.0500    0.0493
    20        5.4949             nan     0.0500    0.0370
    40        4.7006             nan     0.0500    0.0001
    60        4.2682             nan     0.0500   -0.0013
    80        3.9433             nan     0.0500   -0.0022
   100        3.7318             nan     0.0500   -0.0065
   120        3.5650             nan     0.0500   -0.0042
   140        3.4367             nan     0.0500   -0.0039
   160        3.3098             nan     0.0500    0.0004
   180        3.1813             nan     0.0500   -0.0094
   200        3.0926             nan     0.0500   -0.0075

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0616             nan     0.0500    0.1522
     2        6.9165             nan     0.0500    0.1432
     3        6.7697             nan     0.0500    0.1232
     4        6.6242             nan     0.0500    0.1202
     5        6.5025             nan     0.0500    0.0986
     6        6.3628             nan     0.0500    0.1112
     7        6.2386             nan     0.0500    0.1149
     8        6.1392             nan     0.0500    0.0980
     9        6.0378             nan     0.0500    0.0751
    10        5.9474             nan     0.0500    0.0612
    20        5.1443             nan     0.0500    0.0432
    40        4.2601             nan     0.0500    0.0020
    60        3.7695             nan     0.0500   -0.0158
    80        3.4420             nan     0.0500   -0.0093
   100        3.1874             nan     0.0500   -0.0177
   120        2.9954             nan     0.0500   -0.0177
   140        2.7982             nan     0.0500   -0.0113
   160        2.6404             nan     0.0500   -0.0247
   180        2.4920             nan     0.0500   -0.0132
   200        2.3456             nan     0.0500   -0.0137

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0671             nan     0.1000    0.1545
     2        6.8708             nan     0.1000    0.1002
     3        6.7300             nan     0.1000    0.1404
     4        6.6002             nan     0.1000    0.1131
     5        6.4538             nan     0.1000    0.1097
     6        6.4012             nan     0.1000   -0.0287
     7        6.3322             nan     0.1000    0.0653
     8        6.2652             nan     0.1000    0.0764
     9        6.2053             nan     0.1000    0.0241
    10        6.1295             nan     0.1000    0.0725
    20        5.6260             nan     0.1000    0.0278
    40        4.9924             nan     0.1000    0.0054
    60        4.6748             nan     0.1000   -0.0175
    80        4.5079             nan     0.1000   -0.0077
   100        4.3597             nan     0.1000   -0.0251
   120        4.2574             nan     0.1000   -0.0177
   140        4.1957             nan     0.1000   -0.0184
   160        4.1406             nan     0.1000   -0.0233
   180        4.1028             nan     0.1000   -0.0108
   200        4.0559             nan     0.1000   -0.0079

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9773             nan     0.1000    0.2669
     2        6.7569             nan     0.1000    0.2080
     3        6.6205             nan     0.1000   -0.0073
     4        6.4372             nan     0.1000    0.1683
     5        6.2776             nan     0.1000    0.0952
     6        6.0718             nan     0.1000    0.1272
     7        5.9618             nan     0.1000    0.0610
     8        5.8688             nan     0.1000    0.0481
     9        5.7442             nan     0.1000    0.0923
    10        5.6529             nan     0.1000    0.0496
    20        5.0384             nan     0.1000    0.0081
    40        4.4184             nan     0.1000   -0.0089
    60        4.0161             nan     0.1000   -0.0095
    80        3.8229             nan     0.1000   -0.0080
   100        3.6634             nan     0.1000   -0.0062
   120        3.5310             nan     0.1000   -0.0189
   140        3.4335             nan     0.1000   -0.0122
   160        3.3395             nan     0.1000   -0.0107
   180        3.2653             nan     0.1000   -0.0183
   200        3.1977             nan     0.1000   -0.0133

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9434             nan     0.1000    0.1811
     2        6.7110             nan     0.1000    0.1583
     3        6.4489             nan     0.1000    0.2051
     4        6.2543             nan     0.1000    0.1321
     5        6.0845             nan     0.1000    0.1320
     6        5.9661             nan     0.1000    0.0675
     7        5.8342             nan     0.1000    0.1086
     8        5.7545             nan     0.1000    0.0294
     9        5.6123             nan     0.1000    0.0890
    10        5.4616             nan     0.1000    0.0932
    20        4.6941             nan     0.1000   -0.0275
    40        3.9587             nan     0.1000   -0.0300
    60        3.5774             nan     0.1000   -0.0141
    80        3.2904             nan     0.1000   -0.0141
   100        3.0800             nan     0.1000   -0.0120
   120        2.8905             nan     0.1000   -0.0295
   140        2.7497             nan     0.1000   -0.0201
   160        2.6306             nan     0.1000   -0.0325
   180        2.5071             nan     0.1000   -0.0268
   200        2.3625             nan     0.1000   -0.0184

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8561             nan     0.1000    0.3381
     2        6.5410             nan     0.1000    0.2350
     3        6.2719             nan     0.1000    0.1388
     4        5.9885             nan     0.1000    0.1387
     5        5.7967             nan     0.1000    0.1200
     6        5.6106             nan     0.1000    0.0532
     7        5.4684             nan     0.1000    0.0832
     8        5.3287             nan     0.1000    0.1064
     9        5.1995             nan     0.1000    0.0687
    10        5.1056             nan     0.1000    0.0032
    20        4.2788             nan     0.1000   -0.0164
    40        3.4350             nan     0.1000   -0.0293
    60        2.9780             nan     0.1000   -0.0284
    80        2.6702             nan     0.1000   -0.0300
   100        2.3642             nan     0.1000   -0.0141
   120        2.1552             nan     0.1000   -0.0143
   140        1.9672             nan     0.1000   -0.0037
   160        1.8147             nan     0.1000   -0.0293
   180        1.6519             nan     0.1000   -0.0310
   200        1.5241             nan     0.1000   -0.0220

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8814             nan     0.2000    0.3041
     2        6.6223             nan     0.2000    0.2835
     3        6.4949             nan     0.2000    0.0583
     4        6.2460             nan     0.2000    0.1430
     5        6.1224             nan     0.2000    0.0939
     6        5.9407             nan     0.2000    0.1773
     7        5.9081             nan     0.2000   -0.0714
     8        5.8577             nan     0.2000    0.0238
     9        5.7905             nan     0.2000    0.0100
    10        5.6782             nan     0.2000    0.0444
    20        5.0676             nan     0.2000    0.0561
    40        4.5174             nan     0.2000   -0.0359
    60        4.3056             nan     0.2000   -0.0305
    80        4.1754             nan     0.2000   -0.0019
   100        4.1079             nan     0.2000   -0.0388
   120        4.0727             nan     0.2000   -0.0351
   140        4.0714             nan     0.2000   -0.0537
   160        4.0091             nan     0.2000   -0.0350
   180        4.0008             nan     0.2000   -0.0127
   200        3.9943             nan     0.2000   -0.0179

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7977             nan     0.2000    0.3137
     2        6.3089             nan     0.2000    0.4080
     3        6.0360             nan     0.2000    0.2111
     4        5.8095             nan     0.2000    0.1647
     5        5.5677             nan     0.2000    0.0732
     6        5.3934             nan     0.2000    0.0298
     7        5.2968             nan     0.2000    0.0306
     8        5.2265             nan     0.2000   -0.0196
     9        5.1370             nan     0.2000    0.0459
    10        5.0233             nan     0.2000   -0.0141
    20        4.3973             nan     0.2000   -0.0387
    40        3.8769             nan     0.2000   -0.0385
    60        3.6074             nan     0.2000   -0.0557
    80        3.4274             nan     0.2000   -0.0367
   100        3.2497             nan     0.2000   -0.0492
   120        3.0679             nan     0.2000   -0.0332
   140        2.9280             nan     0.2000   -0.0341
   160        2.8243             nan     0.2000   -0.0240
   180        2.7511             nan     0.2000   -0.0282
   200        2.6387             nan     0.2000   -0.0448

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7314             nan     0.2000    0.5173
     2        6.2385             nan     0.2000    0.4126
     3        5.8790             nan     0.2000    0.3247
     4        5.5647             nan     0.2000    0.2327
     5        5.3663             nan     0.2000    0.1055
     6        5.2412             nan     0.2000    0.0298
     7        5.0990             nan     0.2000    0.0128
     8        4.9929             nan     0.2000    0.0245
     9        4.8703             nan     0.2000    0.0459
    10        4.7438             nan     0.2000    0.0461
    20        4.1148             nan     0.2000   -0.0601
    40        3.4747             nan     0.2000   -0.0483
    60        3.1071             nan     0.2000   -0.0362
    80        2.7994             nan     0.2000   -0.0414
   100        2.5219             nan     0.2000   -0.0188
   120        2.3012             nan     0.2000   -0.0297
   140        2.1457             nan     0.2000   -0.0351
   160        2.0134             nan     0.2000   -0.0078
   180        1.8757             nan     0.2000   -0.0548
   200        1.7753             nan     0.2000   -0.0379

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4937             nan     0.2000    0.6012
     2        6.0247             nan     0.2000    0.2259
     3        5.6036             nan     0.2000    0.3067
     4        5.3227             nan     0.2000    0.2308
     5        5.1416             nan     0.2000    0.1213
     6        4.9081             nan     0.2000    0.1447
     7        4.7765             nan     0.2000   -0.0027
     8        4.6505             nan     0.2000   -0.0002
     9        4.5043             nan     0.2000   -0.0189
    10        4.4128             nan     0.2000   -0.0802
    20        3.5942             nan     0.2000   -0.0533
    40        2.7758             nan     0.2000   -0.0714
    60        2.2930             nan     0.2000   -0.0381
    80        1.9268             nan     0.2000   -0.0312
   100        1.6608             nan     0.2000   -0.0521
   120        1.4676             nan     0.2000   -0.0372
   140        1.2477             nan     0.2000   -0.0340
   160        1.0653             nan     0.2000   -0.0286
   180        0.9232             nan     0.2000   -0.0092
   200        0.8178             nan     0.2000   -0.0203

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0873             nan     0.0500    0.0972
     2        6.9725             nan     0.0500    0.0938
     3        6.8921             nan     0.0500    0.0943
     4        6.8019             nan     0.0500    0.0548
     5        6.7179             nan     0.0500    0.0783
     6        6.6174             nan     0.0500    0.0685
     7        6.5482             nan     0.0500    0.0655
     8        6.4904             nan     0.0500    0.0463
     9        6.4275             nan     0.0500    0.0518
    10        6.3728             nan     0.0500    0.0571
    20        6.0036             nan     0.0500    0.0145
    40        5.4614             nan     0.0500    0.0140
    60        5.1003             nan     0.0500   -0.0001
    80        4.8455             nan     0.0500    0.0092
   100        4.6513             nan     0.0500   -0.0085
   120        4.5037             nan     0.0500   -0.0134
   140        4.4056             nan     0.0500   -0.0092
   160        4.3415             nan     0.0500   -0.0044
   180        4.2717             nan     0.0500   -0.0054
   200        4.2117             nan     0.0500   -0.0022

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0224             nan     0.0500    0.1484
     2        6.8851             nan     0.0500    0.0925
     3        6.7776             nan     0.0500    0.1207
     4        6.6664             nan     0.0500    0.0839
     5        6.5798             nan     0.0500    0.0706
     6        6.4637             nan     0.0500    0.0766
     7        6.3630             nan     0.0500    0.0813
     8        6.2947             nan     0.0500    0.0527
     9        6.2014             nan     0.0500    0.0606
    10        6.1303             nan     0.0500    0.0318
    20        5.5436             nan     0.0500    0.0373
    40        4.8898             nan     0.0500    0.0110
    60        4.5218             nan     0.0500    0.0020
    80        4.2886             nan     0.0500   -0.0026
   100        4.0959             nan     0.0500   -0.0096
   120        3.9561             nan     0.0500   -0.0049
   140        3.8479             nan     0.0500   -0.0127
   160        3.7530             nan     0.0500   -0.0149
   180        3.6872             nan     0.0500   -0.0067
   200        3.6063             nan     0.0500   -0.0077

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0106             nan     0.0500    0.1413
     2        6.8451             nan     0.0500    0.1068
     3        6.6811             nan     0.0500    0.1499
     4        6.5605             nan     0.0500    0.1186
     5        6.4418             nan     0.0500    0.0500
     6        6.3726             nan     0.0500    0.0226
     7        6.2780             nan     0.0500    0.0797
     8        6.1576             nan     0.0500    0.0981
     9        6.0709             nan     0.0500    0.0644
    10        5.9768             nan     0.0500    0.0623
    20        5.3061             nan     0.0500    0.0479
    40        4.5963             nan     0.0500    0.0016
    60        4.2003             nan     0.0500    0.0021
    80        3.9279             nan     0.0500   -0.0072
   100        3.7212             nan     0.0500   -0.0062
   120        3.5773             nan     0.0500   -0.0091
   140        3.4428             nan     0.0500   -0.0136
   160        3.3172             nan     0.0500   -0.0028
   180        3.2175             nan     0.0500   -0.0131
   200        3.1165             nan     0.0500   -0.0047

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9900             nan     0.0500    0.1256
     2        6.8398             nan     0.0500    0.0682
     3        6.6634             nan     0.0500    0.1496
     4        6.4693             nan     0.0500    0.1403
     5        6.3219             nan     0.0500    0.1265
     6        6.1890             nan     0.0500    0.1045
     7        6.0561             nan     0.0500    0.1003
     8        5.9331             nan     0.0500    0.0668
     9        5.8239             nan     0.0500    0.0842
    10        5.7168             nan     0.0500    0.0372
    20        4.9318             nan     0.0500    0.0371
    40        4.1462             nan     0.0500    0.0091
    60        3.6666             nan     0.0500    0.0005
    80        3.3568             nan     0.0500   -0.0198
   100        3.1087             nan     0.0500   -0.0292
   120        2.8979             nan     0.0500   -0.0012
   140        2.7254             nan     0.0500   -0.0120
   160        2.5619             nan     0.0500   -0.0113
   180        2.4134             nan     0.0500   -0.0141
   200        2.2904             nan     0.0500   -0.0158

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0083             nan     0.1000    0.2029
     2        6.8064             nan     0.1000    0.1926
     3        6.6449             nan     0.1000    0.1427
     4        6.5335             nan     0.1000    0.1288
     5        6.3883             nan     0.1000    0.1010
     6        6.2781             nan     0.1000    0.0565
     7        6.1746             nan     0.1000    0.0939
     8        6.0962             nan     0.1000   -0.0314
     9        6.0276             nan     0.1000    0.0653
    10        5.9748             nan     0.1000   -0.0207
    20        5.4787             nan     0.1000   -0.0203
    40        4.8277             nan     0.1000    0.0038
    60        4.5138             nan     0.1000    0.0056
    80        4.3138             nan     0.1000   -0.0142
   100        4.2073             nan     0.1000   -0.0159
   120        4.1159             nan     0.1000   -0.0142
   140        4.0657             nan     0.1000   -0.0174
   160        4.0345             nan     0.1000   -0.0091
   180        4.0002             nan     0.1000   -0.0263
   200        3.9743             nan     0.1000   -0.0162

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9418             nan     0.1000    0.2027
     2        6.6967             nan     0.1000    0.2374
     3        6.4752             nan     0.1000    0.1964
     4        6.2850             nan     0.1000    0.1726
     5        6.1449             nan     0.1000    0.0625
     6        5.9934             nan     0.1000    0.1192
     7        5.8632             nan     0.1000    0.1023
     8        5.7518             nan     0.1000    0.0588
     9        5.6373             nan     0.1000    0.0937
    10        5.5570             nan     0.1000    0.0586
    20        4.9138             nan     0.1000    0.0228
    40        4.2692             nan     0.1000    0.0037
    60        4.0033             nan     0.1000   -0.0279
    80        3.7858             nan     0.1000   -0.0164
   100        3.6773             nan     0.1000   -0.0037
   120        3.5304             nan     0.1000   -0.0074
   140        3.4478             nan     0.1000   -0.0246
   160        3.3144             nan     0.1000   -0.0198
   180        3.2265             nan     0.1000   -0.0207
   200        3.1318             nan     0.1000   -0.0103

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8932             nan     0.1000    0.2335
     2        6.5723             nan     0.1000    0.3018
     3        6.3583             nan     0.1000    0.2062
     4        6.1208             nan     0.1000    0.1079
     5        5.9667             nan     0.1000    0.1312
     6        5.8038             nan     0.1000    0.1101
     7        5.6762             nan     0.1000    0.0240
     8        5.5692             nan     0.1000    0.0747
     9        5.4128             nan     0.1000    0.0914
    10        5.2896             nan     0.1000    0.0804
    20        4.4970             nan     0.1000    0.0281
    40        3.8711             nan     0.1000   -0.0168
    60        3.5395             nan     0.1000   -0.0166
    80        3.3309             nan     0.1000   -0.0339
   100        3.1413             nan     0.1000   -0.0235
   120        3.0144             nan     0.1000   -0.0219
   140        2.8508             nan     0.1000   -0.0120
   160        2.6888             nan     0.1000   -0.0134
   180        2.5710             nan     0.1000   -0.0185
   200        2.4526             nan     0.1000   -0.0265

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7320             nan     0.1000    0.3759
     2        6.3857             nan     0.1000    0.3512
     3        6.1445             nan     0.1000    0.1597
     4        5.9104             nan     0.1000    0.1809
     5        5.7150             nan     0.1000    0.1328
     6        5.5537             nan     0.1000    0.0878
     7        5.4413             nan     0.1000    0.0316
     8        5.2866             nan     0.1000    0.0641
     9        5.1801             nan     0.1000    0.0578
    10        5.0797             nan     0.1000    0.0579
    20        4.2426             nan     0.1000   -0.0334
    40        3.4468             nan     0.1000   -0.0309
    60        3.0380             nan     0.1000   -0.0373
    80        2.7220             nan     0.1000   -0.0235
   100        2.4324             nan     0.1000   -0.0194
   120        2.2284             nan     0.1000   -0.0241
   140        2.0394             nan     0.1000   -0.0159
   160        1.8764             nan     0.1000   -0.0148
   180        1.7016             nan     0.1000   -0.0129
   200        1.5813             nan     0.1000   -0.0161

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7708             nan     0.2000    0.3450
     2        6.4599             nan     0.2000    0.2337
     3        6.1941             nan     0.2000    0.2508
     4        6.0556             nan     0.2000    0.0952
     5        5.8968             nan     0.2000    0.1150
     6        5.7416             nan     0.2000    0.0636
     7        5.6578             nan     0.2000    0.0407
     8        5.5375             nan     0.2000    0.0585
     9        5.4560             nan     0.2000    0.0412
    10        5.3704             nan     0.2000    0.0214
    20        4.8894             nan     0.2000   -0.0166
    40        4.3879             nan     0.2000   -0.0118
    60        4.1215             nan     0.2000   -0.0135
    80        4.0342             nan     0.2000   -0.0348
   100        3.9699             nan     0.2000   -0.0265
   120        3.9554             nan     0.2000   -0.0370
   140        3.9069             nan     0.2000   -0.0358
   160        3.8855             nan     0.2000   -0.0291
   180        3.8708             nan     0.2000   -0.0184
   200        3.8665             nan     0.2000   -0.0252

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7388             nan     0.2000    0.4171
     2        6.4151             nan     0.2000    0.1843
     3        6.0068             nan     0.2000    0.3311
     4        5.7648             nan     0.2000    0.2162
     5        5.5535             nan     0.2000    0.1240
     6        5.4631             nan     0.2000   -0.0095
     7        5.2774             nan     0.2000    0.1475
     8        5.1513             nan     0.2000    0.0024
     9        4.9816             nan     0.2000    0.0637
    10        4.8975             nan     0.2000   -0.0728
    20        4.2803             nan     0.2000   -0.0078
    40        3.7759             nan     0.2000   -0.1014
    60        3.5295             nan     0.2000   -0.0385
    80        3.2964             nan     0.2000   -0.0555
   100        3.1870             nan     0.2000   -0.0749
   120        3.0456             nan     0.2000   -0.0437
   140        2.8900             nan     0.2000   -0.0329
   160        2.7812             nan     0.2000   -0.0279
   180        2.6612             nan     0.2000   -0.0324
   200        2.5727             nan     0.2000   -0.0266

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5876             nan     0.2000    0.6400
     2        6.1225             nan     0.2000    0.3674
     3        5.7524             nan     0.2000    0.1913
     4        5.5278             nan     0.2000    0.1621
     5        5.3343             nan     0.2000    0.0845
     6        5.1605             nan     0.2000    0.0016
     7        4.9757             nan     0.2000    0.0907
     8        4.8733             nan     0.2000    0.0362
     9        4.7813             nan     0.2000   -0.0148
    10        4.7094             nan     0.2000    0.0166
    20        4.1195             nan     0.2000   -0.0918
    40        3.4848             nan     0.2000   -0.0526
    60        3.0784             nan     0.2000   -0.0428
    80        2.7491             nan     0.2000   -0.0280
   100        2.4743             nan     0.2000   -0.0371
   120        2.2638             nan     0.2000   -0.0238
   140        2.0802             nan     0.2000   -0.0243
   160        1.9271             nan     0.2000   -0.0517
   180        1.8115             nan     0.2000   -0.0256
   200        1.6901             nan     0.2000   -0.0425

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3912             nan     0.2000    0.6275
     2        5.8065             nan     0.2000    0.5944
     3        5.4635             nan     0.2000    0.0693
     4        5.1927             nan     0.2000    0.0857
     5        4.9790             nan     0.2000   -0.0202
     6        4.8073             nan     0.2000    0.0386
     7        4.6398             nan     0.2000    0.0076
     8        4.5286             nan     0.2000   -0.0489
     9        4.3871             nan     0.2000   -0.0066
    10        4.2617             nan     0.2000    0.0433
    20        3.5270             nan     0.2000   -0.0652
    40        2.8154             nan     0.2000   -0.0460
    60        2.3283             nan     0.2000   -0.0255
    80        2.0194             nan     0.2000   -0.0693
   100        1.6954             nan     0.2000   -0.0153
   120        1.4215             nan     0.2000   -0.0296
   140        1.2143             nan     0.2000   -0.0385
   160        1.0569             nan     0.2000   -0.0347
   180        0.9199             nan     0.2000   -0.0106
   200        0.7960             nan     0.2000   -0.0171

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0404             nan     0.0500    0.1357
     2        6.9305             nan     0.0500    0.1124
     3        6.8233             nan     0.0500    0.0917
     4        6.7167             nan     0.0500    0.0635
     5        6.6194             nan     0.0500    0.0534
     6        6.5219             nan     0.0500    0.0985
     7        6.4485             nan     0.0500    0.0712
     8        6.4109             nan     0.0500    0.0178
     9        6.3344             nan     0.0500    0.0725
    10        6.2815             nan     0.0500    0.0318
    20        5.8284             nan     0.0500    0.0266
    40        5.3132             nan     0.0500    0.0115
    60        4.9419             nan     0.0500   -0.0143
    80        4.6864             nan     0.0500    0.0017
   100        4.4892             nan     0.0500   -0.0072
   120        4.3398             nan     0.0500    0.0002
   140        4.2415             nan     0.0500   -0.0060
   160        4.1631             nan     0.0500   -0.0047
   180        4.0859             nan     0.0500   -0.0002
   200        4.0266             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9850             nan     0.0500    0.1187
     2        6.8701             nan     0.0500    0.1175
     3        6.7506             nan     0.0500    0.0954
     4        6.6198             nan     0.0500    0.1073
     5        6.5250             nan     0.0500    0.0825
     6        6.4198             nan     0.0500    0.0892
     7        6.3260             nan     0.0500    0.0500
     8        6.2314             nan     0.0500    0.0849
     9        6.1527             nan     0.0500    0.0437
    10        6.0506             nan     0.0500    0.1062
    20        5.4614             nan     0.0500    0.0427
    40        4.7337             nan     0.0500   -0.0166
    60        4.3438             nan     0.0500   -0.0197
    80        4.0860             nan     0.0500   -0.0018
   100        3.8895             nan     0.0500   -0.0038
   120        3.7550             nan     0.0500   -0.0052
   140        3.6596             nan     0.0500   -0.0144
   160        3.5779             nan     0.0500   -0.0127
   180        3.5006             nan     0.0500   -0.0044
   200        3.4210             nan     0.0500   -0.0084

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9583             nan     0.0500    0.1709
     2        6.8094             nan     0.0500    0.1418
     3        6.6419             nan     0.0500    0.1014
     4        6.5418             nan     0.0500    0.0936
     5        6.4107             nan     0.0500    0.0414
     6        6.3166             nan     0.0500    0.0569
     7        6.2018             nan     0.0500    0.1045
     8        6.1100             nan     0.0500    0.0573
     9        6.0071             nan     0.0500    0.1007
    10        5.8940             nan     0.0500    0.0896
    20        5.1387             nan     0.0500    0.0322
    40        4.4016             nan     0.0500    0.0131
    60        4.0032             nan     0.0500   -0.0010
    80        3.7712             nan     0.0500   -0.0026
   100        3.5798             nan     0.0500   -0.0090
   120        3.4051             nan     0.0500   -0.0084
   140        3.2686             nan     0.0500   -0.0081
   160        3.1353             nan     0.0500   -0.0132
   180        3.0461             nan     0.0500   -0.0270
   200        2.9593             nan     0.0500   -0.0170

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9356             nan     0.0500    0.2118
     2        6.7141             nan     0.0500    0.1680
     3        6.5351             nan     0.0500    0.1342
     4        6.3376             nan     0.0500    0.1580
     5        6.1953             nan     0.0500    0.1139
     6        6.0710             nan     0.0500    0.0957
     7        5.9510             nan     0.0500    0.0999
     8        5.8156             nan     0.0500    0.0971
     9        5.7035             nan     0.0500    0.0614
    10        5.6251             nan     0.0500    0.0573
    20        4.8315             nan     0.0500    0.0168
    40        3.9360             nan     0.0500   -0.0012
    60        3.4955             nan     0.0500   -0.0080
    80        3.1815             nan     0.0500   -0.0182
   100        2.9434             nan     0.0500   -0.0230
   120        2.7330             nan     0.0500   -0.0086
   140        2.5361             nan     0.0500   -0.0116
   160        2.3994             nan     0.0500   -0.0035
   180        2.2745             nan     0.0500   -0.0056
   200        2.1402             nan     0.0500   -0.0040

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9469             nan     0.1000    0.1828
     2        6.7927             nan     0.1000    0.1260
     3        6.5468             nan     0.1000    0.1676
     4        6.4094             nan     0.1000    0.1483
     5        6.3389             nan     0.1000    0.0511
     6        6.2202             nan     0.1000    0.1234
     7        6.0855             nan     0.1000    0.1025
     8        6.0309             nan     0.1000    0.0311
     9        5.9656             nan     0.1000    0.0371
    10        5.8811             nan     0.1000    0.0627
    20        5.2804             nan     0.1000    0.0199
    40        4.6930             nan     0.1000    0.0047
    60        4.3650             nan     0.1000   -0.0053
    80        4.1651             nan     0.1000   -0.0007
   100        4.0442             nan     0.1000   -0.0045
   120        3.9678             nan     0.1000   -0.0062
   140        3.9018             nan     0.1000   -0.0048
   160        3.8433             nan     0.1000   -0.0134
   180        3.8069             nan     0.1000   -0.0164
   200        3.7650             nan     0.1000   -0.0241

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8672             nan     0.1000    0.2370
     2        6.7442             nan     0.1000    0.0521
     3        6.4881             nan     0.1000    0.2428
     4        6.2471             nan     0.1000    0.2287
     5        6.0680             nan     0.1000    0.1571
     6        5.9137             nan     0.1000    0.1240
     7        5.7938             nan     0.1000    0.0934
     8        5.6719             nan     0.1000    0.1130
     9        5.5634             nan     0.1000    0.0419
    10        5.4358             nan     0.1000    0.0903
    20        4.7730             nan     0.1000    0.0204
    40        4.0879             nan     0.1000   -0.0058
    60        3.7728             nan     0.1000   -0.0163
    80        3.5520             nan     0.1000   -0.0309
   100        3.4413             nan     0.1000   -0.0155
   120        3.3323             nan     0.1000   -0.0282
   140        3.2378             nan     0.1000   -0.0243
   160        3.1169             nan     0.1000   -0.0199
   180        3.0325             nan     0.1000   -0.0251
   200        2.9069             nan     0.1000   -0.0111

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7926             nan     0.1000    0.2373
     2        6.5156             nan     0.1000    0.2576
     3        6.2422             nan     0.1000    0.2301
     4        6.0075             nan     0.1000    0.1888
     5        5.7956             nan     0.1000    0.1696
     6        5.6273             nan     0.1000    0.1009
     7        5.4862             nan     0.1000    0.1040
     8        5.3726             nan     0.1000    0.1063
     9        5.3036             nan     0.1000    0.0206
    10        5.1984             nan     0.1000    0.0587
    20        4.4226             nan     0.1000    0.0011
    40        3.7399             nan     0.1000   -0.0346
    60        3.4299             nan     0.1000   -0.0149
    80        3.2201             nan     0.1000   -0.0057
   100        2.9956             nan     0.1000   -0.0293
   120        2.8002             nan     0.1000   -0.0189
   140        2.6474             nan     0.1000   -0.0271
   160        2.5013             nan     0.1000   -0.0123
   180        2.3927             nan     0.1000   -0.0334
   200        2.2685             nan     0.1000   -0.0120

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6759             nan     0.1000    0.4457
     2        6.3210             nan     0.1000    0.2574
     3        6.0456             nan     0.1000    0.2164
     4        5.7488             nan     0.1000    0.2691
     5        5.5443             nan     0.1000    0.1521
     6        5.3380             nan     0.1000    0.1632
     7        5.1624             nan     0.1000    0.0111
     8        5.0087             nan     0.1000    0.1170
     9        4.8937             nan     0.1000    0.0804
    10        4.7786             nan     0.1000    0.0662
    20        3.9422             nan     0.1000   -0.0042
    40        3.2645             nan     0.1000   -0.0092
    60        2.7934             nan     0.1000   -0.0385
    80        2.4918             nan     0.1000   -0.0407
   100        2.2503             nan     0.1000   -0.0286
   120        2.0410             nan     0.1000   -0.0201
   140        1.8743             nan     0.1000   -0.0099
   160        1.7180             nan     0.1000   -0.0273
   180        1.5885             nan     0.1000   -0.0103
   200        1.4315             nan     0.1000   -0.0121

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7636             nan     0.2000    0.4549
     2        6.4875             nan     0.2000    0.2865
     3        6.1996             nan     0.2000    0.2024
     4        5.9932             nan     0.2000    0.0972
     5        5.7993             nan     0.2000    0.0349
     6        5.6185             nan     0.2000    0.1778
     7        5.5028             nan     0.2000    0.0914
     8        5.4353             nan     0.2000    0.0244
     9        5.3264             nan     0.2000    0.0216
    10        5.2512             nan     0.2000    0.0289
    20        4.7001             nan     0.2000   -0.0352
    40        4.2644             nan     0.2000   -0.0002
    60        4.0068             nan     0.2000   -0.0051
    80        3.9109             nan     0.2000   -0.0218
   100        3.8176             nan     0.2000   -0.0387
   120        3.7844             nan     0.2000   -0.0359
   140        3.7170             nan     0.2000   -0.0203
   160        3.7116             nan     0.2000   -0.0237
   180        3.7046             nan     0.2000   -0.0491
   200        3.6841             nan     0.2000   -0.0364

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6264             nan     0.2000    0.6206
     2        6.2994             nan     0.2000    0.3367
     3        5.8969             nan     0.2000    0.2914
     4        5.6307             nan     0.2000    0.1844
     5        5.4269             nan     0.2000    0.1299
     6        5.2439             nan     0.2000    0.0722
     7        5.1252             nan     0.2000    0.0504
     8        5.0396             nan     0.2000    0.0284
     9        4.9351             nan     0.2000    0.0291
    10        4.8621             nan     0.2000    0.0199
    20        4.1737             nan     0.2000   -0.0497
    40        3.6747             nan     0.2000   -0.0399
    60        3.3425             nan     0.2000   -0.0061
    80        3.1520             nan     0.2000   -0.0120
   100        2.9598             nan     0.2000   -0.0438
   120        2.8089             nan     0.2000   -0.0313
   140        2.6886             nan     0.2000   -0.0351
   160        2.5129             nan     0.2000   -0.0236
   180        2.4160             nan     0.2000   -0.0266
   200        2.3371             nan     0.2000   -0.0564

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5771             nan     0.2000    0.5127
     2        6.1223             nan     0.2000    0.4570
     3        5.6300             nan     0.2000    0.3052
     4        5.2502             nan     0.2000    0.2546
     5        5.0193             nan     0.2000   -0.0284
     6        4.8548             nan     0.2000    0.1457
     7        4.7630             nan     0.2000   -0.0224
     8        4.6658             nan     0.2000   -0.0181
     9        4.5988             nan     0.2000   -0.0293
    10        4.4895             nan     0.2000    0.0244
    20        3.8787             nan     0.2000   -0.0454
    40        3.3410             nan     0.2000   -0.0895
    60        3.0296             nan     0.2000   -0.0465
    80        2.7031             nan     0.2000   -0.0430
   100        2.4782             nan     0.2000   -0.0333
   120        2.2413             nan     0.2000   -0.0244
   140        2.0837             nan     0.2000   -0.0292
   160        1.9148             nan     0.2000   -0.0385
   180        1.7875             nan     0.2000   -0.0287
   200        1.6933             nan     0.2000   -0.0386

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7091             nan     0.2000    0.3650
     2        6.0318             nan     0.2000    0.5693
     3        5.5617             nan     0.2000    0.3869
     4        5.2001             nan     0.2000    0.1151
     5        4.9333             nan     0.2000    0.1080
     6        4.6619             nan     0.2000    0.1323
     7        4.5026             nan     0.2000   -0.0555
     8        4.3628             nan     0.2000   -0.0601
     9        4.2207             nan     0.2000    0.0413
    10        4.0882             nan     0.2000    0.0320
    20        3.3900             nan     0.2000    0.0068
    40        2.7556             nan     0.2000   -0.0847
    60        2.2177             nan     0.2000   -0.0218
    80        1.8631             nan     0.2000   -0.0476
   100        1.5399             nan     0.2000   -0.0157
   120        1.3116             nan     0.2000   -0.0227
   140        1.1312             nan     0.2000   -0.0352
   160        0.9787             nan     0.2000   -0.0252
   180        0.8435             nan     0.2000   -0.0246
   200        0.7615             nan     0.2000   -0.0185

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3112             nan     0.0500    0.1268
     2        7.2099             nan     0.0500    0.0571
     3        7.1198             nan     0.0500    0.0814
     4        7.0381             nan     0.0500    0.0997
     5        6.9416             nan     0.0500    0.0822
     6        6.8650             nan     0.0500    0.0962
     7        6.8162             nan     0.0500    0.0217
     8        6.7510             nan     0.0500    0.0720
     9        6.7136             nan     0.0500    0.0012
    10        6.6409             nan     0.0500    0.0562
    20        6.1173             nan     0.0500   -0.0040
    40        5.6133             nan     0.0500   -0.0084
    60        5.3121             nan     0.0500   -0.0012
    80        5.0606             nan     0.0500    0.0007
   100        4.8846             nan     0.0500   -0.0054
   120        4.7404             nan     0.0500   -0.0136
   140        4.6425             nan     0.0500    0.0001
   160        4.5540             nan     0.0500   -0.0072
   180        4.4848             nan     0.0500   -0.0054
   200        4.4149             nan     0.0500   -0.0081

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2907             nan     0.0500    0.1231
     2        7.1467             nan     0.0500    0.1318
     3        6.9992             nan     0.0500    0.1165
     4        6.8730             nan     0.0500    0.1027
     5        6.7583             nan     0.0500    0.1049
     6        6.6413             nan     0.0500    0.0881
     7        6.5524             nan     0.0500    0.0839
     8        6.4754             nan     0.0500    0.0610
     9        6.3959             nan     0.0500    0.0790
    10        6.3112             nan     0.0500    0.0596
    20        5.7636             nan     0.0500    0.0088
    40        5.0831             nan     0.0500    0.0083
    60        4.6799             nan     0.0500   -0.0028
    80        4.4163             nan     0.0500   -0.0066
   100        4.2084             nan     0.0500   -0.0127
   120        4.0581             nan     0.0500   -0.0161
   140        3.9344             nan     0.0500   -0.0078
   160        3.8298             nan     0.0500   -0.0150
   180        3.7509             nan     0.0500   -0.0019
   200        3.6931             nan     0.0500   -0.0115

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2587             nan     0.0500    0.1884
     2        7.1031             nan     0.0500    0.1304
     3        6.9429             nan     0.0500    0.1523
     4        6.8094             nan     0.0500    0.1116
     5        6.6863             nan     0.0500    0.1278
     6        6.5600             nan     0.0500    0.1143
     7        6.4472             nan     0.0500    0.0788
     8        6.3294             nan     0.0500    0.0813
     9        6.2348             nan     0.0500    0.0499
    10        6.1509             nan     0.0500    0.0735
    20        5.4831             nan     0.0500    0.0392
    40        4.7351             nan     0.0500    0.0130
    60        4.3263             nan     0.0500    0.0003
    80        4.0055             nan     0.0500   -0.0165
   100        3.8121             nan     0.0500   -0.0209
   120        3.6289             nan     0.0500   -0.0238
   140        3.4938             nan     0.0500   -0.0016
   160        3.3898             nan     0.0500   -0.0072
   180        3.2969             nan     0.0500   -0.0157
   200        3.1837             nan     0.0500   -0.0039

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2294             nan     0.0500    0.1432
     2        7.0548             nan     0.0500    0.1727
     3        6.9127             nan     0.0500    0.1314
     4        6.7223             nan     0.0500    0.1095
     5        6.6144             nan     0.0500    0.0856
     6        6.4704             nan     0.0500    0.0825
     7        6.3244             nan     0.0500    0.0845
     8        6.1757             nan     0.0500    0.1080
     9        6.0625             nan     0.0500    0.0726
    10        5.9562             nan     0.0500    0.0597
    20        5.1799             nan     0.0500   -0.0045
    40        4.3291             nan     0.0500    0.0125
    60        3.8253             nan     0.0500   -0.0092
    80        3.5148             nan     0.0500   -0.0185
   100        3.2578             nan     0.0500   -0.0016
   120        3.0777             nan     0.0500   -0.0227
   140        2.8882             nan     0.0500   -0.0177
   160        2.7281             nan     0.0500   -0.0092
   180        2.6005             nan     0.0500   -0.0095
   200        2.4618             nan     0.0500   -0.0079

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2259             nan     0.1000    0.1451
     2        7.0799             nan     0.1000    0.1095
     3        6.9261             nan     0.1000    0.1459
     4        6.7596             nan     0.1000    0.1657
     5        6.5490             nan     0.1000    0.1466
     6        6.4204             nan     0.1000    0.1349
     7        6.3386             nan     0.1000    0.0125
     8        6.2655             nan     0.1000    0.0589
     9        6.1462             nan     0.1000    0.0832
    10        6.1114             nan     0.1000    0.0013
    20        5.5702             nan     0.1000    0.0312
    40        5.0546             nan     0.1000    0.0106
    60        4.7284             nan     0.1000   -0.0244
    80        4.5322             nan     0.1000   -0.0063
   100        4.4275             nan     0.1000   -0.0100
   120        4.3202             nan     0.1000   -0.0075
   140        4.2655             nan     0.1000   -0.0183
   160        4.2273             nan     0.1000   -0.0096
   180        4.2018             nan     0.1000   -0.0088
   200        4.1676             nan     0.1000   -0.0043

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0789             nan     0.1000    0.2844
     2        6.8185             nan     0.1000    0.2287
     3        6.6402             nan     0.1000    0.1511
     4        6.4630             nan     0.1000    0.1828
     5        6.3104             nan     0.1000    0.1015
     6        6.1882             nan     0.1000    0.0366
     7        6.0875             nan     0.1000    0.0285
     8        5.9738             nan     0.1000    0.0838
     9        5.8686             nan     0.1000   -0.0011
    10        5.7846             nan     0.1000    0.0312
    20        5.1763             nan     0.1000    0.0336
    40        4.4566             nan     0.1000   -0.0158
    60        4.1474             nan     0.1000    0.0023
    80        3.9615             nan     0.1000   -0.0305
   100        3.7799             nan     0.1000   -0.0400
   120        3.6471             nan     0.1000   -0.0262
   140        3.5534             nan     0.1000   -0.0170
   160        3.4574             nan     0.1000   -0.0219
   180        3.3505             nan     0.1000   -0.0150
   200        3.2592             nan     0.1000   -0.0122

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0570             nan     0.1000    0.2512
     2        6.7522             nan     0.1000    0.2609
     3        6.5466             nan     0.1000    0.1679
     4        6.3119             nan     0.1000    0.1637
     5        6.1072             nan     0.1000    0.1430
     6        5.9162             nan     0.1000    0.1319
     7        5.7800             nan     0.1000    0.0664
     8        5.6826             nan     0.1000    0.0740
     9        5.5464             nan     0.1000    0.0397
    10        5.4527             nan     0.1000    0.0144
    20        4.6741             nan     0.1000   -0.0029
    40        4.0291             nan     0.1000   -0.0064
    60        3.6727             nan     0.1000   -0.0419
    80        3.4171             nan     0.1000   -0.0247
   100        3.2022             nan     0.1000   -0.0284
   120        3.0091             nan     0.1000   -0.0241
   140        2.8532             nan     0.1000   -0.0206
   160        2.7391             nan     0.1000   -0.0178
   180        2.5728             nan     0.1000   -0.0285
   200        2.4699             nan     0.1000   -0.0218

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9764             nan     0.1000    0.2588
     2        6.6608             nan     0.1000    0.2226
     3        6.4011             nan     0.1000    0.2118
     4        6.1514             nan     0.1000    0.1997
     5        5.9669             nan     0.1000    0.1707
     6        5.7698             nan     0.1000    0.1262
     7        5.5695             nan     0.1000    0.1471
     8        5.4628             nan     0.1000   -0.0070
     9        5.3217             nan     0.1000    0.0943
    10        5.1865             nan     0.1000    0.0297
    20        4.4113             nan     0.1000    0.0263
    40        3.5162             nan     0.1000   -0.0029
    60        3.0667             nan     0.1000   -0.0169
    80        2.7313             nan     0.1000   -0.0120
   100        2.4201             nan     0.1000   -0.0233
   120        2.1846             nan     0.1000   -0.0161
   140        1.9876             nan     0.1000   -0.0145
   160        1.8263             nan     0.1000   -0.0196
   180        1.6557             nan     0.1000   -0.0269
   200        1.5318             nan     0.1000   -0.0203

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0320             nan     0.2000    0.3508
     2        6.7697             nan     0.2000    0.3180
     3        6.5095             nan     0.2000    0.2334
     4        6.3539             nan     0.2000    0.0647
     5        6.2068             nan     0.2000    0.1413
     6        6.1279             nan     0.2000    0.0177
     7        6.0270             nan     0.2000    0.0719
     8        5.9194             nan     0.2000    0.0834
     9        5.8393             nan     0.2000    0.0478
    10        5.7546             nan     0.2000    0.0329
    20        5.1263             nan     0.2000    0.0053
    40        4.5505             nan     0.2000    0.0016
    60        4.3239             nan     0.2000   -0.0489
    80        4.2171             nan     0.2000   -0.0272
   100        4.1801             nan     0.2000   -0.0311
   120        4.1637             nan     0.2000   -0.0351
   140        4.1365             nan     0.2000   -0.0206
   160        4.1162             nan     0.2000   -0.0303
   180        4.0898             nan     0.2000   -0.0252
   200        4.0738             nan     0.2000   -0.0226

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9219             nan     0.2000    0.4877
     2        6.5513             nan     0.2000    0.2698
     3        6.2150             nan     0.2000    0.2250
     4        5.9840             nan     0.2000    0.1542
     5        5.7334             nan     0.2000    0.1607
     6        5.5622             nan     0.2000    0.0930
     7        5.3820             nan     0.2000    0.0890
     8        5.2875             nan     0.2000    0.0406
     9        5.2232             nan     0.2000   -0.0761
    10        5.0806             nan     0.2000    0.0580
    20        4.5017             nan     0.2000   -0.0431
    40        3.9185             nan     0.2000   -0.0316
    60        3.6228             nan     0.2000   -0.0541
    80        3.4647             nan     0.2000   -0.0368
   100        3.2752             nan     0.2000   -0.0782
   120        3.1855             nan     0.2000   -0.0473
   140        3.0596             nan     0.2000   -0.0670
   160        2.8874             nan     0.2000   -0.0110
   180        2.7176             nan     0.2000   -0.0342
   200        2.6199             nan     0.2000   -0.0116

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7666             nan     0.2000    0.4596
     2        6.4118             nan     0.2000    0.3088
     3        6.0422             nan     0.2000    0.3437
     4        5.7418             nan     0.2000    0.1836
     5        5.6008             nan     0.2000    0.0568
     6        5.4567             nan     0.2000   -0.0188
     7        5.2329             nan     0.2000    0.0880
     8        5.1324             nan     0.2000    0.0026
     9        5.0035             nan     0.2000    0.0714
    10        4.8975             nan     0.2000   -0.0201
    20        4.1929             nan     0.2000   -0.0148
    40        3.5388             nan     0.2000   -0.0393
    60        3.1355             nan     0.2000   -0.0281
    80        2.8593             nan     0.2000   -0.0742
   100        2.6382             nan     0.2000   -0.0262
   120        2.4071             nan     0.2000   -0.0413
   140        2.2654             nan     0.2000   -0.0248
   160        2.1660             nan     0.2000   -0.0493
   180        2.0251             nan     0.2000   -0.0258
   200        1.9077             nan     0.2000   -0.0190

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6948             nan     0.2000    0.4461
     2        6.0733             nan     0.2000    0.3562
     3        5.7327             nan     0.2000    0.1187
     4        5.4661             nan     0.2000    0.1085
     5        5.1500             nan     0.2000    0.2744
     6        4.8891             nan     0.2000    0.0973
     7        4.7251             nan     0.2000   -0.1030
     8        4.5909             nan     0.2000   -0.0065
     9        4.4965             nan     0.2000    0.0154
    10        4.3220             nan     0.2000    0.0600
    20        3.5744             nan     0.2000   -0.0266
    40        2.9054             nan     0.2000   -0.0906
    60        2.3983             nan     0.2000   -0.0437
    80        1.9838             nan     0.2000   -0.0419
   100        1.6116             nan     0.2000   -0.0435
   120        1.3630             nan     0.2000   -0.0428
   140        1.1814             nan     0.2000   -0.0234
   160        1.0397             nan     0.2000   -0.0160
   180        0.9304             nan     0.2000   -0.0240
   200        0.8154             nan     0.2000   -0.0159

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2046             nan     0.0500    0.1301
     2        7.0739             nan     0.0500    0.1294
     3        6.9842             nan     0.0500    0.0814
     4        6.8878             nan     0.0500    0.0726
     5        6.8050             nan     0.0500    0.0707
     6        6.7204             nan     0.0500    0.0597
     7        6.6579             nan     0.0500    0.0615
     8        6.6197             nan     0.0500   -0.0016
     9        6.5624             nan     0.0500    0.0612
    10        6.4899             nan     0.0500    0.0759
    20        6.0712             nan     0.0500    0.0276
    40        5.5426             nan     0.0500    0.0146
    60        5.2112             nan     0.0500   -0.0021
    80        4.9608             nan     0.0500    0.0018
   100        4.7787             nan     0.0500    0.0038
   120        4.6318             nan     0.0500   -0.0175
   140        4.5245             nan     0.0500   -0.0086
   160        4.4166             nan     0.0500   -0.0046
   180        4.3407             nan     0.0500   -0.0026
   200        4.2859             nan     0.0500   -0.0069

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1949             nan     0.0500    0.1414
     2        7.0718             nan     0.0500    0.1072
     3        6.9194             nan     0.0500    0.1558
     4        6.8290             nan     0.0500    0.0828
     5        6.7014             nan     0.0500    0.1011
     6        6.6006             nan     0.0500    0.0675
     7        6.5093             nan     0.0500    0.0749
     8        6.4069             nan     0.0500    0.0796
     9        6.3397             nan     0.0500    0.0463
    10        6.2568             nan     0.0500    0.0804
    20        5.6273             nan     0.0500    0.0184
    40        4.9867             nan     0.0500    0.0033
    60        4.5792             nan     0.0500   -0.0064
    80        4.3106             nan     0.0500    0.0000
   100        4.1308             nan     0.0500   -0.0151
   120        3.9806             nan     0.0500   -0.0049
   140        3.8839             nan     0.0500   -0.0117
   160        3.8055             nan     0.0500   -0.0109
   180        3.7308             nan     0.0500   -0.0095
   200        3.6522             nan     0.0500   -0.0095

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1804             nan     0.0500    0.1294
     2        7.0280             nan     0.0500    0.1680
     3        6.8772             nan     0.0500    0.0955
     4        6.7264             nan     0.0500    0.1038
     5        6.6138             nan     0.0500    0.0849
     6        6.4948             nan     0.0500    0.1042
     7        6.3884             nan     0.0500    0.0751
     8        6.3050             nan     0.0500    0.0760
     9        6.1981             nan     0.0500    0.0553
    10        6.0920             nan     0.0500    0.0845
    20        5.4195             nan     0.0500    0.0193
    40        4.6789             nan     0.0500   -0.0067
    60        4.2842             nan     0.0500   -0.0102
    80        4.0018             nan     0.0500   -0.0114
   100        3.8328             nan     0.0500   -0.0078
   120        3.6456             nan     0.0500   -0.0111
   140        3.5096             nan     0.0500   -0.0113
   160        3.3715             nan     0.0500   -0.0039
   180        3.2675             nan     0.0500   -0.0130
   200        3.1869             nan     0.0500   -0.0132

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1355             nan     0.0500    0.2062
     2        6.9343             nan     0.0500    0.1161
     3        6.7699             nan     0.0500    0.1695
     4        6.6119             nan     0.0500    0.1482
     5        6.4571             nan     0.0500    0.1308
     6        6.2996             nan     0.0500    0.1087
     7        6.2015             nan     0.0500    0.0699
     8        6.0773             nan     0.0500    0.0702
     9        5.9635             nan     0.0500    0.0693
    10        5.8670             nan     0.0500    0.0702
    20        5.1197             nan     0.0500    0.0213
    40        4.3069             nan     0.0500   -0.0026
    60        3.8296             nan     0.0500   -0.0164
    80        3.5427             nan     0.0500   -0.0119
   100        3.3024             nan     0.0500   -0.0137
   120        3.0859             nan     0.0500   -0.0001
   140        2.8862             nan     0.0500   -0.0146
   160        2.7335             nan     0.0500   -0.0221
   180        2.5805             nan     0.0500   -0.0063
   200        2.4623             nan     0.0500   -0.0128

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1555             nan     0.1000    0.1718
     2        6.9677             nan     0.1000    0.2160
     3        6.7614             nan     0.1000    0.1569
     4        6.6225             nan     0.1000    0.1331
     5        6.5290             nan     0.1000    0.0917
     6        6.3990             nan     0.1000    0.1386
     7        6.2829             nan     0.1000    0.0769
     8        6.2344             nan     0.1000    0.0145
     9        6.1517             nan     0.1000    0.0646
    10        6.0884             nan     0.1000    0.0079
    20        5.5458             nan     0.1000    0.0060
    40        5.0110             nan     0.1000   -0.0112
    60        4.6996             nan     0.1000    0.0039
    80        4.4969             nan     0.1000   -0.0042
   100        4.3392             nan     0.1000   -0.0013
   120        4.2430             nan     0.1000   -0.0184
   140        4.1683             nan     0.1000   -0.0054
   160        4.1247             nan     0.1000   -0.0070
   180        4.0997             nan     0.1000   -0.0219
   200        4.0667             nan     0.1000   -0.0128

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0010             nan     0.1000    0.2480
     2        6.7550             nan     0.1000    0.1955
     3        6.5585             nan     0.1000    0.1819
     4        6.3525             nan     0.1000    0.1803
     5        6.1829             nan     0.1000    0.1344
     6        6.0347             nan     0.1000    0.0779
     7        5.8974             nan     0.1000    0.1133
     8        5.7784             nan     0.1000    0.1171
     9        5.7129             nan     0.1000    0.0053
    10        5.6627             nan     0.1000    0.0201
    20        4.9829             nan     0.1000   -0.0175
    40        4.3426             nan     0.1000   -0.0122
    60        4.0571             nan     0.1000   -0.0228
    80        3.8859             nan     0.1000   -0.0076
   100        3.7468             nan     0.1000   -0.0259
   120        3.6173             nan     0.1000   -0.0253
   140        3.4649             nan     0.1000   -0.0267
   160        3.3458             nan     0.1000   -0.0226
   180        3.2834             nan     0.1000   -0.0191
   200        3.2119             nan     0.1000   -0.0160

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0384             nan     0.1000    0.2781
     2        6.8082             nan     0.1000    0.1911
     3        6.6069             nan     0.1000    0.1917
     4        6.3875             nan     0.1000    0.2157
     5        6.1449             nan     0.1000    0.1890
     6        5.9722             nan     0.1000    0.1472
     7        5.7930             nan     0.1000    0.1523
     8        5.6571             nan     0.1000    0.0891
     9        5.5128             nan     0.1000    0.0705
    10        5.4184             nan     0.1000    0.0503
    20        4.6674             nan     0.1000   -0.0055
    40        3.9602             nan     0.1000   -0.0232
    60        3.6039             nan     0.1000   -0.0075
    80        3.3700             nan     0.1000   -0.0214
   100        3.1788             nan     0.1000   -0.0125
   120        3.0182             nan     0.1000   -0.0131
   140        2.9002             nan     0.1000   -0.0352
   160        2.7744             nan     0.1000   -0.0295
   180        2.6500             nan     0.1000   -0.0141
   200        2.5194             nan     0.1000   -0.0212

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9839             nan     0.1000    0.2506
     2        6.6239             nan     0.1000    0.3520
     3        6.2841             nan     0.1000    0.2493
     4        6.0515             nan     0.1000    0.1524
     5        5.9215             nan     0.1000    0.1124
     6        5.7441             nan     0.1000    0.0794
     7        5.5631             nan     0.1000    0.0671
     8        5.4100             nan     0.1000    0.0844
     9        5.2328             nan     0.1000    0.1143
    10        5.1389             nan     0.1000    0.0337
    20        4.3320             nan     0.1000    0.0159
    40        3.5207             nan     0.1000   -0.0483
    60        3.0904             nan     0.1000   -0.0251
    80        2.7562             nan     0.1000   -0.0329
   100        2.4823             nan     0.1000   -0.0433
   120        2.2629             nan     0.1000   -0.0387
   140        2.0170             nan     0.1000   -0.0172
   160        1.8323             nan     0.1000   -0.0150
   180        1.6641             nan     0.1000   -0.0137
   200        1.5348             nan     0.1000   -0.0168

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9587             nan     0.2000    0.3857
     2        6.6649             nan     0.2000    0.3124
     3        6.3816             nan     0.2000    0.2825
     4        6.1724             nan     0.2000    0.1343
     5        6.0545             nan     0.2000    0.0107
     6        5.9388             nan     0.2000    0.0538
     7        5.8475             nan     0.2000    0.0680
     8        5.7760             nan     0.2000   -0.0449
     9        5.6370             nan     0.2000    0.1033
    10        5.5702             nan     0.2000   -0.0071
    20        5.0112             nan     0.2000    0.0193
    40        4.4792             nan     0.2000   -0.0247
    60        4.2765             nan     0.2000   -0.0637
    80        4.1276             nan     0.2000   -0.0575
   100        4.0829             nan     0.2000   -0.0208
   120        4.0550             nan     0.2000   -0.0294
   140        4.0504             nan     0.2000   -0.0388
   160        4.0296             nan     0.2000   -0.0266
   180        4.0157             nan     0.2000   -0.0225
   200        3.9766             nan     0.2000   -0.0260

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7225             nan     0.2000    0.5569
     2        6.2839             nan     0.2000    0.3876
     3        5.9773             nan     0.2000    0.0906
     4        5.7662             nan     0.2000    0.1435
     5        5.5783             nan     0.2000    0.1390
     6        5.4462             nan     0.2000    0.0805
     7        5.2718             nan     0.2000    0.0481
     8        5.1639             nan     0.2000    0.0141
     9        5.0493             nan     0.2000   -0.0510
    10        4.9849             nan     0.2000   -0.0097
    20        4.4841             nan     0.2000    0.0065
    40        3.9318             nan     0.2000   -0.0530
    60        3.6562             nan     0.2000   -0.0522
    80        3.4626             nan     0.2000   -0.0598
   100        3.3041             nan     0.2000   -0.0484
   120        3.1840             nan     0.2000   -0.0576
   140        3.0712             nan     0.2000   -0.0564
   160        2.9489             nan     0.2000   -0.0191
   180        2.8491             nan     0.2000   -0.0600
   200        2.7101             nan     0.2000   -0.0266

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6492             nan     0.2000    0.5914
     2        6.3093             nan     0.2000    0.3133
     3        5.9293             nan     0.2000    0.2189
     4        5.5450             nan     0.2000    0.1338
     5        5.3970             nan     0.2000    0.0619
     6        5.1599             nan     0.2000    0.1400
     7        5.0432             nan     0.2000   -0.0212
     8        4.9240             nan     0.2000   -0.0319
     9        4.8486             nan     0.2000   -0.0293
    10        4.7492             nan     0.2000    0.0284
    20        4.2120             nan     0.2000   -0.0303
    40        3.5750             nan     0.2000   -0.0672
    60        3.1717             nan     0.2000   -0.0391
    80        2.9093             nan     0.2000   -0.0180
   100        2.6955             nan     0.2000   -0.0505
   120        2.4222             nan     0.2000   -0.0084
   140        2.1822             nan     0.2000   -0.0403
   160        2.0180             nan     0.2000   -0.0186
   180        1.8782             nan     0.2000   -0.0241
   200        1.7228             nan     0.2000   -0.0208

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7711             nan     0.2000    0.4988
     2        6.2303             nan     0.2000    0.5103
     3        5.8425             nan     0.2000    0.1123
     4        5.4695             nan     0.2000    0.2411
     5        5.1704             nan     0.2000    0.2597
     6        4.9787             nan     0.2000    0.0958
     7        4.8470             nan     0.2000   -0.0034
     8        4.7352             nan     0.2000   -0.0518
     9        4.5807             nan     0.2000   -0.0393
    10        4.4157             nan     0.2000    0.0373
    20        3.6056             nan     0.2000    0.0025
    40        2.8623             nan     0.2000   -0.1111
    60        2.4104             nan     0.2000   -0.0727
    80        2.0345             nan     0.2000   -0.0314
   100        1.7086             nan     0.2000   -0.0390
   120        1.4727             nan     0.2000   -0.0375
   140        1.2778             nan     0.2000   -0.0388
   160        1.1127             nan     0.2000   -0.0285
   180        0.9792             nan     0.2000   -0.0272
   200        0.8647             nan     0.2000   -0.0173

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1488             nan     0.0500    0.0949
     2        7.0421             nan     0.0500    0.1118
     3        6.9354             nan     0.0500    0.0917
     4        6.8659             nan     0.0500    0.0419
     5        6.7838             nan     0.0500    0.0893
     6        6.6944             nan     0.0500    0.0785
     7        6.6730             nan     0.0500   -0.0232
     8        6.5888             nan     0.0500    0.0491
     9        6.5044             nan     0.0500    0.0901
    10        6.4705             nan     0.0500    0.0100
    20        5.9794             nan     0.0500    0.0285
    40        5.4467             nan     0.0500    0.0140
    60        5.1168             nan     0.0500   -0.0045
    80        4.8730             nan     0.0500   -0.0018
   100        4.7068             nan     0.0500   -0.0042
   120        4.5755             nan     0.0500   -0.0132
   140        4.4778             nan     0.0500   -0.0032
   160        4.3791             nan     0.0500    0.0001
   180        4.3112             nan     0.0500   -0.0090
   200        4.2643             nan     0.0500   -0.0024

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0784             nan     0.0500    0.1362
     2        6.9616             nan     0.0500    0.1133
     3        6.8473             nan     0.0500    0.0850
     4        6.7200             nan     0.0500    0.1204
     5        6.6219             nan     0.0500    0.0696
     6        6.5222             nan     0.0500    0.0682
     7        6.4249             nan     0.0500    0.0424
     8        6.3390             nan     0.0500    0.0589
     9        6.2470             nan     0.0500    0.0580
    10        6.1740             nan     0.0500    0.0664
    20        5.6064             nan     0.0500    0.0505
    40        4.9408             nan     0.0500    0.0059
    60        4.5525             nan     0.0500    0.0050
    80        4.3084             nan     0.0500   -0.0064
   100        4.1349             nan     0.0500   -0.0025
   120        3.9737             nan     0.0500   -0.0175
   140        3.8714             nan     0.0500   -0.0151
   160        3.7809             nan     0.0500   -0.0108
   180        3.7114             nan     0.0500   -0.0112
   200        3.6557             nan     0.0500   -0.0074

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1093             nan     0.0500    0.1411
     2        6.9496             nan     0.0500    0.1278
     3        6.7754             nan     0.0500    0.0933
     4        6.6428             nan     0.0500    0.0676
     5        6.5394             nan     0.0500    0.0910
     6        6.4307             nan     0.0500    0.1158
     7        6.3404             nan     0.0500    0.0813
     8        6.2322             nan     0.0500    0.0683
     9        6.1227             nan     0.0500    0.0967
    10        6.0385             nan     0.0500    0.0697
    20        5.3762             nan     0.0500    0.0231
    40        4.5992             nan     0.0500    0.0009
    60        4.2274             nan     0.0500   -0.0056
    80        3.9592             nan     0.0500   -0.0178
   100        3.7506             nan     0.0500   -0.0145
   120        3.6061             nan     0.0500   -0.0119
   140        3.4644             nan     0.0500   -0.0081
   160        3.3801             nan     0.0500   -0.0115
   180        3.2904             nan     0.0500   -0.0144
   200        3.1599             nan     0.0500   -0.0032

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0447             nan     0.0500    0.1697
     2        6.8734             nan     0.0500    0.1476
     3        6.6754             nan     0.0500    0.1658
     4        6.5131             nan     0.0500    0.1187
     5        6.3818             nan     0.0500    0.1031
     6        6.2657             nan     0.0500    0.0711
     7        6.1317             nan     0.0500    0.0950
     8        5.9929             nan     0.0500    0.0837
     9        5.8767             nan     0.0500    0.0767
    10        5.7745             nan     0.0500    0.0717
    20        4.9581             nan     0.0500    0.0333
    40        4.1981             nan     0.0500   -0.0083
    60        3.7600             nan     0.0500   -0.0239
    80        3.4631             nan     0.0500   -0.0169
   100        3.2226             nan     0.0500   -0.0073
   120        3.0523             nan     0.0500   -0.0101
   140        2.8605             nan     0.0500   -0.0213
   160        2.7025             nan     0.0500   -0.0095
   180        2.5777             nan     0.0500   -0.0160
   200        2.4480             nan     0.0500   -0.0080

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0300             nan     0.1000    0.2081
     2        6.8615             nan     0.1000    0.1190
     3        6.6741             nan     0.1000    0.1719
     4        6.5231             nan     0.1000    0.1542
     5        6.4089             nan     0.1000    0.1180
     6        6.3136             nan     0.1000    0.0538
     7        6.2125             nan     0.1000    0.0661
     8        6.1099             nan     0.1000    0.0673
     9        6.0179             nan     0.1000    0.0488
    10        5.9571             nan     0.1000    0.0074
    20        5.4974             nan     0.1000   -0.0021
    40        4.9063             nan     0.1000   -0.0012
    60        4.5944             nan     0.1000   -0.0091
    80        4.3987             nan     0.1000   -0.0083
   100        4.2850             nan     0.1000   -0.0150
   120        4.1928             nan     0.1000   -0.0155
   140        4.1533             nan     0.1000   -0.0195
   160        4.0975             nan     0.1000   -0.0121
   180        4.0537             nan     0.1000   -0.0131
   200        4.0274             nan     0.1000   -0.0220

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9381             nan     0.1000    0.2409
     2        6.6489             nan     0.1000    0.2650
     3        6.4852             nan     0.1000    0.1534
     4        6.2986             nan     0.1000    0.1062
     5        6.1370             nan     0.1000    0.1417
     6        5.9997             nan     0.1000    0.1072
     7        5.8614             nan     0.1000    0.0869
     8        5.7331             nan     0.1000    0.0511
     9        5.6942             nan     0.1000   -0.0168
    10        5.5839             nan     0.1000    0.0632
    20        4.9790             nan     0.1000    0.0219
    40        4.3114             nan     0.1000   -0.0046
    60        4.0149             nan     0.1000   -0.0229
    80        3.8287             nan     0.1000   -0.0179
   100        3.6847             nan     0.1000   -0.0200
   120        3.5971             nan     0.1000   -0.0338
   140        3.4752             nan     0.1000   -0.0008
   160        3.3720             nan     0.1000   -0.0140
   180        3.2599             nan     0.1000   -0.0199
   200        3.2025             nan     0.1000   -0.0218

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0696             nan     0.1000    0.1423
     2        6.7631             nan     0.1000    0.2779
     3        6.4690             nan     0.1000    0.2620
     4        6.2449             nan     0.1000    0.1329
     5        6.0185             nan     0.1000    0.1884
     6        5.8338             nan     0.1000    0.1050
     7        5.6180             nan     0.1000    0.1766
     8        5.4886             nan     0.1000    0.0847
     9        5.3700             nan     0.1000    0.0763
    10        5.2426             nan     0.1000    0.0468
    20        4.5306             nan     0.1000    0.0021
    40        3.9020             nan     0.1000   -0.0326
    60        3.5928             nan     0.1000   -0.0243
    80        3.3764             nan     0.1000   -0.0112
   100        3.1838             nan     0.1000   -0.0150
   120        3.0189             nan     0.1000   -0.0308
   140        2.8644             nan     0.1000   -0.0292
   160        2.7300             nan     0.1000   -0.0230
   180        2.6212             nan     0.1000   -0.0104
   200        2.5136             nan     0.1000   -0.0246

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8819             nan     0.1000    0.3340
     2        6.5142             nan     0.1000    0.2916
     3        6.2217             nan     0.1000    0.2762
     4        5.9636             nan     0.1000    0.2014
     5        5.7861             nan     0.1000    0.0990
     6        5.6442             nan     0.1000    0.1073
     7        5.4541             nan     0.1000    0.1370
     8        5.2721             nan     0.1000    0.0392
     9        5.1156             nan     0.1000    0.0897
    10        4.9955             nan     0.1000    0.0555
    20        4.1765             nan     0.1000   -0.0308
    40        3.4961             nan     0.1000   -0.0176
    60        3.0363             nan     0.1000   -0.0093
    80        2.7326             nan     0.1000   -0.0290
   100        2.4645             nan     0.1000   -0.0099
   120        2.2093             nan     0.1000   -0.0192
   140        2.0210             nan     0.1000   -0.0311
   160        1.8472             nan     0.1000   -0.0207
   180        1.7098             nan     0.1000   -0.0271
   200        1.5903             nan     0.1000   -0.0110

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9163             nan     0.2000    0.3729
     2        6.5124             nan     0.2000    0.2497
     3        6.2724             nan     0.2000    0.2385
     4        6.0686             nan     0.2000    0.0935
     5        5.8633             nan     0.2000    0.1327
     6        5.7716             nan     0.2000    0.0727
     7        5.6631             nan     0.2000    0.0734
     8        5.5774             nan     0.2000    0.0177
     9        5.5284             nan     0.2000   -0.0265
    10        5.4567             nan     0.2000    0.0117
    20        4.9084             nan     0.2000   -0.0115
    40        4.3643             nan     0.2000   -0.0256
    60        4.2328             nan     0.2000   -0.0253
    80        4.1695             nan     0.2000   -0.0264
   100        4.1092             nan     0.2000   -0.0462
   120        4.0617             nan     0.2000   -0.0532
   140        4.0266             nan     0.2000   -0.0133
   160        3.9871             nan     0.2000   -0.0152
   180        3.9831             nan     0.2000   -0.0507
   200        3.9758             nan     0.2000   -0.0349

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7439             nan     0.2000    0.4364
     2        6.3902             nan     0.2000    0.3332
     3        6.0432             nan     0.2000    0.3029
     4        5.7632             nan     0.2000    0.2487
     5        5.5702             nan     0.2000    0.1294
     6        5.4152             nan     0.2000    0.1098
     7        5.3040             nan     0.2000    0.0228
     8        5.1607             nan     0.2000    0.0607
     9        5.0533             nan     0.2000    0.0904
    10        4.9623             nan     0.2000    0.0801
    20        4.3184             nan     0.2000   -0.0661
    40        3.8874             nan     0.2000   -0.0181
    60        3.6406             nan     0.2000   -0.0389
    80        3.4885             nan     0.2000   -0.0752
   100        3.3316             nan     0.2000   -0.0451
   120        3.1516             nan     0.2000   -0.0445
   140        3.0176             nan     0.2000   -0.0211
   160        2.9376             nan     0.2000   -0.0392
   180        2.8450             nan     0.2000   -0.0394
   200        2.7344             nan     0.2000   -0.0343

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5539             nan     0.2000    0.5740
     2        6.1087             nan     0.2000    0.2319
     3        5.7684             nan     0.2000    0.1780
     4        5.5798             nan     0.2000    0.0256
     5        5.3471             nan     0.2000    0.0881
     6        5.1837             nan     0.2000    0.0375
     7        5.1013             nan     0.2000    0.0198
     8        5.0031             nan     0.2000   -0.0278
     9        4.8324             nan     0.2000    0.0760
    10        4.6528             nan     0.2000    0.0732
    20        4.1380             nan     0.2000   -0.0966
    40        3.6655             nan     0.2000   -0.0331
    60        3.2951             nan     0.2000   -0.0763
    80        3.0170             nan     0.2000   -0.0392
   100        2.7744             nan     0.2000   -0.0228
   120        2.5425             nan     0.2000   -0.0368
   140        2.3678             nan     0.2000   -0.0246
   160        2.2179             nan     0.2000   -0.0473
   180        2.0242             nan     0.2000   -0.0286
   200        1.8875             nan     0.2000   -0.0216

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5600             nan     0.2000    0.6071
     2        5.9381             nan     0.2000    0.5100
     3        5.5175             nan     0.2000    0.2882
     4        5.2149             nan     0.2000    0.2602
     5        5.0298             nan     0.2000    0.0632
     6        4.8669             nan     0.2000   -0.0063
     7        4.7038             nan     0.2000    0.0261
     8        4.5700             nan     0.2000   -0.0355
     9        4.4219             nan     0.2000   -0.0280
    10        4.3573             nan     0.2000   -0.1859
    20        3.6118             nan     0.2000   -0.0145
    40        2.9061             nan     0.2000   -0.0437
    60        2.3427             nan     0.2000   -0.0435
    80        1.9740             nan     0.2000   -0.0315
   100        1.6865             nan     0.2000   -0.0390
   120        1.4487             nan     0.2000   -0.0398
   140        1.2367             nan     0.2000   -0.0230
   160        1.0615             nan     0.2000   -0.0298
   180        0.9260             nan     0.2000   -0.0245
   200        0.8175             nan     0.2000   -0.0137

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.4866             nan     0.0500    0.1482
     2        7.3847             nan     0.0500    0.0993
     3        7.2608             nan     0.0500    0.0915
     4        7.1757             nan     0.0500    0.0842
     5        7.1284             nan     0.0500    0.0146
     6        7.0573             nan     0.0500    0.0843
     7        6.9610             nan     0.0500    0.0828
     8        6.8775             nan     0.0500    0.0784
     9        6.8121             nan     0.0500    0.0668
    10        6.7290             nan     0.0500    0.0567
    20        6.2916             nan     0.0500    0.0118
    40        5.7299             nan     0.0500    0.0070
    60        5.3690             nan     0.0500    0.0014
    80        5.1363             nan     0.0500   -0.0021
   100        4.9472             nan     0.0500   -0.0130
   120        4.8195             nan     0.0500   -0.0045
   140        4.6959             nan     0.0500   -0.0092
   160        4.6005             nan     0.0500   -0.0031
   180        4.5286             nan     0.0500    0.0037
   200        4.4673             nan     0.0500   -0.0032

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.4584             nan     0.0500    0.1258
     2        7.3004             nan     0.0500    0.0949
     3        7.1840             nan     0.0500    0.0987
     4        7.0587             nan     0.0500    0.0980
     5        6.9275             nan     0.0500    0.0714
     6        6.8335             nan     0.0500    0.1028
     7        6.7481             nan     0.0500    0.0788
     8        6.6622             nan     0.0500    0.0797
     9        6.5689             nan     0.0500    0.0750
    10        6.4593             nan     0.0500    0.0592
    20        5.8547             nan     0.0500    0.0223
    40        5.1599             nan     0.0500   -0.0059
    60        4.7574             nan     0.0500   -0.0120
    80        4.5060             nan     0.0500    0.0035
   100        4.3123             nan     0.0500   -0.0094
   120        4.1488             nan     0.0500    0.0001
   140        4.0236             nan     0.0500   -0.0116
   160        3.9112             nan     0.0500   -0.0192
   180        3.8186             nan     0.0500   -0.0067
   200        3.7153             nan     0.0500   -0.0111

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.4528             nan     0.0500    0.1727
     2        7.2710             nan     0.0500    0.1464
     3        7.1416             nan     0.0500    0.1332
     4        6.9830             nan     0.0500    0.1432
     5        6.8774             nan     0.0500    0.0514
     6        6.7247             nan     0.0500    0.1064
     7        6.6008             nan     0.0500    0.1224
     8        6.5069             nan     0.0500    0.0547
     9        6.4025             nan     0.0500    0.0972
    10        6.2792             nan     0.0500    0.0879
    20        5.5968             nan     0.0500    0.0300
    40        4.8319             nan     0.0500    0.0080
    60        4.4114             nan     0.0500    0.0021
    80        4.0805             nan     0.0500   -0.0039
   100        3.8192             nan     0.0500   -0.0081
   120        3.6443             nan     0.0500   -0.0138
   140        3.5015             nan     0.0500   -0.0039
   160        3.3545             nan     0.0500   -0.0124
   180        3.2305             nan     0.0500   -0.0062
   200        3.1040             nan     0.0500   -0.0031

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.4458             nan     0.0500    0.1552
     2        7.2474             nan     0.0500    0.1541
     3        7.1025             nan     0.0500    0.0922
     4        6.9620             nan     0.0500    0.1234
     5        6.8143             nan     0.0500    0.1082
     6        6.6731             nan     0.0500    0.1143
     7        6.5365             nan     0.0500    0.1037
     8        6.4157             nan     0.0500    0.0877
     9        6.2884             nan     0.0500    0.0975
    10        6.1721             nan     0.0500    0.0755
    20        5.2982             nan     0.0500    0.0237
    40        4.3869             nan     0.0500    0.0004
    60        3.8436             nan     0.0500    0.0174
    80        3.4986             nan     0.0500   -0.0178
   100        3.2323             nan     0.0500   -0.0178
   120        3.0135             nan     0.0500   -0.0123
   140        2.8045             nan     0.0500   -0.0122
   160        2.6160             nan     0.0500   -0.0127
   180        2.4637             nan     0.0500   -0.0172
   200        2.3238             nan     0.0500   -0.0137

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.4020             nan     0.1000    0.1930
     2        7.1493             nan     0.1000    0.2410
     3        6.9730             nan     0.1000    0.1256
     4        6.8441             nan     0.1000    0.1429
     5        6.6800             nan     0.1000    0.1253
     6        6.5620             nan     0.1000    0.1254
     7        6.4677             nan     0.1000    0.0633
     8        6.3561             nan     0.1000    0.0672
     9        6.3021             nan     0.1000    0.0305
    10        6.2374             nan     0.1000    0.0110
    20        5.7279             nan     0.1000    0.0168
    40        5.1452             nan     0.1000   -0.0083
    60        4.8291             nan     0.1000   -0.0020
    80        4.5989             nan     0.1000   -0.0203
   100        4.4550             nan     0.1000   -0.0195
   120        4.3494             nan     0.1000   -0.0296
   140        4.2799             nan     0.1000   -0.0082
   160        4.2352             nan     0.1000   -0.0132
   180        4.1952             nan     0.1000   -0.0087
   200        4.1655             nan     0.1000   -0.0141

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3047             nan     0.1000    0.3137
     2        7.0875             nan     0.1000    0.1605
     3        6.8890             nan     0.1000    0.1800
     4        6.7014             nan     0.1000    0.1861
     5        6.5695             nan     0.1000    0.1474
     6        6.3694             nan     0.1000    0.1121
     7        6.2200             nan     0.1000    0.1004
     8        6.1130             nan     0.1000    0.0941
     9        5.9804             nan     0.1000    0.1385
    10        5.8757             nan     0.1000    0.0555
    20        5.1704             nan     0.1000    0.0030
    40        4.4651             nan     0.1000   -0.0080
    60        4.1421             nan     0.1000   -0.0132
    80        3.8978             nan     0.1000   -0.0080
   100        3.7448             nan     0.1000   -0.0230
   120        3.6182             nan     0.1000   -0.0182
   140        3.4824             nan     0.1000   -0.0204
   160        3.3759             nan     0.1000   -0.0215
   180        3.2780             nan     0.1000   -0.0041
   200        3.1697             nan     0.1000   -0.0212

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2343             nan     0.1000    0.2912
     2        6.9366             nan     0.1000    0.2290
     3        6.7254             nan     0.1000    0.1155
     4        6.4914             nan     0.1000    0.1881
     5        6.2914             nan     0.1000    0.1176
     6        6.1172             nan     0.1000    0.1726
     7        5.9747             nan     0.1000    0.0861
     8        5.8481             nan     0.1000    0.0376
     9        5.7398             nan     0.1000    0.0125
    10        5.6167             nan     0.1000    0.0525
    20        4.8420             nan     0.1000   -0.0152
    40        4.1920             nan     0.1000   -0.0307
    60        3.7984             nan     0.1000   -0.0195
    80        3.5105             nan     0.1000   -0.0292
   100        3.2725             nan     0.1000   -0.0349
   120        3.0707             nan     0.1000   -0.0015
   140        2.8944             nan     0.1000   -0.0301
   160        2.7447             nan     0.1000   -0.0183
   180        2.6197             nan     0.1000   -0.0265
   200        2.4929             nan     0.1000   -0.0190

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1275             nan     0.1000    0.3127
     2        6.7821             nan     0.1000    0.2695
     3        6.5324             nan     0.1000    0.1547
     4        6.3390             nan     0.1000    0.1427
     5        6.0497             nan     0.1000    0.1472
     6        5.8926             nan     0.1000    0.0281
     7        5.6903             nan     0.1000    0.1791
     8        5.5660             nan     0.1000    0.0320
     9        5.4402             nan     0.1000    0.1019
    10        5.3196             nan     0.1000    0.0285
    20        4.4746             nan     0.1000   -0.0132
    40        3.6287             nan     0.1000   -0.0400
    60        3.1195             nan     0.1000   -0.0166
    80        2.7740             nan     0.1000   -0.0261
   100        2.5043             nan     0.1000   -0.0274
   120        2.2692             nan     0.1000   -0.0351
   140        2.0840             nan     0.1000   -0.0124
   160        1.9449             nan     0.1000   -0.0194
   180        1.7552             nan     0.1000   -0.0206
   200        1.6319             nan     0.1000   -0.0222

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2410             nan     0.2000    0.4163
     2        6.7760             nan     0.2000    0.4550
     3        6.6640             nan     0.2000    0.0358
     4        6.4328             nan     0.2000    0.1315
     5        6.2647             nan     0.2000    0.1411
     6        6.0814             nan     0.2000    0.1529
     7        5.9667             nan     0.2000    0.0907
     8        5.8915             nan     0.2000    0.0437
     9        5.8061             nan     0.2000    0.0242
    10        5.8161             nan     0.2000   -0.1025
    20        5.1881             nan     0.2000   -0.0100
    40        4.6385             nan     0.2000   -0.0266
    60        4.4249             nan     0.2000   -0.0263
    80        4.3217             nan     0.2000   -0.0263
   100        4.2330             nan     0.2000   -0.0125
   120        4.1848             nan     0.2000   -0.0409
   140        4.1320             nan     0.2000   -0.0053
   160        4.1056             nan     0.2000   -0.0337
   180        4.0992             nan     0.2000   -0.0447
   200        4.0971             nan     0.2000   -0.0336

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1448             nan     0.2000    0.3596
     2        6.7508             nan     0.2000    0.2365
     3        6.3643             nan     0.2000    0.2847
     4        6.0556             nan     0.2000    0.2676
     5        5.8859             nan     0.2000    0.0174
     6        5.7286             nan     0.2000    0.0902
     7        5.5861             nan     0.2000    0.1057
     8        5.4657             nan     0.2000   -0.0392
     9        5.3360             nan     0.2000   -0.0039
    10        5.2009             nan     0.2000   -0.0156
    20        4.6401             nan     0.2000   -0.0667
    40        4.0771             nan     0.2000   -0.0294
    60        3.8346             nan     0.2000   -0.0696
    80        3.5686             nan     0.2000   -0.0155
   100        3.4356             nan     0.2000   -0.0359
   120        3.2759             nan     0.2000   -0.0314
   140        3.1254             nan     0.2000   -0.0198
   160        3.0129             nan     0.2000   -0.0313
   180        2.8368             nan     0.2000   -0.0376
   200        2.7075             nan     0.2000   -0.0309

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9093             nan     0.2000    0.6468
     2        6.6529             nan     0.2000    0.1194
     3        6.2161             nan     0.2000    0.2825
     4        5.9313             nan     0.2000    0.2730
     5        5.6539             nan     0.2000    0.2035
     6        5.4883             nan     0.2000    0.0739
     7        5.3297             nan     0.2000    0.1354
     8        5.1828             nan     0.2000    0.0658
     9        5.0767             nan     0.2000   -0.0822
    10        4.9389             nan     0.2000   -0.0082
    20        4.2209             nan     0.2000   -0.0168
    40        3.6061             nan     0.2000   -0.0282
    60        3.2769             nan     0.2000   -0.0722
    80        2.9390             nan     0.2000   -0.0411
   100        2.6811             nan     0.2000   -0.0527
   120        2.4696             nan     0.2000   -0.0607
   140        2.2603             nan     0.2000   -0.0227
   160        2.0734             nan     0.2000   -0.0283
   180        1.9016             nan     0.2000   -0.0120
   200        1.7594             nan     0.2000   -0.0336

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7805             nan     0.2000    0.6510
     2        6.3493             nan     0.2000    0.1341
     3        5.8908             nan     0.2000    0.2969
     4        5.5028             nan     0.2000    0.2533
     5        5.3152             nan     0.2000    0.0567
     6        5.0719             nan     0.2000    0.1486
     7        4.9275             nan     0.2000   -0.0115
     8        4.7405             nan     0.2000    0.0369
     9        4.6254             nan     0.2000   -0.0736
    10        4.4965             nan     0.2000   -0.0151
    20        3.6872             nan     0.2000   -0.0194
    40        2.7870             nan     0.2000   -0.0589
    60        2.3062             nan     0.2000   -0.0496
    80        1.9717             nan     0.2000   -0.0413
   100        1.6166             nan     0.2000   -0.0216
   120        1.3518             nan     0.2000   -0.0397
   140        1.1604             nan     0.2000   -0.0101
   160        0.9979             nan     0.2000   -0.0294
   180        0.8803             nan     0.2000   -0.0177
   200        0.7867             nan     0.2000   -0.0217

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9827             nan     0.0500    0.1025
     2        6.8962             nan     0.0500    0.0703
     3        6.8101             nan     0.0500    0.0784
     4        6.7307             nan     0.0500    0.0665
     5        6.6648             nan     0.0500    0.0571
     6        6.6125             nan     0.0500    0.0346
     7        6.5594             nan     0.0500    0.0587
     8        6.4913             nan     0.0500    0.0784
     9        6.4313             nan     0.0500    0.0573
    10        6.3666             nan     0.0500    0.0537
    20        5.9488             nan     0.0500    0.0249
    40        5.4575             nan     0.0500    0.0035
    60        5.1364             nan     0.0500    0.0055
    80        4.9225             nan     0.0500   -0.0067
   100        4.7470             nan     0.0500   -0.0014
   120        4.6197             nan     0.0500   -0.0008
   140        4.5059             nan     0.0500    0.0027
   160        4.4074             nan     0.0500   -0.0131
   180        4.3338             nan     0.0500   -0.0063
   200        4.2596             nan     0.0500   -0.0065

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9512             nan     0.0500    0.1241
     2        6.8318             nan     0.0500    0.0819
     3        6.6996             nan     0.0500    0.1110
     4        6.5961             nan     0.0500    0.1057
     5        6.4994             nan     0.0500    0.0854
     6        6.4070             nan     0.0500    0.0903
     7        6.3133             nan     0.0500    0.0612
     8        6.2220             nan     0.0500    0.0659
     9        6.1557             nan     0.0500    0.0315
    10        6.0910             nan     0.0500    0.0497
    20        5.5590             nan     0.0500    0.0182
    40        4.8939             nan     0.0500    0.0113
    60        4.5076             nan     0.0500   -0.0045
    80        4.2331             nan     0.0500   -0.0183
   100        4.0475             nan     0.0500   -0.0086
   120        3.9111             nan     0.0500   -0.0121
   140        3.7948             nan     0.0500   -0.0065
   160        3.6988             nan     0.0500   -0.0130
   180        3.6083             nan     0.0500   -0.0102
   200        3.5268             nan     0.0500   -0.0063

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9461             nan     0.0500    0.1044
     2        6.7960             nan     0.0500    0.1421
     3        6.7321             nan     0.0500    0.0254
     4        6.6051             nan     0.0500    0.1058
     5        6.4943             nan     0.0500    0.0564
     6        6.3766             nan     0.0500    0.0966
     7        6.2811             nan     0.0500    0.0505
     8        6.1758             nan     0.0500    0.1028
     9        6.0797             nan     0.0500    0.0614
    10        5.9812             nan     0.0500    0.0660
    20        5.2864             nan     0.0500    0.0390
    40        4.5415             nan     0.0500    0.0030
    60        4.1463             nan     0.0500   -0.0121
    80        3.8855             nan     0.0500   -0.0049
   100        3.7241             nan     0.0500   -0.0169
   120        3.5323             nan     0.0500   -0.0119
   140        3.4205             nan     0.0500   -0.0022
   160        3.3192             nan     0.0500   -0.0017
   180        3.2158             nan     0.0500   -0.0125
   200        3.1271             nan     0.0500   -0.0096

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9077             nan     0.0500    0.1538
     2        6.7399             nan     0.0500    0.1182
     3        6.5777             nan     0.0500    0.1187
     4        6.4295             nan     0.0500    0.1312
     5        6.2939             nan     0.0500    0.0921
     6        6.1687             nan     0.0500    0.0879
     7        6.0467             nan     0.0500    0.0936
     8        5.9143             nan     0.0500    0.0971
     9        5.8043             nan     0.0500    0.0676
    10        5.6954             nan     0.0500    0.0504
    20        4.9036             nan     0.0500    0.0180
    40        4.1277             nan     0.0500    0.0036
    60        3.6681             nan     0.0500    0.0045
    80        3.3923             nan     0.0500    0.0005
   100        3.1266             nan     0.0500   -0.0093
   120        2.8956             nan     0.0500   -0.0182
   140        2.7221             nan     0.0500   -0.0103
   160        2.5583             nan     0.0500   -0.0057
   180        2.4197             nan     0.0500   -0.0120
   200        2.2960             nan     0.0500   -0.0135

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9704             nan     0.1000    0.1260
     2        6.8021             nan     0.1000    0.2247
     3        6.6511             nan     0.1000    0.1728
     4        6.4989             nan     0.1000    0.1228
     5        6.3817             nan     0.1000    0.0701
     6        6.2671             nan     0.1000    0.0930
     7        6.1866             nan     0.1000    0.0419
     8        6.1073             nan     0.1000    0.0857
     9        6.0405             nan     0.1000    0.0182
    10        5.9878             nan     0.1000    0.0084
    20        5.4752             nan     0.1000    0.0077
    40        4.9224             nan     0.1000    0.0046
    60        4.5913             nan     0.1000   -0.0003
    80        4.4092             nan     0.1000   -0.0329
   100        4.3054             nan     0.1000   -0.0116
   120        4.2043             nan     0.1000    0.0017
   140        4.1491             nan     0.1000   -0.0123
   160        4.0985             nan     0.1000   -0.0114
   180        4.0638             nan     0.1000   -0.0142
   200        4.0289             nan     0.1000   -0.0207

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8440             nan     0.1000    0.2361
     2        6.6120             nan     0.1000    0.1809
     3        6.4480             nan     0.1000    0.1808
     4        6.2642             nan     0.1000    0.0966
     5        6.1114             nan     0.1000    0.1084
     6        6.0014             nan     0.1000    0.0353
     7        5.8667             nan     0.1000    0.0821
     8        5.7421             nan     0.1000    0.0878
     9        5.6488             nan     0.1000    0.0227
    10        5.5511             nan     0.1000    0.0540
    20        4.8649             nan     0.1000    0.0016
    40        4.2126             nan     0.1000   -0.0250
    60        3.9046             nan     0.1000   -0.0200
    80        3.7203             nan     0.1000   -0.0139
   100        3.5513             nan     0.1000   -0.0178
   120        3.4477             nan     0.1000   -0.0205
   140        3.4026             nan     0.1000   -0.0218
   160        3.3280             nan     0.1000   -0.0183
   180        3.2212             nan     0.1000   -0.0270
   200        3.1351             nan     0.1000   -0.0411

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8294             nan     0.1000    0.1750
     2        6.5223             nan     0.1000    0.2465
     3        6.2814             nan     0.1000    0.1919
     4        6.0498             nan     0.1000    0.1483
     5        5.8563             nan     0.1000    0.1211
     6        5.7115             nan     0.1000    0.0542
     7        5.5985             nan     0.1000    0.0881
     8        5.4764             nan     0.1000    0.0767
     9        5.3797             nan     0.1000    0.0810
    10        5.2981             nan     0.1000    0.0256
    20        4.6188             nan     0.1000    0.0194
    40        3.9965             nan     0.1000   -0.0172
    60        3.6141             nan     0.1000   -0.0296
    80        3.3813             nan     0.1000   -0.0224
   100        3.1232             nan     0.1000   -0.0128
   120        2.9464             nan     0.1000   -0.0067
   140        2.8034             nan     0.1000   -0.0168
   160        2.6362             nan     0.1000   -0.0161
   180        2.5192             nan     0.1000   -0.0176
   200        2.4195             nan     0.1000   -0.0144

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7343             nan     0.1000    0.2452
     2        6.4049             nan     0.1000    0.1914
     3        6.1818             nan     0.1000    0.1170
     4        5.9324             nan     0.1000    0.2395
     5        5.7430             nan     0.1000    0.0428
     6        5.5311             nan     0.1000    0.1574
     7        5.3582             nan     0.1000    0.0990
     8        5.2016             nan     0.1000    0.1152
     9        5.0848             nan     0.1000    0.0784
    10        4.9931             nan     0.1000    0.0060
    20        4.1460             nan     0.1000   -0.0085
    40        3.3699             nan     0.1000   -0.0148
    60        2.9600             nan     0.1000   -0.0643
    80        2.6524             nan     0.1000   -0.0198
   100        2.3895             nan     0.1000   -0.0328
   120        2.1681             nan     0.1000   -0.0180
   140        1.9386             nan     0.1000   -0.0116
   160        1.7694             nan     0.1000   -0.0206
   180        1.6169             nan     0.1000   -0.0137
   200        1.4845             nan     0.1000   -0.0089

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7720             nan     0.2000    0.1810
     2        6.3928             nan     0.2000    0.2760
     3        6.2694             nan     0.2000    0.1174
     4        6.1026             nan     0.2000    0.1592
     5        5.9375             nan     0.2000    0.1747
     6        5.7863             nan     0.2000    0.0706
     7        5.7077             nan     0.2000    0.0592
     8        5.6106             nan     0.2000    0.0496
     9        5.5413             nan     0.2000    0.0411
    10        5.4856             nan     0.2000   -0.0008
    20        4.9495             nan     0.2000    0.0056
    40        4.4149             nan     0.2000   -0.0415
    60        4.2112             nan     0.2000   -0.0107
    80        4.1337             nan     0.2000   -0.0446
   100        4.0708             nan     0.2000   -0.0338
   120        4.0386             nan     0.2000   -0.0204
   140        4.0054             nan     0.2000   -0.0201
   160        3.9724             nan     0.2000   -0.0426
   180        3.9489             nan     0.2000   -0.0254
   200        3.9046             nan     0.2000   -0.0311

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5366             nan     0.2000    0.5487
     2        6.2936             nan     0.2000    0.1482
     3        6.0088             nan     0.2000    0.2225
     4        5.8344             nan     0.2000    0.0086
     5        5.6610             nan     0.2000    0.0416
     6        5.5040             nan     0.2000    0.0833
     7        5.3196             nan     0.2000    0.0922
     8        5.1816             nan     0.2000    0.0936
     9        4.9968             nan     0.2000    0.1349
    10        4.8606             nan     0.2000    0.0640
    20        4.2573             nan     0.2000    0.0156
    40        3.7786             nan     0.2000   -0.0554
    60        3.5850             nan     0.2000   -0.0255
    80        3.3846             nan     0.2000   -0.0279
   100        3.1724             nan     0.2000   -0.0352
   120        3.0412             nan     0.2000   -0.0301
   140        2.9385             nan     0.2000   -0.0055
   160        2.8559             nan     0.2000   -0.0602
   180        2.7704             nan     0.2000   -0.0304
   200        2.6404             nan     0.2000   -0.0377

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5360             nan     0.2000    0.4932
     2        6.1578             nan     0.2000    0.3054
     3        5.8282             nan     0.2000    0.2199
     4        5.5498             nan     0.2000    0.1983
     5        5.3722             nan     0.2000    0.0346
     6        5.1973             nan     0.2000    0.1133
     7        5.0167             nan     0.2000    0.1101
     8        4.9088             nan     0.2000    0.0705
     9        4.7986             nan     0.2000    0.0296
    10        4.6761             nan     0.2000    0.0233
    20        4.1321             nan     0.2000   -0.0964
    40        3.3836             nan     0.2000   -0.0479
    60        3.0899             nan     0.2000   -0.0185
    80        2.8697             nan     0.2000   -0.0369
   100        2.6663             nan     0.2000   -0.0327
   120        2.4215             nan     0.2000   -0.0228
   140        2.2098             nan     0.2000   -0.0397
   160        2.0413             nan     0.2000   -0.0031
   180        1.8776             nan     0.2000   -0.0288
   200        1.7226             nan     0.2000   -0.0441

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5002             nan     0.2000    0.4095
     2        5.9566             nan     0.2000    0.3881
     3        5.4708             nan     0.2000    0.3564
     4        5.1759             nan     0.2000    0.1770
     5        4.9010             nan     0.2000    0.0988
     6        4.7134             nan     0.2000   -0.0084
     7        4.5779             nan     0.2000   -0.0377
     8        4.4313             nan     0.2000    0.0229
     9        4.3379             nan     0.2000   -0.0432
    10        4.2581             nan     0.2000   -0.0023
    20        3.4304             nan     0.2000   -0.0635
    40        2.6997             nan     0.2000   -0.0409
    60        2.2350             nan     0.2000   -0.0349
    80        1.8285             nan     0.2000   -0.0500
   100        1.5636             nan     0.2000   -0.0343
   120        1.3410             nan     0.2000   -0.0214
   140        1.1460             nan     0.2000   -0.0226
   160        0.9986             nan     0.2000   -0.0260
   180        0.8732             nan     0.2000   -0.0137
   200        0.7720             nan     0.2000   -0.0155

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7033             nan     0.0500    0.0887
     2        6.5967             nan     0.0500    0.0842
     3        6.4984             nan     0.0500    0.0895
     4        6.4048             nan     0.0500    0.0860
     5        6.3173             nan     0.0500    0.0698
     6        6.2553             nan     0.0500    0.0608
     7        6.1790             nan     0.0500    0.0832
     8        6.1184             nan     0.0500    0.0650
     9        6.0673             nan     0.0500    0.0436
    10        5.9996             nan     0.0500    0.0445
    20        5.6119             nan     0.0500    0.0131
    40        5.2222             nan     0.0500    0.0094
    60        4.9295             nan     0.0500    0.0021
    80        4.7011             nan     0.0500   -0.0006
   100        4.5520             nan     0.0500    0.0029
   120        4.4365             nan     0.0500    0.0044
   140        4.3349             nan     0.0500   -0.0037
   160        4.2422             nan     0.0500   -0.0144
   180        4.1823             nan     0.0500   -0.0135
   200        4.1306             nan     0.0500   -0.0046

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6790             nan     0.0500    0.1085
     2        6.5595             nan     0.0500    0.0779
     3        6.4317             nan     0.0500    0.0969
     4        6.3141             nan     0.0500    0.1177
     5        6.2101             nan     0.0500    0.0836
     6        6.1221             nan     0.0500    0.0690
     7        6.0389             nan     0.0500    0.0765
     8        5.9621             nan     0.0500    0.0699
     9        5.8928             nan     0.0500    0.0294
    10        5.8237             nan     0.0500    0.0436
    20        5.3192             nan     0.0500    0.0142
    40        4.7464             nan     0.0500    0.0121
    60        4.3923             nan     0.0500   -0.0090
    80        4.1219             nan     0.0500   -0.0028
   100        3.9721             nan     0.0500   -0.0154
   120        3.8209             nan     0.0500   -0.0107
   140        3.7158             nan     0.0500   -0.0078
   160        3.6454             nan     0.0500   -0.0116
   180        3.5620             nan     0.0500   -0.0058
   200        3.4689             nan     0.0500   -0.0108

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6577             nan     0.0500    0.0581
     2        6.5167             nan     0.0500    0.0973
     3        6.3907             nan     0.0500    0.1145
     4        6.2914             nan     0.0500    0.0594
     5        6.1767             nan     0.0500    0.0920
     6        6.0658             nan     0.0500    0.0905
     7        5.9568             nan     0.0500    0.0651
     8        5.8621             nan     0.0500    0.0604
     9        5.7719             nan     0.0500    0.0469
    10        5.6883             nan     0.0500    0.0927
    20        5.0836             nan     0.0500   -0.0026
    40        4.4022             nan     0.0500    0.0089
    60        4.0186             nan     0.0500   -0.0093
    80        3.7638             nan     0.0500   -0.0232
   100        3.5677             nan     0.0500   -0.0059
   120        3.3922             nan     0.0500   -0.0113
   140        3.2748             nan     0.0500   -0.0039
   160        3.1610             nan     0.0500   -0.0037
   180        3.0566             nan     0.0500   -0.0025
   200        2.9678             nan     0.0500   -0.0082

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6310             nan     0.0500    0.1037
     2        6.4520             nan     0.0500    0.1433
     3        6.3130             nan     0.0500    0.1269
     4        6.2083             nan     0.0500    0.0897
     5        6.0645             nan     0.0500    0.1034
     6        5.9184             nan     0.0500    0.1151
     7        5.7832             nan     0.0500    0.0763
     8        5.6670             nan     0.0500    0.0761
     9        5.5592             nan     0.0500    0.0906
    10        5.4942             nan     0.0500    0.0238
    20        4.7694             nan     0.0500    0.0329
    40        4.0189             nan     0.0500   -0.0126
    60        3.5793             nan     0.0500   -0.0173
    80        3.2595             nan     0.0500   -0.0112
   100        3.0242             nan     0.0500   -0.0079
   120        2.8459             nan     0.0500   -0.0067
   140        2.6817             nan     0.0500   -0.0060
   160        2.5412             nan     0.0500   -0.0096
   180        2.4122             nan     0.0500   -0.0059
   200        2.2945             nan     0.0500   -0.0159

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6064             nan     0.1000    0.2132
     2        6.4605             nan     0.1000    0.1529
     3        6.3010             nan     0.1000    0.1297
     4        6.1608             nan     0.1000    0.1077
     5        6.0289             nan     0.1000    0.1110
     6        5.9120             nan     0.1000    0.0719
     7        5.8731             nan     0.1000    0.0043
     8        5.7696             nan     0.1000    0.0713
     9        5.7210             nan     0.1000    0.0210
    10        5.6553             nan     0.1000    0.0690
    20        5.1970             nan     0.1000    0.0265
    40        4.6970             nan     0.1000    0.0027
    60        4.4285             nan     0.1000   -0.0123
    80        4.2462             nan     0.1000   -0.0164
   100        4.1138             nan     0.1000   -0.0151
   120        4.0564             nan     0.1000   -0.0162
   140        4.0042             nan     0.1000   -0.0185
   160        3.9690             nan     0.1000   -0.0136
   180        3.9184             nan     0.1000   -0.0186
   200        3.8996             nan     0.1000   -0.0116

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5297             nan     0.1000    0.2136
     2        6.3547             nan     0.1000    0.1300
     3        6.1936             nan     0.1000    0.1368
     4        5.9872             nan     0.1000    0.1302
     5        5.8132             nan     0.1000    0.1317
     6        5.7153             nan     0.1000    0.0700
     7        5.6272             nan     0.1000    0.0634
     8        5.5150             nan     0.1000    0.0461
     9        5.4134             nan     0.1000    0.1037
    10        5.3461             nan     0.1000    0.0432
    20        4.7298             nan     0.1000    0.0275
    40        4.1530             nan     0.1000   -0.0361
    60        3.8669             nan     0.1000   -0.0153
    80        3.6497             nan     0.1000   -0.0260
   100        3.5068             nan     0.1000   -0.0302
   120        3.3774             nan     0.1000   -0.0186
   140        3.2842             nan     0.1000   -0.0208
   160        3.1768             nan     0.1000   -0.0079
   180        3.0766             nan     0.1000   -0.0196
   200        2.9993             nan     0.1000   -0.0087

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4566             nan     0.1000    0.2870
     2        6.1862             nan     0.1000    0.2081
     3        5.9756             nan     0.1000    0.1299
     4        5.8791             nan     0.1000    0.0505
     5        5.7091             nan     0.1000    0.0957
     6        5.5763             nan     0.1000    0.1243
     7        5.4395             nan     0.1000    0.1169
     8        5.3090             nan     0.1000    0.0684
     9        5.1788             nan     0.1000    0.0695
    10        5.0689             nan     0.1000    0.0677
    20        4.3982             nan     0.1000    0.0094
    40        3.7640             nan     0.1000   -0.0547
    60        3.4306             nan     0.1000   -0.0288
    80        3.1756             nan     0.1000   -0.0184
   100        2.9806             nan     0.1000   -0.0122
   120        2.8344             nan     0.1000   -0.0261
   140        2.7036             nan     0.1000   -0.0335
   160        2.5594             nan     0.1000   -0.0399
   180        2.4430             nan     0.1000   -0.0207
   200        2.3396             nan     0.1000   -0.0412

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5411             nan     0.1000    0.2172
     2        6.1839             nan     0.1000    0.2119
     3        5.9369             nan     0.1000    0.1700
     4        5.7597             nan     0.1000    0.1323
     5        5.5396             nan     0.1000    0.1776
     6        5.3000             nan     0.1000    0.2041
     7        5.1403             nan     0.1000    0.0895
     8        5.0180             nan     0.1000    0.0647
     9        4.9153             nan     0.1000    0.0762
    10        4.7877             nan     0.1000    0.0699
    20        4.0073             nan     0.1000   -0.0121
    40        3.3061             nan     0.1000   -0.0060
    60        2.8976             nan     0.1000   -0.0221
    80        2.5510             nan     0.1000   -0.0350
   100        2.3084             nan     0.1000   -0.0222
   120        2.1025             nan     0.1000   -0.0190
   140        1.9223             nan     0.1000   -0.0288
   160        1.7100             nan     0.1000   -0.0155
   180        1.5698             nan     0.1000   -0.0243
   200        1.4451             nan     0.1000   -0.0107

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4734             nan     0.2000    0.2729
     2        6.0783             nan     0.2000    0.2924
     3        5.8300             nan     0.2000    0.1452
     4        5.6778             nan     0.2000    0.0457
     5        5.5517             nan     0.2000   -0.0061
     6        5.4417             nan     0.2000    0.1024
     7        5.3716             nan     0.2000    0.0174
     8        5.2548             nan     0.2000    0.0381
     9        5.2154             nan     0.2000   -0.0144
    10        5.1692             nan     0.2000   -0.0604
    20        4.6997             nan     0.2000    0.0123
    40        4.2742             nan     0.2000   -0.0072
    60        4.1013             nan     0.2000   -0.0191
    80        4.0020             nan     0.2000   -0.0260
   100        3.9428             nan     0.2000   -0.0173
   120        3.8966             nan     0.2000   -0.0457
   140        3.8738             nan     0.2000   -0.0300
   160        3.8313             nan     0.2000   -0.0206
   180        3.8334             nan     0.2000   -0.0059
   200        3.8431             nan     0.2000   -0.0371

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3816             nan     0.2000    0.3493
     2        5.9953             nan     0.2000    0.3357
     3        5.7789             nan     0.2000    0.1867
     4        5.6298             nan     0.2000    0.1197
     5        5.3941             nan     0.2000    0.1804
     6        5.2513             nan     0.2000    0.1275
     7        5.0994             nan     0.2000    0.0996
     8        4.9402             nan     0.2000    0.0845
     9        4.8555             nan     0.2000   -0.0255
    10        4.7619             nan     0.2000    0.0039
    20        4.2169             nan     0.2000   -0.0505
    40        3.7790             nan     0.2000   -0.0500
    60        3.5158             nan     0.2000   -0.0500
    80        3.3755             nan     0.2000   -0.0181
   100        3.1910             nan     0.2000   -0.0293
   120        3.0793             nan     0.2000   -0.0253
   140        2.9381             nan     0.2000   -0.0465
   160        2.8284             nan     0.2000   -0.0284
   180        2.7120             nan     0.2000   -0.0457
   200        2.6107             nan     0.2000   -0.0433

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.1645             nan     0.2000    0.6517
     2        5.8038             nan     0.2000    0.2466
     3        5.5182             nan     0.2000    0.0925
     4        5.2754             nan     0.2000    0.1476
     5        5.0441             nan     0.2000    0.0462
     6        4.9211             nan     0.2000    0.0968
     7        4.8094             nan     0.2000    0.0602
     8        4.7125             nan     0.2000   -0.0155
     9        4.6045             nan     0.2000    0.0236
    10        4.4876             nan     0.2000    0.0732
    20        3.8968             nan     0.2000   -0.0623
    40        3.3264             nan     0.2000   -0.0429
    60        2.9867             nan     0.2000   -0.0508
    80        2.6867             nan     0.2000   -0.0302
   100        2.4480             nan     0.2000   -0.0259
   120        2.2053             nan     0.2000   -0.0474
   140        2.0329             nan     0.2000   -0.0257
   160        1.8819             nan     0.2000   -0.0394
   180        1.7319             nan     0.2000   -0.0386
   200        1.6314             nan     0.2000   -0.0192

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.1369             nan     0.2000    0.4526
     2        5.5948             nan     0.2000    0.4512
     3        5.2986             nan     0.2000    0.1650
     4        5.1156             nan     0.2000    0.0502
     5        4.9327             nan     0.2000    0.0125
     6        4.6618             nan     0.2000    0.1679
     7        4.4921             nan     0.2000    0.0989
     8        4.3409             nan     0.2000    0.0553
     9        4.1900             nan     0.2000    0.0164
    10        4.1080             nan     0.2000   -0.0471
    20        3.4103             nan     0.2000   -0.0669
    40        2.6627             nan     0.2000   -0.0086
    60        2.1394             nan     0.2000   -0.0528
    80        1.7735             nan     0.2000   -0.0142
   100        1.5239             nan     0.2000   -0.0372
   120        1.2933             nan     0.2000   -0.0160
   140        1.1048             nan     0.2000   -0.0115
   160        0.9827             nan     0.2000   -0.0324
   180        0.8681             nan     0.2000   -0.0174
   200        0.7614             nan     0.2000   -0.0308

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3998             nan     0.0500    0.1191
     2        7.2668             nan     0.0500    0.1125
     3        7.1491             nan     0.0500    0.0846
     4        7.0590             nan     0.0500    0.0838
     5        6.9785             nan     0.0500    0.0513
     6        6.8945             nan     0.0500    0.0824
     7        6.8130             nan     0.0500    0.0600
     8        6.7456             nan     0.0500    0.0503
     9        6.7029             nan     0.0500    0.0240
    10        6.6720             nan     0.0500    0.0232
    20        6.2121             nan     0.0500    0.0299
    40        5.5955             nan     0.0500    0.0160
    60        5.2663             nan     0.0500    0.0072
    80        5.0207             nan     0.0500    0.0037
   100        4.8378             nan     0.0500   -0.0030
   120        4.7109             nan     0.0500   -0.0026
   140        4.5849             nan     0.0500    0.0012
   160        4.5011             nan     0.0500   -0.0139
   180        4.4286             nan     0.0500   -0.0014
   200        4.3681             nan     0.0500   -0.0033

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3641             nan     0.0500    0.1224
     2        7.2348             nan     0.0500    0.1314
     3        7.1105             nan     0.0500    0.1088
     4        7.0056             nan     0.0500    0.0708
     5        6.8875             nan     0.0500    0.1027
     6        6.7800             nan     0.0500    0.0866
     7        6.6694             nan     0.0500    0.1006
     8        6.5605             nan     0.0500    0.1001
     9        6.5046             nan     0.0500    0.0362
    10        6.4078             nan     0.0500    0.0585
    20        5.7609             nan     0.0500    0.0349
    40        5.0755             nan     0.0500    0.0148
    60        4.6894             nan     0.0500    0.0084
    80        4.3870             nan     0.0500   -0.0035
   100        4.1604             nan     0.0500   -0.0098
   120        4.0361             nan     0.0500   -0.0057
   140        3.9265             nan     0.0500   -0.0109
   160        3.8212             nan     0.0500   -0.0055
   180        3.7458             nan     0.0500   -0.0102
   200        3.6872             nan     0.0500   -0.0126

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3320             nan     0.0500    0.1653
     2        7.1781             nan     0.0500    0.1166
     3        7.0465             nan     0.0500    0.0804
     4        6.9124             nan     0.0500    0.1121
     5        6.7946             nan     0.0500    0.0766
     6        6.6828             nan     0.0500    0.0813
     7        6.5543             nan     0.0500    0.1045
     8        6.4514             nan     0.0500    0.0714
     9        6.3660             nan     0.0500    0.0786
    10        6.2589             nan     0.0500    0.0864
    20        5.5002             nan     0.0500    0.0323
    40        4.7345             nan     0.0500   -0.0113
    60        4.2730             nan     0.0500   -0.0018
    80        4.0311             nan     0.0500   -0.0063
   100        3.8384             nan     0.0500   -0.0106
   120        3.6566             nan     0.0500   -0.0129
   140        3.5190             nan     0.0500   -0.0027
   160        3.4013             nan     0.0500   -0.0015
   180        3.3005             nan     0.0500   -0.0136
   200        3.2072             nan     0.0500   -0.0194

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2675             nan     0.0500    0.1481
     2        7.1045             nan     0.0500    0.1273
     3        6.9347             nan     0.0500    0.1194
     4        6.7671             nan     0.0500    0.1047
     5        6.6058             nan     0.0500    0.1414
     6        6.4534             nan     0.0500    0.1193
     7        6.3221             nan     0.0500    0.0965
     8        6.2062             nan     0.0500    0.0878
     9        6.0981             nan     0.0500    0.0788
    10        5.9736             nan     0.0500    0.0953
    20        5.1674             nan     0.0500   -0.0052
    40        4.2931             nan     0.0500   -0.0035
    60        3.7935             nan     0.0500   -0.0012
    80        3.5053             nan     0.0500   -0.0053
   100        3.2549             nan     0.0500   -0.0166
   120        3.0572             nan     0.0500   -0.0034
   140        2.8963             nan     0.0500   -0.0131
   160        2.7106             nan     0.0500   -0.0122
   180        2.5597             nan     0.0500   -0.0162
   200        2.4323             nan     0.0500   -0.0083

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2992             nan     0.1000    0.1450
     2        7.0739             nan     0.1000    0.2120
     3        6.8757             nan     0.1000    0.1735
     4        6.8096             nan     0.1000    0.0317
     5        6.6729             nan     0.1000    0.1511
     6        6.5727             nan     0.1000    0.0823
     7        6.4550             nan     0.1000    0.0485
     8        6.3354             nan     0.1000    0.0804
     9        6.2591             nan     0.1000    0.0728
    10        6.1903             nan     0.1000    0.0213
    20        5.6472             nan     0.1000    0.0251
    40        5.0559             nan     0.1000    0.0097
    60        4.7335             nan     0.1000   -0.0411
    80        4.5145             nan     0.1000   -0.0130
   100        4.3715             nan     0.1000   -0.0176
   120        4.2825             nan     0.1000    0.0011
   140        4.2157             nan     0.1000   -0.0200
   160        4.1652             nan     0.1000   -0.0053
   180        4.1188             nan     0.1000   -0.0098
   200        4.0849             nan     0.1000   -0.0166

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1987             nan     0.1000    0.2589
     2        6.9802             nan     0.1000    0.1632
     3        6.7674             nan     0.1000    0.2000
     4        6.6059             nan     0.1000    0.1897
     5        6.4242             nan     0.1000    0.1207
     6        6.2862             nan     0.1000    0.0861
     7        6.1200             nan     0.1000    0.0770
     8        6.0076             nan     0.1000    0.0277
     9        5.8757             nan     0.1000    0.0757
    10        5.8128             nan     0.1000    0.0181
    20        5.1272             nan     0.1000   -0.0264
    40        4.4385             nan     0.1000   -0.0016
    60        4.1507             nan     0.1000   -0.0133
    80        3.9392             nan     0.1000   -0.0260
   100        3.7558             nan     0.1000   -0.0217
   120        3.6587             nan     0.1000   -0.0239
   140        3.5583             nan     0.1000   -0.0105
   160        3.4727             nan     0.1000   -0.0181
   180        3.3907             nan     0.1000   -0.0209
   200        3.3098             nan     0.1000   -0.0126

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1366             nan     0.1000    0.3029
     2        6.8324             nan     0.1000    0.2025
     3        6.5643             nan     0.1000    0.1766
     4        6.3857             nan     0.1000    0.1034
     5        6.1999             nan     0.1000    0.1374
     6        6.0106             nan     0.1000    0.1163
     7        5.8352             nan     0.1000    0.0531
     8        5.6840             nan     0.1000    0.1054
     9        5.5382             nan     0.1000    0.1054
    10        5.3965             nan     0.1000    0.0303
    20        4.7703             nan     0.1000    0.0247
    40        4.0990             nan     0.1000   -0.0135
    60        3.6986             nan     0.1000   -0.0253
    80        3.4472             nan     0.1000   -0.0065
   100        3.2118             nan     0.1000   -0.0065
   120        3.0421             nan     0.1000   -0.0385
   140        2.8857             nan     0.1000   -0.0303
   160        2.7846             nan     0.1000   -0.0101
   180        2.6417             nan     0.1000   -0.0237
   200        2.5005             nan     0.1000   -0.0079

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0901             nan     0.1000    0.2914
     2        6.7529             nan     0.1000    0.1751
     3        6.4313             nan     0.1000    0.1848
     4        6.2006             nan     0.1000    0.1833
     5        5.9408             nan     0.1000    0.1904
     6        5.7535             nan     0.1000    0.1721
     7        5.5951             nan     0.1000    0.1425
     8        5.4054             nan     0.1000    0.0949
     9        5.2647             nan     0.1000    0.0572
    10        5.1441             nan     0.1000    0.0483
    20        4.2833             nan     0.1000    0.0227
    40        3.5562             nan     0.1000   -0.0409
    60        3.1004             nan     0.1000   -0.0164
    80        2.7407             nan     0.1000   -0.0308
   100        2.4558             nan     0.1000   -0.0321
   120        2.2246             nan     0.1000   -0.0168
   140        2.0376             nan     0.1000   -0.0175
   160        1.8967             nan     0.1000   -0.0184
   180        1.7146             nan     0.1000   -0.0162
   200        1.5716             nan     0.1000   -0.0134

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0523             nan     0.2000    0.4482
     2        6.7741             nan     0.2000    0.2416
     3        6.4812             nan     0.2000    0.3114
     4        6.2995             nan     0.2000    0.1656
     5        6.1030             nan     0.2000    0.1155
     6        5.9766             nan     0.2000    0.0683
     7        5.9058             nan     0.2000    0.0168
     8        5.7899             nan     0.2000    0.0952
     9        5.6784             nan     0.2000    0.0574
    10        5.5988             nan     0.2000    0.0384
    20        5.0396             nan     0.2000    0.0197
    40        4.5601             nan     0.2000    0.0063
    60        4.3845             nan     0.2000   -0.0455
    80        4.2295             nan     0.2000   -0.0148
   100        4.1777             nan     0.2000   -0.0040
   120        4.1249             nan     0.2000   -0.0318
   140        4.0910             nan     0.2000   -0.0404
   160        4.0819             nan     0.2000   -0.0458
   180        4.0470             nan     0.2000   -0.0363
   200        4.0500             nan     0.2000   -0.0587

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0357             nan     0.2000    0.4326
     2        6.6131             nan     0.2000    0.3450
     3        6.2122             nan     0.2000    0.2728
     4        6.0889             nan     0.2000    0.0183
     5        5.8389             nan     0.2000    0.1258
     6        5.6506             nan     0.2000    0.0537
     7        5.4876             nan     0.2000    0.0779
     8        5.2941             nan     0.2000    0.1173
     9        5.1426             nan     0.2000    0.0445
    10        5.0726             nan     0.2000    0.0052
    20        4.4706             nan     0.2000   -0.0383
    40        3.9610             nan     0.2000   -0.0389
    60        3.6965             nan     0.2000   -0.0491
    80        3.5058             nan     0.2000   -0.0419
   100        3.3315             nan     0.2000   -0.0306
   120        3.2243             nan     0.2000   -0.0421
   140        3.1127             nan     0.2000   -0.0267
   160        2.9464             nan     0.2000   -0.0215
   180        2.8194             nan     0.2000   -0.0417
   200        2.7466             nan     0.2000   -0.0265

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9190             nan     0.2000    0.5128
     2        6.3932             nan     0.2000    0.3550
     3        6.0518             nan     0.2000    0.2892
     4        5.7818             nan     0.2000    0.1608
     5        5.5635             nan     0.2000    0.0391
     6        5.4074             nan     0.2000    0.1065
     7        5.3018             nan     0.2000   -0.0475
     8        5.1778             nan     0.2000   -0.0917
     9        5.0761             nan     0.2000    0.0075
    10        4.8892             nan     0.2000    0.1137
    20        4.1900             nan     0.2000   -0.0740
    40        3.4303             nan     0.2000   -0.0210
    60        3.0372             nan     0.2000   -0.0200
    80        2.7141             nan     0.2000   -0.0305
   100        2.5133             nan     0.2000   -0.0845
   120        2.3686             nan     0.2000   -0.0624
   140        2.2175             nan     0.2000   -0.0539
   160        2.0104             nan     0.2000   -0.0323
   180        1.8544             nan     0.2000   -0.0369
   200        1.7197             nan     0.2000   -0.0095

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6868             nan     0.2000    0.6954
     2        6.1391             nan     0.2000    0.3565
     3        5.8439             nan     0.2000    0.1042
     4        5.4464             nan     0.2000    0.2571
     5        5.1681             nan     0.2000    0.1378
     6        5.0086             nan     0.2000    0.0275
     7        4.8491             nan     0.2000    0.0954
     8        4.6487             nan     0.2000   -0.0281
     9        4.5176             nan     0.2000    0.0162
    10        4.3351             nan     0.2000    0.0418
    20        3.5959             nan     0.2000   -0.0563
    40        2.8787             nan     0.2000   -0.0538
    60        2.3723             nan     0.2000   -0.0804
    80        1.9786             nan     0.2000   -0.0086
   100        1.7194             nan     0.2000   -0.0332
   120        1.4346             nan     0.2000   -0.0538
   140        1.2415             nan     0.2000   -0.0265
   160        1.0891             nan     0.2000   -0.0202
   180        0.9534             nan     0.2000   -0.0164
   200        0.8550             nan     0.2000   -0.0330

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.4032             nan     0.0500    0.1369
     2        7.3042             nan     0.0500    0.0702
     3        7.2071             nan     0.0500    0.0848
     4        7.0959             nan     0.0500    0.1031
     5        7.0297             nan     0.0500    0.0611
     6        6.9379             nan     0.0500    0.0954
     7        6.8443             nan     0.0500    0.0761
     8        6.7624             nan     0.0500    0.0892
     9        6.6896             nan     0.0500    0.0415
    10        6.6241             nan     0.0500    0.0571
    20        6.1675             nan     0.0500    0.0051
    40        5.6562             nan     0.0500   -0.0018
    60        5.2817             nan     0.0500   -0.0031
    80        5.0311             nan     0.0500   -0.0029
   100        4.8441             nan     0.0500   -0.0069
   120        4.6890             nan     0.0500   -0.0068
   140        4.5783             nan     0.0500   -0.0028
   160        4.4901             nan     0.0500   -0.0170
   180        4.4058             nan     0.0500   -0.0027
   200        4.3581             nan     0.0500   -0.0097

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3491             nan     0.0500    0.1339
     2        7.2170             nan     0.0500    0.1147
     3        7.1103             nan     0.0500    0.1142
     4        6.9995             nan     0.0500    0.1104
     5        6.8972             nan     0.0500    0.0890
     6        6.7844             nan     0.0500    0.0844
     7        6.6938             nan     0.0500    0.0749
     8        6.5883             nan     0.0500    0.1139
     9        6.4962             nan     0.0500    0.0710
    10        6.4304             nan     0.0500    0.0377
    20        5.7883             nan     0.0500    0.0303
    40        5.0301             nan     0.0500   -0.0111
    60        4.6213             nan     0.0500   -0.0045
    80        4.3529             nan     0.0500   -0.0017
   100        4.1646             nan     0.0500   -0.0164
   120        4.0239             nan     0.0500   -0.0081
   140        3.9223             nan     0.0500   -0.0091
   160        3.8237             nan     0.0500   -0.0074
   180        3.7382             nan     0.0500   -0.0136
   200        3.6440             nan     0.0500   -0.0041

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3308             nan     0.0500    0.1685
     2        7.1481             nan     0.0500    0.1399
     3        6.9992             nan     0.0500    0.1409
     4        6.8626             nan     0.0500    0.0924
     5        6.7394             nan     0.0500    0.1140
     6        6.6281             nan     0.0500    0.1126
     7        6.5012             nan     0.0500    0.1007
     8        6.3917             nan     0.0500    0.0794
     9        6.2867             nan     0.0500    0.0864
    10        6.1940             nan     0.0500    0.0626
    20        5.5165             nan     0.0500    0.0371
    40        4.7384             nan     0.0500   -0.0049
    60        4.2793             nan     0.0500   -0.0053
    80        4.0067             nan     0.0500   -0.0111
   100        3.8062             nan     0.0500   -0.0198
   120        3.6495             nan     0.0500   -0.0154
   140        3.5178             nan     0.0500   -0.0108
   160        3.3762             nan     0.0500   -0.0142
   180        3.2752             nan     0.0500   -0.0041
   200        3.1592             nan     0.0500   -0.0077

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2585             nan     0.0500    0.1931
     2        7.0760             nan     0.0500    0.1191
     3        6.8566             nan     0.0500    0.1378
     4        6.7014             nan     0.0500    0.1022
     5        6.5360             nan     0.0500    0.1117
     6        6.3931             nan     0.0500    0.0930
     7        6.2493             nan     0.0500    0.0637
     8        6.1370             nan     0.0500    0.0943
     9        6.0076             nan     0.0500    0.0730
    10        5.8993             nan     0.0500    0.0692
    20        5.0902             nan     0.0500    0.0479
    40        4.2302             nan     0.0500    0.0084
    60        3.8113             nan     0.0500   -0.0108
    80        3.4909             nan     0.0500   -0.0171
   100        3.2311             nan     0.0500   -0.0231
   120        3.0368             nan     0.0500   -0.0134
   140        2.8441             nan     0.0500   -0.0057
   160        2.6641             nan     0.0500   -0.0194
   180        2.5234             nan     0.0500   -0.0106
   200        2.3855             nan     0.0500   -0.0047

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2671             nan     0.1000    0.2559
     2        7.1443             nan     0.1000    0.1078
     3        6.9542             nan     0.1000    0.1950
     4        6.7701             nan     0.1000    0.0861
     5        6.6302             nan     0.1000    0.1520
     6        6.5018             nan     0.1000    0.1161
     7        6.4016             nan     0.1000    0.0815
     8        6.3247             nan     0.1000    0.0492
     9        6.2568             nan     0.1000    0.0117
    10        6.1588             nan     0.1000    0.1123
    20        5.6241             nan     0.1000    0.0031
    40        5.0495             nan     0.1000   -0.0150
    60        4.7043             nan     0.1000    0.0012
    80        4.4977             nan     0.1000   -0.0075
   100        4.3540             nan     0.1000   -0.0035
   120        4.2617             nan     0.1000   -0.0129
   140        4.1787             nan     0.1000   -0.0149
   160        4.1442             nan     0.1000   -0.0093
   180        4.1144             nan     0.1000   -0.0157
   200        4.0752             nan     0.1000   -0.0272

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1781             nan     0.1000    0.2637
     2        6.9261             nan     0.1000    0.1747
     3        6.6953             nan     0.1000    0.2093
     4        6.5193             nan     0.1000    0.1336
     5        6.3476             nan     0.1000    0.1589
     6        6.2047             nan     0.1000    0.0790
     7        6.0700             nan     0.1000    0.0809
     8        5.9422             nan     0.1000    0.0729
     9        5.8227             nan     0.1000    0.0409
    10        5.6815             nan     0.1000    0.0280
    20        5.1289             nan     0.1000    0.0050
    40        4.4300             nan     0.1000   -0.0356
    60        4.1134             nan     0.1000    0.0016
    80        3.9096             nan     0.1000   -0.0175
   100        3.7267             nan     0.1000   -0.0303
   120        3.5925             nan     0.1000   -0.0072
   140        3.4623             nan     0.1000   -0.0170
   160        3.3544             nan     0.1000   -0.0117
   180        3.2565             nan     0.1000   -0.0177
   200        3.1793             nan     0.1000   -0.0332

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2061             nan     0.1000    0.2970
     2        6.8871             nan     0.1000    0.2707
     3        6.6436             nan     0.1000    0.1749
     4        6.3806             nan     0.1000    0.2551
     5        6.1422             nan     0.1000    0.2132
     6        5.9605             nan     0.1000    0.0884
     7        5.8073             nan     0.1000    0.1203
     8        5.6907             nan     0.1000    0.0874
     9        5.5313             nan     0.1000    0.1029
    10        5.4052             nan     0.1000    0.0820
    20        4.7044             nan     0.1000    0.0076
    40        4.0119             nan     0.1000   -0.0463
    60        3.5971             nan     0.1000   -0.0329
    80        3.3480             nan     0.1000   -0.0052
   100        3.2066             nan     0.1000   -0.0234
   120        2.9923             nan     0.1000   -0.0158
   140        2.8228             nan     0.1000   -0.0115
   160        2.6920             nan     0.1000   -0.0166
   180        2.5739             nan     0.1000   -0.0203
   200        2.4455             nan     0.1000   -0.0120

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1217             nan     0.1000    0.2749
     2        6.8235             nan     0.1000    0.2035
     3        6.5421             nan     0.1000    0.1564
     4        6.2519             nan     0.1000    0.2828
     5        5.9973             nan     0.1000    0.1629
     6        5.8147             nan     0.1000    0.0889
     7        5.6297             nan     0.1000    0.0784
     8        5.4494             nan     0.1000    0.1455
     9        5.2961             nan     0.1000    0.0694
    10        5.1725             nan     0.1000    0.0650
    20        4.3228             nan     0.1000   -0.0057
    40        3.5643             nan     0.1000   -0.0244
    60        3.1283             nan     0.1000   -0.0015
    80        2.7513             nan     0.1000   -0.0192
   100        2.4656             nan     0.1000   -0.0246
   120        2.2194             nan     0.1000   -0.0253
   140        1.9951             nan     0.1000   -0.0236
   160        1.8163             nan     0.1000   -0.0156
   180        1.6471             nan     0.1000   -0.0170
   200        1.5054             nan     0.1000   -0.0184

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1226             nan     0.2000    0.4958
     2        6.8481             nan     0.2000    0.2923
     3        6.5632             nan     0.2000    0.1758
     4        6.3091             nan     0.2000    0.1207
     5        6.2291             nan     0.2000    0.0496
     6        6.1086             nan     0.2000    0.0305
     7        6.0175             nan     0.2000   -0.0307
     8        5.8336             nan     0.2000    0.0917
     9        5.6962             nan     0.2000    0.1344
    10        5.5889             nan     0.2000    0.0697
    20        5.0498             nan     0.2000   -0.0094
    40        4.6212             nan     0.2000   -0.0195
    60        4.3509             nan     0.2000   -0.0430
    80        4.1937             nan     0.2000   -0.0342
   100        4.1197             nan     0.2000   -0.0227
   120        4.0600             nan     0.2000   -0.0146
   140        4.0174             nan     0.2000   -0.0233
   160        4.0177             nan     0.2000   -0.0550
   180        4.0000             nan     0.2000   -0.0297
   200        3.9918             nan     0.2000   -0.0363

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0358             nan     0.2000    0.4687
     2        6.4871             nan     0.2000    0.3911
     3        6.1740             nan     0.2000    0.2012
     4        5.9259             nan     0.2000    0.1867
     5        5.7009             nan     0.2000    0.1499
     6        5.5384             nan     0.2000    0.0110
     7        5.4060             nan     0.2000    0.0163
     8        5.3180             nan     0.2000    0.0201
     9        5.2508             nan     0.2000   -0.0053
    10        5.1269             nan     0.2000    0.0545
    20        4.4802             nan     0.2000    0.0402
    40        3.9730             nan     0.2000   -0.0513
    60        3.6632             nan     0.2000   -0.0579
    80        3.4434             nan     0.2000   -0.0367
   100        3.2720             nan     0.2000   -0.0267
   120        3.1701             nan     0.2000   -0.0445
   140        3.0159             nan     0.2000   -0.0260
   160        2.8713             nan     0.2000   -0.0213
   180        2.7953             nan     0.2000   -0.0193
   200        2.6919             nan     0.2000   -0.0091

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8247             nan     0.2000    0.6101
     2        6.2989             nan     0.2000    0.3508
     3        6.0033             nan     0.2000    0.1629
     4        5.7171             nan     0.2000    0.1724
     5        5.5140             nan     0.2000    0.0821
     6        5.3909             nan     0.2000    0.0280
     7        5.2071             nan     0.2000    0.0791
     8        5.0117             nan     0.2000    0.0083
     9        4.8830             nan     0.2000    0.0145
    10        4.7469             nan     0.2000    0.0801
    20        4.0366             nan     0.2000   -0.0002
    40        3.3752             nan     0.2000   -0.0974
    60        3.0104             nan     0.2000   -0.0327
    80        2.6794             nan     0.2000   -0.0139
   100        2.4044             nan     0.2000   -0.0047
   120        2.1703             nan     0.2000   -0.0278
   140        2.0222             nan     0.2000   -0.0501
   160        1.8373             nan     0.2000   -0.0164
   180        1.6815             nan     0.2000   -0.0247
   200        1.5810             nan     0.2000   -0.0231

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7501             nan     0.2000    0.6718
     2        6.1128             nan     0.2000    0.3876
     3        5.7351             nan     0.2000    0.3063
     4        5.4076             nan     0.2000    0.1134
     5        5.1118             nan     0.2000    0.0620
     6        4.9564             nan     0.2000    0.0617
     7        4.7803             nan     0.2000    0.0716
     8        4.6271             nan     0.2000    0.0272
     9        4.4645             nan     0.2000    0.0423
    10        4.3203             nan     0.2000    0.0858
    20        3.6550             nan     0.2000   -0.0709
    40        2.8497             nan     0.2000   -0.0551
    60        2.2988             nan     0.2000   -0.0414
    80        1.9788             nan     0.2000   -0.0494
   100        1.6128             nan     0.2000   -0.0406
   120        1.4206             nan     0.2000   -0.0393
   140        1.2286             nan     0.2000   -0.0323
   160        1.0765             nan     0.2000   -0.0234
   180        0.9522             nan     0.2000   -0.0264
   200        0.8251             nan     0.2000   -0.0183

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3506             nan     0.0500    0.1142
     2        7.2583             nan     0.0500    0.0938
     3        7.1489             nan     0.0500    0.0839
     4        7.0468             nan     0.0500    0.0592
     5        6.9515             nan     0.0500    0.0903
     6        6.8650             nan     0.0500    0.0871
     7        6.7739             nan     0.0500    0.0870
     8        6.7323             nan     0.0500    0.0225
     9        6.6756             nan     0.0500    0.0637
    10        6.6010             nan     0.0500    0.0507
    20        6.1302             nan     0.0500    0.0301
    40        5.5865             nan     0.0500    0.0092
    60        5.2606             nan     0.0500    0.0047
    80        5.0178             nan     0.0500   -0.0079
   100        4.8548             nan     0.0500   -0.0035
   120        4.7108             nan     0.0500   -0.0066
   140        4.6104             nan     0.0500    0.0025
   160        4.5262             nan     0.0500   -0.0127
   180        4.4430             nan     0.0500   -0.0043
   200        4.3889             nan     0.0500   -0.0110

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3545             nan     0.0500    0.1132
     2        7.1922             nan     0.0500    0.1410
     3        7.0613             nan     0.0500    0.1031
     4        6.9337             nan     0.0500    0.1028
     5        6.8392             nan     0.0500    0.0684
     6        6.7294             nan     0.0500    0.0950
     7        6.6246             nan     0.0500    0.0795
     8        6.5310             nan     0.0500    0.0773
     9        6.4692             nan     0.0500    0.0405
    10        6.3708             nan     0.0500    0.0638
    20        5.7663             nan     0.0500    0.0252
    40        5.0912             nan     0.0500    0.0107
    60        4.6930             nan     0.0500    0.0039
    80        4.4368             nan     0.0500   -0.0033
   100        4.2524             nan     0.0500   -0.0086
   120        4.1227             nan     0.0500   -0.0077
   140        4.0000             nan     0.0500   -0.0074
   160        3.8876             nan     0.0500   -0.0103
   180        3.8211             nan     0.0500   -0.0064
   200        3.7274             nan     0.0500    0.0018

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2866             nan     0.0500    0.1558
     2        7.1146             nan     0.0500    0.1388
     3        6.9627             nan     0.0500    0.1588
     4        6.8125             nan     0.0500    0.0791
     5        6.6770             nan     0.0500    0.1010
     6        6.5619             nan     0.0500    0.0846
     7        6.4551             nan     0.0500    0.0967
     8        6.3534             nan     0.0500    0.0888
     9        6.2362             nan     0.0500    0.0546
    10        6.1248             nan     0.0500    0.0770
    20        5.4283             nan     0.0500    0.0248
    40        4.7061             nan     0.0500    0.0081
    60        4.3118             nan     0.0500   -0.0108
    80        4.0607             nan     0.0500   -0.0094
   100        3.8777             nan     0.0500   -0.0051
   120        3.7003             nan     0.0500   -0.0091
   140        3.5571             nan     0.0500   -0.0079
   160        3.4296             nan     0.0500   -0.0104
   180        3.3032             nan     0.0500   -0.0156
   200        3.1838             nan     0.0500   -0.0039

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2836             nan     0.0500    0.1677
     2        7.0815             nan     0.0500    0.1883
     3        6.9403             nan     0.0500    0.1291
     4        6.7546             nan     0.0500    0.1583
     5        6.5663             nan     0.0500    0.1273
     6        6.4075             nan     0.0500    0.0934
     7        6.3126             nan     0.0500    0.0720
     8        6.1816             nan     0.0500    0.0320
     9        6.0587             nan     0.0500    0.0768
    10        5.9430             nan     0.0500    0.0591
    20        5.2031             nan     0.0500    0.0035
    40        4.4170             nan     0.0500   -0.0017
    60        3.9352             nan     0.0500   -0.0056
    80        3.5557             nan     0.0500   -0.0070
   100        3.3135             nan     0.0500   -0.0149
   120        3.1030             nan     0.0500   -0.0173
   140        2.9427             nan     0.0500   -0.0113
   160        2.7930             nan     0.0500   -0.0015
   180        2.6387             nan     0.0500   -0.0130
   200        2.4857             nan     0.0500   -0.0142

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2584             nan     0.1000    0.2105
     2        7.0138             nan     0.1000    0.2525
     3        6.8225             nan     0.1000    0.1759
     4        6.6901             nan     0.1000    0.1367
     5        6.5606             nan     0.1000    0.1226
     6        6.4985             nan     0.1000    0.0258
     7        6.3895             nan     0.1000    0.0581
     8        6.3026             nan     0.1000    0.0808
     9        6.2104             nan     0.1000    0.1009
    10        6.1645             nan     0.1000    0.0095
    20        5.5812             nan     0.1000   -0.0062
    40        5.0248             nan     0.1000    0.0061
    60        4.7167             nan     0.1000   -0.0312
    80        4.5332             nan     0.1000   -0.0058
   100        4.4204             nan     0.1000   -0.0106
   120        4.3357             nan     0.1000   -0.0228
   140        4.2488             nan     0.1000   -0.0149
   160        4.2050             nan     0.1000   -0.0118
   180        4.1652             nan     0.1000   -0.0249
   200        4.1390             nan     0.1000   -0.0145

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1825             nan     0.1000    0.2295
     2        6.9850             nan     0.1000    0.2169
     3        6.7593             nan     0.1000    0.1557
     4        6.4939             nan     0.1000    0.2207
     5        6.3421             nan     0.1000    0.1551
     6        6.2157             nan     0.1000    0.1048
     7        6.0714             nan     0.1000    0.1234
     8        5.9186             nan     0.1000    0.0880
     9        5.8420             nan     0.1000    0.0326
    10        5.7674             nan     0.1000    0.0227
    20        5.0642             nan     0.1000    0.0381
    40        4.4531             nan     0.1000    0.0050
    60        4.0536             nan     0.1000   -0.0151
    80        3.8513             nan     0.1000   -0.0029
   100        3.6924             nan     0.1000   -0.0072
   120        3.5551             nan     0.1000   -0.0300
   140        3.4385             nan     0.1000   -0.0125
   160        3.3530             nan     0.1000   -0.0197
   180        3.2760             nan     0.1000   -0.0346
   200        3.1972             nan     0.1000   -0.0146

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2127             nan     0.1000    0.0333
     2        6.8686             nan     0.1000    0.2347
     3        6.6236             nan     0.1000    0.1631
     4        6.4118             nan     0.1000    0.1320
     5        6.1863             nan     0.1000    0.1616
     6        5.9844             nan     0.1000    0.1459
     7        5.8397             nan     0.1000    0.1006
     8        5.6811             nan     0.1000    0.1118
     9        5.5303             nan     0.1000    0.1102
    10        5.3966             nan     0.1000    0.0890
    20        4.7495             nan     0.1000   -0.0178
    40        4.1111             nan     0.1000   -0.0107
    60        3.7382             nan     0.1000   -0.0332
    80        3.4225             nan     0.1000    0.0025
   100        3.1813             nan     0.1000   -0.0111
   120        3.0598             nan     0.1000   -0.0320
   140        2.9115             nan     0.1000   -0.0112
   160        2.7625             nan     0.1000   -0.0223
   180        2.6453             nan     0.1000   -0.0086
   200        2.5370             nan     0.1000   -0.0420

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1107             nan     0.1000    0.2572
     2        6.7815             nan     0.1000    0.2476
     3        6.4599             nan     0.1000    0.2942
     4        6.1948             nan     0.1000    0.2115
     5        5.9226             nan     0.1000    0.2157
     6        5.7426             nan     0.1000    0.1168
     7        5.5881             nan     0.1000    0.1065
     8        5.4362             nan     0.1000    0.1274
     9        5.2884             nan     0.1000    0.1004
    10        5.1814             nan     0.1000    0.0138
    20        4.3406             nan     0.1000    0.0135
    40        3.5813             nan     0.1000    0.0067
    60        3.1028             nan     0.1000   -0.0282
    80        2.7998             nan     0.1000   -0.0404
   100        2.5350             nan     0.1000   -0.0266
   120        2.3311             nan     0.1000   -0.0221
   140        2.1445             nan     0.1000   -0.0136
   160        1.9798             nan     0.1000   -0.0372
   180        1.8001             nan     0.1000   -0.0221
   200        1.6703             nan     0.1000   -0.0219

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0183             nan     0.2000    0.4205
     2        6.6571             nan     0.2000    0.2376
     3        6.4058             nan     0.2000    0.3073
     4        6.1713             nan     0.2000    0.1828
     5        6.0277             nan     0.2000    0.1257
     6        5.8885             nan     0.2000    0.0591
     7        5.8043             nan     0.2000    0.0438
     8        5.7296             nan     0.2000    0.0388
     9        5.6082             nan     0.2000    0.0279
    10        5.5131             nan     0.2000    0.0588
    20        5.0821             nan     0.2000   -0.0457
    40        4.6383             nan     0.2000   -0.0203
    60        4.4337             nan     0.2000   -0.0089
    80        4.2922             nan     0.2000   -0.0159
   100        4.2364             nan     0.2000   -0.0358
   120        4.1558             nan     0.2000   -0.0716
   140        4.1038             nan     0.2000   -0.0252
   160        4.1008             nan     0.2000   -0.0155
   180        4.0757             nan     0.2000   -0.0339
   200        4.0741             nan     0.2000   -0.0195

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8268             nan     0.2000    0.5346
     2        6.4614             nan     0.2000    0.2569
     3        6.2795             nan     0.2000    0.0656
     4        5.9923             nan     0.2000    0.2757
     5        5.7126             nan     0.2000    0.2112
     6        5.5531             nan     0.2000    0.0908
     7        5.4150             nan     0.2000    0.1088
     8        5.3462             nan     0.2000   -0.0738
     9        5.2103             nan     0.2000   -0.0343
    10        5.1494             nan     0.2000   -0.0095
    20        4.5615             nan     0.2000   -0.0120
    40        4.0476             nan     0.2000   -0.0289
    60        3.7715             nan     0.2000   -0.0834
    80        3.5263             nan     0.2000   -0.0369
   100        3.4155             nan     0.2000   -0.0538
   120        3.2850             nan     0.2000   -0.0575
   140        3.1702             nan     0.2000   -0.0548
   160        3.0302             nan     0.2000   -0.0409
   180        2.8854             nan     0.2000   -0.0240
   200        2.7824             nan     0.2000   -0.0392

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8554             nan     0.2000    0.4962
     2        6.3439             nan     0.2000    0.4482
     3        6.1166             nan     0.2000    0.1329
     4        5.7358             nan     0.2000    0.2690
     5        5.5655             nan     0.2000    0.1069
     6        5.3785             nan     0.2000    0.0932
     7        5.2590             nan     0.2000    0.0278
     8        5.1096             nan     0.2000    0.0369
     9        4.9695             nan     0.2000    0.0540
    10        4.7739             nan     0.2000    0.0880
    20        4.1153             nan     0.2000   -0.0419
    40        3.5712             nan     0.2000   -0.0602
    60        3.2595             nan     0.2000   -0.0758
    80        2.8930             nan     0.2000   -0.0503
   100        2.6776             nan     0.2000   -0.0147
   120        2.5496             nan     0.2000   -0.0403
   140        2.3714             nan     0.2000   -0.0236
   160        2.1314             nan     0.2000   -0.0549
   180        1.9384             nan     0.2000   -0.0365
   200        1.8374             nan     0.2000   -0.0218

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6506             nan     0.2000    0.8183
     2        6.0868             nan     0.2000    0.2631
     3        5.6936             nan     0.2000    0.2218
     4        5.3902             nan     0.2000    0.2166
     5        5.1384             nan     0.2000    0.2078
     6        4.9499             nan     0.2000   -0.0053
     7        4.8231             nan     0.2000    0.0452
     8        4.6800             nan     0.2000    0.0316
     9        4.5758             nan     0.2000    0.0180
    10        4.4876             nan     0.2000   -0.0246
    20        3.7122             nan     0.2000   -0.0856
    40        3.0049             nan     0.2000   -0.0787
    60        2.4832             nan     0.2000   -0.0543
    80        2.0982             nan     0.2000   -0.0605
   100        1.7436             nan     0.2000   -0.0264
   120        1.5272             nan     0.2000   -0.0329
   140        1.2941             nan     0.2000   -0.0374
   160        1.1264             nan     0.2000   -0.0040
   180        1.0070             nan     0.2000   -0.0281
   200        0.8802             nan     0.2000   -0.0335

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9922             nan     0.0500    0.0992
     2        6.9050             nan     0.0500    0.0942
     3        6.8239             nan     0.0500    0.0845
     4        6.7441             nan     0.0500    0.0833
     5        6.6768             nan     0.0500    0.0582
     6        6.6269             nan     0.0500    0.0272
     7        6.5687             nan     0.0500    0.0519
     8        6.5364             nan     0.0500    0.0342
     9        6.4564             nan     0.0500    0.0654
    10        6.3864             nan     0.0500    0.0439
    20        6.0014             nan     0.0500    0.0264
    40        5.5031             nan     0.0500   -0.0022
    60        5.1787             nan     0.0500    0.0103
    80        4.9348             nan     0.0500   -0.0077
   100        4.7624             nan     0.0500   -0.0037
   120        4.6202             nan     0.0500   -0.0135
   140        4.5129             nan     0.0500   -0.0006
   160        4.4267             nan     0.0500   -0.0075
   180        4.3562             nan     0.0500   -0.0035
   200        4.2974             nan     0.0500   -0.0060

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9872             nan     0.0500    0.0917
     2        6.8469             nan     0.0500    0.1125
     3        6.7358             nan     0.0500    0.1063
     4        6.6203             nan     0.0500    0.1101
     5        6.5309             nan     0.0500    0.0965
     6        6.4415             nan     0.0500    0.0733
     7        6.3319             nan     0.0500    0.0942
     8        6.2585             nan     0.0500    0.0425
     9        6.1892             nan     0.0500    0.0374
    10        6.1189             nan     0.0500    0.0233
    20        5.6602             nan     0.0500    0.0085
    40        5.0057             nan     0.0500    0.0020
    60        4.5833             nan     0.0500    0.0044
    80        4.3139             nan     0.0500   -0.0136
   100        4.1435             nan     0.0500   -0.0124
   120        3.9976             nan     0.0500   -0.0099
   140        3.9096             nan     0.0500   -0.0205
   160        3.7830             nan     0.0500   -0.0029
   180        3.7035             nan     0.0500   -0.0018
   200        3.6347             nan     0.0500   -0.0100

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9621             nan     0.0500    0.1182
     2        6.7985             nan     0.0500    0.1523
     3        6.6675             nan     0.0500    0.1268
     4        6.5603             nan     0.0500    0.0986
     5        6.4578             nan     0.0500    0.0820
     6        6.3384             nan     0.0500    0.0943
     7        6.2224             nan     0.0500    0.0810
     8        6.1611             nan     0.0500    0.0143
     9        6.0809             nan     0.0500    0.0569
    10        5.9853             nan     0.0500    0.0893
    20        5.3542             nan     0.0500    0.0356
    40        4.6764             nan     0.0500    0.0113
    60        4.2788             nan     0.0500   -0.0041
    80        3.9962             nan     0.0500   -0.0102
   100        3.7727             nan     0.0500    0.0011
   120        3.6094             nan     0.0500   -0.0074
   140        3.4659             nan     0.0500   -0.0091
   160        3.3287             nan     0.0500   -0.0012
   180        3.2167             nan     0.0500   -0.0043
   200        3.1228             nan     0.0500   -0.0107

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9439             nan     0.0500    0.1421
     2        6.7657             nan     0.0500    0.1367
     3        6.5937             nan     0.0500    0.1720
     4        6.4623             nan     0.0500    0.1392
     5        6.3443             nan     0.0500    0.0817
     6        6.2200             nan     0.0500    0.1009
     7        6.0862             nan     0.0500    0.0865
     8        5.9798             nan     0.0500    0.0819
     9        5.8828             nan     0.0500    0.0579
    10        5.7802             nan     0.0500    0.0796
    20        5.0488             nan     0.0500    0.0204
    40        4.2391             nan     0.0500    0.0022
    60        3.7771             nan     0.0500    0.0008
    80        3.4659             nan     0.0500   -0.0092
   100        3.1983             nan     0.0500   -0.0233
   120        2.9787             nan     0.0500   -0.0090
   140        2.7858             nan     0.0500   -0.0121
   160        2.6499             nan     0.0500   -0.0215
   180        2.4932             nan     0.0500   -0.0041
   200        2.3487             nan     0.0500   -0.0125

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8507             nan     0.1000    0.2367
     2        6.6721             nan     0.1000    0.1329
     3        6.5699             nan     0.1000    0.0765
     4        6.4437             nan     0.1000    0.1306
     5        6.3362             nan     0.1000    0.0854
     6        6.2464             nan     0.1000    0.0728
     7        6.1950             nan     0.1000    0.0408
     8        6.1225             nan     0.1000    0.0241
     9        6.0448             nan     0.1000    0.0430
    10        5.9802             nan     0.1000    0.0593
    20        5.5361             nan     0.1000   -0.0035
    40        4.9215             nan     0.1000    0.0141
    60        4.6226             nan     0.1000   -0.0201
    80        4.4405             nan     0.1000   -0.0172
   100        4.3230             nan     0.1000   -0.0033
   120        4.2438             nan     0.1000   -0.0060
   140        4.1699             nan     0.1000   -0.0098
   160        4.1252             nan     0.1000   -0.0042
   180        4.0792             nan     0.1000   -0.0083
   200        4.0601             nan     0.1000   -0.0145

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8946             nan     0.1000    0.2542
     2        6.6276             nan     0.1000    0.1702
     3        6.4621             nan     0.1000    0.0522
     4        6.3359             nan     0.1000    0.0933
     5        6.1532             nan     0.1000    0.1546
     6        6.0009             nan     0.1000    0.1162
     7        5.9116             nan     0.1000    0.0636
     8        5.7799             nan     0.1000    0.0907
     9        5.6675             nan     0.1000    0.0519
    10        5.5553             nan     0.1000    0.0730
    20        4.9528             nan     0.1000    0.0167
    40        4.3379             nan     0.1000   -0.0111
    60        4.0746             nan     0.1000   -0.0069
    80        3.8156             nan     0.1000   -0.0275
   100        3.6650             nan     0.1000   -0.0283
   120        3.5167             nan     0.1000   -0.0222
   140        3.3902             nan     0.1000   -0.0225
   160        3.3283             nan     0.1000   -0.0147
   180        3.2102             nan     0.1000   -0.0194
   200        3.1449             nan     0.1000   -0.0125

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8351             nan     0.1000    0.2535
     2        6.6148             nan     0.1000    0.1772
     3        6.4006             nan     0.1000    0.1442
     4        6.1904             nan     0.1000    0.2097
     5        6.0422             nan     0.1000    0.1013
     6        5.9294             nan     0.1000    0.0474
     7        5.7740             nan     0.1000    0.0963
     8        5.5974             nan     0.1000    0.0926
     9        5.4530             nan     0.1000    0.0781
    10        5.3211             nan     0.1000    0.0483
    20        4.5727             nan     0.1000    0.0099
    40        3.9236             nan     0.1000    0.0050
    60        3.5658             nan     0.1000   -0.0183
    80        3.3187             nan     0.1000   -0.0320
   100        3.1173             nan     0.1000   -0.0223
   120        2.9541             nan     0.1000   -0.0183
   140        2.7915             nan     0.1000   -0.0187
   160        2.6525             nan     0.1000   -0.0178
   180        2.5228             nan     0.1000   -0.0248
   200        2.4380             nan     0.1000   -0.0227

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7187             nan     0.1000    0.2419
     2        6.4406             nan     0.1000    0.1522
     3        6.1763             nan     0.1000    0.2171
     4        5.9786             nan     0.1000    0.0912
     5        5.7504             nan     0.1000    0.0763
     6        5.5750             nan     0.1000    0.1502
     7        5.3644             nan     0.1000    0.1565
     8        5.2033             nan     0.1000    0.0872
     9        5.0765             nan     0.1000    0.1074
    10        4.9527             nan     0.1000    0.0811
    20        4.1884             nan     0.1000   -0.0087
    40        3.4468             nan     0.1000   -0.0134
    60        2.9944             nan     0.1000   -0.0191
    80        2.6499             nan     0.1000   -0.0374
   100        2.3924             nan     0.1000   -0.0344
   120        2.1603             nan     0.1000   -0.0128
   140        1.9403             nan     0.1000   -0.0146
   160        1.7870             nan     0.1000   -0.0217
   180        1.6360             nan     0.1000   -0.0103
   200        1.4988             nan     0.1000   -0.0100

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7012             nan     0.2000    0.4360
     2        6.4909             nan     0.2000    0.2259
     3        6.3308             nan     0.2000    0.1527
     4        6.0969             nan     0.2000    0.2714
     5        5.9743             nan     0.2000    0.0654
     6        5.8414             nan     0.2000    0.0717
     7        5.7324             nan     0.2000    0.0587
     8        5.6598             nan     0.2000   -0.0087
     9        5.5736             nan     0.2000    0.0753
    10        5.5239             nan     0.2000   -0.0567
    20        4.9503             nan     0.2000    0.0098
    40        4.4495             nan     0.2000   -0.0037
    60        4.2478             nan     0.2000   -0.0514
    80        4.1407             nan     0.2000   -0.0046
   100        4.0772             nan     0.2000   -0.0463
   120        4.0396             nan     0.2000   -0.0369
   140        4.0192             nan     0.2000   -0.0229
   160        3.9951             nan     0.2000   -0.0319
   180        3.9685             nan     0.2000   -0.0214
   200        3.9619             nan     0.2000   -0.0316

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6307             nan     0.2000    0.5037
     2        6.2811             nan     0.2000    0.2023
     3        6.0430             nan     0.2000    0.1132
     4        5.8806             nan     0.2000    0.1584
     5        5.6574             nan     0.2000   -0.0306
     6        5.5066             nan     0.2000    0.0668
     7        5.3916             nan     0.2000    0.0078
     8        5.3529             nan     0.2000   -0.0753
     9        5.2174             nan     0.2000    0.0041
    10        5.1387             nan     0.2000   -0.0053
    20        4.4505             nan     0.2000   -0.0003
    40        3.9056             nan     0.2000   -0.0380
    60        3.6558             nan     0.2000   -0.0458
    80        3.4737             nan     0.2000   -0.0594
   100        3.2819             nan     0.2000   -0.0188
   120        3.1033             nan     0.2000   -0.0316
   140        2.9688             nan     0.2000   -0.0388
   160        2.8535             nan     0.2000   -0.0373
   180        2.7053             nan     0.2000   -0.0217
   200        2.5806             nan     0.2000   -0.0261

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4808             nan     0.2000    0.3646
     2        6.0175             nan     0.2000    0.2908
     3        5.7450             nan     0.2000    0.2157
     4        5.4311             nan     0.2000    0.1229
     5        5.2457             nan     0.2000    0.0570
     6        5.1367             nan     0.2000   -0.0439
     7        5.0402             nan     0.2000    0.0232
     8        4.9193             nan     0.2000   -0.0109
     9        4.7966             nan     0.2000    0.0343
    10        4.7458             nan     0.2000   -0.1130
    20        4.1465             nan     0.2000   -0.0788
    40        3.4492             nan     0.2000   -0.0941
    60        2.9675             nan     0.2000   -0.0669
    80        2.7520             nan     0.2000   -0.0303
   100        2.5332             nan     0.2000   -0.0339
   120        2.2934             nan     0.2000   -0.0415
   140        2.1165             nan     0.2000   -0.0435
   160        1.9670             nan     0.2000   -0.0445
   180        1.8453             nan     0.2000   -0.0175
   200        1.7156             nan     0.2000   -0.0247

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4518             nan     0.2000    0.6093
     2        6.0313             nan     0.2000    0.3315
     3        5.6010             nan     0.2000    0.2872
     4        5.2620             nan     0.2000    0.0925
     5        4.9929             nan     0.2000    0.0641
     6        4.7416             nan     0.2000    0.1099
     7        4.5861             nan     0.2000    0.0128
     8        4.4183             nan     0.2000    0.0434
     9        4.3280             nan     0.2000   -0.0123
    10        4.2378             nan     0.2000   -0.0661
    20        3.4923             nan     0.2000   -0.0808
    40        2.7198             nan     0.2000   -0.0712
    60        2.2271             nan     0.2000   -0.0648
    80        1.8822             nan     0.2000   -0.0869
   100        1.5569             nan     0.2000   -0.0357
   120        1.2749             nan     0.2000   -0.0239
   140        1.0938             nan     0.2000   -0.0136
   160        0.9444             nan     0.2000   -0.0300
   180        0.8200             nan     0.2000   -0.0302
   200        0.7265             nan     0.2000   -0.0288

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3403             nan     0.0500    0.1237
     2        7.1907             nan     0.0500    0.0907
     3        7.0725             nan     0.0500    0.0872
     4        6.9805             nan     0.0500    0.0781
     5        6.9003             nan     0.0500    0.0627
     6        6.8147             nan     0.0500    0.0579
     7        6.7417             nan     0.0500    0.0625
     8        6.6684             nan     0.0500    0.0714
     9        6.6416             nan     0.0500   -0.0092
    10        6.5896             nan     0.0500    0.0453
    20        6.1146             nan     0.0500    0.0332
    40        5.5880             nan     0.0500    0.0122
    60        5.2555             nan     0.0500   -0.0001
    80        5.0153             nan     0.0500   -0.0008
   100        4.8441             nan     0.0500    0.0010
   120        4.7201             nan     0.0500   -0.0022
   140        4.6353             nan     0.0500    0.0008
   160        4.5463             nan     0.0500   -0.0027
   180        4.4705             nan     0.0500   -0.0028
   200        4.4166             nan     0.0500   -0.0090

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.3038             nan     0.0500    0.1533
     2        7.1744             nan     0.0500    0.1358
     3        7.0424             nan     0.0500    0.0951
     4        6.8983             nan     0.0500    0.1362
     5        6.7997             nan     0.0500    0.0911
     6        6.6857             nan     0.0500    0.1029
     7        6.5936             nan     0.0500    0.1000
     8        6.4809             nan     0.0500    0.0618
     9        6.3875             nan     0.0500    0.0617
    10        6.3046             nan     0.0500    0.0622
    20        5.7580             nan     0.0500    0.0407
    40        5.0878             nan     0.0500    0.0177
    60        4.7268             nan     0.0500    0.0059
    80        4.4552             nan     0.0500   -0.0192
   100        4.2828             nan     0.0500   -0.0019
   120        4.1551             nan     0.0500   -0.0099
   140        4.0579             nan     0.0500   -0.0160
   160        3.9513             nan     0.0500   -0.0174
   180        3.8538             nan     0.0500   -0.0033
   200        3.7897             nan     0.0500   -0.0130

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2951             nan     0.0500    0.1484
     2        7.1607             nan     0.0500    0.1135
     3        7.0145             nan     0.0500    0.1019
     4        6.8735             nan     0.0500    0.0979
     5        6.7272             nan     0.0500    0.1329
     6        6.6040             nan     0.0500    0.1018
     7        6.4991             nan     0.0500    0.0971
     8        6.3839             nan     0.0500    0.0980
     9        6.2895             nan     0.0500    0.0510
    10        6.2116             nan     0.0500    0.0727
    20        5.5093             nan     0.0500    0.0353
    40        4.7227             nan     0.0500    0.0060
    60        4.3227             nan     0.0500   -0.0082
    80        4.0105             nan     0.0500   -0.0089
   100        3.8160             nan     0.0500   -0.0079
   120        3.6396             nan     0.0500   -0.0144
   140        3.5105             nan     0.0500   -0.0114
   160        3.3710             nan     0.0500   -0.0115
   180        3.2582             nan     0.0500   -0.0101
   200        3.1613             nan     0.0500   -0.0109

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2564             nan     0.0500    0.1653
     2        7.0797             nan     0.0500    0.1259
     3        6.8808             nan     0.0500    0.1237
     4        6.7234             nan     0.0500    0.1232
     5        6.5658             nan     0.0500    0.1018
     6        6.4473             nan     0.0500    0.0553
     7        6.3309             nan     0.0500    0.1034
     8        6.2015             nan     0.0500    0.1043
     9        6.0819             nan     0.0500    0.0851
    10        5.9809             nan     0.0500    0.0483
    20        5.1758             nan     0.0500    0.0480
    40        4.3311             nan     0.0500   -0.0147
    60        3.8552             nan     0.0500   -0.0011
    80        3.5124             nan     0.0500   -0.0139
   100        3.2941             nan     0.0500   -0.0132
   120        3.0690             nan     0.0500   -0.0125
   140        2.8622             nan     0.0500   -0.0061
   160        2.7012             nan     0.0500   -0.0153
   180        2.5937             nan     0.0500   -0.0101
   200        2.4420             nan     0.0500   -0.0084

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2096             nan     0.1000    0.2412
     2        6.9782             nan     0.1000    0.2164
     3        6.8220             nan     0.1000    0.1022
     4        6.6813             nan     0.1000    0.1448
     5        6.5853             nan     0.1000    0.0932
     6        6.4807             nan     0.1000    0.1184
     7        6.3794             nan     0.1000    0.0610
     8        6.3352             nan     0.1000    0.0210
     9        6.2852             nan     0.1000   -0.0046
    10        6.2414             nan     0.1000   -0.0026
    20        5.6350             nan     0.1000    0.0015
    40        5.0787             nan     0.1000    0.0041
    60        4.8098             nan     0.1000   -0.0384
    80        4.6031             nan     0.1000   -0.0126
   100        4.4438             nan     0.1000   -0.0349
   120        4.3613             nan     0.1000   -0.0031
   140        4.2718             nan     0.1000   -0.0144
   160        4.2256             nan     0.1000   -0.0215
   180        4.1840             nan     0.1000   -0.0027
   200        4.1397             nan     0.1000   -0.0406

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1949             nan     0.1000    0.3390
     2        6.9686             nan     0.1000    0.2120
     3        6.7181             nan     0.1000    0.2326
     4        6.5423             nan     0.1000    0.1667
     5        6.3739             nan     0.1000    0.1485
     6        6.2261             nan     0.1000    0.1134
     7        6.1198             nan     0.1000    0.0878
     8        6.0442             nan     0.1000   -0.0374
     9        5.9379             nan     0.1000    0.0492
    10        5.8142             nan     0.1000    0.0544
    20        5.1112             nan     0.1000    0.0092
    40        4.4853             nan     0.1000   -0.0011
    60        4.1130             nan     0.1000   -0.0261
    80        3.8943             nan     0.1000   -0.0251
   100        3.7519             nan     0.1000   -0.0154
   120        3.6156             nan     0.1000   -0.0182
   140        3.5073             nan     0.1000   -0.0180
   160        3.3782             nan     0.1000   -0.0263
   180        3.3063             nan     0.1000   -0.0167
   200        3.2297             nan     0.1000   -0.0186

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1230             nan     0.1000    0.2788
     2        6.8888             nan     0.1000    0.2493
     3        6.6508             nan     0.1000    0.2221
     4        6.4307             nan     0.1000    0.2375
     5        6.2325             nan     0.1000    0.0711
     6        6.0420             nan     0.1000    0.1906
     7        5.9103             nan     0.1000    0.0314
     8        5.7670             nan     0.1000    0.0884
     9        5.6591             nan     0.1000    0.0726
    10        5.5546             nan     0.1000    0.0624
    20        4.7564             nan     0.1000    0.0023
    40        4.0887             nan     0.1000   -0.0200
    60        3.7286             nan     0.1000   -0.0249
    80        3.4852             nan     0.1000   -0.0261
   100        3.2774             nan     0.1000   -0.0461
   120        3.1455             nan     0.1000   -0.0234
   140        2.9697             nan     0.1000   -0.0252
   160        2.8333             nan     0.1000   -0.0363
   180        2.7076             nan     0.1000   -0.0346
   200        2.5535             nan     0.1000   -0.0185

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0589             nan     0.1000    0.3579
     2        6.7259             nan     0.1000    0.3048
     3        6.4378             nan     0.1000    0.2562
     4        6.1622             nan     0.1000    0.2306
     5        5.9687             nan     0.1000    0.1890
     6        5.8213             nan     0.1000    0.0319
     7        5.6479             nan     0.1000    0.1063
     8        5.4812             nan     0.1000    0.1108
     9        5.3129             nan     0.1000    0.0390
    10        5.1613             nan     0.1000    0.0625
    20        4.3439             nan     0.1000    0.0081
    40        3.5371             nan     0.1000   -0.0280
    60        3.1116             nan     0.1000   -0.0226
    80        2.7962             nan     0.1000   -0.0178
   100        2.5508             nan     0.1000   -0.0083
   120        2.3502             nan     0.1000   -0.0272
   140        2.1010             nan     0.1000   -0.0163
   160        1.9134             nan     0.1000   -0.0203
   180        1.7591             nan     0.1000   -0.0142
   200        1.6086             nan     0.1000   -0.0099

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0563             nan     0.2000    0.5105
     2        6.7011             nan     0.2000    0.2935
     3        6.4276             nan     0.2000    0.3370
     4        6.2526             nan     0.2000    0.0964
     5        6.1381             nan     0.2000    0.0233
     6        5.9831             nan     0.2000    0.1145
     7        5.8999             nan     0.2000    0.0604
     8        5.7940             nan     0.2000    0.0431
     9        5.6954             nan     0.2000    0.0788
    10        5.6175             nan     0.2000    0.0308
    20        5.0871             nan     0.2000   -0.0134
    40        4.5818             nan     0.2000    0.0191
    60        4.3665             nan     0.2000   -0.0016
    80        4.2548             nan     0.2000   -0.0459
   100        4.1564             nan     0.2000   -0.0398
   120        4.1418             nan     0.2000   -0.0583
   140        4.1080             nan     0.2000   -0.0626
   160        4.0598             nan     0.2000   -0.0234
   180        4.0432             nan     0.2000   -0.0392
   200        4.0259             nan     0.2000   -0.0227

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9549             nan     0.2000    0.5067
     2        6.5135             nan     0.2000    0.2819
     3        6.1415             nan     0.2000    0.1861
     4        5.8736             nan     0.2000    0.2040
     5        5.6889             nan     0.2000    0.0892
     6        5.5074             nan     0.2000    0.0955
     7        5.3920             nan     0.2000    0.0542
     8        5.2737             nan     0.2000    0.0514
     9        5.1658             nan     0.2000    0.0515
    10        5.1040             nan     0.2000   -0.0593
    20        4.4433             nan     0.2000    0.0161
    40        4.0136             nan     0.2000   -0.0401
    60        3.7208             nan     0.2000   -0.0695
    80        3.5665             nan     0.2000   -0.0495
   100        3.3695             nan     0.2000   -0.0307
   120        3.2593             nan     0.2000   -0.0353
   140        3.1475             nan     0.2000   -0.0310
   160        3.0181             nan     0.2000    0.0000
   180        2.8781             nan     0.2000   -0.0446
   200        2.7271             nan     0.2000   -0.0286

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7853             nan     0.2000    0.6275
     2        6.3335             nan     0.2000    0.4474
     3        6.0003             nan     0.2000    0.2277
     4        5.7326             nan     0.2000    0.1359
     5        5.5656             nan     0.2000    0.0738
     6        5.3161             nan     0.2000    0.1575
     7        5.1268             nan     0.2000    0.0421
     8        4.9334             nan     0.2000    0.1673
     9        4.8525             nan     0.2000    0.0252
    10        4.7402             nan     0.2000   -0.0110
    20        4.0736             nan     0.2000   -0.0565
    40        3.5290             nan     0.2000   -0.0225
    60        3.1315             nan     0.2000   -0.0305
    80        2.8069             nan     0.2000   -0.0485
   100        2.5878             nan     0.2000   -0.0356
   120        2.3887             nan     0.2000   -0.0461
   140        2.1828             nan     0.2000   -0.0404
   160        1.9738             nan     0.2000   -0.0359
   180        1.8164             nan     0.2000   -0.0224
   200        1.7032             nan     0.2000   -0.0273

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7219             nan     0.2000    0.5830
     2        6.2098             nan     0.2000    0.3987
     3        5.7537             nan     0.2000    0.3647
     4        5.5169             nan     0.2000    0.1078
     5        5.2281             nan     0.2000    0.1042
     6        4.9438             nan     0.2000    0.1776
     7        4.7470             nan     0.2000    0.1055
     8        4.6129             nan     0.2000   -0.0631
     9        4.5147             nan     0.2000   -0.0358
    10        4.3916             nan     0.2000   -0.0086
    20        3.7331             nan     0.2000   -0.0953
    40        2.9633             nan     0.2000   -0.0301
    60        2.4955             nan     0.2000   -0.0618
    80        2.1001             nan     0.2000   -0.0459
   100        1.7100             nan     0.2000   -0.0152
   120        1.4418             nan     0.2000   -0.0222
   140        1.2452             nan     0.2000   -0.0399
   160        1.0809             nan     0.2000   -0.0250
   180        0.9623             nan     0.2000   -0.0203
   200        0.8512             nan     0.2000   -0.0150

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2042             nan     0.0500    0.0926
     2        7.1116             nan     0.0500    0.0836
     3        7.0448             nan     0.0500    0.0471
     4        6.9638             nan     0.0500    0.0664
     5        6.9047             nan     0.0500    0.0694
     6        6.8053             nan     0.0500    0.0937
     7        6.7108             nan     0.0500    0.0717
     8        6.6453             nan     0.0500    0.0617
     9        6.5798             nan     0.0500    0.0512
    10        6.5283             nan     0.0500    0.0538
    20        6.0744             nan     0.0500    0.0250
    40        5.5181             nan     0.0500    0.0177
    60        5.1978             nan     0.0500   -0.0026
    80        4.9710             nan     0.0500    0.0057
   100        4.7852             nan     0.0500    0.0058
   120        4.6165             nan     0.0500    0.0017
   140        4.5137             nan     0.0500   -0.0034
   160        4.4106             nan     0.0500   -0.0063
   180        4.3182             nan     0.0500   -0.0093
   200        4.2599             nan     0.0500   -0.0014

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1976             nan     0.0500    0.1045
     2        7.0517             nan     0.0500    0.1182
     3        6.9262             nan     0.0500    0.1287
     4        6.8409             nan     0.0500    0.0837
     5        6.7285             nan     0.0500    0.0864
     6        6.6350             nan     0.0500    0.0892
     7        6.5297             nan     0.0500    0.0942
     8        6.4197             nan     0.0500    0.0547
     9        6.3224             nan     0.0500    0.0576
    10        6.2367             nan     0.0500    0.0832
    20        5.6032             nan     0.0500    0.0249
    40        4.9589             nan     0.0500    0.0160
    60        4.5781             nan     0.0500    0.0024
    80        4.2968             nan     0.0500    0.0026
   100        4.1021             nan     0.0500   -0.0028
   120        3.9376             nan     0.0500   -0.0113
   140        3.7907             nan     0.0500   -0.0018
   160        3.6855             nan     0.0500   -0.0153
   180        3.6076             nan     0.0500   -0.0109
   200        3.5286             nan     0.0500   -0.0097

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1843             nan     0.0500    0.1313
     2        7.0277             nan     0.0500    0.1399
     3        6.8807             nan     0.0500    0.1330
     4        6.7558             nan     0.0500    0.0718
     5        6.6324             nan     0.0500    0.0980
     6        6.5117             nan     0.0500    0.0940
     7        6.4085             nan     0.0500    0.0773
     8        6.3055             nan     0.0500    0.0916
     9        6.2032             nan     0.0500    0.0393
    10        6.1222             nan     0.0500    0.0594
    20        5.4115             nan     0.0500    0.0428
    40        4.6672             nan     0.0500    0.0062
    60        4.2062             nan     0.0500    0.0059
    80        3.9247             nan     0.0500    0.0026
   100        3.6922             nan     0.0500   -0.0158
   120        3.5128             nan     0.0500    0.0009
   140        3.3821             nan     0.0500   -0.0044
   160        3.2406             nan     0.0500   -0.0043
   180        3.1429             nan     0.0500   -0.0151
   200        3.0447             nan     0.0500   -0.0166

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1254             nan     0.0500    0.1787
     2        6.9495             nan     0.0500    0.1149
     3        6.7937             nan     0.0500    0.1245
     4        6.6324             nan     0.0500    0.1593
     5        6.4762             nan     0.0500    0.1029
     6        6.3247             nan     0.0500    0.1010
     7        6.1987             nan     0.0500    0.0626
     8        6.0563             nan     0.0500    0.0946
     9        5.9324             nan     0.0500    0.0895
    10        5.8309             nan     0.0500    0.0869
    20        5.0412             nan     0.0500    0.0203
    40        4.2076             nan     0.0500    0.0195
    60        3.7396             nan     0.0500   -0.0160
    80        3.4210             nan     0.0500   -0.0084
   100        3.1373             nan     0.0500   -0.0151
   120        2.9358             nan     0.0500   -0.0154
   140        2.7647             nan     0.0500   -0.0177
   160        2.6118             nan     0.0500   -0.0097
   180        2.4842             nan     0.0500   -0.0021
   200        2.3582             nan     0.0500   -0.0207

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0981             nan     0.1000    0.2032
     2        6.8861             nan     0.1000    0.2072
     3        6.7264             nan     0.1000    0.1345
     4        6.6034             nan     0.1000    0.1072
     5        6.4915             nan     0.1000    0.1284
     6        6.3943             nan     0.1000   -0.0058
     7        6.3096             nan     0.1000    0.0627
     8        6.2435             nan     0.1000    0.0507
     9        6.1473             nan     0.1000    0.1138
    10        6.0458             nan     0.1000    0.0560
    20        5.5218             nan     0.1000    0.0192
    40        4.9387             nan     0.1000   -0.0138
    60        4.5775             nan     0.1000    0.0022
    80        4.3796             nan     0.1000   -0.0119
   100        4.2753             nan     0.1000   -0.0191
   120        4.1875             nan     0.1000   -0.0217
   140        4.1203             nan     0.1000   -0.0304
   160        4.0878             nan     0.1000   -0.0132
   180        4.0409             nan     0.1000   -0.0171
   200        4.0330             nan     0.1000   -0.0180

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0782             nan     0.1000    0.2508
     2        6.8519             nan     0.1000    0.2661
     3        6.6314             nan     0.1000    0.1752
     4        6.4676             nan     0.1000    0.1060
     5        6.3590             nan     0.1000    0.0785
     6        6.2012             nan     0.1000    0.1158
     7        6.0316             nan     0.1000    0.1048
     8        5.9127             nan     0.1000    0.0775
     9        5.8013             nan     0.1000    0.0185
    10        5.6860             nan     0.1000    0.0690
    20        5.0588             nan     0.1000   -0.0161
    40        4.3484             nan     0.1000   -0.0036
    60        3.9475             nan     0.1000   -0.0127
    80        3.7334             nan     0.1000   -0.0246
   100        3.5367             nan     0.1000   -0.0159
   120        3.4099             nan     0.1000   -0.0287
   140        3.3220             nan     0.1000   -0.0202
   160        3.2483             nan     0.1000   -0.0239
   180        3.1788             nan     0.1000   -0.0231
   200        3.0599             nan     0.1000   -0.0108

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9944             nan     0.1000    0.3499
     2        6.7203             nan     0.1000    0.2143
     3        6.4744             nan     0.1000    0.1584
     4        6.2435             nan     0.1000    0.1228
     5        6.0660             nan     0.1000    0.1742
     6        5.9068             nan     0.1000    0.1169
     7        5.7574             nan     0.1000    0.1080
     8        5.6144             nan     0.1000    0.0889
     9        5.4928             nan     0.1000    0.0906
    10        5.4045             nan     0.1000    0.0185
    20        4.6720             nan     0.1000    0.0261
    40        3.8839             nan     0.1000   -0.0259
    60        3.4716             nan     0.1000    0.0004
    80        3.2230             nan     0.1000   -0.0127
   100        2.9834             nan     0.1000   -0.0164
   120        2.8455             nan     0.1000   -0.0190
   140        2.7036             nan     0.1000   -0.0259
   160        2.5917             nan     0.1000   -0.0153
   180        2.4865             nan     0.1000   -0.0101
   200        2.3792             nan     0.1000   -0.0134

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8781             nan     0.1000    0.3099
     2        6.5815             nan     0.1000    0.2955
     3        6.3247             nan     0.1000    0.1886
     4        6.0491             nan     0.1000    0.1968
     5        5.8271             nan     0.1000    0.0500
     6        5.6381             nan     0.1000    0.1297
     7        5.4562             nan     0.1000    0.0719
     8        5.2960             nan     0.1000    0.1010
     9        5.1485             nan     0.1000    0.1090
    10        5.0371             nan     0.1000   -0.0061
    20        4.2184             nan     0.1000   -0.0168
    40        3.4136             nan     0.1000    0.0123
    60        2.9764             nan     0.1000   -0.0188
    80        2.6313             nan     0.1000   -0.0223
   100        2.3730             nan     0.1000   -0.0158
   120        2.1620             nan     0.1000   -0.0293
   140        1.9628             nan     0.1000   -0.0118
   160        1.7656             nan     0.1000   -0.0125
   180        1.6165             nan     0.1000   -0.0126
   200        1.4962             nan     0.1000   -0.0116

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8869             nan     0.2000    0.3494
     2        6.6426             nan     0.2000    0.1803
     3        6.3169             nan     0.2000    0.2231
     4        6.1391             nan     0.2000    0.1814
     5        5.9982             nan     0.2000    0.0595
     6        5.8410             nan     0.2000    0.1107
     7        5.7577             nan     0.2000   -0.0238
     8        5.6605             nan     0.2000    0.0708
     9        5.5779             nan     0.2000    0.0499
    10        5.5235             nan     0.2000    0.0343
    20        4.9723             nan     0.2000   -0.0332
    40        4.4327             nan     0.2000   -0.0073
    60        4.1932             nan     0.2000   -0.0242
    80        4.0720             nan     0.2000   -0.0110
   100        3.9977             nan     0.2000    0.0022
   120        3.9579             nan     0.2000   -0.0525
   140        3.9422             nan     0.2000   -0.0202
   160        3.9410             nan     0.2000   -0.0214
   180        3.9021             nan     0.2000   -0.0143
   200        3.8876             nan     0.2000   -0.0182

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8615             nan     0.2000    0.4384
     2        6.4467             nan     0.2000    0.3895
     3        6.1187             nan     0.2000    0.2155
     4        5.7768             nan     0.2000    0.1500
     5        5.6067             nan     0.2000    0.1025
     6        5.4800             nan     0.2000    0.0661
     7        5.3182             nan     0.2000    0.1019
     8        5.1899             nan     0.2000    0.0927
     9        5.0726             nan     0.2000    0.0105
    10        4.9940             nan     0.2000    0.0273
    20        4.3982             nan     0.2000   -0.0398
    40        3.8542             nan     0.2000   -0.0296
    60        3.5700             nan     0.2000   -0.0283
    80        3.3106             nan     0.2000   -0.0177
   100        3.1482             nan     0.2000   -0.0340
   120        2.9833             nan     0.2000   -0.0345
   140        2.9100             nan     0.2000   -0.0316
   160        2.8126             nan     0.2000   -0.0131
   180        2.7354             nan     0.2000   -0.0327
   200        2.6452             nan     0.2000   -0.0138

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7713             nan     0.2000    0.4794
     2        6.3507             nan     0.2000    0.3070
     3        5.9297             nan     0.2000    0.3330
     4        5.6287             nan     0.2000    0.2640
     5        5.3143             nan     0.2000    0.1232
     6        5.1355             nan     0.2000    0.0216
     7        4.9817             nan     0.2000    0.1258
     8        4.8571             nan     0.2000    0.0215
     9        4.7625             nan     0.2000    0.0463
    10        4.6735             nan     0.2000   -0.0201
    20        4.0122             nan     0.2000   -0.0260
    40        3.4200             nan     0.2000   -0.0676
    60        3.1191             nan     0.2000   -0.0292
    80        2.8326             nan     0.2000   -0.0360
   100        2.6041             nan     0.2000   -0.0572
   120        2.3994             nan     0.2000   -0.0630
   140        2.2449             nan     0.2000   -0.0190
   160        2.0907             nan     0.2000   -0.0179
   180        1.9324             nan     0.2000   -0.0305
   200        1.8268             nan     0.2000   -0.0131

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6666             nan     0.2000    0.5067
     2        6.0066             nan     0.2000    0.5227
     3        5.6816             nan     0.2000    0.1469
     4        5.3816             nan     0.2000    0.1768
     5        5.1320             nan     0.2000    0.1498
     6        4.8526             nan     0.2000    0.1563
     7        4.6723             nan     0.2000    0.1006
     8        4.5082             nan     0.2000    0.1112
     9        4.3729             nan     0.2000   -0.0487
    10        4.2245             nan     0.2000   -0.0324
    20        3.5180             nan     0.2000   -0.0315
    40        2.8007             nan     0.2000   -0.0509
    60        2.3917             nan     0.2000   -0.0321
    80        2.0045             nan     0.2000   -0.0049
   100        1.7104             nan     0.2000   -0.0701
   120        1.4825             nan     0.2000   -0.0215
   140        1.3065             nan     0.2000   -0.0111
   160        1.1249             nan     0.2000   -0.0172
   180        1.0013             nan     0.2000   -0.0317
   200        0.8698             nan     0.2000   -0.0219

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9895             nan     0.0500    0.1049
     2        6.9074             nan     0.0500    0.0758
     3        6.8048             nan     0.0500    0.0998
     4        6.7297             nan     0.0500    0.0851
     5        6.6522             nan     0.0500    0.0532
     6        6.5690             nan     0.0500    0.0714
     7        6.5009             nan     0.0500    0.0669
     8        6.4323             nan     0.0500    0.0636
     9        6.3712             nan     0.0500    0.0612
    10        6.3032             nan     0.0500    0.0381
    20        5.9136             nan     0.0500    0.0337
    40        5.4788             nan     0.0500    0.0066
    60        5.1298             nan     0.0500    0.0146
    80        4.8974             nan     0.0500    0.0026
   100        4.7135             nan     0.0500    0.0018
   120        4.5706             nan     0.0500   -0.0016
   140        4.4582             nan     0.0500   -0.0069
   160        4.3836             nan     0.0500   -0.0016
   180        4.3057             nan     0.0500   -0.0235
   200        4.2371             nan     0.0500   -0.0021

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9720             nan     0.0500    0.0812
     2        6.8538             nan     0.0500    0.0851
     3        6.7429             nan     0.0500    0.1071
     4        6.6356             nan     0.0500    0.1023
     5        6.5375             nan     0.0500    0.0865
     6        6.4522             nan     0.0500    0.0683
     7        6.3480             nan     0.0500    0.0867
     8        6.3010             nan     0.0500    0.0032
     9        6.2035             nan     0.0500    0.0818
    10        6.1570             nan     0.0500   -0.0061
    20        5.6023             nan     0.0500   -0.0242
    40        4.9476             nan     0.0500    0.0047
    60        4.5781             nan     0.0500    0.0089
    80        4.3169             nan     0.0500   -0.0039
   100        4.1326             nan     0.0500   -0.0090
   120        3.9955             nan     0.0500    0.0005
   140        3.8984             nan     0.0500   -0.0127
   160        3.8010             nan     0.0500   -0.0182
   180        3.7041             nan     0.0500    0.0008
   200        3.6496             nan     0.0500   -0.0084

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9128             nan     0.0500    0.1432
     2        6.7790             nan     0.0500    0.1191
     3        6.6491             nan     0.0500    0.1438
     4        6.5314             nan     0.0500    0.0856
     5        6.4391             nan     0.0500    0.0956
     6        6.3428             nan     0.0500    0.0666
     7        6.2070             nan     0.0500    0.0830
     8        6.1124             nan     0.0500    0.0783
     9        6.0276             nan     0.0500    0.0650
    10        5.9427             nan     0.0500    0.0567
    20        5.3357             nan     0.0500    0.0165
    40        4.6161             nan     0.0500   -0.0228
    60        4.2137             nan     0.0500   -0.0061
    80        3.9412             nan     0.0500   -0.0059
   100        3.7603             nan     0.0500   -0.0066
   120        3.6141             nan     0.0500   -0.0117
   140        3.4779             nan     0.0500    0.0009
   160        3.3708             nan     0.0500   -0.0175
   180        3.2734             nan     0.0500   -0.0225
   200        3.1594             nan     0.0500   -0.0085

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9197             nan     0.0500    0.1485
     2        6.7629             nan     0.0500    0.0894
     3        6.5779             nan     0.0500    0.1262
     4        6.4345             nan     0.0500    0.1195
     5        6.3027             nan     0.0500    0.0878
     6        6.1595             nan     0.0500    0.1146
     7        6.0237             nan     0.0500    0.0801
     8        5.9025             nan     0.0500    0.0838
     9        5.7939             nan     0.0500    0.0316
    10        5.6739             nan     0.0500    0.0956
    20        4.9766             nan     0.0500    0.0202
    40        4.2027             nan     0.0500    0.0125
    60        3.7536             nan     0.0500   -0.0291
    80        3.4697             nan     0.0500   -0.0088
   100        3.2319             nan     0.0500   -0.0131
   120        2.9980             nan     0.0500   -0.0068
   140        2.8086             nan     0.0500   -0.0162
   160        2.6734             nan     0.0500   -0.0243
   180        2.5305             nan     0.0500   -0.0144
   200        2.3877             nan     0.0500   -0.0072

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9079             nan     0.1000    0.1939
     2        6.7342             nan     0.1000    0.1304
     3        6.5627             nan     0.1000    0.1434
     4        6.4380             nan     0.1000    0.1051
     5        6.3090             nan     0.1000    0.1242
     6        6.2473             nan     0.1000    0.0353
     7        6.1665             nan     0.1000    0.0168
     8        6.1041             nan     0.1000    0.0238
     9        6.0345             nan     0.1000    0.0280
    10        5.9607             nan     0.1000    0.0772
    20        5.4099             nan     0.1000    0.0219
    40        4.8619             nan     0.1000   -0.0052
    60        4.5546             nan     0.1000   -0.0301
    80        4.3915             nan     0.1000    0.0003
   100        4.2703             nan     0.1000   -0.0067
   120        4.1730             nan     0.1000   -0.0503
   140        4.1310             nan     0.1000   -0.0068
   160        4.0992             nan     0.1000   -0.0093
   180        4.0665             nan     0.1000   -0.0196
   200        4.0546             nan     0.1000   -0.0319

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8361             nan     0.1000    0.1676
     2        6.6194             nan     0.1000    0.1980
     3        6.4518             nan     0.1000    0.1746
     4        6.2648             nan     0.1000    0.1205
     5        6.0851             nan     0.1000    0.1034
     6        5.9360             nan     0.1000    0.0786
     7        5.8176             nan     0.1000    0.0989
     8        5.7405             nan     0.1000    0.0461
     9        5.6397             nan     0.1000    0.0816
    10        5.5626             nan     0.1000    0.0060
    20        4.9318             nan     0.1000   -0.0134
    40        4.3161             nan     0.1000   -0.0287
    60        3.9837             nan     0.1000   -0.0169
    80        3.7966             nan     0.1000   -0.0202
   100        3.6738             nan     0.1000   -0.0198
   120        3.5869             nan     0.1000   -0.0207
   140        3.4782             nan     0.1000   -0.0197
   160        3.3885             nan     0.1000   -0.0302
   180        3.3001             nan     0.1000   -0.0106
   200        3.1968             nan     0.1000   -0.0201

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7767             nan     0.1000    0.2492
     2        6.5154             nan     0.1000    0.1815
     3        6.2930             nan     0.1000    0.2075
     4        6.0822             nan     0.1000    0.1920
     5        5.9071             nan     0.1000    0.1089
     6        5.7199             nan     0.1000    0.1550
     7        5.5962             nan     0.1000    0.1334
     8        5.4812             nan     0.1000    0.0679
     9        5.3579             nan     0.1000    0.1044
    10        5.2719             nan     0.1000    0.0039
    20        4.6013             nan     0.1000   -0.0011
    40        3.9488             nan     0.1000   -0.0320
    60        3.6188             nan     0.1000   -0.0229
    80        3.3781             nan     0.1000   -0.0287
   100        3.1264             nan     0.1000   -0.0125
   120        2.9517             nan     0.1000   -0.0251
   140        2.7946             nan     0.1000   -0.0178
   160        2.6692             nan     0.1000   -0.0306
   180        2.5214             nan     0.1000   -0.0093
   200        2.4009             nan     0.1000   -0.0252

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7718             nan     0.1000    0.2525
     2        6.4530             nan     0.1000    0.3129
     3        6.2339             nan     0.1000    0.1534
     4        6.0515             nan     0.1000    0.1308
     5        5.8149             nan     0.1000    0.1830
     6        5.5972             nan     0.1000    0.1439
     7        5.4041             nan     0.1000    0.1386
     8        5.2865             nan     0.1000    0.0618
     9        5.2183             nan     0.1000   -0.0699
    10        5.1010             nan     0.1000    0.0966
    20        4.1910             nan     0.1000    0.0307
    40        3.4886             nan     0.1000   -0.0566
    60        3.0235             nan     0.1000   -0.0200
    80        2.6919             nan     0.1000   -0.0201
   100        2.4129             nan     0.1000   -0.0171
   120        2.2107             nan     0.1000   -0.0173
   140        2.0188             nan     0.1000   -0.0211
   160        1.8672             nan     0.1000   -0.0121
   180        1.7089             nan     0.1000   -0.0165
   200        1.5688             nan     0.1000   -0.0173

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6853             nan     0.2000    0.3513
     2        6.3404             nan     0.2000    0.2868
     3        6.1112             nan     0.2000    0.1524
     4        6.0233             nan     0.2000    0.0230
     5        5.8867             nan     0.2000    0.0474
     6        5.8095             nan     0.2000    0.0658
     7        5.7191             nan     0.2000   -0.0019
     8        5.5952             nan     0.2000    0.1186
     9        5.5210             nan     0.2000    0.0442
    10        5.3964             nan     0.2000    0.0636
    20        4.8179             nan     0.2000    0.0111
    40        4.4011             nan     0.2000   -0.0327
    60        4.1680             nan     0.2000   -0.0845
    80        4.1117             nan     0.2000   -0.0356
   100        4.0543             nan     0.2000   -0.0208
   120        4.0357             nan     0.2000   -0.0378
   140        4.0097             nan     0.2000   -0.0289
   160        3.9928             nan     0.2000   -0.0183
   180        3.9979             nan     0.2000   -0.0513
   200        3.9741             nan     0.2000   -0.0073

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6001             nan     0.2000    0.3862
     2        6.1932             nan     0.2000    0.2830
     3        5.8918             nan     0.2000    0.2406
     4        5.6977             nan     0.2000    0.0836
     5        5.5452             nan     0.2000    0.0782
     6        5.3601             nan     0.2000    0.1794
     7        5.2366             nan     0.2000    0.0128
     8        5.1275             nan     0.2000    0.0342
     9        5.0423             nan     0.2000    0.0267
    10        4.9165             nan     0.2000    0.0382
    20        4.3759             nan     0.2000   -0.0359
    40        3.8411             nan     0.2000   -0.0187
    60        3.5755             nan     0.2000   -0.0079
    80        3.3811             nan     0.2000   -0.0326
   100        3.2151             nan     0.2000   -0.0043
   120        3.0519             nan     0.2000   -0.0127
   140        2.9325             nan     0.2000   -0.0443
   160        2.8177             nan     0.2000   -0.0494
   180        2.6885             nan     0.2000   -0.0172
   200        2.5871             nan     0.2000   -0.0372

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5421             nan     0.2000    0.5330
     2        6.1641             nan     0.2000    0.3514
     3        5.8914             nan     0.2000    0.0741
     4        5.5491             nan     0.2000    0.2203
     5        5.3575             nan     0.2000    0.0951
     6        5.1731             nan     0.2000    0.0975
     7        5.0255             nan     0.2000    0.0159
     8        4.8907             nan     0.2000    0.0271
     9        4.7684             nan     0.2000    0.0003
    10        4.6663             nan     0.2000   -0.0244
    20        4.0508             nan     0.2000   -0.0631
    40        3.5545             nan     0.2000   -0.0695
    60        3.2453             nan     0.2000   -0.0569
    80        2.9308             nan     0.2000   -0.0751
   100        2.6665             nan     0.2000   -0.0332
   120        2.4443             nan     0.2000   -0.0414
   140        2.2577             nan     0.2000   -0.0420
   160        2.0612             nan     0.2000   -0.0281
   180        1.8992             nan     0.2000   -0.0137
   200        1.7716             nan     0.2000   -0.0086

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.3704             nan     0.2000    0.3513
     2        5.8609             nan     0.2000    0.5043
     3        5.4150             nan     0.2000    0.2065
     4        5.0757             nan     0.2000    0.2013
     5        4.8028             nan     0.2000    0.0138
     6        4.6559             nan     0.2000    0.0166
     7        4.5429             nan     0.2000   -0.0374
     8        4.4111             nan     0.2000    0.0248
     9        4.3186             nan     0.2000   -0.0430
    10        4.2345             nan     0.2000   -0.0311
    20        3.5390             nan     0.2000   -0.1002
    40        2.7156             nan     0.2000   -0.0231
    60        2.3128             nan     0.2000   -0.0752
    80        1.8995             nan     0.2000   -0.0271
   100        1.6391             nan     0.2000   -0.0253
   120        1.3438             nan     0.2000   -0.0232
   140        1.1713             nan     0.2000   -0.0354
   160        0.9902             nan     0.2000   -0.0193
   180        0.8573             nan     0.2000   -0.0145
   200        0.7463             nan     0.2000   -0.0066

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1236             nan     0.0500    0.0978
     2        7.0275             nan     0.0500    0.1146
     3        6.9507             nan     0.0500    0.0803
     4        6.8357             nan     0.0500    0.0897
     5        6.7293             nan     0.0500    0.0917
     6        6.6509             nan     0.0500    0.0799
     7        6.5817             nan     0.0500    0.0668
     8        6.5229             nan     0.0500    0.0673
     9        6.4390             nan     0.0500    0.0711
    10        6.3802             nan     0.0500    0.0259
    20        5.9363             nan     0.0500    0.0135
    40        5.4590             nan     0.0500   -0.0064
    60        5.1281             nan     0.0500    0.0055
    80        4.8620             nan     0.0500    0.0064
   100        4.6584             nan     0.0500   -0.0058
   120        4.5142             nan     0.0500   -0.0135
   140        4.3991             nan     0.0500    0.0042
   160        4.3099             nan     0.0500   -0.0003
   180        4.2396             nan     0.0500   -0.0017
   200        4.1905             nan     0.0500   -0.0056

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0931             nan     0.0500    0.1196
     2        6.9676             nan     0.0500    0.0961
     3        6.8248             nan     0.0500    0.0957
     4        6.6853             nan     0.0500    0.1069
     5        6.5702             nan     0.0500    0.1153
     6        6.4941             nan     0.0500    0.0649
     7        6.4001             nan     0.0500    0.0501
     8        6.2976             nan     0.0500    0.0331
     9        6.2136             nan     0.0500    0.0531
    10        6.1321             nan     0.0500    0.0523
    20        5.5367             nan     0.0500    0.0301
    40        4.8873             nan     0.0500    0.0108
    60        4.5127             nan     0.0500   -0.0102
    80        4.2345             nan     0.0500   -0.0076
   100        4.0765             nan     0.0500   -0.0059
   120        3.9478             nan     0.0500   -0.0118
   140        3.8202             nan     0.0500   -0.0013
   160        3.7168             nan     0.0500   -0.0055
   180        3.6232             nan     0.0500   -0.0133
   200        3.5443             nan     0.0500   -0.0112

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0717             nan     0.0500    0.1347
     2        6.9311             nan     0.0500    0.1165
     3        6.7816             nan     0.0500    0.1376
     4        6.6480             nan     0.0500    0.1020
     5        6.5280             nan     0.0500    0.0929
     6        6.4256             nan     0.0500    0.0910
     7        6.3147             nan     0.0500    0.0642
     8        6.1992             nan     0.0500    0.0926
     9        6.1217             nan     0.0500    0.0613
    10        6.0225             nan     0.0500    0.0506
    20        5.3503             nan     0.0500    0.0375
    40        4.5340             nan     0.0500   -0.0088
    60        4.0651             nan     0.0500   -0.0008
    80        3.7838             nan     0.0500   -0.0067
   100        3.6108             nan     0.0500   -0.0153
   120        3.4421             nan     0.0500   -0.0106
   140        3.3233             nan     0.0500   -0.0191
   160        3.2163             nan     0.0500   -0.0154
   180        3.0984             nan     0.0500   -0.0192
   200        3.0110             nan     0.0500   -0.0039

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0068             nan     0.0500    0.1652
     2        6.8106             nan     0.0500    0.1810
     3        6.6340             nan     0.0500    0.1240
     4        6.4739             nan     0.0500    0.1047
     5        6.3313             nan     0.0500    0.1174
     6        6.2088             nan     0.0500    0.1017
     7        6.0933             nan     0.0500    0.0772
     8        5.9818             nan     0.0500    0.0498
     9        5.8615             nan     0.0500    0.0817
    10        5.7573             nan     0.0500    0.0407
    20        4.9750             nan     0.0500    0.0488
    40        4.1187             nan     0.0500   -0.0039
    60        3.6648             nan     0.0500   -0.0027
    80        3.3402             nan     0.0500   -0.0090
   100        3.0985             nan     0.0500   -0.0158
   120        2.9076             nan     0.0500   -0.0086
   140        2.7367             nan     0.0500   -0.0160
   160        2.5776             nan     0.0500   -0.0104
   180        2.4343             nan     0.0500   -0.0125
   200        2.3159             nan     0.0500   -0.0042

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0435             nan     0.1000    0.1892
     2        6.8595             nan     0.1000    0.1599
     3        6.6799             nan     0.1000    0.1877
     4        6.5293             nan     0.1000    0.0959
     5        6.4790             nan     0.1000   -0.0036
     6        6.3385             nan     0.1000    0.0931
     7        6.2393             nan     0.1000    0.0991
     8        6.1772             nan     0.1000    0.0190
     9        6.0857             nan     0.1000    0.0627
    10        6.0043             nan     0.1000    0.0514
    20        5.4858             nan     0.1000    0.0292
    40        4.8616             nan     0.1000    0.0049
    60        4.5131             nan     0.1000   -0.0294
    80        4.3350             nan     0.1000   -0.0119
   100        4.2070             nan     0.1000   -0.0034
   120        4.1145             nan     0.1000   -0.0194
   140        4.0342             nan     0.1000   -0.0147
   160        4.0057             nan     0.1000   -0.0107
   180        3.9567             nan     0.1000   -0.0088
   200        3.9423             nan     0.1000   -0.0169

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9345             nan     0.1000    0.2784
     2        6.7799             nan     0.1000    0.1459
     3        6.5635             nan     0.1000    0.1735
     4        6.3505             nan     0.1000    0.1905
     5        6.1694             nan     0.1000    0.1543
     6        6.0241             nan     0.1000    0.1243
     7        5.8977             nan     0.1000    0.1418
     8        5.7846             nan     0.1000   -0.0001
     9        5.6901             nan     0.1000    0.0161
    10        5.6242             nan     0.1000   -0.0068
    20        4.9459             nan     0.1000    0.0064
    40        4.2847             nan     0.1000    0.0085
    60        3.9785             nan     0.1000   -0.0092
    80        3.7531             nan     0.1000   -0.0138
   100        3.5725             nan     0.1000   -0.0376
   120        3.4122             nan     0.1000   -0.0067
   140        3.3067             nan     0.1000   -0.0129
   160        3.2432             nan     0.1000   -0.0238
   180        3.1185             nan     0.1000   -0.0278
   200        3.0344             nan     0.1000   -0.0145

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8812             nan     0.1000    0.3317
     2        6.7601             nan     0.1000    0.0591
     3        6.4981             nan     0.1000    0.2265
     4        6.2166             nan     0.1000    0.2010
     5        5.9928             nan     0.1000    0.1699
     6        5.8672             nan     0.1000    0.0250
     7        5.7262             nan     0.1000    0.0573
     8        5.5916             nan     0.1000    0.0589
     9        5.4208             nan     0.1000    0.1227
    10        5.2997             nan     0.1000    0.0914
    20        4.5789             nan     0.1000    0.0121
    40        3.8206             nan     0.1000   -0.0126
    60        3.4247             nan     0.1000   -0.0087
    80        3.2152             nan     0.1000   -0.0324
   100        3.0192             nan     0.1000   -0.0313
   120        2.8081             nan     0.1000   -0.0191
   140        2.6652             nan     0.1000   -0.0200
   160        2.5395             nan     0.1000   -0.0293
   180        2.4210             nan     0.1000   -0.0088
   200        2.3306             nan     0.1000   -0.0183

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7475             nan     0.1000    0.3913
     2        6.4606             nan     0.1000    0.2541
     3        6.1931             nan     0.1000    0.1340
     4        5.9357             nan     0.1000    0.2371
     5        5.6955             nan     0.1000    0.1480
     6        5.5106             nan     0.1000    0.1464
     7        5.3508             nan     0.1000    0.1124
     8        5.1730             nan     0.1000    0.0932
     9        5.0540             nan     0.1000    0.0659
    10        4.9700             nan     0.1000    0.0179
    20        4.1821             nan     0.1000    0.0417
    40        3.4479             nan     0.1000   -0.0239
    60        2.9803             nan     0.1000   -0.0123
    80        2.6183             nan     0.1000   -0.0227
   100        2.3642             nan     0.1000   -0.0270
   120        2.1007             nan     0.1000   -0.0198
   140        1.9202             nan     0.1000   -0.0181
   160        1.7577             nan     0.1000   -0.0285
   180        1.5988             nan     0.1000   -0.0155
   200        1.4597             nan     0.1000   -0.0152

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8911             nan     0.2000    0.3857
     2        6.6794             nan     0.2000    0.0859
     3        6.3912             nan     0.2000    0.2464
     4        6.1105             nan     0.2000    0.2467
     5        5.8872             nan     0.2000    0.1296
     6        5.7425             nan     0.2000    0.0944
     7        5.6212             nan     0.2000    0.0217
     8        5.5255             nan     0.2000    0.0253
     9        5.4432             nan     0.2000    0.0067
    10        5.3621             nan     0.2000    0.0281
    20        4.8561             nan     0.2000    0.0260
    40        4.3639             nan     0.2000   -0.0220
    60        4.1577             nan     0.2000   -0.0663
    80        4.0451             nan     0.2000   -0.0156
   100        3.9826             nan     0.2000   -0.0295
   120        3.9342             nan     0.2000   -0.0396
   140        3.8938             nan     0.2000   -0.0322
   160        3.8713             nan     0.2000   -0.0555
   180        3.8471             nan     0.2000   -0.0373
   200        3.8302             nan     0.2000   -0.0274

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5874             nan     0.2000    0.5615
     2        6.2817             nan     0.2000    0.3366
     3        6.0005             nan     0.2000    0.2273
     4        5.7735             nan     0.2000    0.1637
     5        5.5446             nan     0.2000    0.1374
     6        5.3729             nan     0.2000    0.0948
     7        5.2394             nan     0.2000   -0.0154
     8        5.1275             nan     0.2000    0.0667
     9        5.0435             nan     0.2000   -0.0201
    10        4.9426             nan     0.2000    0.0357
    20        4.3301             nan     0.2000   -0.0380
    40        3.8338             nan     0.2000   -0.0277
    60        3.5173             nan     0.2000   -0.0309
    80        3.2956             nan     0.2000   -0.0486
   100        3.1842             nan     0.2000   -0.0372
   120        2.9949             nan     0.2000   -0.0216
   140        2.9196             nan     0.2000   -0.0636
   160        2.7522             nan     0.2000   -0.0162
   180        2.6533             nan     0.2000   -0.0314
   200        2.5549             nan     0.2000   -0.0581

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6914             nan     0.2000    0.4484
     2        6.3154             nan     0.2000    0.3417
     3        5.8640             nan     0.2000    0.4216
     4        5.5188             nan     0.2000    0.2287
     5        5.3317             nan     0.2000    0.1085
     6        5.1095             nan     0.2000    0.1850
     7        4.9570             nan     0.2000    0.0212
     8        4.8320             nan     0.2000    0.0354
     9        4.7124             nan     0.2000    0.0204
    10        4.6061             nan     0.2000    0.0099
    20        3.9489             nan     0.2000   -0.0349
    40        3.2444             nan     0.2000   -0.0757
    60        2.9435             nan     0.2000   -0.0534
    80        2.5653             nan     0.2000   -0.0240
   100        2.3633             nan     0.2000   -0.0544
   120        2.1307             nan     0.2000   -0.0264
   140        1.9625             nan     0.2000   -0.0376
   160        1.8460             nan     0.2000   -0.0176
   180        1.7292             nan     0.2000   -0.0262
   200        1.5962             nan     0.2000   -0.0359

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.4902             nan     0.2000    0.5864
     2        5.9581             nan     0.2000    0.2739
     3        5.5775             nan     0.2000    0.2900
     4        5.3602             nan     0.2000    0.0803
     5        5.0388             nan     0.2000    0.2503
     6        4.8759             nan     0.2000    0.0848
     7        4.6284             nan     0.2000    0.0794
     8        4.4422             nan     0.2000    0.1017
     9        4.2962             nan     0.2000   -0.0471
    10        4.1454             nan     0.2000    0.0011
    20        3.4523             nan     0.2000   -0.0289
    40        2.7096             nan     0.2000   -0.0952
    60        2.2052             nan     0.2000   -0.0544
    80        1.8454             nan     0.2000   -0.0481
   100        1.5985             nan     0.2000   -0.0287
   120        1.3673             nan     0.2000   -0.0379
   140        1.1890             nan     0.2000   -0.0287
   160        1.0213             nan     0.2000   -0.0252
   180        0.8999             nan     0.2000   -0.0033
   200        0.7771             nan     0.2000   -0.0198

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0658             nan     0.0500    0.1009
     2        6.9515             nan     0.0500    0.1002
     3        6.8279             nan     0.0500    0.1067
     4        6.7201             nan     0.0500    0.0792
     5        6.6235             nan     0.0500    0.0568
     6        6.5203             nan     0.0500    0.0790
     7        6.4434             nan     0.0500    0.0731
     8        6.3746             nan     0.0500    0.0447
     9        6.3033             nan     0.0500    0.0654
    10        6.2407             nan     0.0500    0.0729
    20        5.7819             nan     0.0500   -0.0001
    40        5.3240             nan     0.0500    0.0162
    60        5.0231             nan     0.0500   -0.0045
    80        4.8026             nan     0.0500   -0.0104
   100        4.6253             nan     0.0500   -0.0060
   120        4.5064             nan     0.0500   -0.0014
   140        4.4095             nan     0.0500   -0.0040
   160        4.3216             nan     0.0500    0.0019
   180        4.2395             nan     0.0500   -0.0063
   200        4.1898             nan     0.0500   -0.0078

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0274             nan     0.0500    0.1279
     2        6.9031             nan     0.0500    0.1141
     3        6.7552             nan     0.0500    0.1133
     4        6.6230             nan     0.0500    0.1223
     5        6.4667             nan     0.0500    0.0940
     6        6.4130             nan     0.0500    0.0065
     7        6.3464             nan     0.0500    0.0481
     8        6.2635             nan     0.0500    0.1027
     9        6.1538             nan     0.0500    0.0869
    10        6.0900             nan     0.0500    0.0634
    20        5.4939             nan     0.0500    0.0259
    40        4.8227             nan     0.0500    0.0087
    60        4.4650             nan     0.0500    0.0010
    80        4.1919             nan     0.0500    0.0013
   100        4.0231             nan     0.0500   -0.0166
   120        3.8631             nan     0.0500   -0.0112
   140        3.7524             nan     0.0500   -0.0016
   160        3.6598             nan     0.0500   -0.0039
   180        3.5854             nan     0.0500   -0.0127
   200        3.5252             nan     0.0500   -0.0078

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0193             nan     0.0500    0.1474
     2        6.8058             nan     0.0500    0.1745
     3        6.6937             nan     0.0500    0.1002
     4        6.5281             nan     0.0500    0.1326
     5        6.3971             nan     0.0500    0.1140
     6        6.2886             nan     0.0500    0.0834
     7        6.1904             nan     0.0500    0.0778
     8        6.1005             nan     0.0500    0.0722
     9        6.0066             nan     0.0500    0.0624
    10        5.9053             nan     0.0500    0.0551
    20        5.2372             nan     0.0500    0.0193
    40        4.5021             nan     0.0500    0.0146
    60        4.1025             nan     0.0500   -0.0089
    80        3.8472             nan     0.0500   -0.0148
   100        3.6187             nan     0.0500   -0.0063
   120        3.4858             nan     0.0500   -0.0108
   140        3.3310             nan     0.0500   -0.0114
   160        3.2159             nan     0.0500   -0.0067
   180        3.1148             nan     0.0500   -0.0048
   200        3.0088             nan     0.0500   -0.0013

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9912             nan     0.0500    0.1058
     2        6.7858             nan     0.0500    0.2039
     3        6.6336             nan     0.0500    0.1509
     4        6.4409             nan     0.0500    0.1236
     5        6.2778             nan     0.0500    0.1275
     6        6.1669             nan     0.0500    0.0903
     7        6.0516             nan     0.0500    0.0874
     8        5.9486             nan     0.0500    0.0818
     9        5.8227             nan     0.0500    0.0637
    10        5.7258             nan     0.0500    0.0480
    20        4.8620             nan     0.0500    0.0226
    40        4.0873             nan     0.0500   -0.0115
    60        3.6253             nan     0.0500   -0.0072
    80        3.3218             nan     0.0500    0.0046
   100        3.0739             nan     0.0500   -0.0137
   120        2.8845             nan     0.0500   -0.0114
   140        2.7077             nan     0.0500   -0.0105
   160        2.5553             nan     0.0500   -0.0129
   180        2.4112             nan     0.0500   -0.0072
   200        2.2756             nan     0.0500   -0.0084

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8897             nan     0.1000    0.2469
     2        6.7092             nan     0.1000    0.1982
     3        6.5397             nan     0.1000    0.1316
     4        6.4211             nan     0.1000    0.1330
     5        6.2894             nan     0.1000    0.0956
     6        6.1520             nan     0.1000    0.1049
     7        6.0756             nan     0.1000    0.0735
     8        5.9782             nan     0.1000    0.0909
     9        5.9102             nan     0.1000    0.0263
    10        5.8380             nan     0.1000    0.0478
    20        5.3580             nan     0.1000   -0.0151
    40        4.7916             nan     0.1000    0.0116
    60        4.5162             nan     0.1000   -0.0217
    80        4.3253             nan     0.1000   -0.0206
   100        4.2125             nan     0.1000   -0.0137
   120        4.1115             nan     0.1000   -0.0122
   140        4.0596             nan     0.1000   -0.0202
   160        4.0188             nan     0.1000   -0.0142
   180        3.9849             nan     0.1000   -0.0091
   200        3.9506             nan     0.1000   -0.0115

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8458             nan     0.1000    0.3281
     2        6.6349             nan     0.1000    0.2227
     3        6.4404             nan     0.1000    0.1641
     4        6.2824             nan     0.1000    0.1533
     5        6.1002             nan     0.1000    0.0829
     6        6.0224             nan     0.1000    0.0329
     7        5.8934             nan     0.1000    0.0498
     8        5.7545             nan     0.1000    0.0242
     9        5.6370             nan     0.1000    0.0991
    10        5.5369             nan     0.1000    0.0326
    20        4.8409             nan     0.1000   -0.0036
    40        4.2648             nan     0.1000    0.0064
    60        3.9990             nan     0.1000   -0.0050
    80        3.7918             nan     0.1000   -0.0256
   100        3.6013             nan     0.1000   -0.0209
   120        3.4247             nan     0.1000   -0.0173
   140        3.2923             nan     0.1000   -0.0052
   160        3.1892             nan     0.1000   -0.0087
   180        3.1163             nan     0.1000   -0.0181
   200        3.0431             nan     0.1000   -0.0130

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9162             nan     0.1000    0.2241
     2        6.6297             nan     0.1000    0.2262
     3        6.3717             nan     0.1000    0.1968
     4        6.1675             nan     0.1000    0.2045
     5        5.9703             nan     0.1000    0.1363
     6        5.8071             nan     0.1000    0.1641
     7        5.6274             nan     0.1000    0.0986
     8        5.5004             nan     0.1000    0.0812
     9        5.3754             nan     0.1000    0.1099
    10        5.2528             nan     0.1000    0.0612
    20        4.5090             nan     0.1000   -0.0052
    40        3.8417             nan     0.1000   -0.0013
    60        3.4592             nan     0.1000   -0.0079
    80        3.2467             nan     0.1000   -0.0246
   100        3.0845             nan     0.1000   -0.0308
   120        2.9111             nan     0.1000   -0.0277
   140        2.7411             nan     0.1000   -0.0337
   160        2.5633             nan     0.1000   -0.0145
   180        2.4384             nan     0.1000   -0.0205
   200        2.3346             nan     0.1000   -0.0093

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7628             nan     0.1000    0.3238
     2        6.4424             nan     0.1000    0.3140
     3        6.1781             nan     0.1000    0.2303
     4        5.8883             nan     0.1000    0.1773
     5        5.6269             nan     0.1000    0.1734
     6        5.4609             nan     0.1000    0.1388
     7        5.2988             nan     0.1000    0.1077
     8        5.1449             nan     0.1000    0.0828
     9        4.9871             nan     0.1000    0.0693
    10        4.8523             nan     0.1000    0.0926
    20        4.1005             nan     0.1000    0.0095
    40        3.3485             nan     0.1000   -0.0048
    60        2.9000             nan     0.1000   -0.0456
    80        2.5998             nan     0.1000   -0.0284
   100        2.3513             nan     0.1000   -0.0206
   120        2.1257             nan     0.1000   -0.0267
   140        1.9374             nan     0.1000   -0.0183
   160        1.7629             nan     0.1000   -0.0108
   180        1.6004             nan     0.1000   -0.0189
   200        1.4667             nan     0.1000   -0.0121

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7085             nan     0.2000    0.3477
     2        6.3885             nan     0.2000    0.3348
     3        6.0907             nan     0.2000    0.2141
     4        5.9029             nan     0.2000    0.1276
     5        5.7728             nan     0.2000    0.0342
     6        5.6503             nan     0.2000    0.0844
     7        5.5605             nan     0.2000    0.0596
     8        5.5304             nan     0.2000   -0.0644
     9        5.4478             nan     0.2000    0.0224
    10        5.3512             nan     0.2000    0.0855
    20        4.8538             nan     0.2000   -0.0473
    40        4.3009             nan     0.2000   -0.0310
    60        4.1474             nan     0.2000   -0.0202
    80        4.0798             nan     0.2000   -0.0438
   100        4.0059             nan     0.2000   -0.0145
   120        3.9815             nan     0.2000   -0.0429
   140        3.9533             nan     0.2000   -0.0272
   160        3.9111             nan     0.2000   -0.0195
   180        3.8760             nan     0.2000   -0.0256
   200        3.8709             nan     0.2000   -0.0449

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6848             nan     0.2000    0.3169
     2        6.2506             nan     0.2000    0.2981
     3        5.8683             nan     0.2000    0.3198
     4        5.6853             nan     0.2000    0.0960
     5        5.4917             nan     0.2000    0.1803
     6        5.3560             nan     0.2000    0.1176
     7        5.2370             nan     0.2000    0.0731
     8        5.0621             nan     0.2000    0.0829
     9        4.9916             nan     0.2000    0.0149
    10        4.9146             nan     0.2000   -0.0326
    20        4.2465             nan     0.2000    0.0002
    40        3.8198             nan     0.2000   -0.0252
    60        3.5637             nan     0.2000   -0.0752
    80        3.3799             nan     0.2000   -0.0434
   100        3.1439             nan     0.2000   -0.0412
   120        2.9344             nan     0.2000    0.0003
   140        2.8061             nan     0.2000   -0.0036
   160        2.6715             nan     0.2000   -0.0438
   180        2.5540             nan     0.2000   -0.0195
   200        2.4993             nan     0.2000   -0.0274

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5407             nan     0.2000    0.6030
     2        5.9480             nan     0.2000    0.5815
     3        5.7152             nan     0.2000    0.1929
     4        5.3805             nan     0.2000    0.2638
     5        5.1522             nan     0.2000    0.1807
     6        4.9624             nan     0.2000    0.1012
     7        4.8814             nan     0.2000   -0.0668
     8        4.7515             nan     0.2000    0.0782
     9        4.6287             nan     0.2000   -0.0018
    10        4.5515             nan     0.2000    0.0112
    20        4.0277             nan     0.2000   -0.0600
    40        3.4115             nan     0.2000   -0.0185
    60        2.9960             nan     0.2000   -0.0044
    80        2.7298             nan     0.2000   -0.0412
   100        2.5136             nan     0.2000   -0.0596
   120        2.3513             nan     0.2000   -0.0945
   140        2.1230             nan     0.2000   -0.0298
   160        1.9709             nan     0.2000   -0.0292
   180        1.8112             nan     0.2000   -0.0269
   200        1.6844             nan     0.2000   -0.0291

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.5428             nan     0.2000    0.4450
     2        5.9809             nan     0.2000    0.4864
     3        5.6109             nan     0.2000    0.1933
     4        5.2264             nan     0.2000    0.2875
     5        5.0440             nan     0.2000   -0.0121
     6        4.7852             nan     0.2000    0.1675
     7        4.5711             nan     0.2000    0.0665
     8        4.4640             nan     0.2000   -0.0074
     9        4.2991             nan     0.2000    0.0834
    10        4.1846             nan     0.2000    0.0135
    20        3.5560             nan     0.2000   -0.1449
    40        2.7855             nan     0.2000   -0.0489
    60        2.2520             nan     0.2000   -0.0403
    80        1.8561             nan     0.2000   -0.0342
   100        1.5401             nan     0.2000   -0.0155
   120        1.2929             nan     0.2000   -0.0384
   140        1.1085             nan     0.2000   -0.0076
   160        0.9738             nan     0.2000   -0.0124
   180        0.8254             nan     0.2000   -0.0140
   200        0.7077             nan     0.2000   -0.0168

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2702             nan     0.0500    0.1189
     2        7.1596             nan     0.0500    0.0897
     3        7.0905             nan     0.0500    0.0510
     4        6.9855             nan     0.0500    0.0835
     5        6.9012             nan     0.0500    0.0795
     6        6.8219             nan     0.0500    0.0590
     7        6.7516             nan     0.0500    0.0610
     8        6.6739             nan     0.0500    0.0522
     9        6.6051             nan     0.0500    0.0599
    10        6.5691             nan     0.0500    0.0049
    20        6.1030             nan     0.0500    0.0413
    40        5.5272             nan     0.0500   -0.0044
    60        5.1640             nan     0.0500    0.0033
    80        4.8981             nan     0.0500    0.0116
   100        4.6992             nan     0.0500    0.0001
   120        4.5471             nan     0.0500    0.0004
   140        4.4234             nan     0.0500   -0.0062
   160        4.3318             nan     0.0500   -0.0032
   180        4.2540             nan     0.0500   -0.0115
   200        4.1947             nan     0.0500   -0.0070

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2607             nan     0.0500    0.1011
     2        7.1324             nan     0.0500    0.1297
     3        6.9892             nan     0.0500    0.1147
     4        6.8774             nan     0.0500    0.0935
     5        6.7485             nan     0.0500    0.1125
     6        6.6462             nan     0.0500    0.0932
     7        6.5470             nan     0.0500    0.1068
     8        6.4408             nan     0.0500    0.0939
     9        6.3664             nan     0.0500    0.0581
    10        6.2766             nan     0.0500    0.0699
    20        5.6643             nan     0.0500    0.0264
    40        4.9615             nan     0.0500    0.0092
    60        4.5089             nan     0.0500   -0.0017
    80        4.2250             nan     0.0500   -0.0031
   100        4.0307             nan     0.0500    0.0026
   120        3.8663             nan     0.0500   -0.0035
   140        3.7432             nan     0.0500   -0.0081
   160        3.6488             nan     0.0500   -0.0073
   180        3.5628             nan     0.0500   -0.0034
   200        3.4933             nan     0.0500   -0.0077

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2021             nan     0.0500    0.1986
     2        7.0614             nan     0.0500    0.1305
     3        6.9105             nan     0.0500    0.1443
     4        6.7510             nan     0.0500    0.0825
     5        6.6196             nan     0.0500    0.0821
     6        6.5371             nan     0.0500    0.0618
     7        6.4148             nan     0.0500    0.0997
     8        6.3179             nan     0.0500    0.0968
     9        6.2154             nan     0.0500    0.0697
    10        6.1406             nan     0.0500    0.0764
    20        5.3723             nan     0.0500    0.0324
    40        4.5470             nan     0.0500   -0.0107
    60        4.0950             nan     0.0500    0.0071
    80        3.7928             nan     0.0500   -0.0033
   100        3.5835             nan     0.0500   -0.0066
   120        3.4172             nan     0.0500   -0.0147
   140        3.2754             nan     0.0500   -0.0109
   160        3.1575             nan     0.0500   -0.0046
   180        3.0563             nan     0.0500   -0.0087
   200        2.9684             nan     0.0500   -0.0157

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1791             nan     0.0500    0.1749
     2        6.9960             nan     0.0500    0.1194
     3        6.8159             nan     0.0500    0.1411
     4        6.6367             nan     0.0500    0.1086
     5        6.5047             nan     0.0500    0.0881
     6        6.3723             nan     0.0500    0.0598
     7        6.2374             nan     0.0500    0.0792
     8        6.1112             nan     0.0500    0.1000
     9        5.9869             nan     0.0500    0.0841
    10        5.8645             nan     0.0500    0.0715
    20        5.0512             nan     0.0500    0.0629
    40        4.0990             nan     0.0500    0.0046
    60        3.6086             nan     0.0500   -0.0105
    80        3.2830             nan     0.0500   -0.0057
   100        3.0255             nan     0.0500   -0.0050
   120        2.8143             nan     0.0500   -0.0116
   140        2.6297             nan     0.0500   -0.0149
   160        2.4740             nan     0.0500   -0.0127
   180        2.3267             nan     0.0500   -0.0021
   200        2.1982             nan     0.0500   -0.0131

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1832             nan     0.1000    0.1641
     2        6.9316             nan     0.1000    0.2267
     3        6.7775             nan     0.1000    0.1657
     4        6.6902             nan     0.1000    0.0575
     5        6.5533             nan     0.1000    0.1257
     6        6.4363             nan     0.1000    0.1145
     7        6.3224             nan     0.1000    0.0851
     8        6.2351             nan     0.1000    0.0891
     9        6.1783             nan     0.1000    0.0416
    10        6.1076             nan     0.1000    0.0358
    20        5.4890             nan     0.1000    0.0177
    40        4.8456             nan     0.1000   -0.0015
    60        4.4988             nan     0.1000   -0.0163
    80        4.3029             nan     0.1000   -0.0278
   100        4.1733             nan     0.1000    0.0003
   120        4.0970             nan     0.1000   -0.0113
   140        4.0366             nan     0.1000   -0.0059
   160        3.9781             nan     0.1000   -0.0063
   180        3.9423             nan     0.1000   -0.0121
   200        3.9188             nan     0.1000   -0.0119

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0908             nan     0.1000    0.1897
     2        6.8650             nan     0.1000    0.1057
     3        6.6220             nan     0.1000    0.1883
     4        6.3938             nan     0.1000    0.2153
     5        6.2172             nan     0.1000    0.1625
     6        6.1084             nan     0.1000    0.0786
     7        6.0067             nan     0.1000    0.1044
     8        5.8714             nan     0.1000    0.0713
     9        5.7607             nan     0.1000    0.0643
    10        5.6819             nan     0.1000    0.0118
    20        4.9195             nan     0.1000    0.0062
    40        4.2204             nan     0.1000   -0.0123
    60        3.8736             nan     0.1000   -0.0346
    80        3.6822             nan     0.1000   -0.0275
   100        3.5022             nan     0.1000   -0.0235
   120        3.3865             nan     0.1000   -0.0147
   140        3.2892             nan     0.1000   -0.0300
   160        3.1801             nan     0.1000   -0.0156
   180        3.0612             nan     0.1000   -0.0290
   200        2.9679             nan     0.1000   -0.0167

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0505             nan     0.1000    0.3236
     2        6.7783             nan     0.1000    0.1760
     3        6.5280             nan     0.1000    0.2334
     4        6.3251             nan     0.1000    0.1196
     5        6.1337             nan     0.1000    0.1131
     6        5.9512             nan     0.1000    0.1112
     7        5.7547             nan     0.1000    0.1471
     8        5.6108             nan     0.1000    0.0701
     9        5.4904             nan     0.1000    0.0768
    10        5.3607             nan     0.1000    0.0683
    20        4.5631             nan     0.1000    0.0120
    40        3.8199             nan     0.1000   -0.0082
    60        3.4150             nan     0.1000   -0.0321
    80        3.1962             nan     0.1000   -0.0292
   100        3.0220             nan     0.1000   -0.0132
   120        2.8816             nan     0.1000   -0.0256
   140        2.6957             nan     0.1000   -0.0170
   160        2.5441             nan     0.1000   -0.0079
   180        2.4143             nan     0.1000   -0.0071
   200        2.3097             nan     0.1000   -0.0222

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9872             nan     0.1000    0.4045
     2        6.6891             nan     0.1000    0.1808
     3        6.3597             nan     0.1000    0.1957
     4        6.1133             nan     0.1000    0.0999
     5        5.8889             nan     0.1000    0.1593
     6        5.6755             nan     0.1000    0.1148
     7        5.5169             nan     0.1000    0.1608
     8        5.3390             nan     0.1000    0.0723
     9        5.1863             nan     0.1000    0.0822
    10        5.0620             nan     0.1000    0.0799
    20        4.1064             nan     0.1000    0.0016
    40        3.2913             nan     0.1000   -0.0330
    60        2.8462             nan     0.1000   -0.0257
    80        2.5428             nan     0.1000   -0.0179
   100        2.2420             nan     0.1000   -0.0235
   120        1.9933             nan     0.1000   -0.0316
   140        1.8045             nan     0.1000   -0.0200
   160        1.6435             nan     0.1000   -0.0156
   180        1.5017             nan     0.1000   -0.0077
   200        1.3669             nan     0.1000   -0.0074

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8950             nan     0.2000    0.4625
     2        6.5993             nan     0.2000    0.1988
     3        6.3075             nan     0.2000    0.2745
     4        6.1285             nan     0.2000    0.2006
     5        5.9761             nan     0.2000    0.0664
     6        5.8461             nan     0.2000    0.0595
     7        5.7010             nan     0.2000    0.0244
     8        5.6358             nan     0.2000    0.0128
     9        5.5436             nan     0.2000    0.0564
    10        5.4760             nan     0.2000   -0.0206
    20        4.8641             nan     0.2000   -0.0160
    40        4.3863             nan     0.2000   -0.0009
    60        4.1061             nan     0.2000   -0.0361
    80        4.0084             nan     0.2000   -0.0733
   100        3.9224             nan     0.2000   -0.0304
   120        3.9092             nan     0.2000   -0.0419
   140        3.8993             nan     0.2000   -0.0446
   160        3.8563             nan     0.2000   -0.0293
   180        3.8608             nan     0.2000   -0.0216
   200        3.8534             nan     0.2000   -0.0240

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8157             nan     0.2000    0.5866
     2        6.3809             nan     0.2000    0.3901
     3        6.1005             nan     0.2000    0.0876
     4        5.8706             nan     0.2000    0.1081
     5        5.6275             nan     0.2000    0.1330
     6        5.4559             nan     0.2000    0.1704
     7        5.2939             nan     0.2000    0.0612
     8        5.1884             nan     0.2000    0.0377
     9        5.0313             nan     0.2000    0.0575
    10        4.9141             nan     0.2000    0.0971
    20        4.2348             nan     0.2000   -0.0203
    40        3.6987             nan     0.2000   -0.0356
    60        3.4866             nan     0.2000   -0.0111
    80        3.2842             nan     0.2000   -0.0342
   100        3.0861             nan     0.2000   -0.0365
   120        2.9184             nan     0.2000   -0.0209
   140        2.7674             nan     0.2000   -0.0158
   160        2.6458             nan     0.2000    0.0046
   180        2.5282             nan     0.2000   -0.0240
   200        2.4072             nan     0.2000   -0.0228

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8118             nan     0.2000    0.3582
     2        6.2639             nan     0.2000    0.3857
     3        5.8620             nan     0.2000    0.3234
     4        5.5644             nan     0.2000    0.1914
     5        5.3530             nan     0.2000    0.0120
     6        5.1618             nan     0.2000    0.1444
     7        4.9567             nan     0.2000    0.1017
     8        4.8031             nan     0.2000    0.0875
     9        4.6525             nan     0.2000    0.0915
    10        4.5388             nan     0.2000    0.0454
    20        3.8287             nan     0.2000   -0.0382
    40        3.2540             nan     0.2000   -0.0251
    60        2.9196             nan     0.2000   -0.0263
    80        2.5687             nan     0.2000   -0.0084
   100        2.3693             nan     0.2000   -0.0475
   120        2.1747             nan     0.2000   -0.0245
   140        2.0432             nan     0.2000   -0.0375
   160        1.9205             nan     0.2000   -0.0324
   180        1.7961             nan     0.2000   -0.0242
   200        1.6742             nan     0.2000   -0.0254

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6960             nan     0.2000    0.6448
     2        6.1883             nan     0.2000    0.4572
     3        5.7036             nan     0.2000    0.3103
     4        5.3764             nan     0.2000    0.2499
     5        5.0360             nan     0.2000    0.1038
     6        4.8167             nan     0.2000   -0.0069
     7        4.6045             nan     0.2000    0.1256
     8        4.4914             nan     0.2000   -0.0102
     9        4.3301             nan     0.2000    0.0593
    10        4.1863             nan     0.2000    0.0728
    20        3.5105             nan     0.2000   -0.0839
    40        2.7804             nan     0.2000   -0.0081
    60        2.2395             nan     0.2000   -0.0391
    80        1.9033             nan     0.2000   -0.0355
   100        1.6807             nan     0.2000   -0.0442
   120        1.4662             nan     0.2000   -0.0451
   140        1.2513             nan     0.2000   -0.0435
   160        1.0570             nan     0.2000   -0.0256
   180        0.9241             nan     0.2000   -0.0076
   200        0.8047             nan     0.2000   -0.0206

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1993             nan     0.0500    0.1071
     2        7.0782             nan     0.0500    0.1242
     3        6.9954             nan     0.0500    0.0880
     4        6.9132             nan     0.0500    0.0943
     5        6.8597             nan     0.0500    0.0186
     6        6.7828             nan     0.0500    0.0666
     7        6.7213             nan     0.0500    0.0332
     8        6.6512             nan     0.0500    0.0769
     9        6.5517             nan     0.0500    0.0897
    10        6.4843             nan     0.0500    0.0760
    20        5.9823             nan     0.0500    0.0179
    40        5.4212             nan     0.0500    0.0041
    60        5.0707             nan     0.0500   -0.0085
    80        4.8417             nan     0.0500    0.0011
   100        4.6568             nan     0.0500   -0.0013
   120        4.5260             nan     0.0500   -0.0033
   140        4.4167             nan     0.0500   -0.0069
   160        4.3294             nan     0.0500   -0.0093
   180        4.2485             nan     0.0500   -0.0044
   200        4.1927             nan     0.0500   -0.0051

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1403             nan     0.0500    0.0796
     2        6.9921             nan     0.0500    0.1565
     3        6.8442             nan     0.0500    0.1260
     4        6.7309             nan     0.0500    0.0822
     5        6.6093             nan     0.0500    0.0870
     6        6.4987             nan     0.0500    0.0780
     7        6.4067             nan     0.0500    0.0620
     8        6.2894             nan     0.0500    0.0725
     9        6.2024             nan     0.0500    0.0680
    10        6.1181             nan     0.0500    0.0690
    20        5.5520             nan     0.0500    0.0117
    40        4.8586             nan     0.0500    0.0083
    60        4.4855             nan     0.0500   -0.0039
    80        4.2231             nan     0.0500    0.0029
   100        4.0646             nan     0.0500   -0.0044
   120        3.9467             nan     0.0500   -0.0089
   140        3.8408             nan     0.0500   -0.0124
   160        3.7334             nan     0.0500   -0.0189
   180        3.6439             nan     0.0500   -0.0003
   200        3.5780             nan     0.0500   -0.0107

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1233             nan     0.0500    0.1659
     2        6.9677             nan     0.0500    0.1608
     3        6.8271             nan     0.0500    0.1109
     4        6.6731             nan     0.0500    0.1153
     5        6.5386             nan     0.0500    0.1052
     6        6.4150             nan     0.0500    0.1068
     7        6.3309             nan     0.0500    0.0477
     8        6.2180             nan     0.0500    0.0966
     9        6.1411             nan     0.0500    0.0389
    10        6.0551             nan     0.0500    0.0764
    20        5.3247             nan     0.0500    0.0147
    40        4.5424             nan     0.0500   -0.0039
    60        4.1074             nan     0.0500   -0.0029
    80        3.8573             nan     0.0500   -0.0033
   100        3.6676             nan     0.0500   -0.0027
   120        3.4885             nan     0.0500   -0.0111
   140        3.3337             nan     0.0500   -0.0043
   160        3.2204             nan     0.0500   -0.0178
   180        3.0903             nan     0.0500   -0.0035
   200        2.9886             nan     0.0500   -0.0080

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0985             nan     0.0500    0.1436
     2        6.8851             nan     0.0500    0.1538
     3        6.7028             nan     0.0500    0.1896
     4        6.5322             nan     0.0500    0.1819
     5        6.3608             nan     0.0500    0.1389
     6        6.1975             nan     0.0500    0.1226
     7        6.0761             nan     0.0500    0.0784
     8        5.9523             nan     0.0500    0.0783
     9        5.8540             nan     0.0500    0.0676
    10        5.7587             nan     0.0500    0.0738
    20        4.9822             nan     0.0500    0.0222
    40        4.1726             nan     0.0500    0.0057
    60        3.6885             nan     0.0500    0.0024
    80        3.3458             nan     0.0500   -0.0170
   100        3.1200             nan     0.0500   -0.0003
   120        2.9099             nan     0.0500   -0.0199
   140        2.7422             nan     0.0500   -0.0075
   160        2.5754             nan     0.0500   -0.0203
   180        2.4126             nan     0.0500   -0.0129
   200        2.2820             nan     0.0500   -0.0145

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0798             nan     0.1000    0.2572
     2        6.8976             nan     0.1000    0.1957
     3        6.7279             nan     0.1000    0.1549
     4        6.5816             nan     0.1000    0.1271
     5        6.4372             nan     0.1000    0.1325
     6        6.3131             nan     0.1000    0.1196
     7        6.2095             nan     0.1000    0.0751
     8        6.1265             nan     0.1000    0.0616
     9        6.0531             nan     0.1000   -0.0065
    10        5.9757             nan     0.1000    0.0677
    20        5.3976             nan     0.1000    0.0081
    40        4.8604             nan     0.1000   -0.0539
    60        4.5554             nan     0.1000   -0.0070
    80        4.3420             nan     0.1000   -0.0110
   100        4.2027             nan     0.1000   -0.0033
   120        4.1236             nan     0.1000   -0.0040
   140        4.0820             nan     0.1000   -0.0271
   160        4.0351             nan     0.1000   -0.0036
   180        3.9955             nan     0.1000   -0.0057
   200        3.9741             nan     0.1000   -0.0089

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9977             nan     0.1000    0.2684
     2        6.7772             nan     0.1000    0.2165
     3        6.5283             nan     0.1000    0.2018
     4        6.3180             nan     0.1000    0.1409
     5        6.1432             nan     0.1000    0.1283
     6        5.9712             nan     0.1000    0.1066
     7        5.8449             nan     0.1000    0.1052
     8        5.6895             nan     0.1000    0.0904
     9        5.6245             nan     0.1000    0.0412
    10        5.5526             nan     0.1000    0.0197
    20        4.9085             nan     0.1000    0.0214
    40        4.2409             nan     0.1000    0.0168
    60        3.9070             nan     0.1000   -0.0137
    80        3.7334             nan     0.1000   -0.0131
   100        3.5640             nan     0.1000   -0.0236
   120        3.4354             nan     0.1000    0.0011
   140        3.3453             nan     0.1000   -0.0303
   160        3.2551             nan     0.1000   -0.0132
   180        3.1842             nan     0.1000   -0.0223
   200        3.1009             nan     0.1000   -0.0295

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9720             nan     0.1000    0.2910
     2        6.7379             nan     0.1000    0.1723
     3        6.4254             nan     0.1000    0.2512
     4        6.2340             nan     0.1000    0.1728
     5        5.9997             nan     0.1000    0.1954
     6        5.7969             nan     0.1000    0.1259
     7        5.6777             nan     0.1000    0.0394
     8        5.5285             nan     0.1000    0.0835
     9        5.4380             nan     0.1000    0.0518
    10        5.3106             nan     0.1000    0.0484
    20        4.6105             nan     0.1000    0.0161
    40        3.9906             nan     0.1000   -0.0260
    60        3.6074             nan     0.1000   -0.0072
    80        3.3523             nan     0.1000   -0.0242
   100        3.1650             nan     0.1000   -0.0173
   120        3.0131             nan     0.1000   -0.0214
   140        2.8319             nan     0.1000   -0.0403
   160        2.6806             nan     0.1000   -0.0114
   180        2.5430             nan     0.1000   -0.0376
   200        2.4600             nan     0.1000   -0.0160

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9048             nan     0.1000    0.3637
     2        6.5302             nan     0.1000    0.2577
     3        6.2526             nan     0.1000    0.1943
     4        5.9528             nan     0.1000    0.1503
     5        5.7496             nan     0.1000    0.0554
     6        5.5497             nan     0.1000    0.1828
     7        5.3701             nan     0.1000    0.1085
     8        5.2301             nan     0.1000    0.0801
     9        5.0895             nan     0.1000    0.0901
    10        4.9686             nan     0.1000    0.0465
    20        4.1333             nan     0.1000   -0.0260
    40        3.4141             nan     0.1000   -0.0260
    60        3.0161             nan     0.1000   -0.0185
    80        2.7628             nan     0.1000   -0.0386
   100        2.4877             nan     0.1000   -0.0304
   120        2.2166             nan     0.1000   -0.0072
   140        2.0131             nan     0.1000   -0.0099
   160        1.8402             nan     0.1000   -0.0146
   180        1.6946             nan     0.1000   -0.0139
   200        1.5518             nan     0.1000   -0.0094

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9382             nan     0.2000    0.4160
     2        6.7508             nan     0.2000    0.0799
     3        6.4211             nan     0.2000    0.2990
     4        6.1207             nan     0.2000    0.2630
     5        5.9312             nan     0.2000    0.1577
     6        5.8040             nan     0.2000    0.0815
     7        5.6825             nan     0.2000    0.0874
     8        5.5702             nan     0.2000    0.0798
     9        5.4940             nan     0.2000    0.0218
    10        5.4247             nan     0.2000    0.0368
    20        4.8563             nan     0.2000    0.0041
    40        4.4072             nan     0.2000   -0.0082
    60        4.2099             nan     0.2000   -0.0369
    80        4.1018             nan     0.2000   -0.0651
   100        4.0391             nan     0.2000   -0.0436
   120        4.0191             nan     0.2000   -0.0395
   140        3.9831             nan     0.2000   -0.0399
   160        3.9805             nan     0.2000   -0.0169
   180        3.9711             nan     0.2000   -0.0603
   200        3.9305             nan     0.2000   -0.0237

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6978             nan     0.2000    0.5752
     2        6.3247             nan     0.2000    0.3481
     3        6.0680             nan     0.2000    0.0552
     4        5.9072             nan     0.2000    0.0970
     5        5.6324             nan     0.2000    0.2366
     6        5.3960             nan     0.2000    0.2054
     7        5.2083             nan     0.2000    0.1322
     8        5.1432             nan     0.2000   -0.0134
     9        5.0243             nan     0.2000    0.0551
    10        4.9040             nan     0.2000    0.0898
    20        4.2368             nan     0.2000    0.0277
    40        3.7614             nan     0.2000   -0.0350
    60        3.4475             nan     0.2000   -0.0698
    80        3.2681             nan     0.2000   -0.0566
   100        3.0611             nan     0.2000   -0.0491
   120        2.9711             nan     0.2000   -0.0464
   140        2.8082             nan     0.2000   -0.0112
   160        2.7225             nan     0.2000   -0.0265
   180        2.6047             nan     0.2000   -0.0152
   200        2.4968             nan     0.2000   -0.0248

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7476             nan     0.2000    0.2730
     2        6.2813             nan     0.2000    0.2379
     3        5.7938             nan     0.2000    0.3724
     4        5.5439             nan     0.2000    0.1769
     5        5.2907             nan     0.2000    0.0306
     6        5.0735             nan     0.2000    0.1420
     7        4.8959             nan     0.2000   -0.0130
     8        4.7621             nan     0.2000    0.0354
     9        4.6667             nan     0.2000   -0.0282
    10        4.5821             nan     0.2000    0.0801
    20        3.9720             nan     0.2000   -0.0261
    40        3.3923             nan     0.2000   -0.0381
    60        3.0143             nan     0.2000   -0.0287
    80        2.6901             nan     0.2000   -0.0234
   100        2.4980             nan     0.2000   -0.0602
   120        2.2238             nan     0.2000   -0.0129
   140        2.0529             nan     0.2000   -0.0209
   160        1.8476             nan     0.2000   -0.0331
   180        1.7372             nan     0.2000   -0.0413
   200        1.5918             nan     0.2000   -0.0260

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6907             nan     0.2000    0.5611
     2        6.1559             nan     0.2000    0.4151
     3        5.6078             nan     0.2000    0.3322
     4        5.3244             nan     0.2000    0.1612
     5        4.9685             nan     0.2000    0.1661
     6        4.7434             nan     0.2000    0.1241
     7        4.5816             nan     0.2000    0.0025
     8        4.4201             nan     0.2000    0.0144
     9        4.2673             nan     0.2000   -0.0095
    10        4.1807             nan     0.2000   -0.0561
    20        3.4834             nan     0.2000   -0.0738
    40        2.6852             nan     0.2000   -0.0023
    60        2.1347             nan     0.2000   -0.0484
    80        1.8150             nan     0.2000   -0.0340
   100        1.5029             nan     0.2000   -0.0198
   120        1.2808             nan     0.2000   -0.0315
   140        1.1011             nan     0.2000   -0.0257
   160        0.9458             nan     0.2000   -0.0199
   180        0.8436             nan     0.2000   -0.0217
   200        0.7479             nan     0.2000   -0.0190

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2616             nan     0.0500    0.0989
     2        7.1331             nan     0.0500    0.0973
     3        7.0643             nan     0.0500    0.0828
     4        6.9731             nan     0.0500    0.0823
     5        6.8736             nan     0.0500    0.0941
     6        6.7854             nan     0.0500    0.0791
     7        6.7124             nan     0.0500    0.0675
     8        6.6350             nan     0.0500    0.0421
     9        6.5796             nan     0.0500    0.0638
    10        6.5431             nan     0.0500    0.0272
    20        6.1408             nan     0.0500    0.0063
    40        5.5860             nan     0.0500   -0.0072
    60        5.2679             nan     0.0500   -0.0024
    80        5.0150             nan     0.0500   -0.0072
   100        4.8429             nan     0.0500   -0.0140
   120        4.7273             nan     0.0500    0.0026
   140        4.6254             nan     0.0500    0.0024
   160        4.5419             nan     0.0500   -0.0070
   180        4.4739             nan     0.0500   -0.0148
   200        4.4201             nan     0.0500   -0.0089

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2422             nan     0.0500    0.1018
     2        7.1030             nan     0.0500    0.1146
     3        6.9724             nan     0.0500    0.1247
     4        6.8522             nan     0.0500    0.1133
     5        6.7275             nan     0.0500    0.0939
     6        6.6307             nan     0.0500    0.0632
     7        6.5412             nan     0.0500    0.0784
     8        6.4518             nan     0.0500    0.0834
     9        6.3816             nan     0.0500    0.0532
    10        6.2973             nan     0.0500    0.0465
    20        5.7167             nan     0.0500    0.0215
    40        5.0748             nan     0.0500    0.0146
    60        4.6623             nan     0.0500    0.0029
    80        4.3698             nan     0.0500   -0.0033
   100        4.1815             nan     0.0500   -0.0090
   120        4.0367             nan     0.0500   -0.0076
   140        3.9239             nan     0.0500   -0.0120
   160        3.8325             nan     0.0500   -0.0128
   180        3.7474             nan     0.0500   -0.0039
   200        3.6686             nan     0.0500   -0.0149

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.2169             nan     0.0500    0.1236
     2        7.0836             nan     0.0500    0.0980
     3        6.9356             nan     0.0500    0.1385
     4        6.7900             nan     0.0500    0.0944
     5        6.6401             nan     0.0500    0.0984
     6        6.5271             nan     0.0500    0.0795
     7        6.4242             nan     0.0500    0.0988
     8        6.3122             nan     0.0500    0.0864
     9        6.2215             nan     0.0500    0.0553
    10        6.1422             nan     0.0500    0.0679
    20        5.4432             nan     0.0500   -0.0043
    40        4.7471             nan     0.0500    0.0030
    60        4.3067             nan     0.0500   -0.0098
    80        4.0310             nan     0.0500   -0.0138
   100        3.8213             nan     0.0500   -0.0110
   120        3.6473             nan     0.0500   -0.0012
   140        3.4952             nan     0.0500   -0.0044
   160        3.3694             nan     0.0500   -0.0063
   180        3.2693             nan     0.0500   -0.0031
   200        3.1626             nan     0.0500   -0.0041

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1786             nan     0.0500    0.1590
     2        6.9735             nan     0.0500    0.1658
     3        6.7968             nan     0.0500    0.1594
     4        6.6401             nan     0.0500    0.0949
     5        6.4945             nan     0.0500    0.1033
     6        6.3403             nan     0.0500    0.1100
     7        6.2111             nan     0.0500    0.0592
     8        6.0968             nan     0.0500    0.0677
     9        5.9551             nan     0.0500    0.0971
    10        5.8405             nan     0.0500    0.0566
    20        5.0932             nan     0.0500    0.0326
    40        4.2408             nan     0.0500    0.0108
    60        3.7575             nan     0.0500   -0.0065
    80        3.4661             nan     0.0500   -0.0098
   100        3.2117             nan     0.0500   -0.0129
   120        3.0044             nan     0.0500   -0.0175
   140        2.8165             nan     0.0500   -0.0053
   160        2.6571             nan     0.0500   -0.0221
   180        2.5098             nan     0.0500   -0.0127
   200        2.3803             nan     0.0500   -0.0091

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1545             nan     0.1000    0.1132
     2        6.9754             nan     0.1000    0.2286
     3        6.7777             nan     0.1000    0.1646
     4        6.6179             nan     0.1000    0.0685
     5        6.4942             nan     0.1000    0.1160
     6        6.3902             nan     0.1000    0.0920
     7        6.3064             nan     0.1000    0.0644
     8        6.2246             nan     0.1000    0.0407
     9        6.1752             nan     0.1000    0.0370
    10        6.1260             nan     0.1000    0.0164
    20        5.6192             nan     0.1000    0.0132
    40        5.0541             nan     0.1000   -0.0137
    60        4.7181             nan     0.1000    0.0103
    80        4.5339             nan     0.1000   -0.0123
   100        4.4327             nan     0.1000   -0.0276
   120        4.3496             nan     0.1000   -0.0083
   140        4.2701             nan     0.1000   -0.0128
   160        4.2242             nan     0.1000   -0.0473
   180        4.1878             nan     0.1000   -0.0242
   200        4.1444             nan     0.1000   -0.0113

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.1046             nan     0.1000    0.2816
     2        6.8582             nan     0.1000    0.2080
     3        6.6483             nan     0.1000    0.1473
     4        6.4687             nan     0.1000    0.1829
     5        6.4028             nan     0.1000    0.0104
     6        6.2950             nan     0.1000    0.0306
     7        6.1536             nan     0.1000    0.1329
     8        6.0774             nan     0.1000   -0.0001
     9        5.9786             nan     0.1000   -0.0000
    10        5.8678             nan     0.1000    0.0502
    20        5.1353             nan     0.1000    0.0181
    40        4.4249             nan     0.1000   -0.0359
    60        4.0904             nan     0.1000    0.0006
    80        3.8411             nan     0.1000   -0.0041
   100        3.6698             nan     0.1000   -0.0116
   120        3.5405             nan     0.1000   -0.0108
   140        3.4525             nan     0.1000   -0.0199
   160        3.3290             nan     0.1000   -0.0312
   180        3.2152             nan     0.1000   -0.0087
   200        3.1201             nan     0.1000   -0.0285

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0348             nan     0.1000    0.2790
     2        6.7621             nan     0.1000    0.2440
     3        6.4544             nan     0.1000    0.1391
     4        6.2235             nan     0.1000    0.1602
     5        6.0755             nan     0.1000    0.1118
     6        5.9025             nan     0.1000    0.1099
     7        5.7710             nan     0.1000    0.0670
     8        5.6473             nan     0.1000    0.1173
     9        5.5124             nan     0.1000    0.0952
    10        5.3961             nan     0.1000    0.0227
    20        4.7440             nan     0.1000   -0.0131
    40        4.0942             nan     0.1000   -0.0177
    60        3.7496             nan     0.1000   -0.0547
    80        3.4820             nan     0.1000   -0.0377
   100        3.2422             nan     0.1000   -0.0245
   120        3.0253             nan     0.1000   -0.0262
   140        2.8785             nan     0.1000   -0.0132
   160        2.7284             nan     0.1000   -0.0343
   180        2.5688             nan     0.1000   -0.0245
   200        2.4517             nan     0.1000   -0.0111

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.9909             nan     0.1000    0.2685
     2        6.6729             nan     0.1000    0.1849
     3        6.3880             nan     0.1000    0.1341
     4        6.1109             nan     0.1000    0.2118
     5        5.9167             nan     0.1000    0.1357
     6        5.7200             nan     0.1000    0.0399
     7        5.5668             nan     0.1000    0.0670
     8        5.4084             nan     0.1000    0.0912
     9        5.2540             nan     0.1000    0.0617
    10        5.1529             nan     0.1000    0.0441
    20        4.3128             nan     0.1000    0.0172
    40        3.5303             nan     0.1000   -0.0230
    60        3.0291             nan     0.1000   -0.0363
    80        2.6663             nan     0.1000   -0.0207
   100        2.3777             nan     0.1000   -0.0234
   120        2.1739             nan     0.1000   -0.0187
   140        1.9564             nan     0.1000   -0.0115
   160        1.8016             nan     0.1000   -0.0192
   180        1.6477             nan     0.1000   -0.0307
   200        1.5122             nan     0.1000   -0.0097

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0200             nan     0.2000    0.3252
     2        6.5698             nan     0.2000    0.3886
     3        6.3243             nan     0.2000    0.1787
     4        6.1274             nan     0.2000    0.1618
     5        5.9695             nan     0.2000    0.0997
     6        5.8513             nan     0.2000    0.0137
     7        5.7482             nan     0.2000    0.0118
     8        5.6982             nan     0.2000    0.0260
     9        5.5937             nan     0.2000    0.0584
    10        5.5178             nan     0.2000    0.0702
    20        5.0902             nan     0.2000   -0.0124
    40        4.6000             nan     0.2000   -0.0201
    60        4.3528             nan     0.2000   -0.0506
    80        4.2239             nan     0.2000   -0.0147
   100        4.1694             nan     0.2000   -0.0349
   120        4.1415             nan     0.2000   -0.0368
   140        4.1114             nan     0.2000   -0.0401
   160        4.0549             nan     0.2000   -0.0218
   180        4.0254             nan     0.2000   -0.0155
   200        4.0300             nan     0.2000   -0.0313

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.8127             nan     0.2000    0.3717
     2        6.4871             nan     0.2000    0.2814
     3        6.1311             nan     0.2000    0.3535
     4        5.8611             nan     0.2000    0.1842
     5        5.7221             nan     0.2000   -0.0090
     6        5.5571             nan     0.2000    0.1014
     7        5.4391             nan     0.2000    0.0536
     8        5.3388             nan     0.2000    0.0362
     9        5.2208             nan     0.2000    0.0610
    10        5.1355             nan     0.2000   -0.0071
    20        4.4131             nan     0.2000    0.0258
    40        3.9043             nan     0.2000   -0.0389
    60        3.5748             nan     0.2000   -0.0567
    80        3.3524             nan     0.2000   -0.0404
   100        3.1983             nan     0.2000   -0.0216
   120        3.0346             nan     0.2000   -0.0311
   140        2.9121             nan     0.2000   -0.0098
   160        2.8037             nan     0.2000   -0.0446
   180        2.7087             nan     0.2000   -0.0695
   200        2.6289             nan     0.2000   -0.0203

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.7608             nan     0.2000    0.5100
     2        6.3366             nan     0.2000    0.4321
     3        5.9648             nan     0.2000    0.2251
     4        5.7550             nan     0.2000    0.0671
     5        5.6009             nan     0.2000    0.0914
     6        5.4486             nan     0.2000   -0.0022
     7        5.3102             nan     0.2000    0.0733
     8        5.1062             nan     0.2000    0.1284
     9        4.9602             nan     0.2000    0.1000
    10        4.8314             nan     0.2000   -0.1009
    20        4.0595             nan     0.2000   -0.0317
    40        3.3401             nan     0.2000   -0.0519
    60        2.9709             nan     0.2000   -0.0252
    80        2.7427             nan     0.2000   -0.0184
   100        2.4842             nan     0.2000   -0.0330
   120        2.3014             nan     0.2000   -0.0322
   140        2.1061             nan     0.2000   -0.0435
   160        1.9655             nan     0.2000   -0.0566
   180        1.8133             nan     0.2000   -0.0380
   200        1.6818             nan     0.2000   -0.0192

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        6.6842             nan     0.2000    0.5128
     2        6.0360             nan     0.2000    0.3701
     3        5.6373             nan     0.2000    0.2701
     4        5.3870             nan     0.2000    0.0852
     5        5.2018             nan     0.2000   -0.0384
     6        4.9596             nan     0.2000    0.0675
     7        4.7641             nan     0.2000    0.0822
     8        4.6331             nan     0.2000   -0.0151
     9        4.5023             nan     0.2000   -0.0041
    10        4.4347             nan     0.2000   -0.1838
    20        3.7710             nan     0.2000   -0.1049
    40        2.9168             nan     0.2000   -0.0333
    60        2.3547             nan     0.2000   -0.0378
    80        1.8861             nan     0.2000   -0.0370
   100        1.5993             nan     0.2000   -0.0220
   120        1.3023             nan     0.2000   -0.0180
   140        1.1199             nan     0.2000   -0.0328
   160        0.9650             nan     0.2000   -0.0211
   180        0.8442             nan     0.2000   -0.0139
   200        0.7408             nan     0.2000   -0.0145

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        7.0755             nan     0.1000    0.2197
     2        6.9130             nan     0.1000    0.1526
     3        6.7533             nan     0.1000    0.1320
     4        6.5907             nan     0.1000    0.1363
     5        6.4550             nan     0.1000    0.1128
     6        6.3393             nan     0.1000    0.0525
     7        6.2030             nan     0.1000    0.1123
     8        6.1659             nan     0.1000    0.0098
     9        6.1287             nan     0.1000   -0.0011
    10        6.0526             nan     0.1000    0.0936
    20        5.5597             nan     0.1000    0.0186
    40        4.9658             nan     0.1000   -0.0267
    60        4.7137             nan     0.1000   -0.0049
    80        4.4834             nan     0.1000   -0.0110
   100        4.3557             nan     0.1000   -0.0162

</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[103]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">POR_SGB_fit</span>
<span class="n">POR_SGB_fit</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Stochastic Gradient Boosting 

454 samples
 30 predictor

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 408, 408, 410, 407, 408, 410, ... 
Resampling results across tuning parameters:

  shrinkage  interaction.depth  n.trees  RMSE      Rsquared   MAE     
  0.05       1                   50      2.361808  0.2641674  1.832330
  0.05       1                  100      2.286546  0.2922513  1.775090
  0.05       1                  200      2.251705  0.3070076  1.742106
  0.05       2                   50      2.299024  0.2967716  1.779744
  0.05       2                  100      2.251095  0.3069657  1.737566
  0.05       2                  200      2.260946  0.3041040  1.738596
  0.05       3                   50      2.280941  0.2985092  1.756481
  0.05       3                  100      2.249625  0.3079126  1.726304
  0.05       3                  200      2.285621  0.2937190  1.752935
  0.05       5                   50      2.262568  0.3032003  1.735799
  0.05       5                  100      2.267950  0.2979722  1.738565
  0.05       5                  200      2.317885  0.2805212  1.780878
  0.10       1                   50      2.287872  0.2912098  1.775348
  0.10       1                  100      2.248430  0.3088850  1.735486
  0.10       1                  200      2.277990  0.2999466  1.757173
  0.10       2                   50      2.248898  0.3089328  1.739349
  0.10       2                  100      2.260384  0.3068716  1.742616
  0.10       2                  200      2.325608  0.2834999  1.791107
  0.10       3                   50      2.258866  0.3018481  1.734260
  0.10       3                  100      2.301115  0.2882081  1.769254
  0.10       3                  200      2.356819  0.2693493  1.813378
  0.10       5                   50      2.289829  0.2874522  1.761090
  0.10       5                  100      2.350358  0.2681959  1.813207
  0.10       5                  200      2.419156  0.2493497  1.869035
  0.20       1                   50      2.266043  0.2973986  1.756036
  0.20       1                  100      2.284981  0.2962215  1.767068
  0.20       1                  200      2.341539  0.2778913  1.810515
  0.20       2                   50      2.303432  0.2848819  1.774774
  0.20       2                  100      2.364468  0.2659621  1.821904
  0.20       2                  200      2.453600  0.2401057  1.898233
  0.20       3                   50      2.340726  0.2710871  1.801798
  0.20       3                  100      2.412621  0.2475371  1.865766
  0.20       3                  200      2.506443  0.2268687  1.945926
  0.20       5                   50      2.399189  0.2493650  1.849331
  0.20       5                  100      2.492011  0.2240516  1.921632
  0.20       5                  200      2.585345  0.2007832  1.999549

Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were n.trees = 100, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 10.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>A gradient boosted model with gaussian loss function.
100 iterations were performed.
There were 39 predictors of which 24 had non-zero influence.</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h6 id="Training-RMSE-for-Each-Model">Training RMSE for Each Model<a class="anchor-link" href="#Training-RMSE-for-Each-Model">&#182;</a></h6><p>RMSE is used as selecting parameters for models</p>
<p>RMSE obtained from Training sets for each model given as;</p>
<p>Lasso RMSE 2.222</p>
<p>Decision Tree RMSE 2.335</p>
<p>Random Forest RMSE 2.218</p>
<p>Stochastic Gradient Boosting RMSE 2.248</p>
<p>Best RMSE obtained with Random Forest model for training set</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[117]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Lasso Regression </span>
<span class="n">POR_Lasso_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">POR_lasso_fit</span><span class="p">,</span> <span class="n">test_Por</span><span class="p">)</span>
<span class="n">RMSE_Lasso</span> <span class="o">&lt;-</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">test_Por</span><span class="o">$</span><span class="n">G3</span><span class="p">,</span><span class="n">POR_Lasso_predict</span><span class="p">)</span>
<span class="n">RMSE_Lasso</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">RMSE_Lasso</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">3</span><span class="p">)</span>
<span class="c1"># Decision Tree Regression </span>
<span class="n">POR_DT_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">POR_DT_fit1</span><span class="p">,</span> <span class="n">test_Por</span><span class="p">)</span>
<span class="n">RMSE_DT</span> <span class="o">&lt;-</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">test_Por</span><span class="o">$</span><span class="n">G3</span><span class="p">,</span><span class="n">POR_DT_predict</span><span class="p">)</span>
<span class="n">RMSE_DT</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">RMSE_DT</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">3</span><span class="p">)</span>
<span class="c1"># Random Forest Regression </span>
<span class="n">POR_RF_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">POR_RF_fit</span><span class="p">,</span> <span class="n">test_Por</span><span class="p">)</span>
<span class="n">RMSE_RF</span> <span class="o">&lt;-</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">test_Por</span><span class="o">$</span><span class="n">G3</span><span class="p">,</span><span class="n">POR_RF_predict</span><span class="p">)</span>
<span class="n">RMSE_RF</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">RMSE_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">3</span><span class="p">)</span>
<span class="c1"># Stochastic Gradient Boosting Regression </span>
<span class="n">POR_SGB_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">POR_SGB_fit</span><span class="p">,</span> <span class="n">test_Por</span><span class="p">)</span>
<span class="n">RMSE_SGB</span> <span class="o">&lt;-</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">test_Por</span><span class="o">$</span><span class="n">G3</span><span class="p">,</span><span class="n">POR_SGB_predict</span><span class="p">)</span>
<span class="n">RMSE_SGB</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">RMSE_SGB</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">3</span><span class="p">)</span>
<span class="n">A</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Lasso Model Test RMSE is&quot;</span><span class="p">,</span> <span class="n">RMSE_Lasso</span><span class="p">)</span>
<span class="n">B</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Decision Tree Test RMSE is&quot;</span><span class="p">,</span> <span class="n">RMSE_DT</span><span class="p">)</span>
<span class="n">C</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Random Forest Test RMSE is&quot;</span><span class="p">,</span> <span class="n">RMSE_RF</span><span class="p">)</span>
<span class="n">D</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Stochastic Gradient Boosting Test RMSE is&quot;</span><span class="p">,</span> <span class="n">RMSE_SGB</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[1] &#34;Lasso Model Test RMSE is 3.6636&#34;
[1] &#34;Decision Tree Test RMSE is 3.7674&#34;
[1] &#34;Random Forest Test RMSE is 3.6299&#34;
[1] &#34;Stochastic Gradient Boosting Test RMSE is 3.5999&#34;
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h6 id="Comments">Comments<a class="anchor-link" href="#Comments">&#182;</a></h6><p>We obtained the best RMSE from Random Forest model during the training as 2.218. RMSE for other models are around the same value, highest RMSE is obtained Decision Tree modes as 2.335, which is not that different from the best one.</p>
<p>The predicted value G3 is a final grade and its maximum value is 20. Our RMSE values are around 2.2 which indicates a significant error even in the trainig set.</p>
<p>Our predictions have RMSE around 3.6. The model which obtained the best result obtained from the test data is Stochastic Gradient Boosting. Our RMSE values for predictions are very high.</p>
<p>The data has some number of categorical or ordinal features, and for regression analysis these type of features may not be good.</p>
<p>Also, if we add G1 and G2, which are midterm grades, the error values should decrease. Features included in the model may not be enough to predict a final grade note for a language exam.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Dataset-3----Online-News-Popularity-Data-Set">Dataset 3 -  Online News Popularity Data Set<a class="anchor-link" href="#Dataset-3----Online-News-Popularity-Data-Set">&#182;</a></h1>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="Data-Set-Information:">Data Set Information:<a class="anchor-link" href="#Data-Set-Information:">&#182;</a></h5><ul>
<li>The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.</li>
<li>Acquisition date: January 8, 2015</li>
<li>The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method. See their article for more details on how the relative performance values were set.</li>
</ul>
<p>Attribute Information:</p>
<p>Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field)</p>
<p>Attribute Information:</p>
<ol>
<li>url: URL of the article (non-predictive)</li>
<li>timedelta: Days between the article publication and the dataset acquisition (non-predictive)</li>
<li>n_tokens_title: Number of words in the title</li>
<li>n_tokens_content: Number of words in the content</li>
<li>n_unique_tokens: Rate of unique words in the content</li>
<li>n_non_stop_words: Rate of non-stop words in the content</li>
<li>n_non_stop_unique_tokens: Rate of unique non-stop words in the content</li>
<li>num_hrefs: Number of links</li>
<li>num_self_hrefs: Number of links to other articles published by Mashable</li>
<li>num_imgs: Number of images</li>
<li>num_videos: Number of videos</li>
<li>average_token_length: Average length of the words in the content</li>
<li>num_keywords: Number of keywords in the metadata</li>
<li>data_channel_is_lifestyle: Is data channel 'Lifestyle'?</li>
<li>data_channel_is_entertainment: Is data channel 'Entertainment'?</li>
<li>data_channel_is_bus: Is data channel 'Business'?</li>
<li>data_channel_is_socmed: Is data channel 'Social Media'?</li>
<li>data_channel_is_tech: Is data channel 'Tech'?</li>
<li>data_channel_is_world: Is data channel 'World'?</li>
<li>kw_min_min: Worst keyword (min. shares)</li>
<li>kw_max_min: Worst keyword (max. shares)</li>
<li>kw_avg_min: Worst keyword (avg. shares)</li>
<li>kw_min_max: Best keyword (min. shares)</li>
<li>kw_max_max: Best keyword (max. shares)</li>
<li>kw_avg_max: Best keyword (avg. shares)</li>
<li>kw_min_avg: Avg. keyword (min. shares)</li>
<li>kw_max_avg: Avg. keyword (max. shares)</li>
<li>kw_avg_avg: Avg. keyword (avg. shares)</li>
<li>self_reference_min_shares: Min. shares of referenced articles in Mashable</li>
<li>self_reference_max_shares: Max. shares of referenced articles in Mashable</li>
<li>self_reference_avg_sharess: Avg. shares of referenced articles in Mashable</li>
<li>weekday_is_monday: Was the article published on a Monday?</li>
<li>weekday_is_tuesday: Was the article published on a Tuesday?</li>
<li>weekday_is_wednesday: Was the article published on a Wednesday?</li>
<li>weekday_is_thursday: Was the article published on a Thursday?</li>
<li>weekday_is_friday: Was the article published on a Friday?</li>
<li>weekday_is_saturday: Was the article published on a Saturday?</li>
<li>weekday_is_sunday: Was the article published on a Sunday?</li>
<li>is_weekend: Was the article published on the weekend?</li>
<li>LDA_00: Closeness to LDA topic 0</li>
<li>LDA_01: Closeness to LDA topic 1</li>
<li>LDA_02: Closeness to LDA topic 2</li>
<li>LDA_03: Closeness to LDA topic 3</li>
<li>LDA_04: Closeness to LDA topic 4</li>
<li>global_subjectivity: Text subjectivity</li>
<li>global_sentiment_polarity: Text sentiment polarity</li>
<li>global_rate_positive_words: Rate of positive words in the content</li>
<li>global_rate_negative_words: Rate of negative words in the content</li>
<li>rate_positive_words: Rate of positive words among non-neutral tokens</li>
<li>rate_negative_words: Rate of negative words among non-neutral tokens</li>
<li>avg_positive_polarity: Avg. polarity of positive words</li>
<li>min_positive_polarity: Min. polarity of positive words</li>
<li>max_positive_polarity: Max. polarity of positive words</li>
<li>avg_negative_polarity: Avg. polarity of negative words</li>
<li>min_negative_polarity: Min. polarity of negative words</li>
<li>max_negative_polarity: Max. polarity of negative words</li>
<li>title_subjectivity: Title subjectivity</li>
<li>title_sentiment_polarity: Title polarity</li>
<li>abs_title_subjectivity: Absolute subjectivity level</li>
<li>abs_title_sentiment_polarity: Absolute polarity level</li>
<li>shares: Number of shares (target)</li>
</ol>
<p>Relevant Papers:</p>
<p>K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence, September, Coimbra, Portugal.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="For-the-analysis">For the analysis<a class="anchor-link" href="#For-the-analysis">&#182;</a></h5><p>Shares will be target but I will classfy them as popular or not. So we will have 2 classes. I will create a class imbalance with that selection.
We have more than 50 features.
First two colums are URL and time, so I will remove them.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#read the data</span>
<span class="n">News_data</span> <span class="o">=</span> <span class="nf">read.csv</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="s">&quot;OnlineNewsPopularity.csv&quot;</span><span class="p">)</span>
<span class="n">News_data</span> <span class="o">&lt;-</span> <span class="n">News_data</span><span class="p">[</span><span class="o">!</span><span class="nf">names</span><span class="p">(</span><span class="n">News_data</span><span class="p">)</span> <span class="o">%in%</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;url&quot;</span><span class="p">,</span> <span class="s">&quot;timedelta&quot;</span><span class="p">)]</span>
<span class="n">News_data</span> <span class="o">=</span> <span class="nf">data.table</span><span class="p">(</span><span class="n">News_data</span><span class="p">)</span>
<span class="n">News_data</span><span class="p">[,</span><span class="n">is_popular</span><span class="o">:=</span><span class="nf">as.factor</span><span class="p">(</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">shares</span><span class="o">&gt;</span><span class="nf">quantile</span><span class="p">(</span><span class="n">shares</span><span class="p">,</span><span class="m">0.7</span><span class="p">)))]</span>  <span class="c1"># top %30 selected as popular to create a class imbalance</span>
<span class="n">News_data</span><span class="p">[,</span><span class="n">shares</span><span class="o">:=</span><span class="kc">NULL</span><span class="p">]</span>

<span class="c1"># divide the train and test data (%80 selected as train %20 selected as test)</span>
<span class="n">m</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">News_data</span><span class="p">)</span>
<span class="n">n</span><span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="m">0.8</span>
<span class="n">News_train</span> <span class="o">=</span> <span class="n">News_data</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">,]</span>
<span class="n">News_test</span> <span class="o">=</span> <span class="n">News_data</span><span class="p">[(</span><span class="n">n</span><span class="m">+1</span><span class="p">)</span><span class="o">:</span><span class="n">m</span><span class="p">,]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 1 - Lasso Regression</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">636</span><span class="p">)</span>
<span class="n">lambda_seq</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0.00001</span><span class="p">,</span><span class="m">0.01</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="m">6</span><span class="p">))</span> <span class="c1">#tried several times but we are asked to use 6 different lamda (I rerun the code)</span>
<span class="n">n_repeats</span><span class="o">=</span><span class="m">5</span>
<span class="n">n_folds</span><span class="o">=</span><span class="m">10</span>
<span class="n">lasso_grid</span> <span class="o">=</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">lambda</span><span class="o">=</span><span class="n">lambda_seq</span><span class="p">)</span>
<span class="n">lasso_control</span><span class="o">=</span><span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span>                        
<span class="n">News_lasso_fit</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">is_popular</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">News_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s">&quot;glmnet&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">lasso_grid</span><span class="p">,</span><span class="n">trControl</span> <span class="o">=</span> <span class="n">lasso_control</span><span class="p">)</span> 
<span class="n">News_lasso_fit</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>glmnet 

31715 samples
   58 predictor
    2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 28544, 28543, 28543, 28543, 28543, 28543, ... 
Resampling results across tuning parameters:

  lambda    Accuracy   Kappa     
  0.000010  0.7068832  0.15273557
  0.002008  0.7043860  0.13004443
  0.004006  0.7013401  0.10491154
  0.006004  0.6988870  0.08270075
  0.008002  0.6967114  0.06513976
  0.010000  0.6952546  0.05104745

Tuning parameter &#39;alpha&#39; was held constant at a value of 1
Accuracy was used to select the optimal model using the largest value.
The final values used for the model were alpha = 1 and lambda = 1e-05.</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 2 - Decision Trees</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">636</span><span class="p">)</span>

<span class="n">DT_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span> 
<span class="n">DT_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">cp</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.01</span><span class="p">,</span><span class="m">0.02</span><span class="p">,</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.005</span><span class="p">,</span><span class="m">0.002</span><span class="p">,</span><span class="m">0.001</span><span class="p">))</span> <span class="c1"># cp by default 0.01, I change by both increasing and decreasing</span>

<span class="c1"># minbucket is originaly &quot;20/3 = 7&quot; so I tried original &quot;7&quot;, increase to &quot;20&quot;, decrease to &quot;2&quot;...</span>
<span class="n">News_DT_fit1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">is_popular</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">News_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">7</span><span class="p">))</span>

<span class="n">News_DT_fit2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">is_popular</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">News_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">20</span><span class="p">))</span>

<span class="n">News_DT_fit3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">is_popular</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">News_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">2</span><span class="p">))</span>

<span class="n">News_DT_fit1</span>
<span class="n">News_DT_fit2</span>
<span class="n">News_DT_fit3</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

31715 samples
   58 predictor
    2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 28544, 28543, 28543, 28543, 28543, 28543, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa    
  0.001  0.7009933  0.1488407
  0.002  0.7001105  0.1198968
  0.005  0.6973926  0.1071019
  0.010  0.6920385  0.0000000
  0.020  0.6920385  0.0000000
  0.050  0.6920385  0.0000000

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.001.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

31715 samples
   58 predictor
    2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 28543, 28544, 28544, 28544, 28543, 28543, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa    
  0.001  0.7016490  0.1510433
  0.002  0.7000535  0.1221678
  0.005  0.6972031  0.1018049
  0.010  0.6920385  0.0000000
  0.020  0.6920385  0.0000000
  0.050  0.6920385  0.0000000

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.001.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

31715 samples
   58 predictor
    2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 28543, 28544, 28543, 28543, 28543, 28544, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa    
  0.001  0.7022670  0.1540894
  0.002  0.7003373  0.1249599
  0.005  0.6981050  0.1085825
  0.010  0.6920385  0.0000000
  0.020  0.6920385  0.0000000
  0.050  0.6920385  0.0000000

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.001.</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h6 id="-"> <a class="anchor-link" href="#-">&#182;</a></h6><p>Best Kappa value is obtained with the minbucket=2 selection so, News_DT_fit3 will be used.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">plot</span><span class="p">(</span><span class="n">News_DT_fit3</span><span class="o">$</span><span class="n">finalModel</span><span class="p">)</span>
<span class="nf">text</span><span class="p">(</span><span class="n">News_DT_fit3</span><span class="o">$</span><span class="n">finalModel</span><span class="p">,</span> <span class="n">all</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">cex</span><span class="o">=</span><span class="n">.</span><span class="m">4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAA7VBMVEUAAAAMDAwXFxcfHx8l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"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 3 - Random Forest</span>

<span class="n">RF_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">mtry</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">10</span><span class="p">,</span><span class="m">15</span><span class="p">))</span> <span class="c1"># default value is 5 I change by both increasing and decreasing</span>
<span class="c1"># RF_control &lt;- trainControl(method = &quot;repeatedcv&quot;, number = n_folds, repeats = 2) </span>
<span class="c1"># repeatedcv tooks so long to compute so I used cv this time and reduced the &quot;mtry&quot; options. </span>
<span class="n">RF_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;cv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">)</span>
<span class="n">News_RF_fit</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">is_popular</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">News_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rf&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">RF_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">RF_control</span><span class="p">)</span>
<span class="n">News_RF_fit</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">News_RF_fit</span><span class="p">)</span>
<span class="n">News_RF_fit</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Random Forest 

31715 samples
   58 predictor
    2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 28543, 28544, 28544, 28544, 28543, 28543, ... 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa    
   3    0.7154972  0.1663410
   5    0.7150242  0.1766100
  10    0.7169792  0.1953825
  15    0.7168531  0.1989622

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 10.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>
Call:
 randomForest(x = x, y = y, mtry = param$mtry) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 10

        OOB estimate of  error rate: 28.47%
Confusion matrix:
      0    1 class.error
0 20439 1509  0.06875342
1  7519 2248  0.76983721</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAgP9NTU1oaGh8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"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 4 - Stochastic Gradient Boosting</span>

<span class="c1"># interaction.depth default is 1 tried 2,3 and 5, n.trees default is 100 I change by both increasing and decreasing, </span>
<span class="c1"># shrinkage default is 0.1 I change by both increasing and decreasing</span>
<span class="n">SGB_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">interaction.depth</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">),</span> <span class="n">n.trees</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">200</span><span class="p">,</span><span class="m">50</span><span class="p">),</span><span class="n">shrinkage</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="m">0.2</span><span class="p">),</span><span class="n">n.minobsinnode</span> <span class="o">=</span><span class="m">10</span><span class="p">)</span>
<span class="c1"># repeatedcv tooks so long to compute so I used cv this time and reduced the &quot;interaction.depth&quot; options.</span>
<span class="c1">#SGB_control &lt;- trainControl(method = &quot;repeatedcv&quot;, number = n_folds, repeats = n_repeats) </span>
<span class="n">SGB_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;cv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">)</span>
<span class="n">News_SGB_fit</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">is_popular</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">News_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;gbm&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">SGB_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">SGB_control</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2313             nan     0.0500    0.0016
     2        1.2281             nan     0.0500    0.0015
     3        1.2252             nan     0.0500    0.0014
     4        1.2226             nan     0.0500    0.0012
     5        1.2203             nan     0.0500    0.0010
     6        1.2179             nan     0.0500    0.0011
     7        1.2157             nan     0.0500    0.0010
     8        1.2136             nan     0.0500    0.0010
     9        1.2117             nan     0.0500    0.0009
    10        1.2100             nan     0.0500    0.0008
    20        1.1958             nan     0.0500    0.0005
    40        1.1799             nan     0.0500    0.0002
    60        1.1697             nan     0.0500    0.0002
    80        1.1620             nan     0.0500    0.0001
   100        1.1561             nan     0.0500    0.0001
   120        1.1513             nan     0.0500    0.0001
   140        1.1471             nan     0.0500    0.0001
   160        1.1435             nan     0.0500    0.0000
   180        1.1407             nan     0.0500    0.0000
   200        1.1383             nan     0.0500    0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2300             nan     0.0500    0.0024
     2        1.2254             nan     0.0500    0.0021
     3        1.2214             nan     0.0500    0.0020
     4        1.2175             nan     0.0500    0.0018
     5        1.2142             nan     0.0500    0.0016
     6        1.2110             nan     0.0500    0.0016
     7        1.2078             nan     0.0500    0.0014
     8        1.2046             nan     0.0500    0.0015
     9        1.2017             nan     0.0500    0.0013
    10        1.1992             nan     0.0500    0.0012
    20        1.1786             nan     0.0500    0.0007
    40        1.1551             nan     0.0500    0.0004
    60        1.1415             nan     0.0500    0.0002
    80        1.1323             nan     0.0500    0.0001
   100        1.1257             nan     0.0500    0.0001
   120        1.1202             nan     0.0500    0.0001
   140        1.1155             nan     0.0500    0.0001
   160        1.1116             nan     0.0500   -0.0000
   180        1.1084             nan     0.0500    0.0001
   200        1.1056             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2294             nan     0.0500    0.0026
     2        1.2241             nan     0.0500    0.0026
     3        1.2190             nan     0.0500    0.0023
     4        1.2145             nan     0.0500    0.0021
     5        1.2103             nan     0.0500    0.0020
     6        1.2068             nan     0.0500    0.0017
     7        1.2032             nan     0.0500    0.0017
     8        1.1995             nan     0.0500    0.0017
     9        1.1962             nan     0.0500    0.0015
    10        1.1933             nan     0.0500    0.0014
    20        1.1700             nan     0.0500    0.0008
    40        1.1439             nan     0.0500    0.0003
    60        1.1289             nan     0.0500    0.0003
    80        1.1183             nan     0.0500    0.0001
   100        1.1112             nan     0.0500    0.0001
   120        1.1052             nan     0.0500    0.0000
   140        1.1003             nan     0.0500    0.0000
   160        1.0958             nan     0.0500    0.0000
   180        1.0917             nan     0.0500    0.0000
   200        1.0879             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2285             nan     0.1000    0.0033
     2        1.2227             nan     0.1000    0.0027
     3        1.2181             nan     0.1000    0.0020
     4        1.2138             nan     0.1000    0.0021
     5        1.2100             nan     0.1000    0.0018
     6        1.2067             nan     0.1000    0.0016
     7        1.2033             nan     0.1000    0.0016
     8        1.2006             nan     0.1000    0.0012
     9        1.1980             nan     0.1000    0.0012
    10        1.1954             nan     0.1000    0.0012
    20        1.1792             nan     0.1000    0.0006
    40        1.1615             nan     0.1000    0.0003
    60        1.1510             nan     0.1000    0.0001
    80        1.1434             nan     0.1000    0.0001
   100        1.1382             nan     0.1000    0.0001
   120        1.1344             nan     0.1000    0.0001
   140        1.1311             nan     0.1000    0.0000
   160        1.1287             nan     0.1000    0.0000
   180        1.1263             nan     0.1000    0.0000
   200        1.1244             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2256             nan     0.1000    0.0045
     2        1.2173             nan     0.1000    0.0040
     3        1.2105             nan     0.1000    0.0034
     4        1.2049             nan     0.1000    0.0027
     5        1.1998             nan     0.1000    0.0022
     6        1.1950             nan     0.1000    0.0022
     7        1.1898             nan     0.1000    0.0025
     8        1.1853             nan     0.1000    0.0020
     9        1.1817             nan     0.1000    0.0017
    10        1.1784             nan     0.1000    0.0015
    20        1.1555             nan     0.1000    0.0008
    40        1.1318             nan     0.1000    0.0004
    60        1.1204             nan     0.1000    0.0001
    80        1.1128             nan     0.1000   -0.0000
   100        1.1071             nan     0.1000    0.0000
   120        1.1023             nan     0.1000   -0.0000
   140        1.0976             nan     0.1000   -0.0000
   160        1.0938             nan     0.1000   -0.0000
   180        1.0901             nan     0.1000    0.0000
   200        1.0865             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2237             nan     0.1000    0.0053
     2        1.2147             nan     0.1000    0.0043
     3        1.2069             nan     0.1000    0.0036
     4        1.1992             nan     0.1000    0.0037
     5        1.1930             nan     0.1000    0.0028
     6        1.1871             nan     0.1000    0.0026
     7        1.1821             nan     0.1000    0.0022
     8        1.1770             nan     0.1000    0.0024
     9        1.1728             nan     0.1000    0.0018
    10        1.1691             nan     0.1000    0.0017
    20        1.1433             nan     0.1000    0.0006
    40        1.1200             nan     0.1000    0.0004
    60        1.1067             nan     0.1000    0.0001
    80        1.0980             nan     0.1000   -0.0001
   100        1.0905             nan     0.1000   -0.0000
   120        1.0828             nan     0.1000   -0.0000
   140        1.0766             nan     0.1000   -0.0001
   160        1.0707             nan     0.1000   -0.0001
   180        1.0649             nan     0.1000    0.0000
   200        1.0597             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2225             nan     0.2000    0.0062
     2        1.2141             nan     0.2000    0.0040
     3        1.2066             nan     0.2000    0.0036
     4        1.2001             nan     0.2000    0.0031
     5        1.1948             nan     0.2000    0.0026
     6        1.1906             nan     0.2000    0.0020
     7        1.1876             nan     0.2000    0.0013
     8        1.1845             nan     0.2000    0.0013
     9        1.1819             nan     0.2000    0.0011
    10        1.1792             nan     0.2000    0.0014
    20        1.1621             nan     0.2000    0.0003
    40        1.1433             nan     0.2000    0.0002
    60        1.1343             nan     0.2000    0.0001
    80        1.1286             nan     0.2000   -0.0000
   100        1.1240             nan     0.2000    0.0001
   120        1.1210             nan     0.2000   -0.0000
   140        1.1181             nan     0.2000   -0.0000
   160        1.1158             nan     0.2000    0.0000
   180        1.1139             nan     0.2000   -0.0000
   200        1.1122             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2167             nan     0.2000    0.0087
     2        1.2044             nan     0.2000    0.0058
     3        1.1935             nan     0.2000    0.0052
     4        1.1847             nan     0.2000    0.0041
     5        1.1783             nan     0.2000    0.0029
     6        1.1720             nan     0.2000    0.0030
     7        1.1666             nan     0.2000    0.0023
     8        1.1609             nan     0.2000    0.0026
     9        1.1569             nan     0.2000    0.0017
    10        1.1540             nan     0.2000    0.0011
    20        1.1325             nan     0.2000    0.0002
    40        1.1141             nan     0.2000    0.0000
    60        1.1041             nan     0.2000    0.0001
    80        1.0966             nan     0.2000   -0.0002
   100        1.0888             nan     0.2000    0.0000
   120        1.0818             nan     0.2000   -0.0002
   140        1.0765             nan     0.2000   -0.0000
   160        1.0714             nan     0.2000   -0.0002
   180        1.0661             nan     0.2000   -0.0001
   200        1.0609             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2141             nan     0.2000    0.0098
     2        1.1987             nan     0.2000    0.0074
     3        1.1867             nan     0.2000    0.0055
     4        1.1768             nan     0.2000    0.0044
     5        1.1689             nan     0.2000    0.0032
     6        1.1606             nan     0.2000    0.0038
     7        1.1554             nan     0.2000    0.0020
     8        1.1509             nan     0.2000    0.0019
     9        1.1475             nan     0.2000    0.0014
    10        1.1435             nan     0.2000    0.0016
    20        1.1201             nan     0.2000    0.0002
    40        1.0992             nan     0.2000    0.0001
    60        1.0855             nan     0.2000   -0.0001
    80        1.0741             nan     0.2000   -0.0000
   100        1.0641             nan     0.2000   -0.0003
   120        1.0532             nan     0.2000   -0.0001
   140        1.0445             nan     0.2000   -0.0002
   160        1.0356             nan     0.2000   -0.0003
   180        1.0264             nan     0.2000   -0.0002
   200        1.0179             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2316             nan     0.0500    0.0017
     2        1.2285             nan     0.0500    0.0015
     3        1.2258             nan     0.0500    0.0013
     4        1.2232             nan     0.0500    0.0012
     5        1.2210             nan     0.0500    0.0011
     6        1.2187             nan     0.0500    0.0011
     7        1.2166             nan     0.0500    0.0010
     8        1.2146             nan     0.0500    0.0010
     9        1.2128             nan     0.0500    0.0009
    10        1.2111             nan     0.0500    0.0007
    20        1.1963             nan     0.0500    0.0005
    40        1.1799             nan     0.0500    0.0003
    60        1.1694             nan     0.0500    0.0002
    80        1.1616             nan     0.0500    0.0001
   100        1.1556             nan     0.0500    0.0001
   120        1.1505             nan     0.0500    0.0000
   140        1.1464             nan     0.0500    0.0001
   160        1.1429             nan     0.0500    0.0000
   180        1.1399             nan     0.0500    0.0000
   200        1.1374             nan     0.0500    0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2300             nan     0.0500    0.0024
     2        1.2257             nan     0.0500    0.0022
     3        1.2215             nan     0.0500    0.0019
     4        1.2178             nan     0.0500    0.0018
     5        1.2140             nan     0.0500    0.0017
     6        1.2108             nan     0.0500    0.0016
     7        1.2076             nan     0.0500    0.0015
     8        1.2045             nan     0.0500    0.0014
     9        1.2016             nan     0.0500    0.0013
    10        1.1989             nan     0.0500    0.0013
    20        1.1790             nan     0.0500    0.0007
    40        1.1546             nan     0.0500    0.0004
    60        1.1411             nan     0.0500    0.0002
    80        1.1310             nan     0.0500    0.0001
   100        1.1242             nan     0.0500    0.0001
   120        1.1192             nan     0.0500    0.0000
   140        1.1151             nan     0.0500    0.0000
   160        1.1116             nan     0.0500    0.0000
   180        1.1085             nan     0.0500   -0.0000
   200        1.1055             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2293             nan     0.0500    0.0026
     2        1.2242             nan     0.0500    0.0024
     3        1.2194             nan     0.0500    0.0023
     4        1.2151             nan     0.0500    0.0020
     5        1.2111             nan     0.0500    0.0019
     6        1.2074             nan     0.0500    0.0017
     7        1.2035             nan     0.0500    0.0019
     8        1.1998             nan     0.0500    0.0016
     9        1.1964             nan     0.0500    0.0015
    10        1.1936             nan     0.0500    0.0012
    20        1.1705             nan     0.0500    0.0008
    40        1.1429             nan     0.0500    0.0003
    60        1.1278             nan     0.0500    0.0002
    80        1.1178             nan     0.0500    0.0001
   100        1.1110             nan     0.0500    0.0000
   120        1.1051             nan     0.0500    0.0000
   140        1.1001             nan     0.0500   -0.0000
   160        1.0958             nan     0.0500    0.0001
   180        1.0916             nan     0.0500    0.0000
   200        1.0876             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2285             nan     0.1000    0.0033
     2        1.2231             nan     0.1000    0.0025
     3        1.2186             nan     0.1000    0.0021
     4        1.2142             nan     0.1000    0.0021
     5        1.2103             nan     0.1000    0.0018
     6        1.2068             nan     0.1000    0.0015
     7        1.2033             nan     0.1000    0.0016
     8        1.2006             nan     0.1000    0.0013
     9        1.1978             nan     0.1000    0.0013
    10        1.1953             nan     0.1000    0.0012
    20        1.1794             nan     0.1000    0.0006
    40        1.1615             nan     0.1000    0.0003
    60        1.1502             nan     0.1000    0.0002
    80        1.1430             nan     0.1000    0.0000
   100        1.1376             nan     0.1000    0.0001
   120        1.1336             nan     0.1000    0.0000
   140        1.1303             nan     0.1000    0.0000
   160        1.1274             nan     0.1000    0.0000
   180        1.1251             nan     0.1000   -0.0000
   200        1.1231             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2252             nan     0.1000    0.0046
     2        1.2172             nan     0.1000    0.0039
     3        1.2105             nan     0.1000    0.0034
     4        1.2045             nan     0.1000    0.0028
     5        1.1989             nan     0.1000    0.0027
     6        1.1936             nan     0.1000    0.0024
     7        1.1888             nan     0.1000    0.0022
     8        1.1850             nan     0.1000    0.0016
     9        1.1811             nan     0.1000    0.0017
    10        1.1777             nan     0.1000    0.0015
    20        1.1552             nan     0.1000    0.0009
    40        1.1324             nan     0.1000    0.0003
    60        1.1204             nan     0.1000    0.0001
    80        1.1131             nan     0.1000   -0.0000
   100        1.1071             nan     0.1000    0.0001
   120        1.1019             nan     0.1000    0.0000
   140        1.0974             nan     0.1000   -0.0000
   160        1.0931             nan     0.1000   -0.0000
   180        1.0897             nan     0.1000   -0.0001
   200        1.0862             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2245             nan     0.1000    0.0051
     2        1.2148             nan     0.1000    0.0043
     3        1.2065             nan     0.1000    0.0038
     4        1.1993             nan     0.1000    0.0032
     5        1.1927             nan     0.1000    0.0031
     6        1.1875             nan     0.1000    0.0024
     7        1.1825             nan     0.1000    0.0023
     8        1.1781             nan     0.1000    0.0020
     9        1.1740             nan     0.1000    0.0018
    10        1.1695             nan     0.1000    0.0021
    20        1.1419             nan     0.1000    0.0007
    40        1.1185             nan     0.1000    0.0002
    60        1.1058             nan     0.1000    0.0001
    80        1.0961             nan     0.1000    0.0000
   100        1.0889             nan     0.1000   -0.0000
   120        1.0818             nan     0.1000   -0.0000
   140        1.0759             nan     0.1000   -0.0001
   160        1.0701             nan     0.1000   -0.0001
   180        1.0643             nan     0.1000   -0.0001
   200        1.0592             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2229             nan     0.2000    0.0058
     2        1.2142             nan     0.2000    0.0044
     3        1.2067             nan     0.2000    0.0035
     4        1.2008             nan     0.2000    0.0028
     5        1.1955             nan     0.2000    0.0026
     6        1.1905             nan     0.2000    0.0024
     7        1.1873             nan     0.2000    0.0016
     8        1.1840             nan     0.2000    0.0014
     9        1.1817             nan     0.2000    0.0011
    10        1.1787             nan     0.2000    0.0012
    20        1.1608             nan     0.2000    0.0008
    40        1.1426             nan     0.2000    0.0001
    60        1.1332             nan     0.2000    0.0001
    80        1.1273             nan     0.2000    0.0000
   100        1.1232             nan     0.2000   -0.0000
   120        1.1197             nan     0.2000   -0.0001
   140        1.1168             nan     0.2000   -0.0000
   160        1.1146             nan     0.2000   -0.0000
   180        1.1128             nan     0.2000    0.0000
   200        1.1111             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2169             nan     0.2000    0.0088
     2        1.2038             nan     0.2000    0.0062
     3        1.1932             nan     0.2000    0.0050
     4        1.1835             nan     0.2000    0.0047
     5        1.1753             nan     0.2000    0.0038
     6        1.1702             nan     0.2000    0.0021
     7        1.1658             nan     0.2000    0.0018
     8        1.1615             nan     0.2000    0.0018
     9        1.1575             nan     0.2000    0.0018
    10        1.1538             nan     0.2000    0.0017
    20        1.1307             nan     0.2000    0.0005
    40        1.1140             nan     0.2000   -0.0000
    60        1.1030             nan     0.2000   -0.0001
    80        1.0954             nan     0.2000   -0.0002
   100        1.0879             nan     0.2000   -0.0002
   120        1.0816             nan     0.2000   -0.0003
   140        1.0755             nan     0.2000   -0.0000
   160        1.0707             nan     0.2000   -0.0002
   180        1.0651             nan     0.2000   -0.0000
   200        1.0592             nan     0.2000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2136             nan     0.2000    0.0104
     2        1.1982             nan     0.2000    0.0070
     3        1.1861             nan     0.2000    0.0060
     4        1.1768             nan     0.2000    0.0042
     5        1.1693             nan     0.2000    0.0036
     6        1.1627             nan     0.2000    0.0029
     7        1.1563             nan     0.2000    0.0025
     8        1.1515             nan     0.2000    0.0020
     9        1.1470             nan     0.2000    0.0016
    10        1.1432             nan     0.2000    0.0016
    20        1.1189             nan     0.2000    0.0003
    40        1.0972             nan     0.2000    0.0000
    60        1.0835             nan     0.2000   -0.0002
    80        1.0715             nan     0.2000   -0.0001
   100        1.0623             nan     0.2000   -0.0001
   120        1.0522             nan     0.2000   -0.0002
   140        1.0426             nan     0.2000   -0.0001
   160        1.0334             nan     0.2000   -0.0002
   180        1.0243             nan     0.2000   -0.0002
   200        1.0156             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2317             nan     0.0500    0.0016
     2        1.2289             nan     0.0500    0.0014
     3        1.2262             nan     0.0500    0.0014
     4        1.2236             nan     0.0500    0.0013
     5        1.2213             nan     0.0500    0.0011
     6        1.2192             nan     0.0500    0.0010
     7        1.2172             nan     0.0500    0.0010
     8        1.2152             nan     0.0500    0.0009
     9        1.2135             nan     0.0500    0.0009
    10        1.2116             nan     0.0500    0.0009
    20        1.1978             nan     0.0500    0.0004
    40        1.1816             nan     0.0500    0.0003
    60        1.1712             nan     0.0500    0.0002
    80        1.1637             nan     0.0500    0.0001
   100        1.1578             nan     0.0500    0.0001
   120        1.1529             nan     0.0500    0.0001
   140        1.1490             nan     0.0500    0.0001
   160        1.1456             nan     0.0500    0.0001
   180        1.1427             nan     0.0500    0.0000
   200        1.1403             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2303             nan     0.0500    0.0023
     2        1.2257             nan     0.0500    0.0021
     3        1.2219             nan     0.0500    0.0017
     4        1.2182             nan     0.0500    0.0017
     5        1.2146             nan     0.0500    0.0017
     6        1.2113             nan     0.0500    0.0016
     7        1.2083             nan     0.0500    0.0014
     8        1.2055             nan     0.0500    0.0014
     9        1.2031             nan     0.0500    0.0012
    10        1.2005             nan     0.0500    0.0012
    20        1.1811             nan     0.0500    0.0006
    40        1.1573             nan     0.0500    0.0003
    60        1.1439             nan     0.0500    0.0001
    80        1.1343             nan     0.0500    0.0001
   100        1.1271             nan     0.0500    0.0001
   120        1.1221             nan     0.0500    0.0000
   140        1.1175             nan     0.0500    0.0000
   160        1.1140             nan     0.0500    0.0000
   180        1.1105             nan     0.0500    0.0000
   200        1.1077             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2293             nan     0.0500    0.0027
     2        1.2240             nan     0.0500    0.0024
     3        1.2193             nan     0.0500    0.0022
     4        1.2151             nan     0.0500    0.0021
     5        1.2112             nan     0.0500    0.0019
     6        1.2073             nan     0.0500    0.0018
     7        1.2041             nan     0.0500    0.0015
     8        1.2006             nan     0.0500    0.0016
     9        1.1972             nan     0.0500    0.0016
    10        1.1945             nan     0.0500    0.0012
    20        1.1719             nan     0.0500    0.0007
    40        1.1457             nan     0.0500    0.0004
    60        1.1307             nan     0.0500    0.0002
    80        1.1206             nan     0.0500    0.0000
   100        1.1135             nan     0.0500    0.0000
   120        1.1078             nan     0.0500    0.0000
   140        1.1030             nan     0.0500    0.0000
   160        1.0980             nan     0.0500    0.0000
   180        1.0936             nan     0.0500   -0.0000
   200        1.0897             nan     0.0500   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2287             nan     0.1000    0.0032
     2        1.2231             nan     0.1000    0.0025
     3        1.2189             nan     0.1000    0.0021
     4        1.2150             nan     0.1000    0.0019
     5        1.2115             nan     0.1000    0.0019
     6        1.2083             nan     0.1000    0.0015
     7        1.2051             nan     0.1000    0.0015
     8        1.2024             nan     0.1000    0.0011
     9        1.2001             nan     0.1000    0.0011
    10        1.1974             nan     0.1000    0.0012
    20        1.1815             nan     0.1000    0.0006
    40        1.1642             nan     0.1000    0.0001
    60        1.1530             nan     0.1000    0.0002
    80        1.1455             nan     0.1000    0.0001
   100        1.1406             nan     0.1000    0.0000
   120        1.1364             nan     0.1000    0.0001
   140        1.1329             nan     0.1000    0.0000
   160        1.1302             nan     0.1000    0.0000
   180        1.1280             nan     0.1000    0.0000
   200        1.1259             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2258             nan     0.1000    0.0045
     2        1.2179             nan     0.1000    0.0038
     3        1.2114             nan     0.1000    0.0031
     4        1.2052             nan     0.1000    0.0031
     5        1.2003             nan     0.1000    0.0022
     6        1.1957             nan     0.1000    0.0021
     7        1.1917             nan     0.1000    0.0018
     8        1.1883             nan     0.1000    0.0016
     9        1.1843             nan     0.1000    0.0020
    10        1.1805             nan     0.1000    0.0018
    20        1.1568             nan     0.1000    0.0007
    40        1.1346             nan     0.1000    0.0002
    60        1.1214             nan     0.1000    0.0002
    80        1.1139             nan     0.1000    0.0000
   100        1.1085             nan     0.1000    0.0000
   120        1.1032             nan     0.1000   -0.0001
   140        1.0988             nan     0.1000   -0.0000
   160        1.0950             nan     0.1000   -0.0001
   180        1.0909             nan     0.1000    0.0000
   200        1.0876             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2243             nan     0.1000    0.0053
     2        1.2150             nan     0.1000    0.0042
     3        1.2076             nan     0.1000    0.0035
     4        1.2012             nan     0.1000    0.0030
     5        1.1952             nan     0.1000    0.0027
     6        1.1896             nan     0.1000    0.0026
     7        1.1848             nan     0.1000    0.0021
     8        1.1803             nan     0.1000    0.0020
     9        1.1763             nan     0.1000    0.0018
    10        1.1716             nan     0.1000    0.0023
    20        1.1456             nan     0.1000    0.0008
    40        1.1219             nan     0.1000    0.0004
    60        1.1082             nan     0.1000    0.0001
    80        1.0985             nan     0.1000    0.0001
   100        1.0907             nan     0.1000   -0.0000
   120        1.0841             nan     0.1000   -0.0000
   140        1.0769             nan     0.1000    0.0000
   160        1.0715             nan     0.1000   -0.0000
   180        1.0657             nan     0.1000   -0.0000
   200        1.0602             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2226             nan     0.2000    0.0060
     2        1.2150             nan     0.2000    0.0036
     3        1.2073             nan     0.2000    0.0037
     4        1.2021             nan     0.2000    0.0025
     5        1.1969             nan     0.2000    0.0026
     6        1.1924             nan     0.2000    0.0022
     7        1.1895             nan     0.2000    0.0014
     8        1.1863             nan     0.2000    0.0014
     9        1.1833             nan     0.2000    0.0012
    10        1.1808             nan     0.2000    0.0011
    20        1.1628             nan     0.2000    0.0006
    40        1.1448             nan     0.2000    0.0003
    60        1.1362             nan     0.2000    0.0002
    80        1.1304             nan     0.2000   -0.0000
   100        1.1263             nan     0.2000   -0.0000
   120        1.1231             nan     0.2000   -0.0000
   140        1.1197             nan     0.2000    0.0000
   160        1.1174             nan     0.2000   -0.0000
   180        1.1153             nan     0.2000   -0.0001
   200        1.1133             nan     0.2000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2182             nan     0.2000    0.0084
     2        1.2052             nan     0.2000    0.0060
     3        1.1954             nan     0.2000    0.0046
     4        1.1866             nan     0.2000    0.0039
     5        1.1808             nan     0.2000    0.0026
     6        1.1752             nan     0.2000    0.0024
     7        1.1712             nan     0.2000    0.0015
     8        1.1659             nan     0.2000    0.0026
     9        1.1609             nan     0.2000    0.0024
    10        1.1576             nan     0.2000    0.0013
    20        1.1346             nan     0.2000    0.0005
    40        1.1166             nan     0.2000    0.0001
    60        1.1066             nan     0.2000    0.0000
    80        1.0982             nan     0.2000   -0.0002
   100        1.0910             nan     0.2000   -0.0001
   120        1.0848             nan     0.2000   -0.0001
   140        1.0778             nan     0.2000   -0.0001
   160        1.0719             nan     0.2000   -0.0001
   180        1.0670             nan     0.2000   -0.0001
   200        1.0612             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2151             nan     0.2000    0.0096
     2        1.2011             nan     0.2000    0.0061
     3        1.1896             nan     0.2000    0.0053
     4        1.1788             nan     0.2000    0.0050
     5        1.1714             nan     0.2000    0.0036
     6        1.1639             nan     0.2000    0.0034
     7        1.1589             nan     0.2000    0.0019
     8        1.1545             nan     0.2000    0.0018
     9        1.1493             nan     0.2000    0.0021
    10        1.1446             nan     0.2000    0.0020
    20        1.1210             nan     0.2000   -0.0000
    40        1.0996             nan     0.2000   -0.0001
    60        1.0868             nan     0.2000   -0.0001
    80        1.0748             nan     0.2000   -0.0001
   100        1.0643             nan     0.2000   -0.0000
   120        1.0545             nan     0.2000   -0.0000
   140        1.0444             nan     0.2000   -0.0002
   160        1.0360             nan     0.2000   -0.0000
   180        1.0284             nan     0.2000   -0.0002
   200        1.0207             nan     0.2000    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2317             nan     0.0500    0.0016
     2        1.2287             nan     0.0500    0.0015
     3        1.2258             nan     0.0500    0.0014
     4        1.2233             nan     0.0500    0.0013
     5        1.2209             nan     0.0500    0.0011
     6        1.2188             nan     0.0500    0.0010
     7        1.2167             nan     0.0500    0.0010
     8        1.2146             nan     0.0500    0.0010
     9        1.2124             nan     0.0500    0.0010
    10        1.2105             nan     0.0500    0.0009
    20        1.1958             nan     0.0500    0.0005
    40        1.1793             nan     0.0500    0.0002
    60        1.1688             nan     0.0500    0.0002
    80        1.1611             nan     0.0500    0.0001
   100        1.1549             nan     0.0500    0.0001
   120        1.1501             nan     0.0500    0.0000
   140        1.1461             nan     0.0500    0.0000
   160        1.1427             nan     0.0500    0.0000
   180        1.1396             nan     0.0500    0.0000
   200        1.1371             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2298             nan     0.0500    0.0024
     2        1.2253             nan     0.0500    0.0022
     3        1.2211             nan     0.0500    0.0020
     4        1.2173             nan     0.0500    0.0018
     5        1.2138             nan     0.0500    0.0017
     6        1.2103             nan     0.0500    0.0016
     7        1.2072             nan     0.0500    0.0015
     8        1.2042             nan     0.0500    0.0014
     9        1.2015             nan     0.0500    0.0013
    10        1.1990             nan     0.0500    0.0012
    20        1.1785             nan     0.0500    0.0008
    40        1.1548             nan     0.0500    0.0003
    60        1.1406             nan     0.0500    0.0002
    80        1.1314             nan     0.0500    0.0001
   100        1.1241             nan     0.0500    0.0001
   120        1.1191             nan     0.0500    0.0000
   140        1.1150             nan     0.0500   -0.0000
   160        1.1113             nan     0.0500    0.0001
   180        1.1083             nan     0.0500    0.0001
   200        1.1054             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2293             nan     0.0500    0.0027
     2        1.2242             nan     0.0500    0.0024
     3        1.2194             nan     0.0500    0.0024
     4        1.2149             nan     0.0500    0.0022
     5        1.2110             nan     0.0500    0.0020
     6        1.2064             nan     0.0500    0.0021
     7        1.2028             nan     0.0500    0.0017
     8        1.1993             nan     0.0500    0.0016
     9        1.1960             nan     0.0500    0.0015
    10        1.1931             nan     0.0500    0.0014
    20        1.1696             nan     0.0500    0.0008
    40        1.1426             nan     0.0500    0.0004
    60        1.1274             nan     0.0500    0.0002
    80        1.1174             nan     0.0500    0.0000
   100        1.1106             nan     0.0500    0.0001
   120        1.1048             nan     0.0500    0.0000
   140        1.1000             nan     0.0500    0.0000
   160        1.0955             nan     0.0500   -0.0000
   180        1.0913             nan     0.0500   -0.0001
   200        1.0877             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2287             nan     0.1000    0.0032
     2        1.2232             nan     0.1000    0.0026
     3        1.2188             nan     0.1000    0.0021
     4        1.2145             nan     0.1000    0.0021
     5        1.2107             nan     0.1000    0.0017
     6        1.2073             nan     0.1000    0.0016
     7        1.2041             nan     0.1000    0.0015
     8        1.2013             nan     0.1000    0.0013
     9        1.1981             nan     0.1000    0.0015
    10        1.1955             nan     0.1000    0.0013
    20        1.1791             nan     0.1000    0.0006
    40        1.1614             nan     0.1000    0.0003
    60        1.1501             nan     0.1000    0.0002
    80        1.1425             nan     0.1000    0.0001
   100        1.1369             nan     0.1000    0.0001
   120        1.1333             nan     0.1000    0.0000
   140        1.1300             nan     0.1000    0.0000
   160        1.1274             nan     0.1000    0.0000
   180        1.1250             nan     0.1000   -0.0000
   200        1.1229             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2252             nan     0.1000    0.0046
     2        1.2171             nan     0.1000    0.0038
     3        1.2106             nan     0.1000    0.0033
     4        1.2046             nan     0.1000    0.0029
     5        1.1993             nan     0.1000    0.0024
     6        1.1944             nan     0.1000    0.0022
     7        1.1898             nan     0.1000    0.0022
     8        1.1859             nan     0.1000    0.0016
     9        1.1825             nan     0.1000    0.0017
    10        1.1793             nan     0.1000    0.0014
    20        1.1547             nan     0.1000    0.0008
    40        1.1315             nan     0.1000    0.0002
    60        1.1196             nan     0.1000    0.0001
    80        1.1118             nan     0.1000   -0.0000
   100        1.1055             nan     0.1000   -0.0000
   120        1.1005             nan     0.1000    0.0000
   140        1.0959             nan     0.1000    0.0001
   160        1.0918             nan     0.1000    0.0000
   180        1.0880             nan     0.1000   -0.0000
   200        1.0844             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2239             nan     0.1000    0.0053
     2        1.2149             nan     0.1000    0.0043
     3        1.2069             nan     0.1000    0.0037
     4        1.2000             nan     0.1000    0.0032
     5        1.1935             nan     0.1000    0.0032
     6        1.1874             nan     0.1000    0.0030
     7        1.1825             nan     0.1000    0.0021
     8        1.1765             nan     0.1000    0.0028
     9        1.1725             nan     0.1000    0.0018
    10        1.1687             nan     0.1000    0.0018
    20        1.1427             nan     0.1000    0.0006
    40        1.1175             nan     0.1000    0.0003
    60        1.1048             nan     0.1000    0.0001
    80        1.0959             nan     0.1000   -0.0001
   100        1.0879             nan     0.1000   -0.0000
   120        1.0814             nan     0.1000   -0.0001
   140        1.0754             nan     0.1000   -0.0001
   160        1.0697             nan     0.1000   -0.0000
   180        1.0636             nan     0.1000   -0.0001
   200        1.0579             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2224             nan     0.2000    0.0062
     2        1.2139             nan     0.2000    0.0040
     3        1.2063             nan     0.2000    0.0034
     4        1.1995             nan     0.2000    0.0033
     5        1.1943             nan     0.2000    0.0027
     6        1.1905             nan     0.2000    0.0018
     7        1.1866             nan     0.2000    0.0018
     8        1.1840             nan     0.2000    0.0011
     9        1.1817             nan     0.2000    0.0007
    10        1.1790             nan     0.2000    0.0014
    20        1.1611             nan     0.2000    0.0004
    40        1.1432             nan     0.2000    0.0001
    60        1.1332             nan     0.2000    0.0002
    80        1.1276             nan     0.2000    0.0001
   100        1.1234             nan     0.2000   -0.0000
   120        1.1196             nan     0.2000    0.0001
   140        1.1170             nan     0.2000    0.0000
   160        1.1149             nan     0.2000   -0.0001
   180        1.1132             nan     0.2000   -0.0001
   200        1.1114             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2166             nan     0.2000    0.0089
     2        1.2033             nan     0.2000    0.0069
     3        1.1930             nan     0.2000    0.0048
     4        1.1845             nan     0.2000    0.0038
     5        1.1779             nan     0.2000    0.0028
     6        1.1718             nan     0.2000    0.0030
     7        1.1671             nan     0.2000    0.0018
     8        1.1621             nan     0.2000    0.0021
     9        1.1575             nan     0.2000    0.0019
    10        1.1545             nan     0.2000    0.0012
    20        1.1318             nan     0.2000    0.0003
    40        1.1124             nan     0.2000    0.0002
    60        1.1029             nan     0.2000   -0.0001
    80        1.0943             nan     0.2000   -0.0002
   100        1.0870             nan     0.2000   -0.0001
   120        1.0805             nan     0.2000   -0.0000
   140        1.0745             nan     0.2000   -0.0001
   160        1.0694             nan     0.2000   -0.0002
   180        1.0643             nan     0.2000   -0.0002
   200        1.0596             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2148             nan     0.2000    0.0101
     2        1.1998             nan     0.2000    0.0071
     3        1.1865             nan     0.2000    0.0063
     4        1.1765             nan     0.2000    0.0045
     5        1.1676             nan     0.2000    0.0040
     6        1.1611             nan     0.2000    0.0026
     7        1.1554             nan     0.2000    0.0025
     8        1.1509             nan     0.2000    0.0018
     9        1.1466             nan     0.2000    0.0017
    10        1.1424             nan     0.2000    0.0017
    20        1.1195             nan     0.2000    0.0003
    40        1.0987             nan     0.2000   -0.0001
    60        1.0844             nan     0.2000   -0.0001
    80        1.0741             nan     0.2000   -0.0003
   100        1.0628             nan     0.2000   -0.0003
   120        1.0523             nan     0.2000   -0.0002
   140        1.0429             nan     0.2000   -0.0001
   160        1.0345             nan     0.2000   -0.0001
   180        1.0257             nan     0.2000   -0.0001
   200        1.0170             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2314             nan     0.0500    0.0016
     2        1.2284             nan     0.0500    0.0015
     3        1.2255             nan     0.0500    0.0014
     4        1.2228             nan     0.0500    0.0012
     5        1.2203             nan     0.0500    0.0011
     6        1.2183             nan     0.0500    0.0010
     7        1.2163             nan     0.0500    0.0009
     8        1.2142             nan     0.0500    0.0010
     9        1.2124             nan     0.0500    0.0009
    10        1.2106             nan     0.0500    0.0008
    20        1.1967             nan     0.0500    0.0005
    40        1.1807             nan     0.0500    0.0003
    60        1.1703             nan     0.0500    0.0002
    80        1.1625             nan     0.0500    0.0001
   100        1.1563             nan     0.0500    0.0001
   120        1.1513             nan     0.0500    0.0001
   140        1.1472             nan     0.0500    0.0001
   160        1.1437             nan     0.0500    0.0001
   180        1.1408             nan     0.0500    0.0000
   200        1.1383             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2301             nan     0.0500    0.0023
     2        1.2255             nan     0.0500    0.0021
     3        1.2213             nan     0.0500    0.0020
     4        1.2174             nan     0.0500    0.0019
     5        1.2139             nan     0.0500    0.0016
     6        1.2105             nan     0.0500    0.0016
     7        1.2074             nan     0.0500    0.0014
     8        1.2047             nan     0.0500    0.0013
     9        1.2020             nan     0.0500    0.0012
    10        1.1993             nan     0.0500    0.0012
    20        1.1799             nan     0.0500    0.0007
    40        1.1559             nan     0.0500    0.0003
    60        1.1423             nan     0.0500    0.0002
    80        1.1324             nan     0.0500    0.0002
   100        1.1256             nan     0.0500    0.0001
   120        1.1201             nan     0.0500    0.0001
   140        1.1156             nan     0.0500    0.0001
   160        1.1117             nan     0.0500   -0.0000
   180        1.1084             nan     0.0500    0.0000
   200        1.1054             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2298             nan     0.0500    0.0025
     2        1.2247             nan     0.0500    0.0024
     3        1.2199             nan     0.0500    0.0022
     4        1.2153             nan     0.0500    0.0021
     5        1.2111             nan     0.0500    0.0020
     6        1.2069             nan     0.0500    0.0019
     7        1.2034             nan     0.0500    0.0016
     8        1.1998             nan     0.0500    0.0016
     9        1.1966             nan     0.0500    0.0016
    10        1.1936             nan     0.0500    0.0013
    20        1.1699             nan     0.0500    0.0008
    40        1.1432             nan     0.0500    0.0004
    60        1.1274             nan     0.0500    0.0002
    80        1.1178             nan     0.0500    0.0002
   100        1.1106             nan     0.0500   -0.0000
   120        1.1044             nan     0.0500    0.0000
   140        1.0995             nan     0.0500    0.0000
   160        1.0953             nan     0.0500   -0.0000
   180        1.0908             nan     0.0500    0.0000
   200        1.0873             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2279             nan     0.1000    0.0032
     2        1.2226             nan     0.1000    0.0026
     3        1.2179             nan     0.1000    0.0019
     4        1.2137             nan     0.1000    0.0021
     5        1.2102             nan     0.1000    0.0016
     6        1.2070             nan     0.1000    0.0016
     7        1.2040             nan     0.1000    0.0014
     8        1.2010             nan     0.1000    0.0015
     9        1.1987             nan     0.1000    0.0011
    10        1.1965             nan     0.1000    0.0012
    20        1.1805             nan     0.1000    0.0004
    40        1.1620             nan     0.1000    0.0003
    60        1.1514             nan     0.1000    0.0002
    80        1.1438             nan     0.1000    0.0001
   100        1.1384             nan     0.1000   -0.0000
   120        1.1342             nan     0.1000    0.0001
   140        1.1309             nan     0.1000    0.0000
   160        1.1282             nan     0.1000    0.0000
   180        1.1258             nan     0.1000    0.0000
   200        1.1236             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2258             nan     0.1000    0.0045
     2        1.2174             nan     0.1000    0.0038
     3        1.2106             nan     0.1000    0.0030
     4        1.2044             nan     0.1000    0.0029
     5        1.1986             nan     0.1000    0.0025
     6        1.1936             nan     0.1000    0.0023
     7        1.1894             nan     0.1000    0.0021
     8        1.1854             nan     0.1000    0.0016
     9        1.1818             nan     0.1000    0.0017
    10        1.1789             nan     0.1000    0.0013
    20        1.1556             nan     0.1000    0.0008
    40        1.1322             nan     0.1000    0.0002
    60        1.1194             nan     0.1000    0.0002
    80        1.1116             nan     0.1000    0.0002
   100        1.1055             nan     0.1000    0.0000
   120        1.1003             nan     0.1000   -0.0000
   140        1.0958             nan     0.1000   -0.0001
   160        1.0917             nan     0.1000    0.0000
   180        1.0883             nan     0.1000    0.0000
   200        1.0847             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2246             nan     0.1000    0.0051
     2        1.2151             nan     0.1000    0.0045
     3        1.2071             nan     0.1000    0.0038
     4        1.1998             nan     0.1000    0.0033
     5        1.1931             nan     0.1000    0.0032
     6        1.1880             nan     0.1000    0.0024
     7        1.1821             nan     0.1000    0.0028
     8        1.1767             nan     0.1000    0.0024
     9        1.1727             nan     0.1000    0.0018
    10        1.1692             nan     0.1000    0.0015
    20        1.1438             nan     0.1000    0.0011
    40        1.1192             nan     0.1000    0.0001
    60        1.1065             nan     0.1000   -0.0001
    80        1.0969             nan     0.1000   -0.0000
   100        1.0896             nan     0.1000   -0.0001
   120        1.0827             nan     0.1000   -0.0001
   140        1.0763             nan     0.1000   -0.0000
   160        1.0702             nan     0.1000    0.0001
   180        1.0643             nan     0.1000   -0.0000
   200        1.0590             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2224             nan     0.2000    0.0062
     2        1.2144             nan     0.2000    0.0038
     3        1.2065             nan     0.2000    0.0037
     4        1.2007             nan     0.2000    0.0029
     5        1.1954             nan     0.2000    0.0024
     6        1.1908             nan     0.2000    0.0022
     7        1.1875             nan     0.2000    0.0015
     8        1.1845             nan     0.2000    0.0014
     9        1.1821             nan     0.2000    0.0012
    10        1.1797             nan     0.2000    0.0011
    20        1.1616             nan     0.2000    0.0008
    40        1.1436             nan     0.2000    0.0003
    60        1.1339             nan     0.2000    0.0001
    80        1.1280             nan     0.2000    0.0000
   100        1.1230             nan     0.2000    0.0000
   120        1.1196             nan     0.2000   -0.0000
   140        1.1171             nan     0.2000   -0.0000
   160        1.1147             nan     0.2000   -0.0001
   180        1.1124             nan     0.2000   -0.0000
   200        1.1108             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2173             nan     0.2000    0.0084
     2        1.2042             nan     0.2000    0.0063
     3        1.1936             nan     0.2000    0.0047
     4        1.1863             nan     0.2000    0.0033
     5        1.1790             nan     0.2000    0.0035
     6        1.1732             nan     0.2000    0.0026
     7        1.1673             nan     0.2000    0.0027
     8        1.1634             nan     0.2000    0.0017
     9        1.1586             nan     0.2000    0.0019
    10        1.1549             nan     0.2000    0.0015
    20        1.1320             nan     0.2000    0.0008
    40        1.1126             nan     0.2000   -0.0001
    60        1.1019             nan     0.2000    0.0003
    80        1.0929             nan     0.2000   -0.0000
   100        1.0866             nan     0.2000   -0.0001
   120        1.0799             nan     0.2000   -0.0001
   140        1.0739             nan     0.2000   -0.0002
   160        1.0691             nan     0.2000   -0.0001
   180        1.0633             nan     0.2000   -0.0002
   200        1.0580             nan     0.2000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2146             nan     0.2000    0.0098
     2        1.1972             nan     0.2000    0.0079
     3        1.1850             nan     0.2000    0.0054
     4        1.1750             nan     0.2000    0.0044
     5        1.1682             nan     0.2000    0.0031
     6        1.1612             nan     0.2000    0.0027
     7        1.1558             nan     0.2000    0.0024
     8        1.1509             nan     0.2000    0.0021
     9        1.1463             nan     0.2000    0.0017
    10        1.1428             nan     0.2000    0.0011
    20        1.1184             nan     0.2000    0.0004
    40        1.0987             nan     0.2000   -0.0002
    60        1.0849             nan     0.2000   -0.0002
    80        1.0732             nan     0.2000   -0.0002
   100        1.0620             nan     0.2000   -0.0003
   120        1.0532             nan     0.2000   -0.0001
   140        1.0445             nan     0.2000   -0.0001
   160        1.0356             nan     0.2000   -0.0001
   180        1.0268             nan     0.2000   -0.0001
   200        1.0182             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2314             nan     0.0500    0.0016
     2        1.2285             nan     0.0500    0.0015
     3        1.2257             nan     0.0500    0.0014
     4        1.2232             nan     0.0500    0.0012
     5        1.2208             nan     0.0500    0.0011
     6        1.2187             nan     0.0500    0.0010
     7        1.2167             nan     0.0500    0.0009
     8        1.2148             nan     0.0500    0.0010
     9        1.2130             nan     0.0500    0.0009
    10        1.2112             nan     0.0500    0.0009
    20        1.1965             nan     0.0500    0.0005
    40        1.1804             nan     0.0500    0.0003
    60        1.1700             nan     0.0500    0.0002
    80        1.1622             nan     0.0500    0.0001
   100        1.1561             nan     0.0500    0.0001
   120        1.1513             nan     0.0500    0.0001
   140        1.1472             nan     0.0500    0.0001
   160        1.1436             nan     0.0500    0.0001
   180        1.1408             nan     0.0500    0.0000
   200        1.1382             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2299             nan     0.0500    0.0024
     2        1.2253             nan     0.0500    0.0021
     3        1.2214             nan     0.0500    0.0020
     4        1.2175             nan     0.0500    0.0019
     5        1.2141             nan     0.0500    0.0017
     6        1.2109             nan     0.0500    0.0015
     7        1.2076             nan     0.0500    0.0016
     8        1.2049             nan     0.0500    0.0012
     9        1.2021             nan     0.0500    0.0014
    10        1.1995             nan     0.0500    0.0012
    20        1.1792             nan     0.0500    0.0007
    40        1.1550             nan     0.0500    0.0003
    60        1.1411             nan     0.0500    0.0003
    80        1.1319             nan     0.0500    0.0001
   100        1.1252             nan     0.0500    0.0001
   120        1.1200             nan     0.0500    0.0000
   140        1.1157             nan     0.0500    0.0000
   160        1.1121             nan     0.0500   -0.0000
   180        1.1087             nan     0.0500   -0.0000
   200        1.1058             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2292             nan     0.0500    0.0027
     2        1.2240             nan     0.0500    0.0025
     3        1.2194             nan     0.0500    0.0022
     4        1.2149             nan     0.0500    0.0021
     5        1.2106             nan     0.0500    0.0020
     6        1.2068             nan     0.0500    0.0018
     7        1.2031             nan     0.0500    0.0016
     8        1.1996             nan     0.0500    0.0017
     9        1.1965             nan     0.0500    0.0014
    10        1.1936             nan     0.0500    0.0014
    20        1.1708             nan     0.0500    0.0010
    40        1.1433             nan     0.0500    0.0005
    60        1.1288             nan     0.0500    0.0002
    80        1.1180             nan     0.0500    0.0001
   100        1.1107             nan     0.0500    0.0000
   120        1.1050             nan     0.0500    0.0000
   140        1.0999             nan     0.0500   -0.0000
   160        1.0954             nan     0.0500   -0.0000
   180        1.0915             nan     0.0500   -0.0000
   200        1.0875             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2283             nan     0.1000    0.0031
     2        1.2229             nan     0.1000    0.0027
     3        1.2182             nan     0.1000    0.0022
     4        1.2142             nan     0.1000    0.0018
     5        1.2106             nan     0.1000    0.0018
     6        1.2072             nan     0.1000    0.0017
     7        1.2042             nan     0.1000    0.0013
     8        1.2011             nan     0.1000    0.0014
     9        1.1984             nan     0.1000    0.0012
    10        1.1962             nan     0.1000    0.0011
    20        1.1799             nan     0.1000    0.0006
    40        1.1616             nan     0.1000    0.0003
    60        1.1506             nan     0.1000    0.0002
    80        1.1432             nan     0.1000    0.0001
   100        1.1377             nan     0.1000    0.0001
   120        1.1335             nan     0.1000    0.0001
   140        1.1301             nan     0.1000    0.0000
   160        1.1272             nan     0.1000    0.0000
   180        1.1250             nan     0.1000    0.0000
   200        1.1230             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2255             nan     0.1000    0.0045
     2        1.2178             nan     0.1000    0.0038
     3        1.2113             nan     0.1000    0.0032
     4        1.2053             nan     0.1000    0.0031
     5        1.2003             nan     0.1000    0.0024
     6        1.1949             nan     0.1000    0.0024
     7        1.1909             nan     0.1000    0.0017
     8        1.1866             nan     0.1000    0.0019
     9        1.1829             nan     0.1000    0.0018
    10        1.1792             nan     0.1000    0.0018
    20        1.1554             nan     0.1000    0.0008
    40        1.1328             nan     0.1000    0.0002
    60        1.1196             nan     0.1000    0.0000
    80        1.1122             nan     0.1000   -0.0001
   100        1.1055             nan     0.1000    0.0000
   120        1.1008             nan     0.1000    0.0000
   140        1.0963             nan     0.1000   -0.0000
   160        1.0923             nan     0.1000   -0.0000
   180        1.0883             nan     0.1000   -0.0000
   200        1.0849             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2244             nan     0.1000    0.0053
     2        1.2149             nan     0.1000    0.0045
     3        1.2067             nan     0.1000    0.0039
     4        1.1998             nan     0.1000    0.0033
     5        1.1934             nan     0.1000    0.0028
     6        1.1878             nan     0.1000    0.0027
     7        1.1827             nan     0.1000    0.0025
     8        1.1783             nan     0.1000    0.0020
     9        1.1744             nan     0.1000    0.0018
    10        1.1707             nan     0.1000    0.0017
    20        1.1434             nan     0.1000    0.0006
    40        1.1175             nan     0.1000    0.0004
    60        1.1043             nan     0.1000    0.0001
    80        1.0953             nan     0.1000    0.0001
   100        1.0868             nan     0.1000   -0.0000
   120        1.0800             nan     0.1000   -0.0000
   140        1.0737             nan     0.1000   -0.0000
   160        1.0677             nan     0.1000   -0.0000
   180        1.0619             nan     0.1000   -0.0000
   200        1.0565             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2230             nan     0.2000    0.0061
     2        1.2146             nan     0.2000    0.0037
     3        1.2074             nan     0.2000    0.0037
     4        1.2014             nan     0.2000    0.0027
     5        1.1955             nan     0.2000    0.0029
     6        1.1914             nan     0.2000    0.0018
     7        1.1882             nan     0.2000    0.0015
     8        1.1848             nan     0.2000    0.0015
     9        1.1816             nan     0.2000    0.0015
    10        1.1791             nan     0.2000    0.0010
    20        1.1609             nan     0.2000    0.0008
    40        1.1426             nan     0.2000    0.0002
    60        1.1329             nan     0.2000    0.0001
    80        1.1268             nan     0.2000    0.0001
   100        1.1223             nan     0.2000   -0.0000
   120        1.1189             nan     0.2000   -0.0000
   140        1.1162             nan     0.2000    0.0000
   160        1.1139             nan     0.2000   -0.0000
   180        1.1116             nan     0.2000   -0.0000
   200        1.1098             nan     0.2000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2168             nan     0.2000    0.0086
     2        1.2039             nan     0.2000    0.0060
     3        1.1938             nan     0.2000    0.0047
     4        1.1860             nan     0.2000    0.0036
     5        1.1798             nan     0.2000    0.0030
     6        1.1735             nan     0.2000    0.0025
     7        1.1670             nan     0.2000    0.0030
     8        1.1623             nan     0.2000    0.0021
     9        1.1588             nan     0.2000    0.0015
    10        1.1556             nan     0.2000    0.0013
    20        1.1333             nan     0.2000    0.0005
    40        1.1134             nan     0.2000   -0.0001
    60        1.1017             nan     0.2000   -0.0002
    80        1.0943             nan     0.2000   -0.0003
   100        1.0874             nan     0.2000   -0.0001
   120        1.0807             nan     0.2000   -0.0001
   140        1.0749             nan     0.2000   -0.0000
   160        1.0691             nan     0.2000   -0.0001
   180        1.0637             nan     0.2000   -0.0001
   200        1.0588             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2144             nan     0.2000    0.0100
     2        1.1995             nan     0.2000    0.0073
     3        1.1882             nan     0.2000    0.0057
     4        1.1796             nan     0.2000    0.0040
     5        1.1716             nan     0.2000    0.0033
     6        1.1651             nan     0.2000    0.0031
     7        1.1603             nan     0.2000    0.0018
     8        1.1544             nan     0.2000    0.0025
     9        1.1497             nan     0.2000    0.0019
    10        1.1450             nan     0.2000    0.0020
    20        1.1206             nan     0.2000    0.0006
    40        1.0981             nan     0.2000   -0.0001
    60        1.0854             nan     0.2000   -0.0002
    80        1.0738             nan     0.2000    0.0001
   100        1.0635             nan     0.2000   -0.0001
   120        1.0532             nan     0.2000   -0.0001
   140        1.0444             nan     0.2000   -0.0002
   160        1.0356             nan     0.2000   -0.0001
   180        1.0276             nan     0.2000   -0.0002
   200        1.0186             nan     0.2000   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2314             nan     0.0500    0.0017
     2        1.2281             nan     0.0500    0.0016
     3        1.2253             nan     0.0500    0.0014
     4        1.2226             nan     0.0500    0.0013
     5        1.2201             nan     0.0500    0.0012
     6        1.2179             nan     0.0500    0.0011
     7        1.2159             nan     0.0500    0.0009
     8        1.2139             nan     0.0500    0.0009
     9        1.2119             nan     0.0500    0.0010
    10        1.2100             nan     0.0500    0.0009
    20        1.1955             nan     0.0500    0.0006
    40        1.1793             nan     0.0500    0.0003
    60        1.1689             nan     0.0500    0.0002
    80        1.1608             nan     0.0500    0.0001
   100        1.1549             nan     0.0500    0.0001
   120        1.1499             nan     0.0500    0.0001
   140        1.1457             nan     0.0500    0.0001
   160        1.1423             nan     0.0500    0.0001
   180        1.1394             nan     0.0500    0.0000
   200        1.1369             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2300             nan     0.0500    0.0025
     2        1.2253             nan     0.0500    0.0022
     3        1.2209             nan     0.0500    0.0021
     4        1.2170             nan     0.0500    0.0019
     5        1.2135             nan     0.0500    0.0017
     6        1.2101             nan     0.0500    0.0016
     7        1.2070             nan     0.0500    0.0015
     8        1.2041             nan     0.0500    0.0014
     9        1.2014             nan     0.0500    0.0013
    10        1.1989             nan     0.0500    0.0011
    20        1.1787             nan     0.0500    0.0006
    40        1.1545             nan     0.0500    0.0004
    60        1.1406             nan     0.0500    0.0002
    80        1.1306             nan     0.0500    0.0002
   100        1.1237             nan     0.0500    0.0000
   120        1.1180             nan     0.0500    0.0001
   140        1.1140             nan     0.0500    0.0000
   160        1.1103             nan     0.0500    0.0000
   180        1.1071             nan     0.0500    0.0000
   200        1.1041             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2290             nan     0.0500    0.0027
     2        1.2240             nan     0.0500    0.0024
     3        1.2192             nan     0.0500    0.0023
     4        1.2146             nan     0.0500    0.0022
     5        1.2106             nan     0.0500    0.0020
     6        1.2066             nan     0.0500    0.0018
     7        1.2029             nan     0.0500    0.0017
     8        1.1993             nan     0.0500    0.0016
     9        1.1960             nan     0.0500    0.0014
    10        1.1926             nan     0.0500    0.0016
    20        1.1690             nan     0.0500    0.0008
    40        1.1430             nan     0.0500    0.0004
    60        1.1277             nan     0.0500    0.0003
    80        1.1174             nan     0.0500    0.0001
   100        1.1106             nan     0.0500    0.0001
   120        1.1043             nan     0.0500   -0.0000
   140        1.0989             nan     0.0500    0.0000
   160        1.0947             nan     0.0500   -0.0000
   180        1.0907             nan     0.0500   -0.0000
   200        1.0867             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2282             nan     0.1000    0.0033
     2        1.2229             nan     0.1000    0.0028
     3        1.2179             nan     0.1000    0.0022
     4        1.2137             nan     0.1000    0.0020
     5        1.2097             nan     0.1000    0.0019
     6        1.2062             nan     0.1000    0.0017
     7        1.2031             nan     0.1000    0.0015
     8        1.2003             nan     0.1000    0.0013
     9        1.1974             nan     0.1000    0.0012
    10        1.1954             nan     0.1000    0.0009
    20        1.1789             nan     0.1000    0.0006
    40        1.1609             nan     0.1000    0.0003
    60        1.1495             nan     0.1000    0.0001
    80        1.1420             nan     0.1000    0.0001
   100        1.1367             nan     0.1000    0.0000
   120        1.1326             nan     0.1000    0.0000
   140        1.1291             nan     0.1000    0.0000
   160        1.1262             nan     0.1000    0.0000
   180        1.1240             nan     0.1000    0.0000
   200        1.1219             nan     0.1000    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2249             nan     0.1000    0.0047
     2        1.2168             nan     0.1000    0.0039
     3        1.2096             nan     0.1000    0.0035
     4        1.2037             nan     0.1000    0.0029
     5        1.1988             nan     0.1000    0.0025
     6        1.1942             nan     0.1000    0.0022
     7        1.1899             nan     0.1000    0.0020
     8        1.1862             nan     0.1000    0.0018
     9        1.1822             nan     0.1000    0.0018
    10        1.1793             nan     0.1000    0.0012
    20        1.1555             nan     0.1000    0.0005
    40        1.1317             nan     0.1000    0.0002
    60        1.1185             nan     0.1000    0.0003
    80        1.1108             nan     0.1000   -0.0000
   100        1.1049             nan     0.1000   -0.0000
   120        1.0994             nan     0.1000    0.0000
   140        1.0952             nan     0.1000   -0.0001
   160        1.0915             nan     0.1000   -0.0001
   180        1.0873             nan     0.1000   -0.0001
   200        1.0840             nan     0.1000    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2238             nan     0.1000    0.0053
     2        1.2142             nan     0.1000    0.0044
     3        1.2059             nan     0.1000    0.0040
     4        1.1992             nan     0.1000    0.0031
     5        1.1928             nan     0.1000    0.0031
     6        1.1866             nan     0.1000    0.0029
     7        1.1815             nan     0.1000    0.0023
     8        1.1769             nan     0.1000    0.0022
     9        1.1729             nan     0.1000    0.0017
    10        1.1686             nan     0.1000    0.0020
    20        1.1424             nan     0.1000    0.0006
    40        1.1170             nan     0.1000    0.0004
    60        1.1039             nan     0.1000    0.0000
    80        1.0950             nan     0.1000    0.0001
   100        1.0871             nan     0.1000   -0.0001
   120        1.0797             nan     0.1000   -0.0000
   140        1.0732             nan     0.1000    0.0001
   160        1.0677             nan     0.1000   -0.0001
   180        1.0613             nan     0.1000    0.0000
   200        1.0558             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2220             nan     0.2000    0.0064
     2        1.2131             nan     0.2000    0.0041
     3        1.2057             nan     0.2000    0.0035
     4        1.1998             nan     0.2000    0.0028
     5        1.1951             nan     0.2000    0.0024
     6        1.1904             nan     0.2000    0.0021
     7        1.1864             nan     0.2000    0.0019
     8        1.1834             nan     0.2000    0.0014
     9        1.1803             nan     0.2000    0.0014
    10        1.1775             nan     0.2000    0.0012
    20        1.1601             nan     0.2000    0.0005
    40        1.1420             nan     0.2000    0.0000
    60        1.1326             nan     0.2000    0.0000
    80        1.1268             nan     0.2000    0.0000
   100        1.1222             nan     0.2000   -0.0001
   120        1.1188             nan     0.2000   -0.0000
   140        1.1160             nan     0.2000   -0.0000
   160        1.1137             nan     0.2000    0.0000
   180        1.1117             nan     0.2000   -0.0001
   200        1.1096             nan     0.2000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2163             nan     0.2000    0.0091
     2        1.2039             nan     0.2000    0.0060
     3        1.1935             nan     0.2000    0.0047
     4        1.1849             nan     0.2000    0.0040
     5        1.1773             nan     0.2000    0.0033
     6        1.1722             nan     0.2000    0.0024
     7        1.1671             nan     0.2000    0.0021
     8        1.1629             nan     0.2000    0.0017
     9        1.1585             nan     0.2000    0.0019
    10        1.1547             nan     0.2000    0.0017
    20        1.1318             nan     0.2000    0.0003
    40        1.1123             nan     0.2000   -0.0001
    60        1.1017             nan     0.2000    0.0001
    80        1.0940             nan     0.2000   -0.0001
   100        1.0869             nan     0.2000    0.0000
   120        1.0809             nan     0.2000   -0.0002
   140        1.0750             nan     0.2000   -0.0001
   160        1.0695             nan     0.2000   -0.0001
   180        1.0645             nan     0.2000   -0.0002
   200        1.0599             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2144             nan     0.2000    0.0098
     2        1.1982             nan     0.2000    0.0078
     3        1.1872             nan     0.2000    0.0051
     4        1.1770             nan     0.2000    0.0046
     5        1.1686             nan     0.2000    0.0037
     6        1.1619             nan     0.2000    0.0032
     7        1.1566             nan     0.2000    0.0022
     8        1.1523             nan     0.2000    0.0015
     9        1.1486             nan     0.2000    0.0015
    10        1.1445             nan     0.2000    0.0014
    20        1.1192             nan     0.2000    0.0005
    40        1.0990             nan     0.2000    0.0000
    60        1.0849             nan     0.2000    0.0001
    80        1.0721             nan     0.2000    0.0001
   100        1.0620             nan     0.2000   -0.0001
   120        1.0519             nan     0.2000   -0.0000
   140        1.0425             nan     0.2000   -0.0001
   160        1.0341             nan     0.2000   -0.0001
   180        1.0251             nan     0.2000   -0.0002
   200        1.0171             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2313             nan     0.0500    0.0018
     2        1.2282             nan     0.0500    0.0016
     3        1.2252             nan     0.0500    0.0014
     4        1.2225             nan     0.0500    0.0013
     5        1.2202             nan     0.0500    0.0012
     6        1.2181             nan     0.0500    0.0011
     7        1.2159             nan     0.0500    0.0010
     8        1.2138             nan     0.0500    0.0010
     9        1.2119             nan     0.0500    0.0009
    10        1.2102             nan     0.0500    0.0009
    20        1.1958             nan     0.0500    0.0005
    40        1.1793             nan     0.0500    0.0003
    60        1.1691             nan     0.0500    0.0002
    80        1.1613             nan     0.0500    0.0001
   100        1.1553             nan     0.0500    0.0001
   120        1.1505             nan     0.0500    0.0001
   140        1.1463             nan     0.0500    0.0001
   160        1.1428             nan     0.0500    0.0000
   180        1.1399             nan     0.0500    0.0000
   200        1.1374             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2298             nan     0.0500    0.0025
     2        1.2251             nan     0.0500    0.0022
     3        1.2209             nan     0.0500    0.0020
     4        1.2170             nan     0.0500    0.0019
     5        1.2135             nan     0.0500    0.0017
     6        1.2101             nan     0.0500    0.0016
     7        1.2067             nan     0.0500    0.0015
     8        1.2038             nan     0.0500    0.0014
     9        1.2009             nan     0.0500    0.0013
    10        1.1982             nan     0.0500    0.0013
    20        1.1789             nan     0.0500    0.0007
    40        1.1550             nan     0.0500    0.0002
    60        1.1413             nan     0.0500    0.0002
    80        1.1317             nan     0.0500    0.0002
   100        1.1247             nan     0.0500    0.0000
   120        1.1193             nan     0.0500    0.0001
   140        1.1143             nan     0.0500    0.0000
   160        1.1107             nan     0.0500    0.0000
   180        1.1078             nan     0.0500   -0.0000
   200        1.1046             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2292             nan     0.0500    0.0028
     2        1.2238             nan     0.0500    0.0024
     3        1.2190             nan     0.0500    0.0023
     4        1.2146             nan     0.0500    0.0020
     5        1.2105             nan     0.0500    0.0019
     6        1.2068             nan     0.0500    0.0017
     7        1.2031             nan     0.0500    0.0018
     8        1.1996             nan     0.0500    0.0017
     9        1.1964             nan     0.0500    0.0016
    10        1.1937             nan     0.0500    0.0012
    20        1.1703             nan     0.0500    0.0009
    40        1.1439             nan     0.0500    0.0003
    60        1.1289             nan     0.0500    0.0001
    80        1.1178             nan     0.0500    0.0002
   100        1.1103             nan     0.0500    0.0001
   120        1.1037             nan     0.0500    0.0000
   140        1.0986             nan     0.0500    0.0000
   160        1.0946             nan     0.0500   -0.0000
   180        1.0899             nan     0.0500    0.0001
   200        1.0864             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2281             nan     0.1000    0.0035
     2        1.2224             nan     0.1000    0.0027
     3        1.2173             nan     0.1000    0.0024
     4        1.2131             nan     0.1000    0.0019
     5        1.2091             nan     0.1000    0.0018
     6        1.2054             nan     0.1000    0.0017
     7        1.2023             nan     0.1000    0.0016
     8        1.1995             nan     0.1000    0.0013
     9        1.1970             nan     0.1000    0.0012
    10        1.1947             nan     0.1000    0.0011
    20        1.1785             nan     0.1000    0.0005
    40        1.1612             nan     0.1000    0.0003
    60        1.1503             nan     0.1000    0.0001
    80        1.1431             nan     0.1000    0.0001
   100        1.1373             nan     0.1000    0.0001
   120        1.1332             nan     0.1000    0.0001
   140        1.1299             nan     0.1000    0.0001
   160        1.1275             nan     0.1000   -0.0000
   180        1.1249             nan     0.1000   -0.0000
   200        1.1228             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2256             nan     0.1000    0.0047
     2        1.2172             nan     0.1000    0.0040
     3        1.2104             nan     0.1000    0.0033
     4        1.2047             nan     0.1000    0.0028
     5        1.1988             nan     0.1000    0.0026
     6        1.1940             nan     0.1000    0.0023
     7        1.1898             nan     0.1000    0.0020
     8        1.1854             nan     0.1000    0.0020
     9        1.1823             nan     0.1000    0.0015
    10        1.1784             nan     0.1000    0.0017
    20        1.1555             nan     0.1000    0.0007
    40        1.1316             nan     0.1000    0.0004
    60        1.1199             nan     0.1000    0.0003
    80        1.1122             nan     0.1000    0.0000
   100        1.1057             nan     0.1000   -0.0000
   120        1.1006             nan     0.1000   -0.0001
   140        1.0960             nan     0.1000   -0.0000
   160        1.0918             nan     0.1000   -0.0000
   180        1.0881             nan     0.1000   -0.0000
   200        1.0839             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2236             nan     0.1000    0.0053
     2        1.2149             nan     0.1000    0.0042
     3        1.2066             nan     0.1000    0.0042
     4        1.1995             nan     0.1000    0.0032
     5        1.1928             nan     0.1000    0.0031
     6        1.1872             nan     0.1000    0.0026
     7        1.1818             nan     0.1000    0.0023
     8        1.1775             nan     0.1000    0.0019
     9        1.1735             nan     0.1000    0.0018
    10        1.1694             nan     0.1000    0.0019
    20        1.1427             nan     0.1000    0.0010
    40        1.1183             nan     0.1000    0.0002
    60        1.1041             nan     0.1000    0.0001
    80        1.0951             nan     0.1000   -0.0001
   100        1.0870             nan     0.1000   -0.0001
   120        1.0800             nan     0.1000   -0.0001
   140        1.0737             nan     0.1000   -0.0001
   160        1.0674             nan     0.1000   -0.0000
   180        1.0616             nan     0.1000   -0.0001
   200        1.0563             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2216             nan     0.2000    0.0065
     2        1.2128             nan     0.2000    0.0043
     3        1.2054             nan     0.2000    0.0034
     4        1.1994             nan     0.2000    0.0030
     5        1.1942             nan     0.2000    0.0025
     6        1.1896             nan     0.2000    0.0023
     7        1.1868             nan     0.2000    0.0014
     8        1.1838             nan     0.2000    0.0013
     9        1.1809             nan     0.2000    0.0014
    10        1.1783             nan     0.2000    0.0011
    20        1.1604             nan     0.2000    0.0008
    40        1.1422             nan     0.2000    0.0003
    60        1.1326             nan     0.2000    0.0000
    80        1.1268             nan     0.2000    0.0001
   100        1.1228             nan     0.2000   -0.0000
   120        1.1195             nan     0.2000   -0.0001
   140        1.1166             nan     0.2000   -0.0001
   160        1.1145             nan     0.2000   -0.0000
   180        1.1128             nan     0.2000   -0.0002
   200        1.1107             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2165             nan     0.2000    0.0090
     2        1.2036             nan     0.2000    0.0063
     3        1.1937             nan     0.2000    0.0047
     4        1.1860             nan     0.2000    0.0036
     5        1.1797             nan     0.2000    0.0025
     6        1.1749             nan     0.2000    0.0020
     7        1.1680             nan     0.2000    0.0030
     8        1.1632             nan     0.2000    0.0021
     9        1.1592             nan     0.2000    0.0015
    10        1.1554             nan     0.2000    0.0015
    20        1.1323             nan     0.2000    0.0005
    40        1.1127             nan     0.2000    0.0000
    60        1.1017             nan     0.2000    0.0001
    80        1.0922             nan     0.2000   -0.0002
   100        1.0856             nan     0.2000   -0.0001
   120        1.0800             nan     0.2000   -0.0001
   140        1.0746             nan     0.2000   -0.0001
   160        1.0692             nan     0.2000   -0.0001
   180        1.0639             nan     0.2000   -0.0002
   200        1.0591             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2138             nan     0.2000    0.0097
     2        1.1985             nan     0.2000    0.0073
     3        1.1868             nan     0.2000    0.0050
     4        1.1764             nan     0.2000    0.0044
     5        1.1671             nan     0.2000    0.0040
     6        1.1603             nan     0.2000    0.0029
     7        1.1546             nan     0.2000    0.0026
     8        1.1495             nan     0.2000    0.0020
     9        1.1451             nan     0.2000    0.0018
    10        1.1414             nan     0.2000    0.0014
    20        1.1188             nan     0.2000    0.0006
    40        1.0976             nan     0.2000   -0.0001
    60        1.0825             nan     0.2000   -0.0001
    80        1.0706             nan     0.2000   -0.0001
   100        1.0605             nan     0.2000   -0.0001
   120        1.0499             nan     0.2000   -0.0001
   140        1.0408             nan     0.2000   -0.0002
   160        1.0323             nan     0.2000   -0.0002
   180        1.0239             nan     0.2000   -0.0002
   200        1.0158             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2314             nan     0.0500    0.0017
     2        1.2283             nan     0.0500    0.0015
     3        1.2256             nan     0.0500    0.0013
     4        1.2230             nan     0.0500    0.0013
     5        1.2207             nan     0.0500    0.0011
     6        1.2185             nan     0.0500    0.0010
     7        1.2165             nan     0.0500    0.0010
     8        1.2145             nan     0.0500    0.0010
     9        1.2125             nan     0.0500    0.0009
    10        1.2107             nan     0.0500    0.0009
    20        1.1966             nan     0.0500    0.0005
    40        1.1804             nan     0.0500    0.0003
    60        1.1701             nan     0.0500    0.0002
    80        1.1624             nan     0.0500    0.0001
   100        1.1564             nan     0.0500    0.0001
   120        1.1515             nan     0.0500    0.0001
   140        1.1474             nan     0.0500    0.0000
   160        1.1439             nan     0.0500    0.0000
   180        1.1409             nan     0.0500    0.0000
   200        1.1386             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2300             nan     0.0500    0.0024
     2        1.2256             nan     0.0500    0.0022
     3        1.2214             nan     0.0500    0.0020
     4        1.2178             nan     0.0500    0.0018
     5        1.2143             nan     0.0500    0.0016
     6        1.2110             nan     0.0500    0.0016
     7        1.2079             nan     0.0500    0.0014
     8        1.2050             nan     0.0500    0.0014
     9        1.2022             nan     0.0500    0.0013
    10        1.1997             nan     0.0500    0.0012
    20        1.1799             nan     0.0500    0.0007
    40        1.1562             nan     0.0500    0.0002
    60        1.1425             nan     0.0500    0.0003
    80        1.1329             nan     0.0500    0.0001
   100        1.1258             nan     0.0500    0.0001
   120        1.1204             nan     0.0500    0.0001
   140        1.1159             nan     0.0500    0.0000
   160        1.1124             nan     0.0500   -0.0000
   180        1.1090             nan     0.0500   -0.0000
   200        1.1061             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2293             nan     0.0500    0.0028
     2        1.2242             nan     0.0500    0.0025
     3        1.2194             nan     0.0500    0.0023
     4        1.2148             nan     0.0500    0.0022
     5        1.2108             nan     0.0500    0.0019
     6        1.2069             nan     0.0500    0.0019
     7        1.2034             nan     0.0500    0.0015
     8        1.2001             nan     0.0500    0.0016
     9        1.1971             nan     0.0500    0.0014
    10        1.1941             nan     0.0500    0.0014
    20        1.1714             nan     0.0500    0.0007
    40        1.1441             nan     0.0500    0.0005
    60        1.1289             nan     0.0500    0.0002
    80        1.1186             nan     0.0500    0.0001
   100        1.1111             nan     0.0500    0.0000
   120        1.1050             nan     0.0500   -0.0001
   140        1.1000             nan     0.0500    0.0000
   160        1.0956             nan     0.0500    0.0000
   180        1.0912             nan     0.0500    0.0000
   200        1.0874             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2282             nan     0.1000    0.0033
     2        1.2229             nan     0.1000    0.0025
     3        1.2181             nan     0.1000    0.0023
     4        1.2141             nan     0.1000    0.0018
     5        1.2103             nan     0.1000    0.0019
     6        1.2070             nan     0.1000    0.0016
     7        1.2036             nan     0.1000    0.0016
     8        1.2010             nan     0.1000    0.0012
     9        1.1984             nan     0.1000    0.0013
    10        1.1961             nan     0.1000    0.0011
    20        1.1806             nan     0.1000    0.0005
    40        1.1623             nan     0.1000    0.0003
    60        1.1514             nan     0.1000    0.0002
    80        1.1440             nan     0.1000    0.0001
   100        1.1384             nan     0.1000    0.0000
   120        1.1345             nan     0.1000    0.0000
   140        1.1312             nan     0.1000    0.0000
   160        1.1283             nan     0.1000    0.0000
   180        1.1260             nan     0.1000    0.0000
   200        1.1240             nan     0.1000    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2252             nan     0.1000    0.0045
     2        1.2172             nan     0.1000    0.0039
     3        1.2105             nan     0.1000    0.0032
     4        1.2045             nan     0.1000    0.0029
     5        1.1990             nan     0.1000    0.0026
     6        1.1943             nan     0.1000    0.0023
     7        1.1901             nan     0.1000    0.0020
     8        1.1863             nan     0.1000    0.0018
     9        1.1827             nan     0.1000    0.0016
    10        1.1796             nan     0.1000    0.0014
    20        1.1562             nan     0.1000    0.0007
    40        1.1332             nan     0.1000    0.0003
    60        1.1211             nan     0.1000    0.0002
    80        1.1129             nan     0.1000    0.0001
   100        1.1066             nan     0.1000    0.0000
   120        1.1013             nan     0.1000    0.0000
   140        1.0971             nan     0.1000   -0.0000
   160        1.0930             nan     0.1000   -0.0000
   180        1.0891             nan     0.1000   -0.0001
   200        1.0851             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2238             nan     0.1000    0.0052
     2        1.2144             nan     0.1000    0.0043
     3        1.2065             nan     0.1000    0.0038
     4        1.1995             nan     0.1000    0.0034
     5        1.1937             nan     0.1000    0.0026
     6        1.1884             nan     0.1000    0.0025
     7        1.1836             nan     0.1000    0.0023
     8        1.1795             nan     0.1000    0.0017
     9        1.1753             nan     0.1000    0.0018
    10        1.1706             nan     0.1000    0.0021
    20        1.1445             nan     0.1000    0.0008
    40        1.1185             nan     0.1000    0.0002
    60        1.1055             nan     0.1000    0.0000
    80        1.0960             nan     0.1000   -0.0000
   100        1.0885             nan     0.1000   -0.0000
   120        1.0814             nan     0.1000    0.0000
   140        1.0748             nan     0.1000   -0.0002
   160        1.0686             nan     0.1000   -0.0000
   180        1.0624             nan     0.1000    0.0000
   200        1.0569             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2221             nan     0.2000    0.0061
     2        1.2141             nan     0.2000    0.0039
     3        1.2066             nan     0.2000    0.0035
     4        1.2009             nan     0.2000    0.0027
     5        1.1951             nan     0.2000    0.0026
     6        1.1905             nan     0.2000    0.0021
     7        1.1873             nan     0.2000    0.0015
     8        1.1846             nan     0.2000    0.0011
     9        1.1815             nan     0.2000    0.0014
    10        1.1789             nan     0.2000    0.0012
    20        1.1615             nan     0.2000    0.0005
    40        1.1435             nan     0.2000    0.0002
    60        1.1348             nan     0.2000   -0.0000
    80        1.1283             nan     0.2000    0.0000
   100        1.1241             nan     0.2000    0.0001
   120        1.1205             nan     0.2000    0.0000
   140        1.1177             nan     0.2000   -0.0000
   160        1.1154             nan     0.2000   -0.0001
   180        1.1133             nan     0.2000   -0.0001
   200        1.1117             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2165             nan     0.2000    0.0088
     2        1.2034             nan     0.2000    0.0063
     3        1.1934             nan     0.2000    0.0044
     4        1.1849             nan     0.2000    0.0044
     5        1.1775             nan     0.2000    0.0031
     6        1.1717             nan     0.2000    0.0026
     7        1.1661             nan     0.2000    0.0027
     8        1.1615             nan     0.2000    0.0020
     9        1.1564             nan     0.2000    0.0021
    10        1.1535             nan     0.2000    0.0010
    20        1.1320             nan     0.2000    0.0004
    40        1.1138             nan     0.2000   -0.0000
    60        1.1043             nan     0.2000   -0.0001
    80        1.0955             nan     0.2000   -0.0001
   100        1.0883             nan     0.2000   -0.0001
   120        1.0823             nan     0.2000   -0.0001
   140        1.0769             nan     0.2000   -0.0001
   160        1.0718             nan     0.2000   -0.0002
   180        1.0663             nan     0.2000   -0.0001
   200        1.0621             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2139             nan     0.2000    0.0102
     2        1.1982             nan     0.2000    0.0076
     3        1.1865             nan     0.2000    0.0052
     4        1.1780             nan     0.2000    0.0038
     5        1.1704             nan     0.2000    0.0035
     6        1.1637             nan     0.2000    0.0029
     7        1.1576             nan     0.2000    0.0025
     8        1.1529             nan     0.2000    0.0018
     9        1.1476             nan     0.2000    0.0024
    10        1.1441             nan     0.2000    0.0013
    20        1.1202             nan     0.2000    0.0006
    40        1.1000             nan     0.2000    0.0000
    60        1.0861             nan     0.2000   -0.0001
    80        1.0741             nan     0.2000   -0.0000
   100        1.0638             nan     0.2000   -0.0003
   120        1.0541             nan     0.2000   -0.0000
   140        1.0452             nan     0.2000   -0.0003
   160        1.0359             nan     0.2000   -0.0003
   180        1.0267             nan     0.2000   -0.0002
   200        1.0181             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2315             nan     0.0500    0.0017
     2        1.2285             nan     0.0500    0.0015
     3        1.2256             nan     0.0500    0.0014
     4        1.2231             nan     0.0500    0.0012
     5        1.2208             nan     0.0500    0.0012
     6        1.2186             nan     0.0500    0.0010
     7        1.2165             nan     0.0500    0.0010
     8        1.2145             nan     0.0500    0.0010
     9        1.2124             nan     0.0500    0.0009
    10        1.2107             nan     0.0500    0.0008
    20        1.1963             nan     0.0500    0.0005
    40        1.1800             nan     0.0500    0.0003
    60        1.1695             nan     0.0500    0.0002
    80        1.1622             nan     0.0500    0.0001
   100        1.1562             nan     0.0500    0.0001
   120        1.1513             nan     0.0500    0.0001
   140        1.1475             nan     0.0500    0.0000
   160        1.1440             nan     0.0500    0.0001
   180        1.1412             nan     0.0500    0.0001
   200        1.1386             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2300             nan     0.0500    0.0023
     2        1.2256             nan     0.0500    0.0021
     3        1.2213             nan     0.0500    0.0020
     4        1.2175             nan     0.0500    0.0018
     5        1.2140             nan     0.0500    0.0017
     6        1.2107             nan     0.0500    0.0016
     7        1.2076             nan     0.0500    0.0015
     8        1.2048             nan     0.0500    0.0013
     9        1.2021             nan     0.0500    0.0013
    10        1.1995             nan     0.0500    0.0012
    20        1.1788             nan     0.0500    0.0009
    40        1.1558             nan     0.0500    0.0005
    60        1.1420             nan     0.0500    0.0002
    80        1.1326             nan     0.0500    0.0002
   100        1.1254             nan     0.0500    0.0001
   120        1.1198             nan     0.0500    0.0000
   140        1.1156             nan     0.0500    0.0000
   160        1.1121             nan     0.0500   -0.0000
   180        1.1090             nan     0.0500   -0.0000
   200        1.1060             nan     0.0500   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2292             nan     0.0500    0.0027
     2        1.2240             nan     0.0500    0.0025
     3        1.2192             nan     0.0500    0.0024
     4        1.2150             nan     0.0500    0.0020
     5        1.2110             nan     0.0500    0.0019
     6        1.2070             nan     0.0500    0.0019
     7        1.2033             nan     0.0500    0.0017
     8        1.2000             nan     0.0500    0.0015
     9        1.1970             nan     0.0500    0.0014
    10        1.1940             nan     0.0500    0.0013
    20        1.1698             nan     0.0500    0.0008
    40        1.1440             nan     0.0500    0.0003
    60        1.1288             nan     0.0500    0.0001
    80        1.1188             nan     0.0500    0.0002
   100        1.1113             nan     0.0500    0.0000
   120        1.1053             nan     0.0500    0.0000
   140        1.1001             nan     0.0500    0.0000
   160        1.0958             nan     0.0500   -0.0000
   180        1.0918             nan     0.0500    0.0000
   200        1.0877             nan     0.0500    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2287             nan     0.1000    0.0032
     2        1.2232             nan     0.1000    0.0028
     3        1.2187             nan     0.1000    0.0023
     4        1.2148             nan     0.1000    0.0019
     5        1.2110             nan     0.1000    0.0019
     6        1.2077             nan     0.1000    0.0015
     7        1.2041             nan     0.1000    0.0016
     8        1.2014             nan     0.1000    0.0012
     9        1.1984             nan     0.1000    0.0014
    10        1.1961             nan     0.1000    0.0012
    20        1.1801             nan     0.1000    0.0005
    40        1.1622             nan     0.1000    0.0003
    60        1.1516             nan     0.1000    0.0001
    80        1.1440             nan     0.1000    0.0001
   100        1.1386             nan     0.1000    0.0000
   120        1.1347             nan     0.1000    0.0000
   140        1.1315             nan     0.1000    0.0001
   160        1.1286             nan     0.1000    0.0001
   180        1.1263             nan     0.1000    0.0000
   200        1.1243             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2252             nan     0.1000    0.0046
     2        1.2174             nan     0.1000    0.0038
     3        1.2105             nan     0.1000    0.0032
     4        1.2046             nan     0.1000    0.0029
     5        1.1991             nan     0.1000    0.0025
     6        1.1945             nan     0.1000    0.0022
     7        1.1899             nan     0.1000    0.0022
     8        1.1857             nan     0.1000    0.0018
     9        1.1825             nan     0.1000    0.0014
    10        1.1784             nan     0.1000    0.0019
    20        1.1557             nan     0.1000    0.0009
    40        1.1333             nan     0.1000    0.0003
    60        1.1211             nan     0.1000    0.0001
    80        1.1127             nan     0.1000    0.0002
   100        1.1068             nan     0.1000    0.0000
   120        1.1013             nan     0.1000    0.0000
   140        1.0965             nan     0.1000    0.0000
   160        1.0920             nan     0.1000    0.0000
   180        1.0880             nan     0.1000   -0.0001
   200        1.0841             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2238             nan     0.1000    0.0053
     2        1.2146             nan     0.1000    0.0043
     3        1.2066             nan     0.1000    0.0037
     4        1.1998             nan     0.1000    0.0029
     5        1.1935             nan     0.1000    0.0028
     6        1.1878             nan     0.1000    0.0026
     7        1.1826             nan     0.1000    0.0024
     8        1.1785             nan     0.1000    0.0019
     9        1.1749             nan     0.1000    0.0016
    10        1.1708             nan     0.1000    0.0018
    20        1.1442             nan     0.1000    0.0008
    40        1.1193             nan     0.1000    0.0000
    60        1.1065             nan     0.1000   -0.0001
    80        1.0963             nan     0.1000    0.0002
   100        1.0889             nan     0.1000   -0.0001
   120        1.0817             nan     0.1000   -0.0000
   140        1.0753             nan     0.1000   -0.0001
   160        1.0692             nan     0.1000   -0.0001
   180        1.0628             nan     0.1000   -0.0001
   200        1.0575             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2223             nan     0.2000    0.0063
     2        1.2138             nan     0.2000    0.0042
     3        1.2061             nan     0.2000    0.0035
     4        1.1998             nan     0.2000    0.0030
     5        1.1946             nan     0.2000    0.0026
     6        1.1913             nan     0.2000    0.0014
     7        1.1878             nan     0.2000    0.0016
     8        1.1849             nan     0.2000    0.0014
     9        1.1827             nan     0.2000    0.0010
    10        1.1799             nan     0.2000    0.0014
    20        1.1621             nan     0.2000    0.0007
    40        1.1439             nan     0.2000    0.0003
    60        1.1347             nan     0.2000    0.0001
    80        1.1287             nan     0.2000    0.0000
   100        1.1241             nan     0.2000    0.0001
   120        1.1209             nan     0.2000   -0.0001
   140        1.1179             nan     0.2000    0.0000
   160        1.1154             nan     0.2000   -0.0001
   180        1.1134             nan     0.2000    0.0000
   200        1.1117             nan     0.2000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2165             nan     0.2000    0.0085
     2        1.2034             nan     0.2000    0.0063
     3        1.1931             nan     0.2000    0.0047
     4        1.1859             nan     0.2000    0.0032
     5        1.1791             nan     0.2000    0.0031
     6        1.1740             nan     0.2000    0.0021
     7        1.1682             nan     0.2000    0.0027
     8        1.1639             nan     0.2000    0.0017
     9        1.1596             nan     0.2000    0.0019
    10        1.1560             nan     0.2000    0.0013
    20        1.1334             nan     0.2000    0.0001
    40        1.1157             nan     0.2000    0.0002
    60        1.1037             nan     0.2000   -0.0001
    80        1.0944             nan     0.2000   -0.0000
   100        1.0876             nan     0.2000   -0.0001
   120        1.0810             nan     0.2000   -0.0001
   140        1.0754             nan     0.2000   -0.0001
   160        1.0697             nan     0.2000   -0.0000
   180        1.0644             nan     0.2000   -0.0000
   200        1.0584             nan     0.2000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2138             nan     0.2000    0.0097
     2        1.1995             nan     0.2000    0.0068
     3        1.1877             nan     0.2000    0.0052
     4        1.1782             nan     0.2000    0.0042
     5        1.1709             nan     0.2000    0.0033
     6        1.1653             nan     0.2000    0.0025
     7        1.1594             nan     0.2000    0.0025
     8        1.1536             nan     0.2000    0.0026
     9        1.1482             nan     0.2000    0.0022
    10        1.1443             nan     0.2000    0.0012
    20        1.1205             nan     0.2000   -0.0000
    40        1.0996             nan     0.2000   -0.0000
    60        1.0866             nan     0.2000   -0.0000
    80        1.0744             nan     0.2000   -0.0001
   100        1.0636             nan     0.2000   -0.0003
   120        1.0540             nan     0.2000   -0.0002
   140        1.0437             nan     0.2000   -0.0001
   160        1.0346             nan     0.2000   -0.0001
   180        1.0257             nan     0.2000   -0.0003
   200        1.0170             nan     0.2000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2256             nan     0.1000    0.0047
     2        1.2177             nan     0.1000    0.0038
     3        1.2107             nan     0.1000    0.0034
     4        1.2046             nan     0.1000    0.0028
     5        1.1993             nan     0.1000    0.0025
     6        1.1948             nan     0.1000    0.0021
     7        1.1903             nan     0.1000    0.0020
     8        1.1855             nan     0.1000    0.0022
     9        1.1816             nan     0.1000    0.0018
    10        1.1784             nan     0.1000    0.0015
    20        1.1556             nan     0.1000    0.0006
    40        1.1327             nan     0.1000    0.0005
    60        1.1208             nan     0.1000    0.0001
    80        1.1130             nan     0.1000   -0.0000
   100        1.1073             nan     0.1000    0.0001
   120        1.1025             nan     0.1000    0.0000
   140        1.0980             nan     0.1000   -0.0000
   160        1.0941             nan     0.1000    0.0000
   180        1.0902             nan     0.1000   -0.0000
   200        1.0868             nan     0.1000   -0.0001

</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">News_SGB_fit</span>
<span class="n">News_SGB_fit</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Stochastic Gradient Boosting 

31715 samples
   58 predictor
    2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 28543, 28543, 28544, 28543, 28545, 28543, ... 
Resampling results across tuning parameters:

  shrinkage  interaction.depth  n.trees  Accuracy   Kappa     
  0.05       1                   50      0.6920385  0.00000000
  0.05       1                  100      0.6970201  0.04163981
  0.05       1                  200      0.7040830  0.10859762
  0.05       3                   50      0.6997317  0.05654661
  0.05       3                  100      0.7084974  0.13948121
  0.05       3                  200      0.7136058  0.18085186
  0.05       5                   50      0.7050291  0.09730966
  0.05       5                  100      0.7124388  0.16595735
  0.05       5                  200      0.7158129  0.19615907
  0.10       1                   50      0.6975876  0.04678712
  0.10       1                  100      0.7038307  0.11124181
  0.10       1                  200      0.7091595  0.15811836
  0.10       3                   50      0.7080246  0.14104946
  0.10       3                  100      0.7132273  0.18200003
  0.10       3                  200      0.7164751  0.20496480
  0.10       5                   50      0.7110515  0.16330797
  0.10       5                  100      0.7152765  0.19530509
  0.10       5                  200      0.7163171  0.20960372
  0.20       1                   50      0.7036100  0.11119381
  0.20       1                  100      0.7085921  0.15659671
  0.20       1                  200      0.7129437  0.18730816
  0.20       3                   50      0.7112091  0.17993931
  0.20       3                  100      0.7145828  0.20190071
  0.20       3                  200      0.7132902  0.20882830
  0.20       5                   50      0.7155920  0.19912331
  0.20       5                  100      0.7152136  0.21008699
  0.20       5                  200      0.7127858  0.21598928

Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
Accuracy was used to select the optimal model using the largest value.
The final values used for the model were n.trees = 200, interaction.depth =
 3, shrinkage = 0.1 and n.minobsinnode = 10.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>A gradient boosted model with bernoulli loss function.
200 iterations were performed.
There were 58 predictors of which 52 had non-zero influence.</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h6 id="Accuracy-and-Kappa-values-for-Each-Model-on-Training-Sets">Accuracy and Kappa values for Each Model on Training Sets<a class="anchor-link" href="#Accuracy-and-Kappa-values-for-Each-Model-on-Training-Sets">&#182;</a></h6>
<pre><code>Lasso Model --&gt; Accuracy 0.7069  --  Kappa --&gt; 0.1527

Decision Tree Model  --&gt; Accuracy 0.7023   Kappa --&gt;  0.1541

Random Forest Model  --&gt; Accuracy 0.7170  Kappa --&gt;  0.1954

Stochastic Gradient Boosting Model  --&gt; Accuracy 0.7165  Kappa --&gt;  0.2050</code></pre>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Lasso Prediction</span>
<span class="n">News_Lasso_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">News_lasso_fit</span><span class="p">,</span> <span class="n">News_test</span><span class="p">)</span>
<span class="n">CM_Lasso</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">News_Lasso_predict</span><span class="p">,</span> <span class="n">News_test</span><span class="o">$</span><span class="n">is_popular</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_Lasso</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_Lasso</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">Kappa_Lasso</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Kappa&#39;</span><span class="p">]</span>
<span class="n">CM_Lasso</span>
<span class="n">Accuracy_Lasso</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_Lasso</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Kappa_Lasso</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Kappa_Lasso</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="c1"># Decision Tree Prediction</span>
<span class="n">News_DT_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">News_DT_fit3</span><span class="p">,</span> <span class="n">News_test</span><span class="p">)</span>
<span class="n">CM_DT</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">News_DT_predict</span><span class="p">,</span> <span class="n">News_test</span><span class="o">$</span><span class="n">is_popular</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_DT</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_DT</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">Kappa_DT</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Kappa&#39;</span><span class="p">]</span>
<span class="n">CM_DT</span>
<span class="n">Accuracy_DT</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_DT</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Kappa_DT</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Kappa_DT</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="c1"># Random Forest Prediction</span>
<span class="n">News_RF_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">News_RF_fit</span><span class="p">,</span> <span class="n">News_test</span><span class="p">)</span>
<span class="n">CM_RF</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">News_RF_predict</span><span class="p">,</span> <span class="n">News_test</span><span class="o">$</span><span class="n">is_popular</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_RF</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_RF</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">Kappa_RF</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Kappa&#39;</span><span class="p">]</span>
<span class="n">CM_RF</span>
<span class="n">Accuracy_RF</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Kappa_RF</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Kappa_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="c1"># Stochastic Gradient Boosting Prediction</span>
<span class="n">News_SGB_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">News_SGB_fit</span><span class="p">,</span> <span class="n">News_test</span><span class="p">)</span>
<span class="n">CM_SGB</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">News_SGB_predict</span><span class="p">,</span> <span class="n">News_test</span><span class="o">$</span><span class="n">is_popular</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_SGB</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_SGB</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">Kappa_SGB</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Kappa&#39;</span><span class="p">]</span>
<span class="n">CM_SGB</span>
<span class="n">Accuracy_SGB</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Kappa_SGB</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Kappa_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>

<span class="n">A</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Lasso Model Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_Lasso</span><span class="p">,</span> <span class="s">&quot; and Kappa is&quot;</span><span class="p">,</span> <span class="n">Kappa_Lasso</span><span class="p">)</span>
<span class="n">B</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Decision Tree Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_DT</span><span class="p">,</span> <span class="s">&quot; and Kappa is&quot;</span><span class="p">,</span> <span class="n">Kappa_DT</span><span class="p">)</span>
<span class="n">C</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Random Forest Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_RF</span><span class="p">,</span> <span class="s">&quot; and Kappa is&quot;</span><span class="p">,</span> <span class="n">Kappa_RF</span><span class="p">)</span>
<span class="n">D</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Stochastic Gradient Boosting Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_SGB</span><span class="p">,</span> <span class="s">&quot; and Kappa is&quot;</span><span class="p">,</span> <span class="n">Kappa_SGB</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0 5546 1647
         1  336  399
                                          
               Accuracy : 0.7499          
                 95% CI : (0.7402, 0.7594)
    No Information Rate : 0.7419          
    P-Value [Acc &gt; NIR] : 0.05397         
                                          
                  Kappa : 0.1743          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2e-16         
                                          
            Sensitivity : 0.9429          
            Specificity : 0.1950          
         Pos Pred Value : 0.7710          
         Neg Pred Value : 0.5429          
             Prevalence : 0.7419          
         Detection Rate : 0.6995          
   Detection Prevalence : 0.9073          
      Balanced Accuracy : 0.5689          
                                          
       &#39;Positive&#39; Class : 0               
                                          </pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0 5344 1497
         1  538  549
                                          
               Accuracy : 0.7433          
                 95% CI : (0.7335, 0.7529)
    No Information Rate : 0.7419          
    P-Value [Acc &gt; NIR] : 0.3945          
                                          
                  Kappa : 0.2088          
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          
                                          
            Sensitivity : 0.9085          
            Specificity : 0.2683          
         Pos Pred Value : 0.7812          
         Neg Pred Value : 0.5051          
             Prevalence : 0.7419          
         Detection Rate : 0.6741          
   Detection Prevalence : 0.8629          
      Balanced Accuracy : 0.5884          
                                          
       &#39;Positive&#39; Class : 0               
                                          </pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0 5540 1590
         1  342  456
                                          
               Accuracy : 0.7563          
                 95% CI : (0.7467, 0.7657)
    No Information Rate : 0.7419          
    P-Value [Acc &gt; NIR] : 0.0017          
                                          
                  Kappa : 0.2056          
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          
                                          
            Sensitivity : 0.9419          
            Specificity : 0.2229          
         Pos Pred Value : 0.7770          
         Neg Pred Value : 0.5714          
             Prevalence : 0.7419          
         Detection Rate : 0.6988          
   Detection Prevalence : 0.8993          
      Balanced Accuracy : 0.5824          
                                          
       &#39;Positive&#39; Class : 0               
                                          </pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0 5545 1605
         1  337  441
                                          
               Accuracy : 0.755           
                 95% CI : (0.7454, 0.7645)
    No Information Rate : 0.7419          
    P-Value [Acc &gt; NIR] : 0.003799        
                                          
                  Kappa : 0.1983          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.9427          
            Specificity : 0.2155          
         Pos Pred Value : 0.7755          
         Neg Pred Value : 0.5668          
             Prevalence : 0.7419          
         Detection Rate : 0.6994          
   Detection Prevalence : 0.9019          
      Balanced Accuracy : 0.5791          
                                          
       &#39;Positive&#39; Class : 0               
                                          </pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[1] &#34;Lasso Model Test Accuracy is 0.7499  and Kappa is 0.1743&#34;
[1] &#34;Decision Tree Test Accuracy is 0.7433  and Kappa is 0.2088&#34;
[1] &#34;Random Forest Test Accuracy is 0.7563  and Kappa is 0.2056&#34;
[1] &#34;Stochastic Gradient Boosting Test Accuracy is 0.7563  and Kappa is 0.2056&#34;
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="Comments">Comments<a class="anchor-link" href="#Comments">&#182;</a></h5><p>Our training data accuracy is around %70 and Kappa values are scattered around 0.15 and 0.20. When we made the predictions with the models, we observe that our accuracy is increased to %75 which is more than what obtained for each model on the training set. We also get Kappa values around 0.20 for our predictions. Since it is a class imbalance problem Kappa values have more meaning. Although we improved our accuracy for the test data, since it is a 0.7 to 0.3 class imbalance set, if we made our guesses as class "0" for each data, we would have get a %70 accuracy. So obtaining a %75 accuracy does not mean a lot. I can not tell which Model is best for the dataset but I would not suggest Lasso Model which gave the lowest Kappa value.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Dataset-4---Dota2-Games-Results-Data-Set">Dataset 4 - Dota2 Games Results Data Set<a class="anchor-link" href="#Dataset-4---Dota2-Games-Results-Data-Set">&#182;</a></h1>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p><a href="https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results">https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results</a></p>
<h5 id="Data-Set-Information:">Data Set Information:<a class="anchor-link" href="#Data-Set-Information:">&#182;</a></h5><p>Dota 2 is a popular computer game with two teams of 5 players. At the start of the game each player chooses a unique hero with different strengths and weaknesses. The dataset is reasonably sparse as only 10 of 113 possible heroes are chosen in a given game. All games were played in a space of 2 hours on the 13th of August, 2016</p>
<p>The data was collected using: [<a href="https://gist.github.com/da-steve101/1a7ae319448db431715bd75391a66e1b">https://gist.github.com/da-steve101/1a7ae319448db431715bd75391a66e1b</a>]</p>
<h5 id="Attribute-Information:">Attribute Information:<a class="anchor-link" href="#Attribute-Information:">&#182;</a></h5><p>Each row of the dataset is a single game with the following features (in the order in the vector):</p>
<ol>
<li><p>Team won the game (1 or -1)</p>
</li>
<li><p>Cluster ID (related to location)</p>
</li>
<li><p>Game mode (eg All Pick)</p>
</li>
<li><p>Game type (eg. Ranked)</p>
</li>
<li><p>end: Each element is an indicator for a hero. Value of 1 indicates that a player from team '1' played as that hero and '-1' for the other team. Hero can be selected by only one player each game. This means that each row has five '1' and five '-1' values.</p>
</li>
</ol>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="For-the-analysis:">For the analysis:<a class="anchor-link" href="#For-the-analysis:">&#182;</a></h4><p>Dataset is one of the I found that has more than 50 features. It is a 2 class problem. Team won the game will be the target.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#read the data</span>
<span class="n">DOTA2_train</span> <span class="o">=</span> <span class="nf">read.csv</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="s">&quot;dota2Train.csv&quot;</span><span class="p">)</span>
<span class="n">DOTA2_test</span> <span class="o">=</span> <span class="nf">read.csv</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="s">&quot;dota2Test.csv&quot;</span><span class="p">)</span>
<span class="n">DOTA2_train</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">DOTA2_train</span><span class="p">[,])</span>
<span class="n">DOTA2_train</span> <span class="o">&lt;-</span> <span class="n">DOTA2_train</span><span class="p">[</span><span class="o">!</span><span class="nf">names</span><span class="p">(</span><span class="n">DOTA2_train</span><span class="p">)</span> <span class="o">%in%</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;X223&quot;</span><span class="p">)]</span> <span class="c1">#removed the second column about the location considered as &quot;nonpredictive&quot;</span>
<span class="n">DOTA2_test</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">DOTA2_train</span><span class="p">)</span>
<span class="n">DOTA2_test</span> <span class="o">&lt;-</span> <span class="n">DOTA2_test</span><span class="p">[</span><span class="o">!</span><span class="nf">names</span><span class="p">(</span><span class="n">DOTA2_test</span><span class="p">)</span> <span class="o">%in%</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;X223&quot;</span><span class="p">)]</span>
<span class="n">DOTA2_train</span><span class="o">$</span><span class="n">X.1</span> <span class="o">&lt;-</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">DOTA2_train</span><span class="o">$</span><span class="n">X.1</span><span class="p">)</span> <span class="c1">#It will be classification so needs to be factor?</span>
<span class="n">DOTA2_test</span><span class="o">$</span><span class="n">X.1</span> <span class="o">&lt;-</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">DOTA2_test</span><span class="o">$</span><span class="n">X.1</span><span class="p">)</span>

<span class="c1">#my RAM does not allow me to process the whole data so I took %10 of it still 9k for train and 1k for test</span>

<span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">DOTA2_train</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">*</span><span class="m">0.1</span>
<span class="n">m</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">DOTA2_test</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="m">0.1</span>
<span class="n">DOTA2_train</span> <span class="o">=</span> <span class="n">DOTA2_train</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="n">n</span><span class="p">),]</span>
<span class="n">DOTA2_test</span> <span class="o">=</span> <span class="n">DOTA2_test</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="n">m</span><span class="p">),]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 1 - Lasso Regression</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">636</span><span class="p">)</span>
<span class="n">lambda_seq</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0.00001</span><span class="p">,</span><span class="m">0.02</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="m">6</span><span class="p">))</span> <span class="c1">#tried several times but we are asked to use 6 different lamda (I rerun the code)</span>
<span class="n">n_repeats</span><span class="o">=</span><span class="m">5</span>
<span class="n">n_folds</span><span class="o">=</span><span class="m">10</span>
<span class="n">lasso_grid</span> <span class="o">=</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">lambda</span><span class="o">=</span><span class="n">lambda_seq</span><span class="p">)</span>
<span class="n">lasso_control</span><span class="o">=</span><span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span>                        
<span class="n">DOTA2_lasso_fit</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">X.1</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">DOTA2_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s">&quot;glmnet&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">lasso_grid</span><span class="p">,</span><span class="n">trControl</span> <span class="o">=</span> <span class="n">lasso_control</span><span class="p">)</span> 
<span class="n">DOTA2_lasso_fit</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>glmnet 

9264 samples
 115 predictor
   2 classes: &#39;-1&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 8337, 8338, 8338, 8337, 8337, 8338, ... 
Resampling results across tuning parameters:

  lambda    Accuracy   Kappa     
  0.000010  0.5887522  0.16761065
  0.004008  0.5875002  0.16208394
  0.008006  0.5812395  0.14472722
  0.012004  0.5715671  0.11725222
  0.016002  0.5526765  0.06687411
  0.020000  0.5402620  0.02927013

Tuning parameter &#39;alpha&#39; was held constant at a value of 1
Accuracy was used to select the optimal model using the largest value.
The final values used for the model were alpha = 1 and lambda = 1e-05.</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 2 - Decision Trees</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">636</span><span class="p">)</span>

<span class="n">DT_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="n">n_repeats</span><span class="p">)</span> 
<span class="n">DT_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">cp</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.01</span><span class="p">,</span><span class="m">0.02</span><span class="p">,</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.005</span><span class="p">,</span><span class="m">0.002</span><span class="p">,</span><span class="m">0.001</span><span class="p">))</span> <span class="c1"># cp by default 0.01, I change by both increasing and decreasing</span>

<span class="c1"># minbucket is originaly &quot;20/3 = 7&quot; so I tried original &quot;7&quot;, increase to &quot;20&quot;, decrease to &quot;2&quot;...</span>
<span class="n">DOTA2_DT_fit1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">X.1</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">DOTA2_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">7</span><span class="p">))</span>

<span class="n">DOTA2_DT_fit2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">X.1</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">DOTA2_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">20</span><span class="p">))</span>

<span class="n">DOTA2_DT_fit3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">X.1</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">DOTA2_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">DT_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">DT_control</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="m">2</span><span class="p">))</span>

<span class="n">DOTA2_DT_fit1</span>
<span class="n">DOTA2_DT_fit2</span>
<span class="n">DOTA2_DT_fit3</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

9264 samples
 115 predictor
   2 classes: &#39;-1&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 8337, 8338, 8338, 8337, 8337, 8338, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa        
  0.001  0.5487684   0.0872293481
  0.002  0.5547058   0.0962851445
  0.005  0.5356218   0.0291722641
  0.010  0.5300959   0.0062334349
  0.020  0.5298799  -0.0002883401
  0.050  0.5309802   0.0000000000

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.002.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

9264 samples
 115 predictor
   2 classes: &#39;-1&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 8338, 8338, 8337, 8337, 8337, 8338, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa       
  0.001  0.5490474   0.086875318
  0.002  0.5518545   0.088752748
  0.005  0.5369167   0.033226245
  0.010  0.5292738   0.002521757
  0.020  0.5293397  -0.001359194
  0.050  0.5309802   0.000000000

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.002.</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>CART 

9264 samples
 115 predictor
   2 classes: &#39;-1&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 8337, 8338, 8337, 8338, 8338, 8338, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa       
  0.001  0.5481878  0.0865871499
  0.002  0.5534993  0.0954359196
  0.005  0.5360530  0.0313589696
  0.010  0.5312820  0.0065490853
  0.020  0.5305481  0.0003187359
  0.050  0.5309802  0.0000000000

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.002.</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h6 id="-"> <a class="anchor-link" href="#-">&#182;</a></h6><p>Best Kappa value is obtained with the minbucket=7 selection so, DOTA2_DT_fit1 will be used. All Kappa values are bad though.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">plot</span><span class="p">(</span><span class="n">DOTA2_DT_fit1</span><span class="o">$</span><span class="n">finalModel</span><span class="p">)</span>
<span class="nf">text</span><span class="p">(</span><span class="n">DOTA2_DT_fit1</span><span class="o">$</span><span class="n">finalModel</span><span class="p">,</span> <span class="n">all</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">cex</span><span class="o">=</span><span class="n">.</span><span class="m">4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 3 - Random Forest</span>

<span class="n">RF_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">mtry</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">10</span><span class="p">))</span> <span class="c1"># default value is 5 I change by both increasing and decreasing</span>
<span class="c1"># RF_control &lt;- trainControl(method = &quot;repeatedcv&quot;, number = n_folds, repeats = 2) </span>
<span class="c1"># repeatedcv tooks so long to compute so I used cv this time and reduced the &quot;mtry&quot; options. </span>
<span class="n">RF_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;cv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">)</span>
<span class="n">DOTA2_RF_fit</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">X.1</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">DOTA2_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;rf&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">RF_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">RF_control</span><span class="p">)</span>
<span class="n">DOTA2_RF_fit</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">DOTA2_RF_fit</span><span class="p">)</span>
<span class="n">DOTA2_RF_fit</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Model 4 - Stochastic Gradient Boosting</span>

<span class="c1"># interaction.depth default is 1 tried 2,3 and 5, n.trees default is 100 I change by both increasing and decreasing, </span>
<span class="c1"># shrinkage default is 0.1 I change by both increasing and decreasing</span>
<span class="n">SGB_grid</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">interaction.depth</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">),</span> <span class="n">n.trees</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">200</span><span class="p">,</span><span class="m">50</span><span class="p">),</span><span class="n">shrinkage</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="m">0.2</span><span class="p">),</span><span class="n">n.minobsinnode</span> <span class="o">=</span><span class="m">10</span><span class="p">)</span>
<span class="c1"># repeatedcv tooks so long to compute so I used cv this time and reduced the &quot;interaction.depth&quot; options.</span>
<span class="c1">#SGB_control &lt;- trainControl(method = &quot;repeatedcv&quot;, number = n_folds, repeats = n_repeats) </span>
<span class="n">SGB_control</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;cv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">)</span>
<span class="n">DOTA2_SGB_fit</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">X.1</span><span class="o">~</span> <span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">DOTA2_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span><span class="s">&quot;gbm&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">SGB_grid</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span><span class="n">SGB_control</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">DOTA2_SGB_fit</span>
<span class="n">DOTA2_SGB_fit</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">###### Accuracy and Kappa values for Each Model on Training Sets</span>

                                     
    <span class="n">Lasso</span> <span class="n">Model</span> <span class="o">--&gt;</span> <span class="n">Accuracy</span> <span class="m">0.5887</span>  <span class="o">--</span>  <span class="n">Kappa</span> <span class="o">--&gt;</span> <span class="m">0.1676</span>

    <span class="n">Decision</span> <span class="n">Tree</span> <span class="n">Model</span>  <span class="o">--&gt;</span> <span class="n">Accuracy</span> <span class="m">0.5547</span>   <span class="n">Kappa</span> <span class="o">--&gt;</span>  <span class="m">0.0963</span>

    <span class="n">Random</span> <span class="n">Forest</span> <span class="n">Model</span>  <span class="o">--&gt;</span> <span class="n">Accuracy</span> <span class="n">N</span><span class="o">/</span><span class="n">A</span>  <span class="n">Kappa</span> <span class="o">--&gt;</span>  <span class="n">N</span><span class="o">/</span><span class="n">A</span>

    <span class="n">Stochastic</span> <span class="n">Gradient</span> <span class="n">Boosting</span> <span class="n">Model</span>  <span class="o">--&gt;</span> <span class="n">Accuracy</span> <span class="n">N</span><span class="o">/</span><span class="n">A</span>  <span class="n">Kappa</span> <span class="o">--&gt;</span>  <span class="n">N</span><span class="o">/</span><span class="n">A</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Lasso Prediction</span>
<span class="n">DOTA2_Lasso_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">DOTA2_lasso_fit</span><span class="p">,</span> <span class="n">DOTA2_test</span><span class="p">)</span>
<span class="n">CM_Lasso</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">DOTA2_Lasso_predict</span><span class="p">,</span> <span class="n">DOTA2_test</span><span class="o">$</span><span class="n">X.1</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_Lasso</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_Lasso</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">Kappa_Lasso</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Kappa&#39;</span><span class="p">]</span>
<span class="n">CM_Lasso</span>
<span class="n">Accuracy_Lasso</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_Lasso</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Kappa_Lasso</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Kappa_Lasso</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">A</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Lasso Model Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_Lasso</span><span class="p">,</span> <span class="s">&quot; and Kappa is&quot;</span><span class="p">,</span> <span class="n">Kappa_Lasso</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction   -1    1
        -1 2223 1506
        1  2122 3413
                                          
               Accuracy : 0.6084          
                 95% CI : (0.5984, 0.6183)
    No Information Rate : 0.531           
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.2072          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.5116          
            Specificity : 0.6938          
         Pos Pred Value : 0.5961          
         Neg Pred Value : 0.6166          
             Prevalence : 0.4690          
         Detection Rate : 0.2400          
   Detection Prevalence : 0.4025          
      Balanced Accuracy : 0.6027          
                                          
       &#39;Positive&#39; Class : -1              
                                          </pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Decision Tree Prediction</span>
<span class="n">DOTA2_DT_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">DOTA2_DT_fit1</span><span class="p">,</span> <span class="n">DOTA2_test</span><span class="p">)</span>
<span class="n">CM_DT</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">DOTA2_DT_predict</span><span class="p">,</span> <span class="n">DOTA2_test</span><span class="o">$</span><span class="n">X.1</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_DT</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_DT</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">Kappa_DT</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Kappa&#39;</span><span class="p">]</span>
<span class="n">CM_DT</span>
<span class="n">Accuracy_DT</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_DT</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Kappa_DT</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Kappa_DT</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">B</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Decision Tree Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_DT</span><span class="p">,</span> <span class="s">&quot; and Kappa is&quot;</span><span class="p">,</span> <span class="n">Kappa_DT</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Confusion Matrix and Statistics

          Reference
Prediction   -1    1
        -1 1961 1510
        1  2384 3409
                                          
               Accuracy : 0.5797          
                 95% CI : (0.5695, 0.5897)
    No Information Rate : 0.531           
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.1461          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.4513          
            Specificity : 0.6930          
         Pos Pred Value : 0.5650          
         Neg Pred Value : 0.5885          
             Prevalence : 0.4690          
         Detection Rate : 0.2117          
   Detection Prevalence : 0.3747          
      Balanced Accuracy : 0.5722          
                                          
       &#39;Positive&#39; Class : -1              
                                          </pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Random Forest Prediction</span>
<span class="n">DOTA2_RF_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">DOTA2_RF_fit</span><span class="p">,</span> <span class="n">DOTA2_test</span><span class="p">)</span>
<span class="n">CM_RF</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">News_RF_predict</span><span class="p">,</span> <span class="n">DOTA2_test</span><span class="o">$</span><span class="n">X.1</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_RF</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_RF</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">Kappa_RF</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Kappa&#39;</span><span class="p">]</span>
<span class="n">CM_RF</span>
<span class="n">Accuracy_RF</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Kappa_RF</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Kappa_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">C</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Random Forest Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_RF</span><span class="p">,</span> <span class="s">&quot; and Kappa is&quot;</span><span class="p">,</span> <span class="n">Kappa_RF</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Stochastic Gradient Boosting Prediction</span>
<span class="n">DOTA2_SGB_predict</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">DOTA2_SGB_fit</span><span class="p">,</span> <span class="n">DOTA2_test</span><span class="p">)</span>
<span class="n">DOTA2_SGB</span> <span class="o">&lt;-</span> <span class="nf">confusionMatrix</span><span class="p">(</span><span class="n">DOTA2_SGB_predict</span><span class="p">,</span> <span class="n">DOTA2_test</span><span class="o">$</span><span class="n">X.1</span><span class="p">)</span>
<span class="n">overall</span> <span class="o">&lt;-</span> <span class="n">CM_SGB</span><span class="o">$</span><span class="n">overall</span>
<span class="n">Accuracy_SGB</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">Kappa_SGB</span> <span class="o">&lt;-</span> <span class="n">overall</span><span class="p">[</span><span class="s">&#39;Kappa&#39;</span><span class="p">]</span>
<span class="n">CM_SGB</span>
<span class="n">Accuracy_SGB</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Accuracy_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">Kappa_SGB</span> <span class="o">&lt;-</span> <span class="nf">round</span><span class="p">(</span><span class="n">Kappa_RF</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="n">D</span> <span class="o">&lt;-</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Stochastic Gradient Boosting Test Accuracy is&quot;</span><span class="p">,</span> <span class="n">Accuracy_SGB</span><span class="p">,</span> <span class="s">&quot; and Kappa is&quot;</span><span class="p">,</span> <span class="n">Kappa_SGB</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[1] &#34;Lasso Model Test Accuracy is 0.6084  and Kappa is 0.2072&#34;
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[1] &#34;Decision Tree Test Accuracy is 0.5797  and Kappa is 0.1461&#34;
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="Comments">Comments<a class="anchor-link" href="#Comments">&#182;</a></h5><p>Overall our accuracy and Kappa values are low no matter what model is chosen. Our accuracy is around %50 which is almost equal to random. Pre-processing the data might be helpful. Also the data may not be suitable for selected models or parameters.</p>
<p>Our prediction accuracies are around %60 and Kappa values are between 0.15 and 0.20. Lasso Model gave better results.</p>
<p>Working on Random Forest and Stochastic Gradient Boosting but could not able to finish them on time.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
</body>







</html>

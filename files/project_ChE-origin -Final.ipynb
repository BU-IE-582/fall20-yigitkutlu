{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used libraries\n",
    "library(data.table)\n",
    "library(Matrix)\n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(glmnet)\n",
    "library(caret)\n",
    "library(rpart)\n",
    "library(randomForest)\n",
    "library(e1071)\n",
    "library(gbm)\n",
    "library(DMwR)\n",
    "library(ROSE)\n",
    "library(pROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_train <- read.csv(\"IE582_Fall20_ProjectTrain.csv\")\n",
    "project_test <- read.csv(\"IE582_Fall20_ProjectTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing no variance data\n",
    "project_train2 <- project_train[!names(project_train) %in% c(\"x18\", \"x37\", \"x50\", \"x52\", \"x57\")] \n",
    "project_test2 <- project_test[!names(project_test) %in% c(\"x18\", \"x37\", \"x50\", \"x52\", \"x57\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight calculations for weighted trainings (0.5 values are modified)\n",
    "model_weights <- ifelse(project_train$y == \"a\",\n",
    "                        (1/table(project_train$y)[1]) * 0.5,\n",
    "                        (1/table(project_train$y)[2]) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model - Lasso Regression\n",
    "set.seed(666)\n",
    "lambda_seq = c(seq(0,0.01,by=0.0001)) #wide range for lambda\n",
    "n_repeats=5\n",
    "n_folds=10\n",
    "lasso_grid = expand.grid(alpha=1,lambda=lambda_seq)\n",
    "lasso_control=trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary, method = \"repeatedcv\", number = n_folds, repeats = n_repeats)                        \n",
    "project_lasso_fit = train(y~ .,data=project_train2, method = \"glmnet\", weights = model_weights, metric = 'ROC', tuneGrid = lasso_grid,trControl = lasso_control) \n",
    "project_lasso_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model - Decision Trees\n",
    "\n",
    "set.seed(666)\n",
    "\n",
    "DT_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary, method = \"repeatedcv\", number = n_folds, repeats = n_repeats) \n",
    "DT_grid <- expand.grid(cp=c(0.0005,0.01,0.05,0.005,0.001,0.007)) # cp grid parameters are changed each time\n",
    "\n",
    "# minbucket is tried manually \n",
    "project_DT_fit1 <- train(y~ .,data=project_train2, method =\"rpart\", weights = model_weights, metric = 'ROC',tuneGrid = DT_grid, trControl=DT_control, control = rpart.control(minbucket=10))\n",
    "project_DT_fit2 <- train(y~ .,data=project_train2, method =\"rpart\", weights = model_weights, metric = 'ROC',tuneGrid = DT_grid, trControl=DT_control, control = rpart.control(minbucket=8))\n",
    "project_DT_fit3 <- train(y~ .,data=project_train2, method =\"rpart\", weights = model_weights, metric = 'ROC',tuneGrid = DT_grid, trControl=DT_control, control = rpart.control(minbucket=12))\n",
    "\n",
    "project_DT_fit1\n",
    "project_DT_fit2\n",
    "project_DT_fit3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model - Random Forest - weighted\n",
    "set.seed(666)\n",
    "RF_grid <- expand.grid(mtry = c(7)) #parameters are changed each time\n",
    "n_repeats=5\n",
    "n_folds=10\n",
    "RF_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats) \n",
    "project_RF_fit <- train(y~ .,data=project_train2, method =\"rf\", weights = model_weights, metric = 'ROC',tuneGrid = RF_grid, trControl=RF_control)\n",
    "project_RF_fit\n",
    "project_RF_fit$finalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model - Random Forest - up smote down\n",
    "set.seed(666)\n",
    "RF_grid <- expand.grid(mtry = c(3,5,7)) #parameters are changed each time\n",
    "n_repeats=5\n",
    "n_folds=10\n",
    "RF_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats, sampling = \"up\")\n",
    "#RF_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats, sampling = \"smote\")\n",
    "#RF_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats, sampling = \"rose\")\n",
    "project_RF_fit <- train(y~ .,data=project_train2, method =\"rf\", metric = 'ROC',tuneGrid = RF_grid, trControl=RF_control)\n",
    "project_RF_fit\n",
    "project_RF_fit$finalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model - Random Forest - ROSE sampling\n",
    "set.seed(666)\n",
    "RF_grid <- expand.grid(mtry = c(7)) #parameters are changed each time\n",
    "n_repeats=5\n",
    "n_folds=10\n",
    "RF_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats, sampling = \"rose\") \n",
    "project_RF_fit <- train(y~ .,data=project_train2, method =\"rf\", metric = 'ROC',tuneGrid = RF_grid, trControl=RF_control)\n",
    "project_RF_fit\n",
    "project_RF_fit$finalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model - SGB weighted \n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "n_repeats=5\n",
    "SGB_grid <- expand.grid(interaction.depth=c(5,7), n.trees = c(400,600,800),shrinkage=c(0.01),n.minobsinnode =c(5,7)) #parameters are changed each time\n",
    "SGB_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats)\n",
    "project_SGB_fit <- train(y~ .,data=project_train2, method =\"gbm\", weights = model_weights, metric = 'ROC',tuneGrid = SGB_grid, trControl=SGB_control)\n",
    "project_SGB_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model - SGB up/down/smote\n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "n_repeats=5\n",
    "SGB_grid <- expand.grid(interaction.depth=c(5,7), n.trees = c(400,600,800),shrinkage=c(0.01),n.minobsinnode =c(5,7)) #parameters are changed each time\n",
    "SGB_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats, sampling = \"up\")\n",
    "#SGB_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats, sampling = \"down\")\n",
    "#SGB_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats, sampling = \"smote\")\n",
    "project_SGB_fit <- train(Class~ .,data=project_train2, method =\"gbm\", metric = 'ROC',tuneGrid = SGB_grid, trControl=SGB_control)\n",
    "project_SGB_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   a    b \n",
       "1565 1565 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  a   b \n",
       "509 509 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creating outside up sampling (or down)\n",
    "set.seed(1)\n",
    "up_train <- upSample(x = project_train2[, -ncol(project_train2)],\n",
    "                     y = project_train2$y)                         \n",
    "table(up_train$Class) \n",
    "\n",
    "down_train <- downSample(x = project_train2[, -ncol(project_train2)],\n",
    "                     y = project_train2$y)                         \n",
    "table(down_train$Class) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model - SGB out up - or down\n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "n_repeats=5\n",
    "SGB_grid <- expand.grid(interaction.depth=c(5,7), n.trees = c(1000),shrinkage=c(0.01),n.minobsinnode =c(5,8)) #parameters are changed each time\n",
    "SGB_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats)\n",
    "project_SGB_fit <- train(Class~ .,data=up_train, method =\"gbm\", metric = 'ROC',tuneGrid = SGB_grid, trControl=SGB_control)\n",
    "#project_SGB_fit <- train(Class~ .,data=up_train, method =\"gbm\", metric = 'ROC',tuneGrid = SGB_grid, trControl=SGB_control)\n",
    "project_SGB_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model - creating smote and rose sampling \n",
    "set.seed(1)\n",
    "smote_train <- SMOTE(y ~ ., data  = project_train2)                         \n",
    "table(smote_train$y) \n",
    "\n",
    "rose_train <- ROSE(y ~ ., data  = project_train2)$data          \n",
    "table(rose_train$y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model - SGB out SMOTE (or ROSE)\n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "n_repeats=5\n",
    "SGB_grid <- expand.grid(interaction.depth=c(5), n.trees = c(600),shrinkage=c(0.01),n.minobsinnode =c(5)) #parameters are changed each time\n",
    "SGB_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats)\n",
    "project_SGB_fit <- train(y~ .,data=smote_train, method =\"gbm\", metric = 'ROC',tuneGrid = SGB_grid, trControl=SGB_control)\n",
    "#project_SGB_fit <- train(y~ .,data=rose_train, method =\"gbm\", metric = 'ROC',tuneGrid = SGB_grid, trControl=SGB_control)\n",
    "project_SGB_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting class predictions\n",
    "pred_prob <- predict(project_SGB_fit, project_test2, type=\"prob\")\n",
    "pred_prob\n",
    "predictions <- pred_prob$b\n",
    "predictions\n",
    "save(predictions, file = \"myvector.rda\") #save predictions as rda file\n",
    "write.csv(predictions, file =\"myfile2.csv\", row.names=FALSE) #save predictions as csv file (personal use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Best Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Model\n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "n_repeats=5\n",
    "SGB_grid <- expand.grid(interaction.depth=c(7), n.trees = c(800),shrinkage=c(0.01),n.minobsinnode =c(5))\n",
    "SGB_control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary,  method = \"repeatedcv\", number = n_folds, repeats = n_repeats)\n",
    "project_SGB_best <- train(Class~ .,data=up_train, method =\"gbm\", metric = 'ROC',tuneGrid = SGB_grid, trControl=SGB_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "3130 samples\n",
       "  55 predictor\n",
       "   2 classes: 'a', 'b' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 2818, 2818, 2817, 2817, 2817, 2817, ... \n",
       "Resampling results:\n",
       "\n",
       "  ROC        Sens       Spec     \n",
       "  0.9316653  0.8174833  0.8886894\n",
       "\n",
       "Tuning parameter 'n.trees' was held constant at a value of 800\n",
       "Tuning\n",
       "\n",
       "Tuning parameter 'shrinkage' was held constant at a value of 0.01\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_SGB_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>var</th><th scope=col>rel.inf</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>x23</th><td>x23        </td><td>29.59791331</td></tr>\n",
       "\t<tr><th scope=row>x30</th><td>x30        </td><td>12.25562644</td></tr>\n",
       "\t<tr><th scope=row>x32</th><td>x32        </td><td>10.60814228</td></tr>\n",
       "\t<tr><th scope=row>x42</th><td>x42        </td><td> 7.22517355</td></tr>\n",
       "\t<tr><th scope=row>x14</th><td>x14        </td><td> 6.21438005</td></tr>\n",
       "\t<tr><th scope=row>x10</th><td>x10        </td><td> 4.99550095</td></tr>\n",
       "\t<tr><th scope=row>x27</th><td>x27        </td><td> 3.65699855</td></tr>\n",
       "\t<tr><th scope=row>x9</th><td>x9         </td><td> 3.59476297</td></tr>\n",
       "\t<tr><th scope=row>x11</th><td>x11        </td><td> 2.57621195</td></tr>\n",
       "\t<tr><th scope=row>x48</th><td>x48        </td><td> 2.43012470</td></tr>\n",
       "\t<tr><th scope=row>x8</th><td>x8         </td><td> 1.64770348</td></tr>\n",
       "\t<tr><th scope=row>x36</th><td>x36        </td><td> 1.63051449</td></tr>\n",
       "\t<tr><th scope=row>x6</th><td>x6         </td><td> 1.54012467</td></tr>\n",
       "\t<tr><th scope=row>x5</th><td>x5         </td><td> 1.45146316</td></tr>\n",
       "\t<tr><th scope=row>x1</th><td>x1         </td><td> 1.14616679</td></tr>\n",
       "\t<tr><th scope=row>x20</th><td>x20        </td><td> 1.09142984</td></tr>\n",
       "\t<tr><th scope=row>x7</th><td>x7         </td><td> 0.99806053</td></tr>\n",
       "\t<tr><th scope=row>x24</th><td>x24        </td><td> 0.97261407</td></tr>\n",
       "\t<tr><th scope=row>x21</th><td>x21        </td><td> 0.60793155</td></tr>\n",
       "\t<tr><th scope=row>x40</th><td>x40        </td><td> 0.54874902</td></tr>\n",
       "\t<tr><th scope=row>x53</th><td>x53        </td><td> 0.49189572</td></tr>\n",
       "\t<tr><th scope=row>x54</th><td>x54        </td><td> 0.46108102</td></tr>\n",
       "\t<tr><th scope=row>x19</th><td>x19        </td><td> 0.39329533</td></tr>\n",
       "\t<tr><th scope=row>x31</th><td>x31        </td><td> 0.31666492</td></tr>\n",
       "\t<tr><th scope=row>x45</th><td>x45        </td><td> 0.29945431</td></tr>\n",
       "\t<tr><th scope=row>x34</th><td>x34        </td><td> 0.28797960</td></tr>\n",
       "\t<tr><th scope=row>x38</th><td>x38        </td><td> 0.28111087</td></tr>\n",
       "\t<tr><th scope=row>x3</th><td>x3         </td><td> 0.27357766</td></tr>\n",
       "\t<tr><th scope=row>x15</th><td>x15        </td><td> 0.22432679</td></tr>\n",
       "\t<tr><th scope=row>x39</th><td>x39        </td><td> 0.19248672</td></tr>\n",
       "\t<tr><th scope=row>x16</th><td>x16        </td><td> 0.16859546</td></tr>\n",
       "\t<tr><th scope=row>x51</th><td>x51        </td><td> 0.16840824</td></tr>\n",
       "\t<tr><th scope=row>x58</th><td>x58        </td><td> 0.15152490</td></tr>\n",
       "\t<tr><th scope=row>x44</th><td>x44        </td><td> 0.14897126</td></tr>\n",
       "\t<tr><th scope=row>x2</th><td>x2         </td><td> 0.12967660</td></tr>\n",
       "\t<tr><th scope=row>x56</th><td>x56        </td><td> 0.12877085</td></tr>\n",
       "\t<tr><th scope=row>x12</th><td>x12        </td><td> 0.12108701</td></tr>\n",
       "\t<tr><th scope=row>x17</th><td>x17        </td><td> 0.11127367</td></tr>\n",
       "\t<tr><th scope=row>x41</th><td>x41        </td><td> 0.11063123</td></tr>\n",
       "\t<tr><th scope=row>x25</th><td>x25        </td><td> 0.10558963</td></tr>\n",
       "\t<tr><th scope=row>x29</th><td>x29        </td><td> 0.10232459</td></tr>\n",
       "\t<tr><th scope=row>x4</th><td>x4         </td><td> 0.09206710</td></tr>\n",
       "\t<tr><th scope=row>x13</th><td>x13        </td><td> 0.07763491</td></tr>\n",
       "\t<tr><th scope=row>x47</th><td>x47        </td><td> 0.07664543</td></tr>\n",
       "\t<tr><th scope=row>x28</th><td>x28        </td><td> 0.07255025</td></tr>\n",
       "\t<tr><th scope=row>x55</th><td>x55        </td><td> 0.06989806</td></tr>\n",
       "\t<tr><th scope=row>x33</th><td>x33        </td><td> 0.06339482</td></tr>\n",
       "\t<tr><th scope=row>x35</th><td>x35        </td><td> 0.03406361</td></tr>\n",
       "\t<tr><th scope=row>x22</th><td>x22        </td><td> 0.02957700</td></tr>\n",
       "\t<tr><th scope=row>x43</th><td>x43        </td><td> 0.02006222</td></tr>\n",
       "\t<tr><th scope=row>x46</th><td>x46        </td><td> 0.00578788</td></tr>\n",
       "\t<tr><th scope=row>x26</th><td>x26        </td><td> 0.00000000</td></tr>\n",
       "\t<tr><th scope=row>x49</th><td>x49        </td><td> 0.00000000</td></tr>\n",
       "\t<tr><th scope=row>x59</th><td>x59        </td><td> 0.00000000</td></tr>\n",
       "\t<tr><th scope=row>x60</th><td>x60        </td><td> 0.00000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & var & rel.inf\\\\\n",
       "\\hline\n",
       "\tx23 & x23         & 29.59791331\\\\\n",
       "\tx30 & x30         & 12.25562644\\\\\n",
       "\tx32 & x32         & 10.60814228\\\\\n",
       "\tx42 & x42         &  7.22517355\\\\\n",
       "\tx14 & x14         &  6.21438005\\\\\n",
       "\tx10 & x10         &  4.99550095\\\\\n",
       "\tx27 & x27         &  3.65699855\\\\\n",
       "\tx9 & x9          &  3.59476297\\\\\n",
       "\tx11 & x11         &  2.57621195\\\\\n",
       "\tx48 & x48         &  2.43012470\\\\\n",
       "\tx8 & x8          &  1.64770348\\\\\n",
       "\tx36 & x36         &  1.63051449\\\\\n",
       "\tx6 & x6          &  1.54012467\\\\\n",
       "\tx5 & x5          &  1.45146316\\\\\n",
       "\tx1 & x1          &  1.14616679\\\\\n",
       "\tx20 & x20         &  1.09142984\\\\\n",
       "\tx7 & x7          &  0.99806053\\\\\n",
       "\tx24 & x24         &  0.97261407\\\\\n",
       "\tx21 & x21         &  0.60793155\\\\\n",
       "\tx40 & x40         &  0.54874902\\\\\n",
       "\tx53 & x53         &  0.49189572\\\\\n",
       "\tx54 & x54         &  0.46108102\\\\\n",
       "\tx19 & x19         &  0.39329533\\\\\n",
       "\tx31 & x31         &  0.31666492\\\\\n",
       "\tx45 & x45         &  0.29945431\\\\\n",
       "\tx34 & x34         &  0.28797960\\\\\n",
       "\tx38 & x38         &  0.28111087\\\\\n",
       "\tx3 & x3          &  0.27357766\\\\\n",
       "\tx15 & x15         &  0.22432679\\\\\n",
       "\tx39 & x39         &  0.19248672\\\\\n",
       "\tx16 & x16         &  0.16859546\\\\\n",
       "\tx51 & x51         &  0.16840824\\\\\n",
       "\tx58 & x58         &  0.15152490\\\\\n",
       "\tx44 & x44         &  0.14897126\\\\\n",
       "\tx2 & x2          &  0.12967660\\\\\n",
       "\tx56 & x56         &  0.12877085\\\\\n",
       "\tx12 & x12         &  0.12108701\\\\\n",
       "\tx17 & x17         &  0.11127367\\\\\n",
       "\tx41 & x41         &  0.11063123\\\\\n",
       "\tx25 & x25         &  0.10558963\\\\\n",
       "\tx29 & x29         &  0.10232459\\\\\n",
       "\tx4 & x4          &  0.09206710\\\\\n",
       "\tx13 & x13         &  0.07763491\\\\\n",
       "\tx47 & x47         &  0.07664543\\\\\n",
       "\tx28 & x28         &  0.07255025\\\\\n",
       "\tx55 & x55         &  0.06989806\\\\\n",
       "\tx33 & x33         &  0.06339482\\\\\n",
       "\tx35 & x35         &  0.03406361\\\\\n",
       "\tx22 & x22         &  0.02957700\\\\\n",
       "\tx43 & x43         &  0.02006222\\\\\n",
       "\tx46 & x46         &  0.00578788\\\\\n",
       "\tx26 & x26         &  0.00000000\\\\\n",
       "\tx49 & x49         &  0.00000000\\\\\n",
       "\tx59 & x59         &  0.00000000\\\\\n",
       "\tx60 & x60         &  0.00000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | var | rel.inf |\n",
       "|---|---|---|\n",
       "| x23 | x23         | 29.59791331 |\n",
       "| x30 | x30         | 12.25562644 |\n",
       "| x32 | x32         | 10.60814228 |\n",
       "| x42 | x42         |  7.22517355 |\n",
       "| x14 | x14         |  6.21438005 |\n",
       "| x10 | x10         |  4.99550095 |\n",
       "| x27 | x27         |  3.65699855 |\n",
       "| x9 | x9          |  3.59476297 |\n",
       "| x11 | x11         |  2.57621195 |\n",
       "| x48 | x48         |  2.43012470 |\n",
       "| x8 | x8          |  1.64770348 |\n",
       "| x36 | x36         |  1.63051449 |\n",
       "| x6 | x6          |  1.54012467 |\n",
       "| x5 | x5          |  1.45146316 |\n",
       "| x1 | x1          |  1.14616679 |\n",
       "| x20 | x20         |  1.09142984 |\n",
       "| x7 | x7          |  0.99806053 |\n",
       "| x24 | x24         |  0.97261407 |\n",
       "| x21 | x21         |  0.60793155 |\n",
       "| x40 | x40         |  0.54874902 |\n",
       "| x53 | x53         |  0.49189572 |\n",
       "| x54 | x54         |  0.46108102 |\n",
       "| x19 | x19         |  0.39329533 |\n",
       "| x31 | x31         |  0.31666492 |\n",
       "| x45 | x45         |  0.29945431 |\n",
       "| x34 | x34         |  0.28797960 |\n",
       "| x38 | x38         |  0.28111087 |\n",
       "| x3 | x3          |  0.27357766 |\n",
       "| x15 | x15         |  0.22432679 |\n",
       "| x39 | x39         |  0.19248672 |\n",
       "| x16 | x16         |  0.16859546 |\n",
       "| x51 | x51         |  0.16840824 |\n",
       "| x58 | x58         |  0.15152490 |\n",
       "| x44 | x44         |  0.14897126 |\n",
       "| x2 | x2          |  0.12967660 |\n",
       "| x56 | x56         |  0.12877085 |\n",
       "| x12 | x12         |  0.12108701 |\n",
       "| x17 | x17         |  0.11127367 |\n",
       "| x41 | x41         |  0.11063123 |\n",
       "| x25 | x25         |  0.10558963 |\n",
       "| x29 | x29         |  0.10232459 |\n",
       "| x4 | x4          |  0.09206710 |\n",
       "| x13 | x13         |  0.07763491 |\n",
       "| x47 | x47         |  0.07664543 |\n",
       "| x28 | x28         |  0.07255025 |\n",
       "| x55 | x55         |  0.06989806 |\n",
       "| x33 | x33         |  0.06339482 |\n",
       "| x35 | x35         |  0.03406361 |\n",
       "| x22 | x22         |  0.02957700 |\n",
       "| x43 | x43         |  0.02006222 |\n",
       "| x46 | x46         |  0.00578788 |\n",
       "| x26 | x26         |  0.00000000 |\n",
       "| x49 | x49         |  0.00000000 |\n",
       "| x59 | x59         |  0.00000000 |\n",
       "| x60 | x60         |  0.00000000 |\n",
       "\n"
      ],
      "text/plain": [
       "    var rel.inf    \n",
       "x23 x23 29.59791331\n",
       "x30 x30 12.25562644\n",
       "x32 x32 10.60814228\n",
       "x42 x42  7.22517355\n",
       "x14 x14  6.21438005\n",
       "x10 x10  4.99550095\n",
       "x27 x27  3.65699855\n",
       "x9  x9   3.59476297\n",
       "x11 x11  2.57621195\n",
       "x48 x48  2.43012470\n",
       "x8  x8   1.64770348\n",
       "x36 x36  1.63051449\n",
       "x6  x6   1.54012467\n",
       "x5  x5   1.45146316\n",
       "x1  x1   1.14616679\n",
       "x20 x20  1.09142984\n",
       "x7  x7   0.99806053\n",
       "x24 x24  0.97261407\n",
       "x21 x21  0.60793155\n",
       "x40 x40  0.54874902\n",
       "x53 x53  0.49189572\n",
       "x54 x54  0.46108102\n",
       "x19 x19  0.39329533\n",
       "x31 x31  0.31666492\n",
       "x45 x45  0.29945431\n",
       "x34 x34  0.28797960\n",
       "x38 x38  0.28111087\n",
       "x3  x3   0.27357766\n",
       "x15 x15  0.22432679\n",
       "x39 x39  0.19248672\n",
       "x16 x16  0.16859546\n",
       "x51 x51  0.16840824\n",
       "x58 x58  0.15152490\n",
       "x44 x44  0.14897126\n",
       "x2  x2   0.12967660\n",
       "x56 x56  0.12877085\n",
       "x12 x12  0.12108701\n",
       "x17 x17  0.11127367\n",
       "x41 x41  0.11063123\n",
       "x25 x25  0.10558963\n",
       "x29 x29  0.10232459\n",
       "x4  x4   0.09206710\n",
       "x13 x13  0.07763491\n",
       "x47 x47  0.07664543\n",
       "x28 x28  0.07255025\n",
       "x55 x55  0.06989806\n",
       "x33 x33  0.06339482\n",
       "x35 x35  0.03406361\n",
       "x22 x22  0.02957700\n",
       "x43 x43  0.02006222\n",
       "x46 x46  0.00578788\n",
       "x26 x26  0.00000000\n",
       "x49 x49  0.00000000\n",
       "x59 x59  0.00000000\n",
       "x60 x60  0.00000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAATlBMVEUAAAAAAP8AHP8AOf8A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\nRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#summary of final model - most influencing parameters\n",
    "summary(\n",
    " project_SGB_best$finalModel, \n",
    "  cBars = 10,\n",
    "  method = relative.influence, # also can use permutation.test.gbm\n",
    "  las = 2\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
